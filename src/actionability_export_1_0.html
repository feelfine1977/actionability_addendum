<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Integrated Exploration of Data-Intensive Business Processes [Extended Abstract]  </p>

<p>Authors: Carlo Combi, Barbara Oliboni, Francesca Zerbato  </p>

<p>DOI: 10.1109/SERVICES55459.2022.00038  </p>

<p>Year: 2022  </p>

<p>Publication Type: Conference (Extended Abstract)  </p>

<p>Discipline/Domain: Computer Science / Business Process Management  </p>

<p>Subdomain/Topic: Data-aware business process modeling and analysis  </p>

<p>Eligibility: Not Eligible  </p>

<p>Overall Relevance Score: 20 — Mentions “insights” and “support for process (re-)design and improvement” but does not frame these in terms of actionability or define conditions for being actionable.  </p>

<p>Operationalization Score: 30 — Operational methods are detailed (Activity View, queries, algorithms) but not linked to an explicit notion of actionability.  </p>

<p>Actionable/Actionability Used in Paper: No  </p>

<p>Authors Argue for Need for Actionability Without Defining It: No  </p>

<p>Contains Definition of Actionability: No  </p>

<p>Contains Systematic Features/Dimensions: No  </p>

<p>Contains Explainability: No  </p>

<p>Contains Interpretability: No  </p>

<p>Contains Framework/Model: Yes — Activity View, complex value schema, process–data integration algorithm.  </p>

<p>Operationalization Present: Yes — Operational queries and algorithms for integrated process-data analysis.  </p>

<p>Primary Methodology: Conceptual + Controlled Experiment + Proof-of-Concept Implementation  </p>

<p>Study Context: Data-intensive business processes with BPMN models linked to conceptual database schemas.  </p>

<p>Geographic/Institutional Context: University of Verona, Italy; University of St. Gallen, Switzerland.  </p>

<p>Target Users/Stakeholders: Process modelers, analysts.  </p>

<p>Primary Contribution Type: Conceptual framework and analysis method.  </p>

<p>CL: No  </p>

<p>CR: No  </p>

<p>FE: No  </p>

<p>TI: No  </p>

<p>EX: No  </p>

<p>GA: No  </p>

<p>Reason if Not Eligible: The paper focuses on process–data integration for analysis and improvement, without conceptualizing or defining “actionability” or related properties; “insights” are not framed in actionable terms.  </p>

<!--META_END-->

<p><strong>Title:</strong> Integrated Exploration of Data-Intensive Business Processes [Extended Abstract]  </p>

<p><strong>Authors:</strong> Carlo Combi, Barbara Oliboni, Francesca Zerbato  </p>

<p><strong>DOI:</strong> 10.1109/SERVICES55459.2022.00038  </p>

<p><strong>Year:</strong> 2022  </p>

<p><strong>Publication Type:</strong> Conference (Extended Abstract)  </p>

<p><strong>Discipline/Domain:</strong> Computer Science / Business Process Management  </p>

<p><strong>Subdomain/Topic:</strong> Data-aware business process modeling and analysis  </p>

<p><strong>Contextual Background:</strong> The paper extends previous work on integrating process and data models to better support the analysis of data-intensive business processes, leveraging BPMN and conceptual database schemas.  </p>

<p><strong>Geographic/Institutional Context:</strong> University of Verona (Italy); University of St. Gallen (Switzerland)  </p>

<p><strong>Target Users/Stakeholders:</strong> Business process modelers and analysts.  </p>

<p><strong>Primary Methodology:</strong> Conceptual + Controlled Experiment + Proof-of-Concept Implementation  </p>

<p><strong>Primary Contribution Type:</strong> Conceptual framework, operational queries, and algorithm.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This extended abstract summarizes a framework for the conceptual modeling and design-time analysis of data operations within business processes. The authors propose a uniform formal representation that integrates BPMN process models, conceptual database schemas, and the operations performed by processes on these databases. The approach is centered on the “Activity View,” which depicts the parts of a database schema accessed by each process activity and the operations performed. An algorithm identifies structural relations between activities (sequential, exclusive, parallel) and supports formal queries to answer four defined information needs concerning data usage. The approach was evaluated through a controlled experiment with 33 participants, demonstrating improved comprehension of integrated process–data models, and via a proof-of-concept implementation for both relational and XML databases.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No — The paper discusses “insights” and “support” for process redesign but does not use or define “actionable,” “actionability,” or related terms.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No — The focus is on data–process integration for improved analysis, not on actionability as a concept.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A — While operationalization is present for process–data analysis, it is not tied to a notion of being actionable.</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> No  </p></li>
<li><p><strong>FE (Feasibility):</strong> No  </p></li>
<li><p><strong>TI (Timeliness):</strong> No  </p></li>
<li><p><strong>EX (Explainability):</strong> No  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> No  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Activity View concept  </p></li>
<li><p>BPMN process modeling  </p></li>
<li><p>Conceptual database schema design</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p>N/A</p>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The authors build on prior research linking BPMN processes and data models, highlighting limited support for the data perspective in process modeling languages and proposing an integrated approach to address this.</p>

<hr />

<h2>Summary</h2>

<p>This extended abstract outlines a framework for the integrated exploration of business processes and their associated data models. Using a unified formal representation that connects BPMN processes with conceptual database schemas, the approach supports formal querying to address specific informational needs, such as identifying identical data operations, data usage along and across process paths, and concurrent access. The Activity View serves as the central construct, enabling clearer understanding of how process activities interact with data. Evaluation included a controlled experiment, showing improved comprehension of integrated process–data models, and a proof-of-concept demonstrating applicability to both relational and XML databases. While the work offers practical analytical methods, it does not conceptualize or define “actionability” or present conditions that make insights actionable, focusing instead on enhancing process–data integration for analysis and improvement.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 20 — The work’s “insights” and “support” could indirectly relate to actionability, but no definition, conceptualization, or explicit link is provided.  </p></li>
<li><p><strong>Operationalization Score:</strong> 30 — Operational methods (Activity View, queries, algorithms) are well described but not linked to an actionable framework.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“...we show how such a formal model can be queried to obtain insights into the informational perspective of business process models and, in turn, support process modelers and analysts in reasoning about process (re-) design and improvement.” (p. 1)  </p></li>
<li><p>“The Activity View... improves the comprehension of conceptual models of integrated processes and data.” (p. 1)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Actionable Knowledge Discovery for Increasing Enterprise Profit, Using Domain Driven-Data Mining</p>

<p>Authors: Rakhi Batra; M. Abdul Rehman</p>

<p>DOI: 10.1109/ACCESS.2019.2959841</p>

<p>Year: 2019</p>

<p>Publication Type: Journal (IEEE Access)</p>

<p>Discipline/Domain: Data Mining / Knowledge Discovery</p>

<p>Subdomain/Topic: Actionable Knowledge Discovery (AKD); Domain-Driven Data Mining (D3M); Post-processing Decision Trees; Profit-centric action rules</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 86</p>

<p>Operationalization Score: 78</p>

<p>Actionable/Actionability Used in Paper: Yes — “Actionability is an important subjective interestingness measure… a pattern is interesting or actionable if the user can do something about it to his or her advantage.” (p. 3) “Actionable Knowledge… transforms the knowledge into business-friendly actions that are both concrete and profitable to decision-makers.” (p. 1) :contentReference[oaicite:0]{index=0}</p>

<p>Authors Argue for Need for Actionability Without Defining It: No — They provide an explicit conceptualization and operational framing (Two-way Significance framework). (pp. 2–3) :contentReference[oaicite:1]{index=1}</p>

<p>Contains Definition of Actionability: Yes — “a pattern is interesting or actionable if the user can do something about it to his or her advantage.” (p. 3) :contentReference[oaicite:2]{index=2}</p>

<p>Contains Systematic Features/Dimensions: Yes — Objective/Subjective Technical &amp; Objective/Subjective Business interestingness (“Two-way Significance”). (p. 2) :contentReference[oaicite:3]{index=3}</p>

<p>Contains Explainability: Partial — uses decision-tree rules and pruned rule paths; not framed explicitly as explainability. (pp. 6–8) :contentReference[oaicite:4]{index=4}</p>

<p>Contains Interpretability: Partial — rule-based decision paths from C4.5 aid interpretability. (pp. 6–8) :contentReference[oaicite:5]{index=5}</p>

<p>Contains Framework/Model: Yes — Two-way Significance formalization; tightly/loosely coupled AKD frameworks; workflow (Fig. 3); action-generation algorithm (Fig. 8). (pp. 2–3, 3, 6, 8–9) :contentReference[oaicite:6]{index=6}</p>

<p>Operationalization Present: Yes — cost matrices, expected profit, probability gain, pruning, algorithmic steps, correlation checks. (pp. 6–9) :contentReference[oaicite:7]{index=7}</p>

<p>Primary Methodology: Conceptual + Quantitative experiments (comparative evaluation on UCI datasets)</p>

<p>Study Context: CRM/HR illustrative use-case; evaluation on German/Australian credit, Adult Income, IBM HR datasets. (pp. 6, 10–12) :contentReference[oaicite:8]{index=8}</p>

<p>Geographic/Institutional Context: Sukkur IBA University, Pakistan (authors’ affiliation). (p. 1) :contentReference[oaicite:9]{index=9}</p>

<p>Target Users/Stakeholders: Business decision-makers, CRM managers, HR analysts, BI practitioners. (pp. 1–2, 6) :contentReference[oaicite:10]{index=10}</p>

<p>Primary Contribution Type: Method/Algorithm + Evaluation (search-space reduction for action extraction with domain knowledge)</p>

<p>CL: Partial</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Partial</p>

<p>EX: Partial</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Actionable Knowledge Discovery for Increasing Enterprise Profit, Using Domain Driven-Data Mining</p>

<p><strong>Authors:</strong>  </p>

<p>Rakhi Batra; M. Abdul Rehman</p>

<p><strong>DOI:</strong>  </p>

<p>10.1109/ACCESS.2019.2959841</p>

<p><strong>Year:</strong>  </p>

<p>2019</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal (IEEE Access)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Data Mining / Knowledge Discovery</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Actionable Knowledge Discovery (AKD); Domain-Driven Data Mining (D3M); Decision-tree post-processing; Profit-aware action rules</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper critiques data-centric mining for overlooking business constraints (cost/profit) and proposes AKD within D3M to convert patterns into profit-oriented actions. (pp. 1–2) :contentReference[oaicite:11]{index=11}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Sukkur IBA University, Pakistan. (p. 1) :contentReference[oaicite:12]{index=12}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Decision-makers in CRM/BI/HR seeking profitable, implementable actions. (pp. 1–2, 6) :contentReference[oaicite:13]{index=13}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework + algorithmic method; quantitative comparison against Yang (2007) and OF‑CEAMA on UCI datasets. (pp. 10–12) :contentReference[oaicite:14]{index=14}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>An action-generation method that prunes negative-class leaves, uses domain knowledge (flexible/stable attributes, cost matrices, expected profit), and maximizes net profit. (pp. 6–9) :contentReference[oaicite:15]{index=15}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors propose a domain-driven AKD method that reduces computation while preserving profit by pruning decision-tree rules to only desired-class leaves and then generating costed actions that move instances from undesirable to desirable states. They formalize business/technical interestingness via a Two-way Significance view, define net profit using expected profit and probability gain minus action costs, and incorporate domain knowledge through flexible vs. stable attributes and cost matrices. A workflow (Fig. 3) guides preprocessing, tree induction (C4.5), domain knowledge setup, and action generation (Fig. 8). Experiments on four UCI datasets show fewer rules considered and significantly less runtime than Yang’s method and OF‑CEAMA, with equal net profit on three datasets and near-equal on HR. (pp. 2–3, 6–12; Fig. 3 p. 6; Fig. 8 p. 9) :contentReference[oaicite:16]{index=16}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>Yes.</strong>  </p>

<ul>
<li><p>“Actionability is an important subjective interestingness measure… a pattern is interesting or actionable if the user can do something about it to his or her advantage.” (p. 3) :contentReference[oaicite:17]{index=17}  </p></li>
<li><p>“Actionable Knowledge… transforms the knowledge into business-friendly actions that are both concrete and profitable to decision-makers.” (p. 1) :contentReference[oaicite:18]{index=18}  </p></li>
<li><p>“Basically, actions suggest how and which attribute values can be changed in order to achieve maximum profit in the corresponding domain.” (p. 3) :contentReference[oaicite:19]{index=19}</p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>No.</strong> They provide both a conceptual grounding (Two-way Significance) and a procedural/algorithmic operationalization. (pp. 2–3, 6–9) :contentReference[oaicite:20]{index=20}</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>“Actionable Knowledge reflects business needs and end-user preferences and helps business people in direct decision making… It transforms the knowledge into business-friendly actions that are both concrete and profitable to decision-makers.” (p. 1)  </p>

<blockquote>
  <p>“a pattern is interesting or actionable if the user can do something about it to his or her advantage.” (p. 3) :contentReference[oaicite:21]{index=21}</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Bidirectional significance (technical + business):</strong>  </p>

<p> &gt; “This framework measures actionability from both technical and business perspectives… Objective/Subjective Technical and Objective/Subjective Business interestingness.” (p. 2) :contentReference[oaicite:22]{index=22}</p></li>
<li><p><strong>Change-oriented, feasible attribute manipulation:</strong>  </p>

<p> &gt; “actions suggest how and which attribute values can be changed in order to achieve maximum profit… Flexible vs Stable attributes.” (p. 3) :contentReference[oaicite:23]{index=23}</p></li>
<li><p><strong>Profit impact (expected profit &amp; probability gain vs cost):</strong>  </p>

<p> &gt; “P<em>net = P</em>e × P<em>gain − Σ Cost</em>i.” (p. 8) :contentReference[oaicite:24]{index=24}</p></li>
<li><p><strong>Domain knowledge alignment:</strong>  </p>

<p> &gt; “selection of Flexible and Stable attributes, cost matrix for Flexible attributes and expected profit… determined by domain experts.” (p. 8) :contentReference[oaicite:25]{index=25}</p></li>
<li><p><strong>Validity with respect to desired class:</strong>  </p>

<p> &gt; pruning negative-class leaves so actions actually move objects to the desired status. (pp. 7–8, 12) :contentReference[oaicite:26]{index=26}</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong>  </p>

<p> Two-way Significance (technical/business); Loosely vs. Tightly Coupled AKD; Proposed D3M-ba</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: A framework for analyzing the relationships between cancer patient satisfaction, nurse care, patient attitude, and nurse attitude in healthcare systems  </p>

<p>Authors: Ng Kim-Soon, Alyaa Idrees Abdulmaged, Salama A. Mostafa, Mazin Abed Mohammed, Fadia Abdalla Musbah, Rabei Raad Ali, Oana Geman  </p>

<p>DOI: https://doi.org/10.1007/s12652-020-02888-x  </p>

<p>Year: 2022  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Healthcare Management / Patient Experience  </p>

<p>Subdomain/Topic: Cancer patient satisfaction, nurse care, attitudes, hospital service quality  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 78  </p>

<p>Operationalization Score: 65  </p>

<p>Contains Definition of Actionability: Yes (implicit — as actionable insights for improving patient satisfaction)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: No  </p>

<p>Contains Interpretability: Partial (through statistical relationships)  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Quantitative  </p>

<p>Study Context: National Cancer Institute, Misurata, Libya — cancer patient treatment satisfaction  </p>

<p>Geographic/Institutional Context: Libya, National Institute of Oncology (Misurata)  </p>

<p>Target Users/Stakeholders: Hospital managers, nurses, healthcare policy makers  </p>

<p>Primary Contribution Type: Empirical framework and statistical analysis  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: No  </p>

<p>TI: No  </p>

<p>EX: No  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>A framework for analyzing the relationships between cancer patient satisfaction, nurse care, patient attitude, and nurse attitude in healthcare systems  </p>

<p><strong>Authors:</strong>  </p>

<p>Ng Kim-Soon, Alyaa Idrees Abdulmaged, Salama A. Mostafa, Mazin Abed Mohammed, Fadia Abdalla Musbah, Rabei Raad Ali, Oana Geman  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1007/s12652-020-02888-x  </p>

<p><strong>Year:</strong>  </p>

<p>2022  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Healthcare Management / Patient Experience  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Cancer patient satisfaction, nurse care, attitudes, hospital service quality  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The study examines how nurse care, nurse attitude, and patient attitude affect cancer patient satisfaction, considering hospital service quality and patient characteristics as control variables. Conducted in Libya’s National Cancer Institute in Misurata, it aims to provide actionable strategies for healthcare managers to enhance service quality for cancer patients.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Libya, National Institute of Oncology (Misurata)  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Hospital managers, nurses, healthcare policy makers  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical framework and statistical analysis  </p>

<h2>General Summary of the Paper</h2>

<p>This paper develops and tests a framework linking cancer patient satisfaction with nurse care, nurse attitude, and patient attitude, while controlling for hospital service quality and patient characteristics. Using a survey of 217 cancer patients, statistical analysis (correlation and multiple regression) revealed that patient attitude had the strongest influence on satisfaction, while nurse care also had a positive relationship. Nurse attitude showed possible but not statistically strong effects. The study identifies key improvement areas, especially enhancing nurse care quality and fostering positive patient attitudes, to provide actionable guidance for hospital managers in improving cancer care services.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>Actionability is understood as producing “actionable insights to improve the healthcare services” by identifying modifiable service factors (nurse care, patient attitudes) that directly influence patient satisfaction, thus guiding healthcare policy and management interventions.</p>

<blockquote>
  <p>“Measuring the level of satisfaction provides actionable insights to improve the healthcare system” (p. 88)  </p>
</blockquote>

<blockquote>
  <p>“It pointed to several important areas to enhance the satisfaction of cancer patients by analyzing the level of nurse care, nurse attitude, and patient attitude” (p. 87)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Identifiable, measurable service quality attributes (tangibility, empathy, responsiveness, reliability, assurance)  </p></li>
<li><p>Modifiable interpersonal and efficiency aspects of nurse care  </p></li>
<li><p>Positive patient attitudes (trust, willingness to engage in treatment discussions, confidence in nurses)  </p></li>
<li><p>Hospital service empathy and responsiveness  </p></li>
<li><p>Alignment of nurse care with patient needs</p></li>
</ul>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Cancer patient satisfaction–nurse care–attitude model  </p></li>
<li><p><strong>Methods/Levers:</strong> Quantitative survey, Likert-scale items on service quality and attitudes  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify satisfaction determinants → Measure through patient surveys → Analyze statistically → Target improvement areas in nurse training and patient engagement  </p></li>
<li><p><strong>Data &amp; Measures:</strong> 5-point Likert scale for nurse care, nurse attitude, patient attitude, service quality; regression and correlation analyses  </p></li>
<li><p><strong>Implementation Context:</strong> National Cancer Institute, Misurata, Libya  </p></li>
</ul>

<blockquote>
  <p>“A comprehensive approach… conceptualized to assess the service quality” (p. 87)  </p>
</blockquote>

<blockquote>
  <p>“Descriptive statistics, correlation, and multiple regression were applied in the analyses” (p. 87)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Clarity in communication and service processes improves satisfaction (linked to nurse and patient attitude measurement items).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Service quality assessment tailored to Libyan cancer care context.  </p></li>
<li><p><strong>FE (Feasibility):</strong> No — No explicit mention of implementation feasibility.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No — Not explicitly linked to being actionable.  </p></li>
<li><p><strong>EX (Explainability):</strong> No — Statistical results are reported but not tied to explainability of interventions.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — Aligns nurse care improvements with patient satisfaction goals.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Empathy, responsiveness, interpersonal skills.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Expectation Confirmation Theory (Oliver, 1980)  </p></li>
<li><p>Theory of Reasoned Action (Fishbein &amp; Ajzen, 1980)  </p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Likert scale scores on nurse care, attitudes, and service quality attributes  </p></li>
<li><p>Beta coefficients from regression analysis indicating strongest predictors of satisfaction  </p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Limited prior research in Libya; patient illness severity limiting survey participation; lower levels of nurse and patient attitude scores.  </p></li>
<li><p><strong>Enablers:</strong> Structured measurement instruments; high reliability (Cronbach’s alpha ≥ 0.70); strong statistical relationships guiding targeted improvement.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>The paper extends existing satisfaction research by jointly considering nurse and patient attitudes alongside nurse care in a developing country oncology context, a gap in prior work which often examined only service quality or patient perceptions.</p>

<h2>Summary</h2>

<p>This study presents a framework linking nurse care, nurse attitude, and patient attitude to cancer patient satisfaction, grounded in expectation confirmation and reasoned action theories. Actionability is framed as identifying measurable, modifiable factors that can guide managerial decisions to enhance service quality. While both nurse care and patient attitude influence satisfaction, patient attitude emerged as the strongest predictor. The study operationalizes actionability via a structured survey, statistical analysis, and a targeted framework for improvement. Notably, contextual relevance and clarity are emphasized, but feasibility, timeliness, and explicit explainability are underdeveloped.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 78 — Strong conceptual link to actionability with systematic features identified, though some dimensions (feasibility, timeliness) absent.  </p></li>
<li><p><strong>Operationalization Score:</strong> 65 — Clear operational steps and statistical testing, but limited discussion of implementation feasibility and continuous monitoring.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Measuring the level of satisfaction provides actionable insights to improve the healthcare system” (p. 88)  </p></li>
<li><p>“It pointed to several important areas to enhance the satisfaction of cancer patients by analyzing the level of nurse care, nurse attitude, and patient attitude” (p. 87)  </p></li>
<li><p>“A comprehensive approach… conceptualized to assess the service quality” (p. 87)  </p></li>
<li><p>“Patient attitude significantly affected cancer patient satisfaction” (p. 98)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Oliver, R.L. (1980) Expectation Confirmation Theory  </p></li>
<li><p>Fishbein, M., &amp; Ajzen, I. (1980) Theory of Reasoned Action  </p></li>
<li><p>Al-Borie &amp; Damanhouri (2013) SERVQUAL analysis in hospitals  </p></li>
<li><p>Kang &amp; Oh (2015) Hospital service quality attributes and satisfaction</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: YarnSense: Automated Data Storytelling for Multimodal Learning Analytics</p>

<p>Authors: Gloria Milena Fernández-Nieto, Vanessa Echeverria, Roberto Martinez-Maldonado, Simon Buckingham Shum</p>

<p>DOI: N/A</p>

<p>Year: 2024</p>

<p>Publication Type: Conference (Workshop Proceedings)</p>

<p>Discipline/Domain: Learning Analytics / Educational Technology</p>

<p>Subdomain/Topic: Automated Data Storytelling, Multimodal Learning Analytics, Nursing Simulation Training</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 88</p>

<p>Operationalization Score: 90</p>

<p>Contains Definition of Actionability: Yes (implicit)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual + Reference Implementation</p>

<p>Study Context: Clinical nursing simulation with 254 students, 6 teachers</p>

<p>Geographic/Institutional Context: Monash University (Australia), University of Technology Sydney, Escuela Superior Politecnica del Litoral (Ecuador)</p>

<p>Target Users/Stakeholders: Students, Teachers, Researchers in education/training</p>

<p>Primary Contribution Type: Architecture &amp; System Implementation</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Yes</p>

<p>EX: Yes</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>YarnSense: Automated Data Storytelling for Multimodal Learning Analytics</p>

<p><strong>Authors:</strong>  </p>

<p>Gloria Milena Fernández-Nieto, Vanessa Echeverria, Roberto Martinez-Maldonado, Simon Buckingham Shum</p>

<p><strong>DOI:</strong>  </p>

<p>N/A</p>

<p><strong>Year:</strong>  </p>

<p>2024</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference (Workshop Proceedings)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Learning Analytics / Educational Technology</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Automated Data Storytelling, Multimodal Learning Analytics, Nursing Simulation Training</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the challenge of making complex multimodal learning analytics data interpretable and actionable for students and teachers. The focus is on automated data storytelling (DS) in immersive, high-stakes training scenarios, exemplified by nursing simulations, to support reflective learning and performance improvement.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Monash University (Australia), University of Technology Sydney (Australia), Escuela Superior Politecnica del Litoral (Ecuador)</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Students, Teachers, Educational Researchers</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual architecture development with in-the-wild reference implementation</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>System architecture + case study</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors present <em>YarnSense</em>, a multi-tier architecture for automatically generating educational data stories from multimodal behavioural data collected via wearable and environmental sensors, combined with teacher-defined pedagogical intentions. The aim is to transform raw sensor data into contextualised, interpretable, and pedagogically aligned narratives for student reflection. The architecture consists of: (1) a context modeller for teachers to define learning activities and assessment criteria; (2) a multimodal sensor data capture system; (3) multimodal modelling to generate learner models; and (4) a data storytelling generator combining visualisations and narratives. The system is demonstrated in large-scale nursing simulations with 254 students, producing automated feedback on errors and teamwork patterns. The paper discusses design considerations, alignment with learning theories, and potential future enhancements including LLM-based narrative generation.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is framed implicitly as the ability of multimodal data outputs to <strong>support reflection, identify performance gaps, and align with pedagogical intentions</strong> so students can meaningfully improve.</p>

<blockquote>
  <p>“Based on the notion of data storytelling as a means of extracting actionable insights from data…” (Abstract)  </p>
</blockquote>

<blockquote>
  <p>“…weaving complex data into coherent narratives that align with the teacher’s pedagogical intentions” (p. 9)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Alignment with teacher’s pedagogical intentions and learning design</p></li>
<li><p>Translation of raw sensor data into meaningful constructs</p></li>
<li><p>Integration of contextual knowledge (roles, resources, assessment criteria)</p></li>
<li><p>Clear visual and narrative presentation to non-experts</p></li>
<li><p>Timely delivery to support post-activity reflection</p></li>
<li><p>Inclusion of error detection and performance feedback linked to guidelines</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> YarnSense Architecture  </p></li>
<li><p><strong>Methods/Levers:</strong> Pedagogical rule definition, sensor-based multimodal data capture, QE modelling, automated narrative &amp; visual generation  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Teachers define learning context &amp; pedagogical intentions (Context Modeller)  </p>

<p> 2. Collect multimodal data from machine and human sensing  </p>

<p> 3. Transform into learner models via multimodal matrices and QE modelling  </p>

<p> 4. Generate DS outputs combining data, visuals, and teacher feedback  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Positioning data, physiological data, audio/video, logged actions  </p></li>
<li><p><strong>Implementation Context:</strong> Nursing simulations with defined critical actions and teamwork assessment  </p></li>
</ul>

<blockquote>
  <p>“Data from the Learner Model are visualised and combined with narratives to convey a story for an individual student or a team.” (p. 6)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — DS principles include removing unnecessary elements, highlighting important features  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — tied to pedagogical intentions and activity specifics  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — aligned with realistic instructional and technological constraints  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — aimed at post-activity debriefs in near-real time  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — multimodal constructs and DS enhance interpretability  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — narratives tied directly to teacher’s learning goals  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> User agency in modifying rules; integration with teacher feedback loops</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Data Storytelling principles (purposeful communication, meaningful visuals, narrative structures)</p></li>
<li><p>Quantitative Ethnography (QE)  </p></li>
<li><p>Multimodal Matrix methodology  </p></li>
<li><p>Theory of Proxemics for spatial interaction analysis</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Error detection types (Sequence, Timeliness, Frequency)</p></li>
<li><p>Time spent in proximity to patients or team members</p></li>
<li><p>Adherence to clinical guideline-timed actions</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Complexity of multimodal data; automation challenges for certain modalities; need for context-specific adaptation  </p></li>
<li><p><strong>Enablers:</strong> Teacher-defined rules; automated DS generation; integration of multiple sensing modalities; near-real-time feedback</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on prior work in multimodal learning analytics and DS, extending from high-fidelity prototypes to fully automated, large-scale implementations. Addresses gaps in automation and pedagogical alignment.</p>

<hr />

<h2>Summary</h2>

<p><em>YarnSense</em> operationalises actionability in educational analytics as the transformation of raw multimodal sensor data into timely, clear, pedagogically aligned data stories that facilitate reflection and performance improvement. By integrating teacher-defined assessment criteria with automated multimodal modelling and narrative visualisation, it ensures contextual relevance, clarity, and goal alignment. Its reference implementation in nursing simulations demonstrates scalability and adaptability, detecting clinically relevant errors and visualising teamwork dynamics in a form that is understandable to students and instructors. The architecture’s modular design supports user agency, explainability, and adaptability across contexts, positioning it as a robust model for automated, actionable learning analytics.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 — Strong conceptualisation of actionability through DS and pedagogical alignment, though definition is implicit.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Comprehensive architecture, clearly defined workflow, demonstrated in large-scale authentic context.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[...] based on the notion of data storytelling as a means of extracting actionable insights from data…” (Abstract)  </p></li>
<li><p>“... weaving complex data into coherent narratives that align with the teacher’s pedagogical intentions” (p. 9)  </p></li>
<li><p>“Data from the Learner Model are visualised and combined with narratives to convey a story for an individual student or a team.” (p. 6)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Martinez-Maldonado et al. (2020) — Layered storytelling approach for multimodal learning analytics  </p></li>
<li><p>Echeverria et al. (2018) — Educational data storytelling for teacher attention  </p></li>
<li><p>Fernández-Nieto et al. (2022) — Combining visualisation, narrative, and storytelling for student data insights</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Why-Not Explainable Graph Recommender  </p>

<p>Authors: Herve-Madelein Attolou, Katerina Tzompanaki, Kostas Stefanidis, Dimitris Kotzinos  </p>

<p>DOI: 10.1109/ICDE60146.2024.00178  </p>

<p>Year: 2024  </p>

<p>Publication Type: Conference  </p>

<p>Discipline/Domain: Computer Science / Artificial Intelligence  </p>

<p>Subdomain/Topic: Explainable Recommender Systems, Counterfactual Explanations, Graph-based Recommendations  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes (implicit and explicit through actionable explanation design)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (EMiGRe)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual + Experimental Evaluation  </p>

<p>Study Context: Graph-based recommendation systems with user–item interaction data  </p>

<p>Geographic/Institutional Context: CY Cergy Paris University, Tampere University  </p>

<p>Target Users/Stakeholders: End-users of RS, system developers/debuggers  </p>

<p>Primary Contribution Type: Algorithm/Framework Proposal with Evaluation  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: No  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Why-Not Explainable Graph Recommender</p>

<p><strong>Authors:</strong>  </p>

<p>Herve-Madelein Attolou, Katerina Tzompanaki, Kostas Stefanidis, Dimitris Kotzinos</p>

<p><strong>DOI:</strong>  </p>

<p>10.1109/ICDE60146.2024.00178</p>

<p><strong>Year:</strong>  </p>

<p>2024</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Artificial Intelligence</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Explainable Recommender Systems, Counterfactual Explanations, Graph-based Recommendations</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The work is situated in the area of explainable AI for recommendation systems, particularly in addressing <em>Why-Not</em> questions—cases where a user wants to know why a specific, expected item was not recommended. The authors focus on graph-based recommendation systems and adapt counterfactual explanation methods to provide actionable insights either as past actions to remove or new actions to take.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>CY Cergy Paris University (France), Tampere University (Finland)</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>End-users seeking transparency; system developers for debugging and improving recommender performance</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework development + algorithm design + experimental evaluation on Amazon product review data</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Algorithm/Framework (EMiGRe) and empirical validation</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper introduces <strong>EMiGRe</strong>, a framework for generating <em>Why-Not explanations</em> in graph-based recommender systems, explaining why a desired item was not the top recommendation. Unlike existing explainable RS approaches (e.g., PRINCE), EMiGRe targets missing recommendations and outputs <strong>actionable insights</strong> in the form of counterfactual changes to the user’s interaction graph—either edges to remove (past actions) or edges to add (potential actions). The framework defines a formal problem setting, proposes search strategies (Add/Remove modes) with heuristics (Incremental, Powerset, Exhaustive Comparison), and evaluates performance on a processed Amazon reviews dataset. Results show feasibility, differences in runtime, success rates, and explanation size across methods. The authors highlight challenges such as popular items, cold-start users, and the need for meta-explanations.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as providing explanations that <em>suggest concrete, feasible actions a user can take (or could have taken) to obtain the desired recommendation</em>. This goes beyond interpretability by prescribing <strong>specific edge additions/removals</strong> in the user–item graph.  </p>

<blockquote>
  <p>“We opt for a form of Counterfactual Explanations… proposing a possible world that could have led to the desired outcome” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“…provides… actionable insights on the source data and their interrelations” (p. 1)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Directly modifiable by the user (edges rooted at the user node)</p></li>
<li><p>Feasibility within privacy constraints (only user’s own actions)</p></li>
<li><p>Causally linked to producing the desired recommendation (must result in WNI being top-1)</p></li>
<li><p>Specificity (identifies exact edges to add or remove)</p></li>
<li><p>Adaptability to system constraints and user preferences</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> EMiGRe (Explainable Missing Graph Recommendation)</p></li>
<li><p><strong>Methods/Levers:</strong> Counterfactual graph modifications via edge addition (Add Mode) or removal (Remove Mode)</p></li>
<li><p><strong>Operational Steps / Workflow:</strong></p>

<p> 1. Define Why-Not item (WNI)</p>

<p> 2. Identify candidate edges (user-rooted) influencing WNI ranking using Personalized PageRank contributions</p>

<p> 3. Search for minimal modification set (Incremental, Powerset, Exhaustive Comparison)</p>

<p> 4. Validate candidate explanations against top-1 constraint</p></li>
<li><p><strong>Data &amp; Measures:</strong> Personalized PageRank scores, contribution metrics, runtime, success rate, explanation size</p></li>
<li><p><strong>Implementation Context:</strong> Post-hoc explanation for graph-based RS, tested on Amazon product reviews</p></li>
</ul>

<blockquote>
  <p>“…set of edges rooted at the user u node… to replace rec by WNI as the recommendation” (p. 5)  </p>
</blockquote>

<blockquote>
  <p>“…propose… missing pertinent edges to be added… or existing edges to be removed” (p. 5)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — explicitly identifies specific, understandable actions (edges)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — actions are user-specific and relevant to target item  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — constrained to actions the user can perform  </p></li>
<li><p><strong>TI (Timeliness):</strong> No — no explicit discussion of time sensitivity  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — method provides causal reasoning via counterfactuals  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — directly tied to achieving WNI recommendation  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Privacy-preserving scope</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Counterfactual explanations (AI interpretability literature)</p></li>
<li><p>Graph-based recommendation and Personalized PageRank</p></li>
<li><p>Why-Not questions in databases and ranking functions</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Success rate (ability to achieve WNI in top-1)</p></li>
<li><p>Size of explanation (fewer edges preferred)</p></li>
<li><p>Runtime efficiency (practicality of producing the explanation)</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong></p>

<p> - Cold start/low activity users (few modifiable edges)</p>

<p> - Highly popular competing items (structurally difficult to displace)</p>

<p> - Out-of-scope cases where only edge additions or removals are insufficient</p></li>
<li><p><strong>Enablers:</strong></p>

<p> - Availability of rich user–item interaction data</p>

<p> - Graph-based structure allowing edge-level manipulation</p>

<p> - Efficient PPR computation methods</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Extends explainable RS literature from <em>Why</em> to <em>Why-Not</em> scenarios, differing from PRINCE by:</p>

<ol>
<li><p>Focusing on missing recommendations</p></li>
<li><p>Providing both past-action and future-action explanations</p></li>
</ol>

<p>Builds on prior Why-Not work in databases and adapts it to graph RS with privacy-preserving constraints.</p>

<hr />

<h2>Summary</h2>

<p>The paper introduces EMiGRe, a novel framework for producing actionable Why-Not explanations in graph-based recommender systems. Actionability is defined through concrete, user-feasible modifications—adding or removing edges in the user–item graph—to achieve a specific desired recommendation. The framework operationalizes this via Personalized PageRank-based influence scoring and search strategies (Incremental, Powerset, Exhaustive Comparison), ensuring that the suggested actions directly cause the Why-Not item to become top-1. The approach is privacy-conscious, focusing only on the user’s own actions. Evaluation on Amazon review data shows varying trade-offs between runtime, explanation size, and success rates across methods. The work makes a strong conceptual and practical contribution to actionable explainability in RS, though timeliness is not addressed and popularity biases remain challenging.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 — Strong conceptualization of actionability with explicit operational features; slightly reduced due to lack of temporal considerations.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Detailed algorithms, heuristics, and evaluation directly tied to producing actionable outputs.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We opt for a form of Counterfactual Explanations… proposing a possible world that could have led to the desired outcome” (p. 1)  </p></li>
<li><p>“…set of edges rooted at the user u node… to replace rec by WNI as the recommendation” (p. 5)  </p></li>
<li><p>“We provide more actionable explanations, by proposing not only existing actions… but also new actions” (p. 5)  </p></li>
<li><p>“This form of explanation provides user-comprehensible and actionable evidence of the trustworthiness of the system” (p. 4)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Ghazimatin et al. (2020) — PRINCE: Provider-side Interpretability with Counterfactual Explanations in RS  </p></li>
<li><p>Miller (2017, 2021) — Contrastive explanation theory  </p></li>
<li><p>Database and IR Why-Not literature (e.g., Bidoit et al. 2014, Chapman &amp; Jagadish 2009)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: When Rigor Meets Relevance: the Development of Hybrid Actionable Knowledge Production Systems  </p>

<p>Authors: Thomaz Wood Jr, Edvalter Becker Holz, Renato Souza  </p>

<p>DOI: https://doi.org/10.1007/s11213-022-09596-x  </p>

<p>Year: 2023  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Management / Organizational Studies  </p>

<p>Subdomain/Topic: Actionable Knowledge, Hybrid Research Systems, Rigor–Relevance Gap  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 92  </p>

<p>Operationalization Score: 88  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: No  </p>

<p>Contains Interpretability: No  </p>

<p>Contains Framework/Model: Yes (Hybridization process model)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Qualitative (Inductive, interpretive case studies; grounded theory)  </p>

<p>Study Context: Business schools as hybrid research systems  </p>

<p>Geographic/Institutional Context: Canada and Brazil  </p>

<p>Target Users/Stakeholders: Business school researchers, practitioners, institutional leaders (deans, directors)  </p>

<p>Primary Contribution Type: Conceptual + Empirical (Model development)  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: No  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>When Rigor Meets Relevance: the Development of Hybrid Actionable Knowledge Production Systems  </p>

<p><strong>Authors:</strong>  </p>

<p>Thomaz Wood Jr, Edvalter Becker Holz, Renato Souza  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1007/s11213-022-09596-x  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Management / Organizational Studies  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Actionable Knowledge, Hybrid Research Systems, Rigor–Relevance Gap  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper examines how business schools can develop research systems that produce knowledge that is simultaneously rigorous and relevant — “actionable knowledge” (AK). Instead of the traditional “bridging” view (rigor and relevance as separate realms), the authors adopt an ontology of hybridism, exploring how the two can become ontologically mingled within institutional systems.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Canadian Business School (CBS) and Brazilian Business School (BBS), both top-tier, AACSB/EFMD/AMBA-accredited institutions.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Researchers, practitioners, institutional leaders (e.g., deans, directors), policymakers in higher education.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Qualitative — inductive, interpretive case studies using grounded theory and “knowing-from-within” epistemology.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual + empirical — development of a three-stage hybridization model for AK generation.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper challenges the dominant “bridging theories” of actionable knowledge, which assume rigor and relevance are ontologically separate and must be linked through temporary collaborative mechanisms. Instead, the authors introduce the concept of “research hybridization,” where these dimensions are institutionally mingled over time. Through two case studies of business schools in Canada and Brazil, the authors develop a three-stage model of hybridization: <strong>coexistence</strong>, <strong>juxtaposition</strong>, and <strong>mingling</strong>. These stages describe the evolution from parallel operation of rigorous and relevant knowledge systems to fully integrated outputs indistinguishable in their dual qualities. The study highlights the role of institutional actions — not just individual collaborations — in sustaining AK production, and contrasts these mechanisms with those found in bridging theories.  </p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>AK is defined as knowledge that is both <strong>rigorous</strong> (advances theoretical understanding) and <strong>relevant</strong> (produces practical or social impact). It involves changes in professional practice or institutions through active stakeholder participation.  </p>

<blockquote>
  <p>“AK refers to knowledge that both advances the theoretical understanding of phenomena and allows for a better resolution of real problems…” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“…embodying the features of both systems in a way that one could not distinguish them in the final material output.” (p. 24)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Integrates <strong>scientific rigor</strong> and <strong>practical relevance</strong> in the same output.  </p></li>
<li><p>Involves <strong>multi-stakeholder participation</strong> and recognition.  </p></li>
<li><p>Supported by <strong>institutional structures</strong> that embed this integration.  </p></li>
<li><p>Produces outputs (e.g., reports, journal articles, cases) <strong>valued by both academic and practitioner audiences</strong>.  </p></li>
<li><p>Sustains <strong>legitimacy</strong> across both academic and practice communities.  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Research Hybridization (three stages: coexistence, juxtaposition, mingling)  </p></li>
<li><p><strong>Methods/Levers:</strong> Institutional entrepreneurial/supportive actions; structural mechanisms for regulation; stakeholder engagement  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. <strong>Coexistence</strong> — bring together rigor- and relevance-oriented components via projects, partnerships, thematic teams.  </p>

<p> 2. <strong>Juxtaposition</strong> — formalize and couple processes, regulations, revenue models.  </p>

<p> 3. <strong>Mingling</strong> — produce outputs embodying both rigor and relevance seamlessly.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Project portfolios, partnerships, publication and dissemination outputs, stakeholder feedback.  </p></li>
<li><p><strong>Implementation Context:</strong> Business schools with research offices and hybrid research units.  </p></li>
</ul>

<blockquote>
  <p>“We developed a conceptual model to describe the process by which… knowledge systems are hybridized…” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“Institutional entrepreneurial and supportive actions aimed at creating multivoiced knowledge-based projects…” (p. 25)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — clarity in communicating research values to both academics and practitioners (p. 12).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — strong emphasis on solving real, context-specific problems (p. 15).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — structurally embedded processes ensure actionable outputs are deliverable (p. 23).  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — urgency of emerging topics noted as a challenge (p. 13).  </p></li>
<li><p><strong>EX (Explainability):</strong> No explicit linkage to actionability.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — alignment between institutional mission, academic outputs, and societal needs (p. 21).  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Institutional legitimacy, stakeholder participation, economic sustainability.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Hybridism (Battilana &amp; Dorado 2010; Battilana &amp; Lee 2014)  </p></li>
<li><p>Actionable knowledge literature (Tenkasi &amp; Hay 2004; Sharma &amp; Bansal 2020)  </p></li>
<li><p>Grounded theory methodology  </p></li>
<li><p>Knowing-from-within epistemology (Shotter 2008)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Publication in both <strong>top-tier academic journals</strong> and <strong>practice-oriented outlets</strong>.  </p></li>
<li><p>Stakeholder recognition and engagement levels.  </p></li>
<li><p>Revenue generation from practice-linked projects.  </p></li>
<li><p>Diversity of dissemination formats (books, cases, reports, events).  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Loss of academic talent to private sector (p. 13)  </p>

<p> - Pressure to diversify revenue (p. 13)  </p>

<p> - Bureaucratic overload (p. 16)  </p>

<p> - Skepticism from traditional academics (p. 18)  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Institutional entrepreneurial actions (p. 21)  </p>

<p> - Structural governance mechanisms (p. 23)  </p>

<p> - Multi-stakeholder networks (p. 24)  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Contrasts with bridging theories, which rely on temporary, discretionary collaboration between researchers and practitioners. Proposes that <strong>institutional-level hybridization mechanisms</strong> can create sustained systems where rigor and relevance are ontologically mingled.  </p>

<hr />

<h2>Summary</h2>

<p>This paper reconceptualizes actionable knowledge (AK) generation by replacing the “bridging” paradigm with a “hybridization” model grounded in hybridism. Through qualitative case studies of two leading business schools, the authors map a three-stage process—coexistence, juxtaposition, mingling—by which scientific rigor and practical relevance are not just linked but merged into a single, sustainable system. Actionability here is institutionally embedded, multi-stakeholder, and legitimized across academic and practice domains. Key mechanisms include entrepreneurial institutional actions, governance structures, and broad stakeholder participation. This approach extends AK theory to less-traditional research settings and shifts responsibility from individual collaborations to institutional strategies, offering a durable pathway for integrating theory and practice.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Strong conceptual clarity on actionability, explicit features, and novel theoretical contribution via hybridization model.  </p></li>
<li><p><strong>Operationalization Score:</strong> 88 — Detailed three-stage process with mechanisms and institutional practices, though some dimensions (e.g., timeliness, explainability) are underdeveloped.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“AK refers to knowledge that both advances the theoretical understanding of phenomena and allows for a better resolution of real problems…” (p. 2)  </p></li>
<li><p>“…views, norms, forms and practices… are materialized in the form of outputs that embody characteristics of both rigor and relevance…” (p. 24)  </p></li>
<li><p>“Institutional entrepreneurial and supportive actions aimed at creating multivoiced knowledge-based projects…” (p. 25)  </p></li>
<li><p>“Support from contract experts is also important because some projects involve researchers from other schools…” (p. 23)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Babüroglu &amp; Ravn (1992) — Normative action research  </p></li>
<li><p>Tenkasi &amp; Hay (2004) — Theory–practice linkages  </p></li>
<li><p>Sharma &amp; Bansal (2020) — Co-creating rigorous and relevant knowledge  </p></li>
<li><p>Battilana &amp; Dorado (2010); Battilana &amp; Lee (2014) — Hybrid organizations  </p></li>
<li><p>Beer (2020) — Developing actionable knowledge for practice and theory</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: What Is “Actionable” Science for Climate and Environment?  </p>

<p>Authors: Ziheng Sun  </p>

<p>DOI: 10.1007/978-3-031-41758-0_1  </p>

<p>Year: 2023  </p>

<p>Publication Type: Book Chapter  </p>

<p>Discipline/Domain: Environmental Science / Climate Science  </p>

<p>Subdomain/Topic: Actionable science; climate change adaptation and mitigation; environmental decision support  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual with quantitative framework proposal  </p>

<p>Study Context: Climate and environmental science research, with focus on science-to-action translation  </p>

<p>Geographic/Institutional Context: Global, with examples from the USA (California), coastal resilience, and international projects  </p>

<p>Target Users/Stakeholders: Policymakers, engineers, scientists, local communities, funding agencies, industry stakeholders  </p>

<p>Primary Contribution Type: Conceptual framework and evaluation model  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>What Is “Actionable” Science for Climate and Environment?  </p>

<p><strong>Authors:</strong>  </p>

<p>Ziheng Sun  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1007/978-3-031-41758-0_1  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Book Chapter  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Environmental Science / Climate Science  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Actionable science; climate change adaptation and mitigation; environmental decision support  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>This chapter addresses the concept, necessity, and evaluation of “actionable” science within climate and environmental contexts, focusing on bridging research with real-world applications and decision-making. It presents a quantitative framework to assess the “actionableness” of projects.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Global scope, with examples including California climate adaptation, NOAA coastal resilience programs, and international climate modeling efforts.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Decision-makers, scientists, engineers, industry stakeholders, local communities, and funding agencies.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework development, supported by illustrative case studies and proposed quantitative formulas.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual definition and operationalization model for actionability.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The chapter defines “actionable science” as research explicitly designed to produce knowledge, recommendations, or tools that can be applied directly to address real-world environmental and climate challenges. It distinguishes this from traditional science focused on “why” questions, emphasizing application-specific “what” and “how” questions in a defined time and place. The author presents a multi-factor quantitative model for assessing actionability, incorporating relevance to real-world needs, feasibility, public understanding, societal impact, operational practicality, and stakeholder engagement. Real-world examples include sea-level rise adaptation, carbon capture technology, and coastal resilience programs. The chapter also addresses barriers such as funding limitations, policy constraints, and lack of interdisciplinary collaboration, advocating for strategies to integrate science into decision-making processes effectively.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionable science is “oriented towards answering inquiries such as ‘What actions should we take in this specific place and time today’” and must integrate the “why,” “what,” and “how” dimensions, aiming for solutions implementable in the present or near future.  </p>

<blockquote>
  <p>“Actionable science requires a meticulous examination of ideas within the confines of practical constraints and a holistic assessment of their feasibility for stakeholders.” (p. 5)  </p>
</blockquote>

<blockquote>
  <p>“An actionable science endeavor should not run counter to the overarching consensus goals shared by both the scientific community and society at large.” (p. 7)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Alignment with real-world challenges and operational application goals.</p></li>
<li><p>Practical application potential for significant societal challenges.</p></li>
<li><p>Consideration of “what-if” engineering questions and operational uncertainties.</p></li>
<li><p>Feasibility within resource, scalability, political, and economic constraints.</p></li>
<li><p>Public understanding through clarity and transparency.</p></li>
<li><p>Measurable societal, environmental, economic, and cultural impacts.</p></li>
<li><p>Practicality from the operators’ perspective.</p></li>
<li><p>High engagement with stakeholders and end users.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Quantitative actionability assessment model.  </p></li>
<li><p><strong>Methods/Levers:</strong> Six-factor model: Relevance, Feasibility, Public Understanding, Societal Impact, Practicality by Operators, Stakeholder Engagement.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Define project objectives and societal alignment.  </p>

<p> 2. Assess each factor using quantitative/qualitative indicators.  </p>

<p> 3. Identify barriers (e.g., policy, economics) and design mitigation strategies.  </p>

<p> 4. Engage stakeholders early and iteratively.  </p>

<p> 5. Use feedback to refine applicability and implementation readiness.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Accessibility scores, scalability indices, impact metrics (economic, environmental, social, health, cultural), complexity and cost assessments, engagement rates.  </p></li>
<li><p><strong>Implementation Context:</strong> Climate and environmental projects at local, regional, and global scales.  </p></li>
</ul>

<blockquote>
  <p>“If the answer is ‘yes’ to all three questions, the research falls within the high basket of actionable science.” (p. 7)  </p>
</blockquote>

<blockquote>
  <p>“The overarching goal is to provide decision-makers with the tools and information they need to make well-informed choices.” (p. 8)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><strong>CL (Clarity):</strong> Yes – Explicitly tied to public understanding and communication effectiveness.  </li>
</ul>

<blockquote>
  <p>“Effective communication is essential for promoting public understanding and support.” (p. 14)  </p>
</blockquote>

<ul>
<li><strong>CR (Contextual Relevance):</strong> Yes – Research must align with specific societal and operational needs.  </li>
</ul>

<blockquote>
  <p>“Aligned with real-world challenges and part of a broader community effort.” (p. 7)  </p>
</blockquote>

<ul>
<li><strong>FE (Feasibility):</strong> Yes – Multi-factor feasibility assessment provided.  </li>
</ul>

<blockquote>
  <p>“Another important factor for actionable research is the feasibility of implementing the results into real-world products or applications.” (p. 10)  </p>
</blockquote>

<ul>
<li><p><strong>TI (Timeliness):</strong> Partial – Timeliness is implied via real-time science discussion but not formalized as a dimension.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – Linked to transparency, clarity, and addressing “what-if” questions.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – Must not run counter to shared societal/scientific goals.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Stakeholder engagement, practicality by operators, societal impact.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Knowledge transfer frameworks (Chai et al., 2003; Agrawal, 2001).</p></li>
<li><p>Co-production of knowledge (Beier et al., 2017).</p></li>
<li><p>Climate information usability literature (Kirchhoff et al., 2013).</p></li>
<li><p>Life cycle and environmental impact assessment methods.</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Quantitative scores for relevance, feasibility, public understanding, societal impact, practicality, and engagement.</p></li>
<li><p>Sub-metrics: accessibility, scalability, reproducibility, political/economic feasibility, clarity, transparency, impact valuations, complexity, cost, participation rates.</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Funding constraints, policy misalignment, technological immaturity, public misunderstanding, academic incentive structures favoring publications over application.  </p></li>
<li><p><strong>Enablers:</strong> Early stakeholder engagement, clear communication, alignment with policy goals, interdisciplinary collaboration, real-time data integration.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions itself as integrating and extending prior definitions of actionable knowledge by proposing a comprehensive, measurable framework. Builds on co-production, usability, and stakeholder engagement literature but adds operational feasibility and quantitative assessment.</p>

<hr />

<h2>Summary</h2>

<p>This chapter provides one of the most comprehensive conceptualizations and operational frameworks for “actionable science” in the climate and environmental domain. Sun explicitly defines actionable science as research designed to yield applicable solutions to immediate, place-specific problems, integrating “why,” “what,” and “how” dimensions. The proposed model quantitatively assesses actionability using six factors: relevance, feasibility, public understanding, societal impact, practicality by operators, and stakeholder engagement. Each factor includes detailed sub-metrics, offering a practical evaluation toolkit for scientists, funders, and decision-makers. The chapter addresses the importance of interdisciplinary collaboration, policy alignment, and real-time data integration while identifying systemic barriers such as misaligned academic incentives. Its contribution lies in transforming the often vague notion of “actionability” into an operational, measurable construct, bridging the science–policy–practice gap.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 – Highly explicit definition, detailed attributes, and strong conceptual clarity.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 – Provides structured, measurable framework with concrete metrics, examples, and implementation guidance.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Actionable science requires a meticulous examination of ideas within the confines of practical constraints and a holistic assessment of their feasibility for stakeholders.” (p. 5)  </p></li>
<li><p>“An actionable science endeavor should not run counter to the overarching consensus goals shared by both the scientific community and society at large.” (p. 7)  </p></li>
<li><p>“If the answer is ‘yes’ to all three questions, the research falls within the high basket of actionable science.” (p. 7)  </p></li>
<li><p>“Effective communication is essential for promoting public understanding and support.” (p. 14)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Beier et al. (2017) – Co-production of actionable science.  </p></li>
<li><p>Kirchhoff et al. (2013) – Actionable knowledge usability.  </p></li>
<li><p>Meinke et al. (2006) – Actionable climate knowledge.  </p></li>
<li><p>Chai et al. (2003); Agrawal (2001) – Knowledge sharing/transfer.  </p></li>
<li><p>Lemos et al. (2012) – Climate information usability gap.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: What About Her? Increasing the Actionability of HUMINT in Paternalistic Cultures by Considering Female Intelligence  </p>

<p>Authors: Stephan Lau &amp; Farina T. S. Bauer  </p>

<p>DOI: 10.1080/08850607.2022.2068890  </p>

<p>Year: 2022  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Intelligence Studies / Security Studies  </p>

<p>Subdomain/Topic: Human Intelligence (HUMINT), Gender Integration, Paternalistic Cultures  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 88  </p>

<p>Operationalization Score: 80  </p>

<p>Contains Definition of Actionability: Yes (explicitly in context of HUMINT diversity and flexibility)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: No  </p>

<p>Contains Framework/Model: Yes (conceptual framework linking female integration to actionability)  </p>

<p>Operationalization Present: Yes (survey, interview data, training, recruitment, targeting recommendations)  </p>

<p>Primary Methodology: Mixed Methods (Survey + Interviews + Literature Review)  </p>

<p>Study Context: Military HUMINT operations in paternalistic cultures (primarily Afghanistan, also Iraq, Kosovo)  </p>

<p>Geographic/Institutional Context: Bundeswehr (German military) &amp; NATO operations  </p>

<p>Target Users/Stakeholders: Military intelligence planners, HUMINT operatives, defense policymakers  </p>

<p>Primary Contribution Type: Conceptual framework + empirical practitioner insights  </p>

<p>CL: Yes — “effective and actionable human intelligence collection” linked to gender-sensitive planning (p. 4)  </p>

<p>CR: Yes — strong emphasis on cultural context (paternalistic norms) affecting access and utility of operators and targets (p. 4–5)  </p>

<p>FE: Yes — operational feasibility discussed via recruitment, training, interpreters (p. 15–16)  </p>

<p>TI: Partial — timeliness not a major theme, though linked implicitly to live collection flexibility (“actionability”)  </p>

<p>EX: Partial — explainability emerges in clarifying myths and assumptions but not as formal feature  </p>

<p>GA: Yes — alignment with mission goals stressed via “targeting” and “actionability” as central concepts (p. 16–17)  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>What About Her? Increasing the Actionability of HUMINT in Paternalistic Cultures by Considering Female Intelligence  </p>

<p><strong>Authors:</strong>  </p>

<p>Stephan Lau &amp; Farina T. S. Bauer  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1080/08850607.2022.2068890  </p>

<p><strong>Year:</strong>  </p>

<p>2022  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Intelligence Studies / Security Studies  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Human Intelligence (HUMINT), Gender Integration, Paternalistic Cultures  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The study addresses the integration of women as both operators and targets in military human intelligence (HUMINT) collection, with focus on paternalistic cultural settings such as Afghanistan. It critiques myths, evaluates past initiatives (e.g., Female Engagement Teams, Cultural Support Teams), and uses Bundeswehr field data to identify barriers and strategies to increase the “actionability” of intelligence units through mixed-gender integration.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>German Bundeswehr HUMINT units in NATO missions (Afghanistan, Iraq, Kosovo).  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Military HUMINT planners, operators, NATO leadership, defense policymakers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed Methods (Survey of 40 operatives + 2 interviews + literature review).  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework and operational recommendations.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The article examines the role of “female intelligence” — the gender-sensitive integration of women as both targets and operatives — in enhancing HUMINT actionability in paternalistic cultural contexts. It critiques outdated and emerging myths about women’s utility in intelligence, evaluates historical initiatives such as Female Engagement Teams (FETs) and Cultural Support Teams (CSTs), and identifies four key areas of concern: basic assumptions, implementation, human resource development, and recruitment. Using survey and interview data from Bundeswehr operatives, the study reveals mixed incorporation of female targets, persistent interpreter shortages, and both opportunities and limits in female operators’ access. The authors argue that the true value of female integration lies in increasing operational “actionability” — the flexibility and options available to HUMINT teams. Recommendations include systematic targeting of women, integrated mixed-gender teams, improved training, and building a cadre of female interpreters.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as the increased operational flexibility and diversity in options available to HUMINT units when female operators are integrated and female targets are systematically engaged. It is not gender-exclusive but derives from mixed-gender teams leveraging complementary access, influence, and tactical roles.  </p>

<blockquote>
  <p>“We advocate the integration of female and male operators in the same units by creating and supporting mixed teams… increase the actionability of intelligence collection entities” (p. 17)  </p>
</blockquote>

<blockquote>
  <p>“Actionability… [is] the general flexibility and the elbow room to play with the circumstances” (p. 17)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Inclusion of both male and female operators to broaden operational scenarios.</p></li>
<li><p>Ability to engage otherwise inaccessible targets (especially across gender lines in paternalistic cultures).</p></li>
<li><p>Flexibility in adapting team composition and role-playing to exploit cultural dynamics.</p></li>
<li><p>Adequate logistical, linguistic, and training support (e.g., interpreters, cultural competence).</p></li>
<li><p>Targeting strategy that includes both male and female sources.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Female Intelligence Integration for Actionability (conceptual).  </p></li>
<li><p><strong>Methods/Levers:</strong> Targeting female sources, mixed-gender team integration, debunking myths, systematic inclusion in planning.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Assessment of current beliefs, recruitment and training, inclusion in mission briefs, language skill development, role-play exploitation in cultural contexts.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Survey (Likert-scale) and interviews with Bundeswehr HUMINT operators; descriptive and inferential analysis of access patterns and perceptions.  </p></li>
<li><p><strong>Implementation Context:</strong> Military HUMINT in Afghanistan, Iraq, Kosovo.  </p></li>
</ul>

<blockquote>
  <p>“Two concepts are essential: targeting female sources and increasing actionability” (p. 14)  </p>
</blockquote>

<blockquote>
  <p>“Including female targets and… combining male and female capabilities… would increase the actionability of intelligence collection entities” (p. 17)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — linked to clear operational understanding of female capabilities and myth correction (p. 14–15).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — integration strategies rooted in cultural norms of paternalistic societies (p. 4–5).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — feasibility tied to recruitment, interpreters, training (p. 15–16).  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — implied through live flexibility in engagements.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — addresses misconceptions but no formal explainability model.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — female integration linked to mission success and HUMINT collection effectiveness.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Diversity, mixed-team synergy, cultural competence.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Gender-sensitive HUMINT theory in counterinsurgency.</p></li>
<li><p>Cultural access theory (third gender perception).</p></li>
<li><p>Intelligence actionability as operational flexibility.</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Operator access levels to male/female targets.</p></li>
<li><p>Availability of female interpreters.</p></li>
<li><p>Proportion of female targets included in mission planning.</p></li>
<li><p>Role of female operators in achieving mission objectives.</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Myths/stereotypes, lack of interpreters, unclear targeting strategy, insufficient training, small recruitment pool.  </p></li>
<li><p><strong>Enablers:</strong> Mixed-gender teams, cultural role exploitation, persistent engagement, rigorous training (tradecraft + physical), language skills.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on critiques of FET and CST programs, integrates prior cultural engagement research, and adds Bundeswehr-specific empirical data. Distinctive in explicitly framing “actionability” as the central benefit of female integration.</p>

<hr />

<h2>Summary</h2>

<p>This paper presents a comprehensive conceptual and empirical examination of integrating women as both HUMINT operators and targets to enhance operational “actionability” in paternalistic cultures. Actionability is defined as the increased flexibility and tactical options available to intelligence units, achievable through mixed-gender teams that exploit diverse access routes and cultural dynamics. Drawing on Bundeswehr survey and interview data, the authors identify barriers (stereotypes, logistical gaps, limited recruitment) and opportunities (expanded access, cultural leverage). They recommend systematic targeting of female sources, integrated team structures, focused recruitment, language training, and building a cadre of female interpreters. The study’s novelty lies in explicitly linking gender integration to a measurable operational advantage in HUMINT.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 — Strong explicit conceptualization of actionability in HUMINT, clear link to gender integration, grounded in empirical data.  </p></li>
<li><p><strong>Operationalization Score:</strong> 80 — Offers concrete operational strategies (targeting, training, recruitment), though some remain conceptual rather than tested at scale.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Female intelligence… recognizes females as targets of collection but also considers females as operatives… to create… actionable human intelligence collection” (p. 4)  </p></li>
<li><p>“Mixed teams would increase the actionability of intelligence collection entities” (p. 17)  </p></li>
<li><p>“Two concepts are essential: targeting female sources and increasing actionability” (p. 14)  </p></li>
<li><p>“Access to local women was significantly less denied to female operators” (p. 12)  </p></li>
<li><p>“Lack of female interpreters… constitutes an implementation problem with a high priority” (p. 15)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Pottinger, Jilani, &amp; Russo (2010) on Afghan women’s influence.  </p></li>
<li><p>Azarbaijani-Moghaddam (2014) on FET evaluations.  </p></li>
<li><p>Rohwerder (2015) on lessons from FETs.  </p></li>
<li><p>Brandon et al. (2018) on science-based interviewing and elicitation.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: User Perceptions of Actionability in Data Dashboards  </p>

<p>Authors: Madeleine Sorapure  </p>

<p>DOI: 10.1177/10506519231161611  </p>

<p>Year: 2023  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Technical and Professional Communication / Data Visualization  </p>

<p>Subdomain/Topic: COVID-19 Dashboards, Actionability, User Perceptions  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 92  </p>

<p>Operationalization Score: 88  </p>

<p>Contains Definition of Actionability: Yes (explicit and implicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (Ivanković et al.’s 7 criteria + added dimensions)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Qualitative (usability study with thematic analysis)  </p>

<p>Study Context: Evaluation of two COVID-19 county-level dashboards (Santa Barbara County, CAN)  </p>

<p>Geographic/Institutional Context: Santa Barbara County, California, USA; University of California, Santa Barbara  </p>

<p>Target Users/Stakeholders: Nonexpert public users of public health dashboards  </p>

<p>Primary Contribution Type: Empirical study expanding conceptual framework of dashboard actionability  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Partial  </p>

<p>TI: No  </p>

<p>EX: Partial  </p>

<p>GA: No  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>User Perceptions of Actionability in Data Dashboards  </p>

<p><strong>Authors:</strong>  </p>

<p>Madeleine Sorapure  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1177/10506519231161611  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Technical and Professional Communication / Data Visualization  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>COVID-19 Dashboards, Actionability, User Perceptions  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The study examines how nonexpert users interact with COVID-19 dashboards, particularly regarding actionability—defined as the ability to support decision making. It compares two county-level dashboards, applying and extending Ivanković et al.’s seven criteria for actionability.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Santa Barbara County, California; University of California, Santa Barbara  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Nonexpert, general public users of public health dashboards  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Qualitative usability study with think-aloud protocols, thematic analysis, and post-interview survey  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical evaluation and conceptual extension of dashboard actionability framework  </p>

<h2>General Summary of the Paper</h2>

<p>The article reports on a multiphase usability study of ten nonexpert participants interacting with two COVID-19 dashboards—Santa Barbara County Community (SBCC) and Covid Act Now (CAN). Using Ivanković et al.’s (2021) seven criteria for dashboard actionability as an evaluative framework, the study investigates how users perceive and interact with dashboard features that support decision making. Findings suggest that criteria related to knowing the audience, managing information volume/flow, and providing local granularity were most important, while others (e.g., linking to policy decisions) were less salient. The study identifies an additional dimension—emotional impact of dashboard data—as crucial to actionability. The author proposes prioritization of criteria when designing for general audiences.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionability is explicitly defined as the ability of data dashboards to inform and support user decision making, with criteria from Ivanković et al. (2021) guiding evaluation. Implicitly, actionability is also framed as the “fit” between information, user, and purpose, requiring relevance, accessibility, and usability.  </p>

<blockquote>
  <p>“Actionable data—that is, data that can inform decisions that users need to make” (p. 257)  </p>
</blockquote>

<blockquote>
  <p>“There needs to be a ‘fit’ between the information, the user, and the purposes for which the information is being sought” (p. 258)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Alignment with audience needs and contexts  </p></li>
<li><p>Appropriate type, amount, and organization of information  </p></li>
<li><p>Clear data sources and methodology  </p></li>
<li><p>Time trends linked to relevant decisions  </p></li>
<li><p>Locally granular data  </p></li>
<li><p>Demographic subgroup breakdowns  </p></li>
<li><p>Storytelling and intuitive visual cues  </p></li>
<li><p>Emotional engagement that does not overwhelm decision making</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Ivanković et al.’s seven criteria for actionable dashboards (adapted)  </p></li>
<li><p><strong>Methods/Levers:</strong> Usability design principles (navigation structure, composite indicators, visual simplification), local and demographic data inclusion, accessible explanations, multilingual support  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Audience analysis → Data selection → Display design (tabs, color codes, summaries) → Navigation optimization → Contextual explanations → Emotional impact consideration  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Infection rates, vaccination rates, hospitalizations, mortality, demographic breakdowns, risk levels  </p></li>
<li><p><strong>Implementation Context:</strong> COVID-19 public health dashboards at county level  </p></li>
</ul>

<blockquote>
  <p>“Participants frequently discussed wanting to find data that met their information needs, was relatively easy to navigate, and provided local granularity” (p. 269)  </p>
</blockquote>

<blockquote>
  <p>“Accounting for the emotional impact of data dashboards… would be a helpful addition to an analysis of their actionability” (p. 268)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — clarity of visual presentation and navigation linked to actionability (p. 267)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — local and personally relevant data emphasized (p. 265)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — some acknowledgment of limits on user actions in pandemic context (p. 257)  </p></li>
<li><p><strong>TI (Timeliness):</strong> No — timeliness not explicitly tied to actionability beyond data recency  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — accessible explanations provided but often underutilized by users (p. 264)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> No explicit mention  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Emotional impact of data viewing; need for prioritization of criteria</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Ivanković et al.’s seven actionability criteria  </p></li>
<li><p>Concepts of “fitness for purpose” and “fitness for use” in dashboard design  </p></li>
<li><p>User-centered design principles from TPC and data visualization literature</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Composite risk scores with visual color scales  </p></li>
<li><p>Survey agreement ratings on actionability criteria (Likert scale)  </p></li>
<li><p>User-reported clarity, relevance, and decision-making support</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Information overload; low granularity; inaccessible explanations; emotional stress; scrolling navigation issues  </p></li>
<li><p><strong>Enablers:</strong> Local data; concise summaries; familiar visual metaphors; intuitive navigation; demographic breakdowns</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions findings within ongoing debates on COVID-19 dashboards’ effectiveness, contributing empirical evidence of nonexpert user experiences and proposing refinements (e.g., emotional impact) to existing frameworks.</p>

<h2>Summary</h2>

<p>Sorapure’s study offers an in-depth empirical look at how nonexpert users perceive and use public health dashboards during COVID-19. By applying Ivanković et al.’s seven criteria for actionability, the research identifies which features matter most to general audiences—chiefly relevance to personal/local context, manageable information load, and clear navigation. Less important to participants were explicit links between time trends and policy decisions or demographic subgroup data, unless personally relevant. The study adds “emotional impact” as a critical, previously unrecognized dimension of actionability, noting that stress from viewing data can shape decision-making behavior. The findings support a prioritization approach to actionability criteria and provide design insights for dashboards intended for broad public use.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Strong explicit and implicit conceptualization of actionability, detailed criteria, and user-derived refinements.  </p></li>
<li><p><strong>Operationalization Score:</strong> 88 — Clear application of an existing framework to dashboard design and user testing, with concrete design implications, though some dimensions (e.g., timeliness, feasibility) are less developed.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Actionable data—that is, data that can inform decisions that users need to make” (p. 257)  </p></li>
<li><p>“There needs to be a ‘fit’ between the information, the user, and the purposes for which the information is being sought” (p. 258)  </p></li>
<li><p>“Participants frequently discussed wanting to find data that met their information needs, was relatively easy to navigate, and provided local granularity” (p. 269)  </p></li>
<li><p>“Accounting for the emotional impact of data dashboards… would be a helpful addition to an analysis of their actionability” (p. 268)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Ivanković et al. (2021) — Features constituting actionable COVID-19 dashboards  </p></li>
<li><p>Barbazza et al. (2021) — Assessment of dashboard actionability over time  </p></li>
<li><p>Yigitbasioglu &amp; Velcu (2012) — Fitness for purpose/use in dashboards  </p></li>
<li><p>Pappas &amp; Whitman (2011) — User-centered design for dashboard development</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: TriCTI: an actionable cyber threat intelligence discovery system via trigger-enhanced neural network  </p>

<p>Authors: Jian Liu, Junjie Yan, Jun Jiang, Yitong He, Xuren Wang, Zhengwei Jiang, Peian Yang, Ning Li  </p>

<p>DOI: https://doi.org/10.1186/s42400-022-00110-3  </p>

<p>Year: 2022  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Cybersecurity  </p>

<p>Subdomain/Topic: Cyber threat intelligence, NLP, threat detection  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 92  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Mixed Methods (conceptual + experimental model implementation)  </p>

<p>Study Context: Automated extraction of actionable CTI from unstructured cybersecurity reports using NLP and trigger-enhanced neural networks  </p>

<p>Geographic/Institutional Context: Chinese Academy of Sciences; Capital Normal University  </p>

<p>Target Users/Stakeholders: Security operations centers (SOC), cybersecurity analysts, threat intelligence teams  </p>

<p>Primary Contribution Type: Methodological framework and system development (TriCTI)  </p>

<p>CL: Yes – clarity of campaign stage and IOC association explicitly tied to actionability (p.2)  </p>

<p>CR: Yes – contextual relevance via mapping IOCs to campaign stages (p.2)  </p>

<p>FE: Yes – feasibility demonstrated by operational system tested on 29k reports (p.1, p.12)  </p>

<p>TI: Partial – system processes historical and near-real-time data, but not explicitly constrained by latency  </p>

<p>EX: Yes – interpretability through “campaign triggers” enhancing classification explainability (p.2, p.6)  </p>

<p>GA: Yes – goal alignment through prioritizing defense actions based on campaign stage severity (p.8–9)  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>TriCTI: an actionable cyber threat intelligence discovery system via trigger-enhanced neural network  </p>

<p><strong>Authors:</strong>  </p>

<p>Jian Liu, Junjie Yan, Jun Jiang, Yitong He, Xuren Wang, Zhengwei Jiang, Peian Yang, Ning Li  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1186/s42400-022-00110-3  </p>

<p><strong>Year:</strong>  </p>

<p>2022  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Cybersecurity  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Cyber threat intelligence, NLP, threat detection  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the challenge of extracting actionable cyber threat intelligence (CTI) from the vast and growing number of unstructured cybersecurity reports. Actionable CTI is defined as intelligence that provides context—specifically, the campaign stage of an IOC—enabling timely, effective mitigation decisions.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Institute of Information Engineering, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Capital Normal University, China.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Security operations centers (SOC), incident response teams, cybersecurity researchers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed methods: conceptual framework design, NLP-based system architecture, experimental validation on large corpus.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Novel system (TriCTI) and methodology for discovering actionable CTI with enhanced interpretability.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors propose TriCTI, a trigger-enhanced neural network system for discovering actionable cyber threat intelligence from unstructured cybersecurity reports. Actionable CTI, in this context, couples indicators of compromise (IOCs) with their campaign stages (e.g., Delivery, Exploitation, Command &amp; Control). The system uses “campaign triggers” — explanatory keywords or phrases — to improve classification accuracy and interpretability. TriCTI employs data preprocessing, IOC detection and filtering, trigger annotation, data augmentation (via retrofitted CBERT), and a trigger-enhanced BERT classifier. Evaluations on over 29,000 reports and 113,543 extracted actionable CTIs show improved performance over baseline models (F1: 87.02%). The system is validated against VirusTotal data, demonstrating that TriCTI can identify actionable intelligence across all campaign stages, surpassing existing industry tools.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionable CTI is defined as CTI that “conveys a richer context of IOCs by revealing their campaign stages” (p.2) and enables SOC teams to prioritize urgent threats and “take appropriate mitigation measures based on contextual information of the alerts” (p.1–2).  </p>

<blockquote>
  <p>“Actionable CTI can provide incident response teams with actionable insights and recommendations to stay nimble and precise in decision-making and taking effective actions” (p.2)  </p>
</blockquote>

<blockquote>
  <p>“If actionable CTI is integrated into intrusion detection systems, SOC teams can take appropriate mitigation actions based on contextual information of the alerts” (p.2)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Coupling IOCs with campaign stages for context.  </p></li>
<li><p>Providing interpretability for prioritization of threats.  </p></li>
<li><p>Supporting direct mitigation decisions aligned with attack phase.  </p></li>
<li><p>Being complete across all stages of the attack lifecycle.  </p></li>
<li><p>Accurate extraction to avoid false positives.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> TriCTI (Trigger-enhanced Cyber Threat Intelligence discovery system)  </p></li>
<li><p><strong>Methods/Levers:</strong> Campaign trigger annotation, IOC detection and filtering, BERT-based trigger vector generation, data augmentation via retrofitted CBERT  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Data crawling → preprocessing (purification, segmentation, IOC fanging) → regex-based IOC identification and filtering → candidate sentence extraction → trigger annotation → data augmentation → trigger vector training → trigger-enhanced classification → actionable CTI generation with campaign stage mapping.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> 29,686 cybersecurity reports; annotated datasets DS-1 and DS-2; evaluation metrics: Accuracy, Precision, Recall, Macro F1; VirusTotal verification.  </p></li>
<li><p><strong>Implementation Context:</strong> Applied to unstructured vendor reports spanning 2000–2021; verified using large-scale IOC data from VirusTotal.  </p></li>
</ul>

<blockquote>
  <p>“The sooner the detection is done, the less loss the organization under attack will suffer” (p.8)  </p>
</blockquote>

<blockquote>
  <p>“Applying actionable CTI to intrusion detection systems can guide security operators to make faster, better decisions” (p.8)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – clear association of IOCs to campaign stages is essential (p.2).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – mapping to campaign stages ensures relevance to defense context (p.2).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – operationalized on large dataset with automation (p.1, p.12).  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial – while timely response is stressed, the system is not explicitly real-time.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – campaign triggers improve interpretability (p.2, p.6).  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – enables prioritization according to severity of campaign stage (p.8–9).  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Completeness across all campaign stages; interpretability; reduced false positives.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Cyber Kill Chain model (Hutchins et al., 2011) for campaign stage definitions.  </p></li>
<li><p>NLP concepts: BERT, CBERT augmentation, trigger-based attention mechanisms.  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Campaign stage correctly assigned to IOC.  </p></li>
<li><p>Classification performance (Accuracy, F1 score).  </p></li>
<li><p>Coverage across all campaign stages.  </p></li>
<li><p>Verified maliciousness via VirusTotal relationships.</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Scarcity of annotated cybersecurity corpora; complexity of sentences with multiple stages; incorrect IOC-stage associations; evolving attack patterns (concept drift).  </p></li>
<li><p><strong>Enablers:</strong> Trigger-based explainability; data augmentation; automated large-scale processing; validation against external data sources.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper critiques prior IOC extraction and threat action identification work for lacking campaign stage context, interpretability, or completeness. TriCTI integrates these missing aspects, providing both extraction and contextualization.</p>

<hr />

<h2>Summary</h2>

<p>This paper presents TriCTI, an NLP-based, trigger-enhanced neural network framework for discovering actionable cyber threat intelligence from unstructured cybersecurity reports. Actionability is conceptualized as providing rich contextualization by coupling IOCs with campaign stages, enabling effective prioritization and mitigation. The system operationalizes this through campaign trigger annotation, IOC detection and filtering, BERT-based classification, and targeted data augmentation. TriCTI achieves state-of-the-art performance (F1: 87.02%) and demonstrates practical viability by extracting 113,543 actionable CTIs from over 29k reports, with verification against VirusTotal. The work is notable for embedding explainability into the operationalization of actionability and addressing completeness across the attack lifecycle.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 – Strong, explicit conceptualization of actionability with comprehensive feature set tied directly to the definition.  </p></li>
<li><p><strong>Operationalization Score:</strong> 92 – Detailed, step-by-step operationalization with system architecture, workflow, data pipeline, and real-world validation.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[Actionable CTI] conveys a richer context of IOCs by revealing their campaign stages” (p.2)  </p></li>
<li><p>“SOC teams can take appropriate mitigation actions based on contextual information of the alerts” (p.2)  </p></li>
<li><p>“We introduce the ‘campaign trigger’… to improve the performance of the classification model” (p.1)  </p></li>
<li><p>“Applying actionable CTI to intrusion detection systems can guide security operators to make faster, better decisions” (p.8)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Hutchins et al. (2011) – Cyber Kill Chain model.  </p></li>
<li><p>Yadav and Rao (2015) – Technical aspects of the cyber kill chain.  </p></li>
<li><p>Liao et al. (2016), Zhou et al. (2018), Long et al. (2019) – IOC extraction methods.  </p></li>
<li><p>Zhu and Dumitras (2018) – Campaign stage identification with rule-based approach.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Towards User Guided Actionable Recourse</p>

<p>Authors: Jayanth Yetukuri, Ian Hardy, Yang Liu</p>

<p>DOI: https://doi.org/10.1145/3600211.3604708</p>

<p>Year: 2023</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Artificial Intelligence / Human-Centered Computing</p>

<p>Subdomain/Topic: Actionable Recourse, User Preferences in ML Explanations</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 92</p>

<p>Operationalization Score: 95</p>

<p>Contains Definition of Actionability: Yes (implicit, user-preference-centered)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes (UP-AR optimization &amp; workflow)</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual with empirical evaluation</p>

<p>Study Context: Actionable recourse in ML decision-making across domains such as credit, hiring, insurance, and criminal justice</p>

<p>Geographic/Institutional Context: University of California, Santa Cruz; U.S.</p>

<p>Target Users/Stakeholders: End-users affected by ML decisions (e.g., loan applicants), ML system designers</p>

<p>Primary Contribution Type: Method/Framework Proposal with Empirical Validation</p>

<p>CL: Yes — “communicating in terms of preference scores… improves the explainability of a recourse generation mechanism” (p.1)</p>

<p>CR: Yes — “actionability… centered explicitly around individual preferences… may not necessarily be equally actionable” (p.1)</p>

<p>FE: Yes — “feasible action set… actionable by Alice” (p.1)</p>

<p>TI: Partial — timeliness not a primary dimension, but operational efficiency is addressed</p>

<p>EX: Yes — “preference scores… improves the explainability of a recourse generation mechanism” (p.1)</p>

<p>GA: Yes — goal alignment with user’s own constraints and desires (p.1–2)</p>

<p>Reason if Not Eligible: n/a</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Towards User Guided Actionable Recourse  </p>

<p><strong>Authors:</strong>  </p>

<p>Jayanth Yetukuri, Ian Hardy, Yang Liu  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1145/3600211.3604708  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Artificial Intelligence / Human-Centered Computing  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Actionable Recourse, User Preferences in ML Explanations  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the challenge of making ML-generated recourse actionable for individuals adversely affected by automated decisions in domains such as lending, hiring, insurance, and criminal justice. It critiques existing methods for ignoring individual user preferences, proposing a method to integrate them directly into the recourse generation process.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of California, Santa Cruz; U.S.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>End-users denied desired outcomes by ML systems; system designers and policymakers interested in trustworthy, user-centered AI.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework and algorithm development with empirical evaluation across multiple datasets.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Method/Framework Proposal with Empirical Validation  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors introduce <strong>User Preferred Actionable Recourse (UP-AR)</strong>, a novel method for generating actionable recourse that incorporates explicit user preferences into the optimization process. They argue that existing actionable recourse (AR) approaches prioritize technical efficiency (e.g., proximity, sparsity, cost) but often ignore individual feasibility rooted in user constraints and desires. UP-AR captures preferences in three forms — scoring continuous features, bounding feature values, and ranking categorical features — and embeds them as soft and hard constraints in a gradient-based optimization framework. The approach is validated empirically across credit, income, and criminal recidivism datasets, showing better adherence to user preferences (lower pRMSE) and competitive or superior performance on traditional AR metrics. The authors emphasize that tailoring recourse to user-specific feasibility increases trust, explainability, and adoption.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is defined implicitly as the <strong>viability of taking a suggested action</strong> within the constraints and preferences of the individual. It is user-centered — what is actionable for one person may not be for another — and includes both universal feasibility constraints (e.g., immutable features) and local feasibility constraints (personal reluctances or capacities).  </p>

<blockquote>
  <p>“Actionability… is centered explicitly around individual preferences, and similar recourses… may not necessarily be equally actionable” (p.1)  </p>
</blockquote>

<blockquote>
  <p>“AR aims to provide… a feasible action set which is both actionable by Alice and… as low-cost [as possible]” (p.1)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Alignment with individual user constraints and desires (hard and soft rules)</p></li>
<li><p>Ability to operationalize within user’s own cost and effort parameters</p></li>
<li><p>Feasibility in practice (e.g., avoiding impossible or undesirable feature changes)</p></li>
<li><p>Explainability of why the action is suggested and how it fits user preferences</p></li>
<li><p>Personalization beyond general feasibility rules</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name:</strong> User Preferred Actionable Recourse (UP-AR)  </p></li>
<li><p><strong>Methods/Levers:</strong> Gradient-based iterative optimization weighted by user preference scores; temperature scaling for categorical action frequency; cost correction to remove redundant steps.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Elicit three types of preferences (scoring, bounding, ranking) from the user.  </p>

<p> 2. Embed these as constraints in optimization.  </p>

<p> 3. Generate candidate recourse via stochastic gradient-based updates informed by user preference-weighted costs.  </p>

<p> 4. Apply redundancy and cost correction to finalize recourse.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Percentile shift cost function; pRMSE to evaluate preference adherence; traditional AR metrics (success rate, redundancy, sparsity, proximity).  </p></li>
<li><p><strong>Implementation Context:</strong> Credit lending, income prediction, recidivism risk prediction.  </p></li>
</ul>

<blockquote>
  <p>“We start by enabling Alice to provide three types of user preferences… We embed them into an optimization function to guide the recourse generation mechanism” (p.2)  </p>
</blockquote>

<blockquote>
  <p>“The proposed method minimizes the cost of a recourse weighted by Γᵢ for all actionable features” (p.3)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — user preference scores increase explainability (p.1)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — recourse tailored to individual user profile (p.1–2)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — constraints ensure recommendations are viable for that user (p.1–3)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — efficiency in generation is discussed, but timeliness as a decision-making window is not explicit  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — preference-based reasoning improves explainability (p.1)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — recourse aligned with user’s stated objectives (p.1–2)  </p></li>
<li><p><strong>Other Dimensions:</strong> Diversity only as secondary contrast to preference tailoring  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Builds on <strong>Actionable Recourse (AR)</strong> as per Ustun et al. (2019)  </p></li>
<li><p>Local feasibility concept from Mahajan et al. (2019)  </p></li>
<li><p>Preference elicitation parallels human-in-the-loop approaches (De Toni et al., 2022)  </p></li>
<li><p>Optimization inspired by gradient-based adversarial example generation  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>pRMSE between desired and achieved feature cost proportions  </p></li>
<li><p>Constraint violations (lower is better)  </p></li>
<li><p>Redundancy (steps that don’t affect outcome)  </p></li>
<li><p>Sparsity (number of features changed)  </p></li>
<li><p>Proximity (l2 distance from original point)  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Ignoring user-specific constraints; reliance on universal cost functions; high redundancy; expensive categorical changes  </p></li>
<li><p><strong>Enablers:</strong> Explicit preference capture; flexible optimization accommodating hard/soft constraints; cost correction  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The authors note most AR literature focuses on universal feasibility and cost minimization, sometimes adding diversity to hedge against unknown preferences. UP-AR directly incorporates known preferences, going beyond diversity-based approaches by personalizing the optimization process.</p>

<hr />

<h2>Summary</h2>

<p>This paper reframes <strong>actionability</strong> in ML recourse as inherently <strong>user-specific</strong> and <strong>preference-driven</strong>, arguing that what is “doable” varies across individuals with identical profiles. The proposed UP-AR framework operationalizes this view by eliciting explicit user preferences in three structured forms and embedding them into a gradient-based recourse generation process. By weighting feature changes according to these preferences and applying redundancy/cost correction, UP-AR improves alignment between suggested actions and user feasibility, outperforming existing methods on preference adherence and maintaining strong results on traditional AR metrics. This personalized approach enhances trust and explainability, and positions actionability as a function of both model mechanics and user-centered feasibility constraints.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Strong, explicit integration of user-centered definition of actionability with clear features and metrics.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Detailed algorithm and empirical workflow directly aimed at achieving actionability.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Actionability… is centered explicitly around individual preferences…” (p.1)  </p></li>
<li><p>“We start by enabling Alice to provide three types of user preferences… embed them into an optimization function…” (p.2)  </p></li>
<li><p>“Communicating in terms of preference scores… improves the explainability of a recourse generation mechanism” (p.1)  </p></li>
<li><p>“The proposed method minimizes the cost of a recourse weighted by Γᵢ for all actionable features” (p.3)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Ustun et al. (2019) — Actionable Recourse in Linear Classification  </p></li>
<li><p>Mahajan et al. (2019) — Local Feasibility  </p></li>
<li><p>De Toni et al. (2022) — Human-in-the-loop preference elicitation  </p></li>
<li><p>Wachter et al. (2017) — Counterfactual Explanations  </p></li>
<li><p>Poyiadzi et al. (2020) — FACE method</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Towards an Extensible Web Usage Mining Framework for Actionable Knowledge  </p>

<p>Authors: N. Pushpalatha, S. Sai Satyanarayana Reddy  </p>

<p>DOI: n/a  </p>

<p>Year: 2017  </p>

<p>Publication Type: Conference Paper  </p>

<p>Discipline/Domain: Computer Science / Data Mining  </p>

<p>Subdomain/Topic: Web Usage Mining, Actionable Knowledge, Fuzzy Clustering  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 78  </p>

<p>Operationalization Score: 82  </p>

<p>Contains Definition of Actionability: Implicit  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (XWUMF)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual + Experimental (Prototype implementation)  </p>

<p>Study Context: Web log analysis for user behaviour and business intelligence  </p>

<p>Geographic/Institutional Context: India (JNTU Hyderabad, Vardhaman College of Engineering)  </p>

<p>Target Users/Stakeholders: Businesses, Web Analysts, Decision-Makers  </p>

<p>Primary Contribution Type: Framework and Algorithm Proposal (XWUMF, SWUM)  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Partial  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Towards an Extensible Web Usage Mining Framework for Actionable Knowledge  </p>

<p><strong>Authors:</strong>  </p>

<p>N. Pushpalatha, S. Sai Satyanarayana Reddy  </p>

<p><strong>DOI:</strong>  </p>

<p>n/a  </p>

<p><strong>Year:</strong>  </p>

<p>2017  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference Paper  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Data Mining  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Web Usage Mining, Actionable Knowledge, Fuzzy Clustering  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The study focuses on developing a flexible, extensible web usage mining framework (XWUMF) to transform raw web log data into actionable knowledge that supports business intelligence and strategic decision-making.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>India (JNTU Hyderabad, Vardhaman College of Engineering)  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Businesses, Web Analysts, Decision-Makers  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual + Experimental (Prototype implementation with empirical evaluation)  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework and Algorithm Proposal (XWUMF, SWUM)  </p>

<h2>General Summary of the Paper</h2>

<p>The paper introduces the eXtensible Web Usage Mining Framework (XWUMF) designed to process web log data using a hybrid approach of fuzzy clustering and user behaviour analysis. This extensible architecture accommodates new algorithms and supports personalized analysis settings. A core contribution is the Sequential Web Usage Miner (SWUM) algorithm, which identifies user patterns from sequential web logs using minimum time and minimum confidence thresholds. The prototype implementation demonstrated the ability to extract patterns that, when interpreted by domain experts, yield actionable knowledge for businesses. Empirical results from four datasets (one real, three synthetic) highlight the framework’s efficiency in execution time and memory usage.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>The authors implicitly define actionability as the transformation of web usage patterns into “business intelligence” that supports expert decision-making and improves customer-centric strategies.</p>

<blockquote>
  <p>“The patterns when interpreted by domain experts can result in business intelligence.” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“Our empirical results revealed that the framework helps in discovering actionable knowledge.” (p. 1)  </p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Derives from <strong>meaningful usage patterns</strong> that reflect actual user behaviour.  </p></li>
<li><p>Must be interpretable by <strong>domain experts</strong> to support decision-making.  </p></li>
<li><p>Should enable <strong>customer-centric strategies</strong> in competitive environments.  </p></li>
<li><p>Requires <strong>quality thresholds</strong> (MinTime, MinConfidence) to ensure reliability of patterns.</p></li>
</ul>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> XWUMF (eXtensible Web Usage Mining Framework)  </p></li>
<li><p><strong>Methods/Levers:</strong> Hybrid fuzzy clustering + user behaviour analysis; sequential mining with quality thresholds.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Pre-processing → Fuzzy clustering → Usage mining → Pattern discovery → Pattern analysis → Business intelligence.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Execution time, memory usage; MinTime and MinConfidence thresholds.  </p></li>
<li><p><strong>Implementation Context:</strong> Tested on WDC dataset + 3 synthetic datasets.  </p></li>
</ul>

<blockquote>
  <p>“The framework supports a hybrid approach which can have fuzzy clustering techniques and web mining techniques working together…” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“Sequential Web Usage Miner… generates patterns that reflect user behaviour.” (p. 3)  </p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – Patterns must be interpretable by domain experts.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – Patterns tied to customer behaviour for strategic business use.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – Extensible design allows integration of algorithms suitable for different domains.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial – Execution time evaluated, but real-time capability not central.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial – Domain expert interpretation required; not fully automated explainability.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – Focused on customer-centric business intelligence.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Extensibility, personalization, performance efficiency.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Business intelligence theory (data-to-decision processes)  </p></li>
<li><p>Web usage mining and fuzzy logic principles  </p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Execution time  </p></li>
<li><p>Memory usage  </p></li>
<li><p>Minimum time threshold (MinTime)  </p></li>
<li><p>Minimum confidence threshold (MinConfidence)</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Domain dependence for interpretation; quality of raw web logs; computational constraints.  </p></li>
<li><p><strong>Enablers:</strong> Extensible framework; hybrid methodology; performance tuning via parameters.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>The authors situate their work in the context of prior research in fuzzy logic, neural networks, case-based reasoning, and semantic web mining, noting that most approaches are domain-specific and lack extensibility for future technologies.</p>

<h2>Summary</h2>

<p>Pushpalatha and Reddy (2017) propose XWUMF, an extensible, hybrid framework for mining actionable knowledge from web usage logs. Actionability is understood as the extraction of patterns that can be interpreted by domain experts to produce customer-centric business intelligence. The Sequential Web Usage Miner algorithm operationalizes actionability by filtering and validating patterns based on statistical thresholds. Evaluated through execution time and memory usage on multiple datasets, the framework is positioned as adaptable, scalable, and domain-agnostic, with the potential to support strategic decision-making across sectors.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 78 – Strong implicit definition and explicit feature linkages, but lacking formal conceptual definition.  </p></li>
<li><p><strong>Operationalization Score:</strong> 82 – Clear operational workflow and algorithm with performance metrics; however, limited domain application examples.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“The patterns when interpreted by domain experts can result in business intelligence.” (p. 1)  </p></li>
<li><p>“The framework supports a hybrid approach which can have fuzzy clustering techniques and web mining techniques working together…” (p. 2)  </p></li>
<li><p>“Sequential Web Usage Miner… generates patterns that reflect user behaviour.” (p. 3)  </p></li>
<li><p>“Our empirical results revealed that the framework helps in discovering actionable knowledge.” (p. 1)  </p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Lin &amp; Hong (2013) – Fuzzy web mining survey  </p></li>
<li><p>He (2013) – Case-based reasoning + text mining for UX improvement  </p></li>
<li><p>Abello et al. (2015) – Semantic web for OLAP exploration</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Actionable Recommendations in the Bright Futures Child Health Supervision Guidelines  </p>

<p>Authors: S.M.E. Finnell, J.L. Stanton, S.M. Downs  </p>

<p>DOI: http://dx.doi.org/10.4338/ACI-2014-02-RA-0012  </p>

<p>Year: 2014  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Clinical Informatics / Pediatrics  </p>

<p>Subdomain/Topic: Pediatric preventive care guidelines, clinical decision support, guideline implementability  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 88  </p>

<p>Operationalization Score: 80  </p>

<p>Contains Definition of Actionability: Yes (explicit via GLIA criteria)  </p>

<p>Contains Systematic Features/Dimensions: Yes (decidability, executability)  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: No  </p>

<p>Contains Framework/Model: Yes (Service Interval Diagram, GLIA)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Qualitative (guideline content analysis)  </p>

<p>Study Context: Evaluation of Bright Futures pediatric preventive care guideline for computer implementation  </p>

<p>Geographic/Institutional Context: United States; Indiana University School of Medicine / Regenstrief Institute  </p>

<p>Target Users/Stakeholders: Pediatricians, clinical decision support developers, public health agencies  </p>

<p>Primary Contribution Type: Conceptual and methodological assessment  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Partial  </p>

<p>TI: No  </p>

<p>EX: Partial  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Actionable Recommendations in the Bright Futures Child Health Supervision Guidelines  </p>

<p><strong>Authors:</strong>  </p>

<p>S.M.E. Finnell, J.L. Stanton, S.M. Downs  </p>

<p><strong>DOI:</strong>  </p>

<p>http://dx.doi.org/10.4338/ACI-2014-02-RA-0012  </p>

<p><strong>Year:</strong>  </p>

<p>2014  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Clinical Informatics / Pediatrics  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Pediatric preventive care guidelines, clinical decision support, guideline implementability  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>Bright Futures is the most widely accepted pediatric preventive health care guideline in the U.S., organized by well-child visits from birth to age 21. The growing use of electronic health record systems creates demand for computer-implementable guidelines. The authors assess how many Bright Futures recommendations are “actionable” using formal criteria from the GuideLine Implementability Appraisal v2.0 (GLIA), focusing on decidability and executability.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>United States; Indiana University School of Medicine / Regenstrief Institute  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Pediatricians, clinical decision support developers, public health agencies  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Qualitative (guideline content analysis)  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual and methodological assessment  </p>

<h2>General Summary of the Paper</h2>

<p>This study evaluates the Bright Futures pediatric preventive care guidelines to determine their suitability for computer implementation in electronic health records. The authors consolidated 2,161 action statements into 245 discrete recommendations and assessed each for “actionability” using GLIA’s decidability and executability criteria. Only 52 recommendations (21%) met both criteria, with most falling under screening or injury prevention; few anticipatory guidance topics (e.g., nutrition, lifestyle) were actionable, and none related to discipline, family function, or mental health qualified. The authors propose a Service Interval Diagram (SID) to represent actionable recommendations across continuous age intervals, enabling flexible application regardless of missed visits. They conclude substantial revisions are needed to make Bright Futures fully computer-implementable.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionability is explicitly defined through GLIA as requiring:</p>

<ul>
<li><p><strong>Decidability</strong>: Clear specification of the conditions under which to apply a recommendation.  </p></li>
<li><p><strong>Executability</strong>: Specific, unambiguous, detailed description of what action to take.  </p></li>
</ul>

<blockquote>
  <p>“Actionable recommendation statements are both decidable (…clinical circumstances… clearly enough…) and executable (…action… stated specifically and unambiguously)” (p. 652)  </p>
</blockquote>

<blockquote>
  <p>“It is impossible to create computer implementable decision rules if the guideline statements are vague on the decidability and executability criteria” (p. 653)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Precise conditions for applicability (decidability)  </p></li>
<li><p>Specific, detailed, unambiguous action steps (executability)  </p></li>
<li><p>Consistency in recommendation wording  </p></li>
<li><p>Potential adaptation to continuous age-based intervals for missed or delayed visits  </p></li>
</ul>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> GuideLine Implementability Appraisal (GLIA) v2.0; Service Interval Diagram (SID)  </p></li>
<li><p><strong>Methods/Levers:</strong> Consolidation of action statements, GLIA-based assessment, representation of recommendations by continuous age interval  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Consolidate duplicate and fragmented actions into discrete recommendations  </p>

<p> 2. Apply decidability criterion first; if met, apply executability  </p>

<p> 3. Develop SID to map recommendations across ages  </p></li>
<li><p><strong>Data &amp; Measures:</strong> 2,161 Bright Futures actions; reduced to 245 recommendations; 52 actionable  </p></li>
<li><p><strong>Implementation Context:</strong> Pediatric preventive care; EHR-based clinical decision support  </p></li>
</ul>

<blockquote>
  <p>“The SID spans… from birth to 21 years… represents the appropriate time for delivering services as a continuous interval” (p. 654)  </p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — clarity in conditions and actions is essential.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — recommendations should be relevant to specific ages and contexts.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — feasibility implied but not systematically assessed.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No explicit link to actionability.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — some detail provided, but not uniformly.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — linked indirectly via alignment with preventive care objectives.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> None beyond GLIA’s standard eight dimensions.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>GLIA v2.0 (Shiffman et al., 2005) for implementability assessment  </p></li>
<li><p>CDC immunization schedule concept for SID format analogy  </p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Meets GLIA decidability and executability criteria  </p></li>
<li><p>Count and proportion of recommendations deemed actionable  </p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Vague recommendations lacking specificity  </p>

<p> - Organization by visit rather than age interval  </p>

<p> - Inconsistent wording across visits  </p>

<p> - Lack of detail for sensitive topics (e.g., mental health)  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Clear, specific age-based criteria  </p>

<p> - Standardized, detailed action descriptions  </p>

<p> - Consolidation of redundant actions  </p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Authors build on prior GLIA applications in multiple clinical domains and extend the method to pediatric preventive guidelines. They also draw from CDC scheduling models to propose the SID as an implementation aid.</p>

<h2>Summary</h2>

<p>The paper provides a rigorous, criteria-based evaluation of Bright Futures guidelines’ actionability, focusing on GLIA’s decidability and executability dimensions. Only 21% of recommendations met these criteria, primarily in screening and injury prevention. Many anticipatory guidance topics were too vague or inconsistent for computer implementation. The authors operationalize actionability through systematic consolidation, GLIA-based evaluation, and the novel Service Interval Diagram to support flexible, age-based application. Their work underscores the need for standardized, detailed, and consistently worded recommendations to enable effective clinical decision support integration in pediatric preventive care.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 — Explicit definition of actionability via GLIA; comprehensive application to all recommendations; strong conceptual framing.  </p></li>
<li><p><strong>Operationalization Score:</strong> 80 — Clear process for assessing and representing actionability; SID offers tangible method, though not fully validated in implementation.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Actionable recommendation statements are both decidable… and executable…” (p. 652)  </p></li>
<li><p>“It is impossible to create computer implementable decision rules if the guideline statements are vague on the decidability and executability criteria” (p. 653)  </p></li>
<li><p>“The SID spans… from birth to 21 years… represents the appropriate time for delivering services as a continuous interval” (p. 654)  </p></li>
<li><p>“Only 52 (21%) meet criteria for actionability…” (p. 657)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Shiffman RN et al. (2005) on GLIA  </p></li>
<li><p>CDC immunization schedules as a model for SID  </p></li>
<li><p>Multiple GLIA applications in other specialties (Hill et al., Peleg &amp; Garber, Nagler et al., van Dijk et al.)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: The Heuristic Uses of Four 'Knows' for Managing Knowledge in Education</p>

<p>Authors: Chung Hong Tam</p>

<p>DOI: n/a</p>

<p>Year: n/a</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Education / Knowledge Management</p>

<p>Subdomain/Topic: Heuristic frameworks for knowledge management in educational contexts</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 92</p>

<p>Operationalization Score: 95</p>

<p>Contains Definition of Actionability: Yes (implicit and explicit via “relevant or actionable knowledge” in Know-How cycle)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual with applied case discussion</p>

<p>Study Context: Knowledge Management in schools and “Knowledge Community” projects (Hong Kong and international collaborative learning projects)</p>

<p>Geographic/Institutional Context: Hong Kong (primary/secondary education), cross-national projects</p>

<p>Target Users/Stakeholders: Teachers, school leaders, educational policymakers, students</p>

<p>Primary Contribution Type: Conceptual framework revision and application to education</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Partial</p>

<p>EX: Partial</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: n/a</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>The Heuristic Uses of Four 'Knows' for Managing Knowledge in Education</p>

<p><strong>Authors:</strong>  </p>

<p>Chung Hong Tam</p>

<p><strong>DOI:</strong>  </p>

<p>n/a</p>

<p><strong>Year:</strong>  </p>

<p>n/a</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Education / Knowledge Management</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Heuristic frameworks for knowledge management in educational contexts</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the persistent confusion between knowledge management (KM) and information management (IM) in the education sector, proposing a revision of Lundvall and Johnson’s (1994) “Four Knows” framework—Know-Why, Know-Who, Know-What, and Know-How—specifically for educational contexts. It situates these within the Knowledge Community (KC) concept, informed by Hong Kong and international collaborative projects.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Hong Kong schools, with examples from global collaborative projects.</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Teachers, school leaders, education policymakers, students.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual with applied case discussion.</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework revision and operationalization for education.</p>

<h2>General Summary of the Paper</h2>

<p>This paper revises the “Four Knows” (Know-Why, Know-Who, Know-What, Know-How) framework to address the specific needs and challenges of managing knowledge in education. It differentiates KM from IM and emphasizes defining knowledge attributes and drivers before project initiation. The revised Four Knows clarify the purposes (Know-Why), roles (Know-Who), content and pedagogical needs (Know-What), and complete KM cycle from creation to dissemination (Know-How). Drawing on the “Knowledge Community” (KC) approach, the paper describes how these dimensions operate in school contexts, detailing barriers, enablers, and governance strategies. It provides a six-step operational process for KM and discusses issues of sustainability, codification, quality control, and resource allocation.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as transforming knowledge into “relevant or actionable knowledge” for the beneficiary, achieved through the Know-How cycle. The revised Know-How entails creating, capturing, codifying, storing, managing, and disseminating knowledge in formats and contexts that enable others to use it effectively.</p>

<blockquote>
  <p>“Know-How…transforms the knowledge creator’s knowledge into the relevant or actionable knowledge of the beneficiary” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“Knowledge must be placed in context so that it is actionable” (p. 5)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Clear purpose and value for decision-making (Know-Why)</p></li>
<li><p>Defined stakeholders and governance of roles/responsibilities (Know-Who)</p></li>
<li><p>Adequate, relevant, and pedagogically aligned content (Know-What)</p></li>
<li><p>Structured processes for transforming and delivering knowledge so it can be used (Know-How)</p></li>
<li><p>Codification into accessible, usable formats</p></li>
<li><p>Timely updating and quality assurance</p></li>
<li><p>Contextualization to user needs</p></li>
<li><p>Alignment with institutional goals</p></li>
</ul>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Revised Four Knows; Knowledge Community (KC)</p></li>
<li><p><strong>Methods/Levers:</strong> Six-step KM cycle: create, capture, codify, store, manage, disseminate</p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify drivers, assign roles, define content needs, follow KM cycle with codification and governance</p></li>
<li><p><strong>Data &amp; Measures:</strong> Repository content quality, user engagement, avoidance of duplication, alignment with learning objectives</p></li>
<li><p><strong>Implementation Context:</strong> Applied in Hong Kong primary/secondary schools and cross-national collaborative projects</p></li>
</ul>

<blockquote>
  <p>“Six steps… create, capture, codify, store, manage, disseminate” (p. 5)  </p>
</blockquote>

<blockquote>
  <p>“Codification strategies to ensure all subject knowledge… can be transferred to the right person” (p. 3)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — “Define KM clearly at the early stage to understand its contours and challenges” (p. 1)</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — “Knowledge must be placed in context so that it is actionable” (p. 5)</p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — “Education strategies should manage resource allocation so that variation in quality… can be avoided” (p. 4)</p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Implied in need for timely updating and dissemination</p></li>
<li><p><strong>EX (Explainability):</strong> Partial — Codification into understandable formats is emphasized, but not explicitly framed as explainability</p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — KM tied to school/learning community objectives</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Sustainability, governance, stakeholder engagement</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Lundvall &amp; Johnson’s (1994) Four Knows</p></li>
<li><p>Wenger’s (1998) Communities of Practice</p></li>
<li><p>Tacit/explicit knowledge distinction (Polanyi, 1958)</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Repository usability and access</p></li>
<li><p>Quality and relevance of stored materials</p></li>
<li><p>Evidence of knowledge reuse and sharing</p></li>
<li><p>Reduction in duplication of materials</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Role ambiguity; lack of codification strategies; resource constraints; poor quality content; reluctance to share knowledge; duplication; inadequate governance</p></li>
<li><p><strong>Enablers:</strong> Clear definition of KM; role clarity; codification; knowledge-sharing culture; adequate infrastructure; leadership support</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions the revised Four Knows as a bridge between KM theory and educational practice, enhancing Lundvall &amp; Johnson’s original model with operational detail, stakeholder governance, and application to school-based knowledge communities.</p>

<h2>Summary</h2>

<p>The paper reframes the Four Knows—Know-Why, Know-Who, Know-What, and Know-How—for educational KM, making actionability central. Actionable knowledge is that which is relevant to the beneficiary’s context, transformed through structured processes into usable formats. The Know-How cycle operationalizes this via six steps: creation, capture, codification, storage, management, and dissemination. Each “Know” adds a dimension to actionability: purpose and drivers (Why), stakeholder roles and governance (Who), pedagogical content (What), and process for transformation and delivery (How). Barriers such as unclear roles, duplication, and poor codification are countered by enablers like strong leadership, codification strategies, and knowledge-sharing culture. The work is notable for its integration of conceptual clarity with applied, process-level operationalization in school-based and global learning communities.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Strong conceptual framing of actionability via “relevant or actionable knowledge” and comprehensive features tied to actionability.</p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Detailed, step-by-step KM process explicitly aimed at achieving actionable knowledge.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Know-How…transforms the knowledge creator’s knowledge into the relevant or actionable knowledge of the beneficiary” (p. 1)  </p></li>
<li><p>“Knowledge must be placed in context so that it is actionable” (p. 5)  </p></li>
<li><p>“Six steps… create, capture, codify, store, manage, disseminate” (p. 5)  </p></li>
<li><p>“Codification strategies to ensure all subject knowledge… can be transferred to the right person” (p. 3)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Lundvall &amp; Johnson (1994) — original Four Knows</p></li>
<li><p>Wenger (1998) — Communities of Practice</p></li>
<li><p>Polanyi (1958) — tacit knowledge concept</p></li>
<li><p>Turban et al. (2002) — KM processes</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: The Emerging Role of Global Situational Awareness 2.0 Resources in Disaster Response</p>

<p>Authors: Carl Taylor</p>

<p>DOI: 10.1117/12.853113</p>

<p>Year: 2010</p>

<p>Publication Type: Conference Proceedings</p>

<p>Discipline/Domain: Public Health / Disaster Response</p>

<p>Subdomain/Topic: Situational Awareness, Health Informatics, Emergency Management</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 85</p>

<p>Operationalization Score: 90</p>

<p>Contains Definition of Actionability: Yes (implicit – situational awareness as acquiring relevant event data and translating it into actionable knowledge)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes (Situational Awareness 2.0 concept)</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual / Use-Case Review</p>

<p>Study Context: Disaster response with public health and medical integration</p>

<p>Geographic/Institutional Context: Global; examples from Haiti, Chile, UK; U.S.-based institutional perspective</p>

<p>Target Users/Stakeholders: Public health officials, disaster responders, healthcare providers, NGOs, government agencies</p>

<p>Primary Contribution Type: Conceptual framework with practical technology examples</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Yes</p>

<p>EX: Partial</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>The Emerging Role of Global Situational Awareness 2.0 Resources in Disaster Response</p>

<p><strong>Authors:</strong>  </p>

<p>Carl Taylor</p>

<p><strong>DOI:</strong>  </p>

<p>10.1117/12.853113</p>

<p><strong>Year:</strong>  </p>

<p>2010</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference Proceedings</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Public Health / Disaster Response</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Situational Awareness, Health Informatics, Emergency Management</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the integration of emerging web-based, open-source, and social networking tools into public health disaster response systems to enhance situational awareness. It critiques traditional hospital-centric approaches, advocating for community- and patient-centric models that leverage multi-source data for actionable disaster management.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Global application with examples from Haiti, Chile, the UK; institutional perspective from the U.S. (University of South Alabama, National Center for the Study of Disaster Medical Response).</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Public health officials, emergency managers, healthcare providers, NGOs, governmental and military agencies.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual / Use-case review</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework and operational examples</p>

<h2>General Summary of the Paper</h2>

<p>This paper presents “Situational Awareness 2.0” as a next-generation approach to disaster response, integrating patient- and community-centric data collection with multi-source, real-time analytics. It argues that traditional, hospital-centric situational awareness tools fail to capture the full scope of community needs during crises. Using examples from Haiti’s 2010 earthquake, the author demonstrates how open-source mapping platforms, mobile reporting tools, and social networking can create actionable knowledge for disaster responders. The framework emphasizes linking situational awareness with transactional response capabilities to enable timely, relevant, and feasible interventions. The paper also categorizes data sources into validated/structured, unvalidated/structured, and unvalidated/unstructured, outlining their respective roles and limitations.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Situational awareness is described as “acquiring all relevant information about the event and translating that information into actionable knowledge” (p. 1). Actionability in this context means enabling responders to move from passive observation to active intervention, informed by timely, context-rich, and multi-source data.</p>

<blockquote>
  <p>“True situational awareness means acquiring all relevant information about the event and translating that information into actionable knowledge.” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“Awareness without transactional capability may allow you to view the event but only as a mostly passive bystander rather than an intervening force of assistance.” (p. 2)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Inclusion of both community and patient-centric data  </p></li>
<li><p>Ability to foresee developments (“see around corners”)  </p></li>
<li><p>Integration of multi-source data (structured/unstructured, validated/unvalidated)  </p></li>
<li><p>Real-time adaptability to update strategies  </p></li>
<li><p>Linkage to response mechanisms (transactional capacity)  </p></li>
<li><p>Contextual relevance to affected populations  </p></li>
<li><p>Engagement with social networks and emergent coherence  </p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Situational Awareness 2.0  </p></li>
<li><p><strong>Methods/Levers:</strong> Integration of open-source mapping (Ushahidi, Google Evolve), SMS reporting, patient health records, IVR systems, crowdsourced intelligence, social networking collaboration hubs  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Pre-event modeling; multi-channel data collection; community/patient tracking; rapid dissemination to responders; adaptive strategy updates  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Structured hospital data, structured mobile survey data, unstructured social media/txt/blog data; tracking of comorbidities, supply chain status, infrastructure damage  </p></li>
<li><p><strong>Implementation Context:</strong> Disaster response scenarios (H1N1, Haiti earthquake)  </p></li>
</ul>

<blockquote>
  <p>“With appropriate integration of situational awareness 2.0 tools, public health can both manage the community needs for care and those of specific patients.” (p. 5)  </p>
</blockquote>

<blockquote>
  <p>“Situational awareness (2.0) is a fundamental component of preparedness.” (p. 5)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – Clarity in data patterns is necessary for effective response (p. 7)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – Data must be relevant to community and patient context (p. 3–4)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – Tools must be usable under disaster constraints (low bandwidth, mobile access) (p. 4–5)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes – Real-time or near-real-time data critical (p. 4)  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial – Emphasis on understanding patterns but less on model transparency  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – Aligns awareness and response with public health mission (p. 2–3)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Emergent coherence, transactional capability</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Ashby’s Law of Requisite Variety  </p></li>
<li><p>Science 2.0 (Ben Shneiderman)  </p></li>
<li><p>Concepts of emergent coherence in social networks  </p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Ability to prioritize patients based on comorbidities and risk  </p></li>
<li><p>Surge capacity avoidance through patient diversion  </p></li>
<li><p>Accuracy and timeliness of data flows  </p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Overly hospital-centric approaches; fragmented data sources; unreliable/unvalidated data; bandwidth limitations  </p></li>
<li><p><strong>Enablers:</strong> Open-source/free tools; multi-modal data collection; social network engagement; pre-event modeling  </p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions itself as extending Science 2.0 concepts to disaster management, combining predictive modeling with collaborative, cross-disciplinary situational awareness tools.</p>

<h2>Summary</h2>

<p>Taylor’s paper reframes situational awareness as inherently linked to actionability, arguing that data must be transformed into interventions, not just observations. Situational Awareness 2.0 moves beyond hospital-centric models to integrate patient- and community-level data with global, multi-source intelligence. The author demonstrates this through the Haiti earthquake response, showing the value of combining validated structured data with unstructured social media and crowdsourced reports. Actionability here is defined by timeliness, relevance, feasibility, clarity, and goal alignment, with success contingent on transactional capability. The framework’s operationalization is well-developed, leveraging accessible, often open-source technologies, and emphasizing the importance of emergent social networks in disaster response.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 – Strong implicit definition of actionability, clear list of features linked to actionable knowledge, supported by case evidence.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 – Detailed processes, tools, and workflows directly tied to achieving actionability in real disaster contexts.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“True situational awareness means acquiring all relevant information about the event and translating that information into actionable knowledge.” (p. 1)  </p></li>
<li><p>“Awareness without transactional capability may allow you to view the event but only as a mostly passive bystander rather than an intervening force of assistance.” (p. 2)  </p></li>
<li><p>“With appropriate integration of situational awareness 2.0 tools, public health can both manage the community needs for care and those of specific patients.” (p. 5)  </p></li>
<li><p>“Situational awareness (2.0) is a fundamental component of preparedness.” (p. 5)  </p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Toner, E. (2009) Creating Situational Awareness: A Systems Approach  </p></li>
<li><p>Taylor &amp; Stephens (2009) Situational Awareness 2.0  </p></li>
<li><p>Patrick Meier &amp; Jen Ziemke (2010) Crisis Mapping  </p></li>
<li><p>Ben Shneiderman (Science 2.0 concepts)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: The assessment of urban eco-efficiency of Brazilian municipalities based on directional distance functions  </p>

<p>Authors: Andreia Zanella, Renata Oliveira  </p>

<p>DOI: 10.1108/JM2-11-2024-0369  </p>

<p>Year: 2025  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Urban Sustainability / Environmental Management  </p>

<p>Subdomain/Topic: Eco-efficiency assessment, Data Envelopment Analysis (DEA), Sustainable Development Goals (SDGs)  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes (implicit and explicit in “actionable insights” framing)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (Expanded Urban Eco-efficiency DEA-DDF model)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Quantitative (DEA with Directional Distance Function)  </p>

<p>Study Context: Urban eco-efficiency in large Brazilian municipalities (&gt;300k inhabitants)  </p>

<p>Geographic/Institutional Context: Brazil, Sustainable Cities Program (ICS-SDSN)  </p>

<p>Target Users/Stakeholders: Municipal policymakers, urban planners, environmental agencies  </p>

<p>Primary Contribution Type: Empirical assessment model and benchmarking tool for urban eco-efficiency  </p>

<p>CL: Yes – clarity in KPI definitions linked to actionability  </p>

<p>CR: Yes – contextual relevance tied to Brazilian urban and regional disparities  </p>

<p>FE: Yes – feasibility considered through realistic improvement scenarios and GDP constraint  </p>

<p>TI: Partial – scenarios consider current data but not explicit urgency thresholds  </p>

<p>EX: Yes – model explainability via indicator weights and peer benchmarking  </p>

<p>GA: Yes – alignment with SDGs and municipal sustainability goals  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>The assessment of urban eco-efficiency of Brazilian municipalities based on directional distance functions  </p>

<p><strong>Authors:</strong>  </p>

<p>Andreia Zanella, Renata Oliveira  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1108/JM2-11-2024-0369  </p>

<p><strong>Year:</strong>  </p>

<p>2025  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Urban Sustainability / Environmental Management  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Eco-efficiency assessment, DEA, Sustainable Development Goals  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>Evaluates eco-efficiency of Brazilian cities using SDG-linked KPIs, combining desirable and undesirable outputs in an expanded DEA-DDF model to generate actionable scenarios and benchmarks for municipal sustainability planning.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Brazil; Instituto Cidades Sustentáveis (ICS) and Sustainable Development Solutions Network (SDSN) data.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Municipal decision-makers, environmental managers, policy analysts.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative (DEA with Directional Distance Functions).  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Methodological innovation in urban eco-efficiency measurement and operational policy guidance tool.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This study develops and applies an optimization model based on Data Envelopment Analysis (DEA) and Directional Distance Functions (DDF) to assess the eco-efficiency of Brazil’s 90 largest municipalities. Using Sustainable Development Goals (SDG)-aligned KPIs, it integrates both desirable (e.g., water access, sewage coverage, conservation areas) and undesirable outputs (e.g., solid waste, CO₂ emissions, deforestation). The model explores three scenarios: (1) simultaneous improvement of desirable and undesirable indicators, (2) focus only on desirable outputs, and (3) focus only on reducing undesirable outputs. Results reveal significant regional disparities, with higher scores in the South and Southeast and lower scores in the North and Northeast. The model supports peer benchmarking and scenario-based improvement planning, offering actionable policy insights for targeted interventions.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as the ability to provide “actionable insights” to policymakers through eco-efficiency measurement that identifies strengths, weaknesses, peer examples, and tailored improvement scenarios.  </p>

<blockquote>
  <p>“The model specified can identify best practices and areas for targeted improvement, offering actionable insights to policymakers.” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“…highlights their specific strengths and weaknesses, providing decision-makers with alternative scenarios to explore potential improvements.” (p. 2)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Clear linkage to specific, measurable KPIs.</p></li>
<li><p>Ability to benchmark against high-performing peers.</p></li>
<li><p>Scenario-specific improvement pathways.</p></li>
<li><p>Alignment with SDG targets.</p></li>
<li><p>Interpretability via weight assignment to indicators.</p></li>
<li><p>Feasibility maintained by keeping GDP (wealth proxy) constant.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Expanded Urban Eco-efficiency Framework (DEA-DDF with SDG-linked KPIs).  </p></li>
<li><p><strong>Methods/Levers:</strong> DEA with directional distance functions; weight restrictions to ensure KPI relevance; scenario-based directional vectors.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Select 8 KPIs (inputs, desirable outputs, undesirable outputs) aligned with SDGs.  </p>

<p> 2. Collect municipal data (2019–2022) from ICS-SDSN.  </p>

<p> 3. Apply DEA-DDF model under weight constraints.  </p>

<p> 4. Run three improvement scenarios with fixed GDP per capita.  </p>

<p> 5. Identify peer cities for benchmarking.  </p>

<p> 6. Analyze indicator weights to detect strengths/weaknesses.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> GDP per capita, % water/sewage/waste collection, % conservation area, waste generation, CO₂ emissions, deforestation.  </p></li>
<li><p><strong>Implementation Context:</strong> Brazilian municipalities with &gt;300,000 inhabitants.  </p></li>
</ul>

<blockquote>
  <p>“…enables the reflection of alternative decision scenarios…providing actionable insights to support the adoption of sustainable practices…” (p. 8)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – KPIs precisely defined and linked to SDGs.  </p>

<p> &gt; “…enables local governments to prioritize their efforts effectively…” (p. 8)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – tailored to Brazilian regional disparities.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – keeps GDP constant to reflect realistic constraints.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial – scenarios reflect current data but no explicit urgency metric.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – indicator weights and peer benchmarking enhance interpretability.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – fully aligned with SDG targets.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Equity in service provision; environmental burden mitigation.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>WBCSD eco-efficiency principles.</p></li>
<li><p>Expanded eco-efficiency definition from Oliveira et al. (2017).</p></li>
<li><p>DEA literature on environmental performance with undesirable outputs (Chung et al., 1997; Seiford &amp; Zhu, 2002).</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>8 SDG-linked KPIs (input, desirable outputs, undesirable outputs).</p></li>
<li><p>Eco-efficiency scores from DEA-DDF model.</p></li>
<li><p>Peer similarity coefficients (λ values).</p></li>
<li><p>Scenario-specific performance differentials.</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Data variability and quality.  </p>

<p> - Regional inequalities in infrastructure and governance.  </p>

<p> - Environmental pressures in Amazonian cities.  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - SDG-aligned indicator framework.  </p>

<p> - Benchmarking culture.  </p>

<p> - Scenario-specific targeting of improvements.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on DEA-based eco-efficiency studies but is the first to apply multiple directional vectors to urban eco-efficiency in Brazil, incorporating both desirable and undesirable outputs and directly aligning with SDG monitoring.</p>

<hr />

<h2>Summary</h2>

<p>This paper operationalizes actionability in urban sustainability assessment through a DEA-DDF model that delivers interpretable, regionally relevant, and scenario-specific guidance for municipal decision-makers. By combining clear SDG-linked KPIs with benchmarking and scenario analysis, it enables targeted, feasible, and goal-aligned interventions. The work advances eco-efficiency measurement in Latin America by integrating undesirable outputs into the efficiency frontier and using weight restrictions to maintain indicator relevance, thereby producing actionable insights that are both data-driven and policy-oriented.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 — Strong conceptual clarity on actionability (via actionable insights framing), comprehensive feature set (clarity, contextual relevance, feasibility, explainability, goal alignment).  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Fully specified DEA-DDF operational workflow with real-world data, scenarios, and peer benchmarking tied to actionability.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“The model specified can identify best practices and areas for targeted improvement, offering actionable insights to policymakers.” (p. 1)  </p></li>
<li><p>“…highlighting specific strengths and weaknesses, providing decision-makers with alternative scenarios to explore potential improvements.” (p. 2)  </p></li>
<li><p>“…enables the reflection of alternative decision scenarios…providing actionable insights to support the adoption of sustainable practices…” (p. 8)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Oliveira et al. (2017, 2019, 2020) – Expanded eco-efficiency assessment methods.  </p></li>
<li><p>Chung et al. (1997) – Incorporating undesirable outputs in DEA.  </p></li>
<li><p>Seiford &amp; Zhu (2002) – Desirable input modeling.  </p></li>
<li><p>WBCSD (2000) – Eco-efficiency definition.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Telling stories: Exploring the relationship between myths and ecological wisdom  </p>

<p>Authors: Esther Eidinow  </p>

<p>DOI: 10.1016/j.landurbplan.2016.04.014  </p>

<p>Year: 2016  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Environmental Studies / Classics  </p>

<p>Subdomain/Topic: Myths, ecological wisdom, scenario planning  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 85  </p>

<p>Contains Definition of Actionability: Yes (implicitly through ecological wisdom and its actionable transmission)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (scenario planning as mechanism)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual / Theoretical synthesis with illustrative case studies  </p>

<p>Study Context: Interdisciplinary exploration linking classical mythology, indigenous knowledge, and environmental planning  </p>

<p>Geographic/Institutional Context: Global, with case studies from Greece, Indonesia, and Borneo; University of Nottingham  </p>

<p>Target Users/Stakeholders: Environmental planners, policymakers, indigenous communities, scholars  </p>

<p>Primary Contribution Type: Conceptual framework and methodological suggestion  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Partial  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Telling stories: Exploring the relationship between myths and ecological wisdom  </p>

<p><strong>Authors:</strong>  </p>

<p>Esther Eidinow  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1016/j.landurbplan.2016.04.014  </p>

<p><strong>Year:</strong>  </p>

<p>2016  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Environmental Studies / Classics  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Myths, ecological wisdom, scenario planning  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper bridges classical studies, indigenous ecological knowledge, and environmental planning to argue that myths can encapsulate and transmit both theoretical and practical ecological wisdom, making them vehicles for actionable environmental insight.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Global scope; cases from ancient Greece, Komodo Island (Indonesia), and Borneo. Author based at University of Nottingham.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Environmental planners, policymakers, indigenous communities, academics across humanities and environmental sciences.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual synthesis with illustrative historical and ethnographic case studies.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework linking myth-making with ecological wisdom and operational suggestion for scenario planning.  </p>

<h2>General Summary of the Paper</h2>

<p>This paper proposes that myths function as repositories and transmitters of ecological wisdom, integrating both theoretical (sophia) and practical (phronesis) knowledge. Drawing on Aristotelian categories of wisdom and cognitive research, Eidinow illustrates through case studies—from ancient Greek territorial myths to indigenous Komodo dragon kinship stories—how myths shape human–environment relations and provoke action. The paper argues for the strategic use of myth-making in contemporary environmental contexts, specifically through scenario planning, to integrate diverse knowledge systems without eroding their identities. Scenario planning is presented as a tool to create “new myths” that bridge disciplinary and cultural divides, fostering actionable ecological wisdom for urban and landscape planning.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>Actionability is framed through the lens of ecological wisdom as both theoretical ideas (sophia) and practical wisdom leading to effective action (phronesis). Myths are proposed as vehicles that embody, transmit, and provoke actionable knowledge, linking cultural values with practical environmental behavior.</p>

<blockquote>
  <p>“Myths… can provide a framework for… capturing ecological wisdom… [and] transmitting it as actionable knowledge” (p. 47)  </p>
</blockquote>

<blockquote>
  <p>“They are practical, they provoke action, and they shape our perception of the world” (p. 49)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Integration of theoretical and practical wisdom.</p></li>
<li><p>Embedding knowledge in culturally resonant narratives.</p></li>
<li><p>Ability to provoke context-relevant action.</p></li>
<li><p>Retention of multiple perspectives and plurality of narratives.</p></li>
<li><p>Connection to lived, practical experience and socio-political realities.</p></li>
</ul>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Myth-making; Scenario Planning.  </p></li>
<li><p><strong>Methods/Levers:</strong> Use of culturally embedded narratives; stakeholder engagement across knowledge systems.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify existing myths; preserve plurality; integrate via scenario planning; create “future histories” that bridge and stretch perspectives.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Narrative content, stakeholder perspectives, scenario quality metrics (informational vividness, ergonomic design, plausible unexpectedness).  </p></li>
<li><p><strong>Implementation Context:</strong> Multi-stakeholder environmental planning, integrating indigenous and scientific knowledge.  </p></li>
</ul>

<blockquote>
  <p>“Scenario-planning… offers a mechanism for creating new myths… facilitating the integration of multiple myths from different stakeholders” (p. 51)  </p>
</blockquote>

<blockquote>
  <p>“Scenarios… encapsulate and transmit new information… developing shared mental models… and stretching beyond current assumptions” (p. 51)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — scenarios must have “ergonomic design” and coherent sequence (p. 51).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — myths emerge from and reflect local ecological and socio-political contexts (p. 48–49).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — implied in practical wisdom but not systematically defined.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — responsiveness of myths to contemporary events noted (p. 48).  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — myths’ cultural logic and resonance explained via cognitive and aesthetic theory (p. 50).  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — aligning myths with ecological wisdom goals and integrated planning outcomes (p. 51).  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Multiplicity; flexibility; integration without dilution.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Aristotelian sophia and phronesis.  </p></li>
<li><p>Cognitive metaphor theory (Fauconnier &amp; Turner).  </p></li>
<li><p>Indigenous knowledge integration literature (Bohensky &amp; Maru, 2011).  </p></li>
<li><p>Scenario planning theory (Schwartz, Wack).</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Narrative’s ability to provoke action.  </p></li>
<li><p>Participant engagement and shared mental model formation in scenarios.  </p></li>
<li><p>Scenario attributes: vividness, coherence, plausible unexpectedness.</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Difficulty integrating diverse knowledge systems; risk of erasing local perspectives; dominant myths marginalizing others.  </p></li>
<li><p><strong>Enablers:</strong> Plurality of myths; culturally embedded narratives; scenario planning methodology.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Builds on Xiang’s (2014) ecological wisdom framework, expands by integrating classical and indigenous narrative traditions, and proposes operationalization via scenario planning to bridge theoretical-practical divide.</p>

<h2>Summary</h2>

<p>Eidinow positions myths as dual carriers of theoretical and practical ecological wisdom, capable of making environmental knowledge actionable. Myths’ cultural embeddedness enables them to provoke action, shape perception, and adapt to socio-political contexts. Drawing from case studies across time and geography, the paper emphasizes plurality, integration, and the retention of knowledge system identities. Scenario planning is proposed as a contemporary mechanism to generate “new myths” that bridge and stretch stakeholder perspectives, facilitating actionable ecological wisdom across disciplines. The approach reframes actionability as the interplay of narrative resonance, cultural legitimacy, and practical feasibility, offering both a conceptual and operational pathway for integrating ecological wisdom into environmental planning.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 — Strong conceptual clarity linking actionability to integrated theoretical/practical wisdom, explicit features identified, supported by cross-context examples.  </p></li>
<li><p><strong>Operationalization Score:</strong> 85 — Concrete mechanism (scenario planning) tied to actionability, with defined attributes for effectiveness; could be strengthened with empirical implementation data.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Myths… can provide a framework for… capturing ecological wisdom… [and] transmitting it as actionable knowledge” (p. 47)  </p></li>
<li><p>“They are practical, they provoke action, and they shape our perception of the world” (p. 49)  </p></li>
<li><p>“Scenario-planning… offers a mechanism for creating new myths… facilitating the integration of multiple myths from different stakeholders” (p. 51)  </p></li>
<li><p>“Scenarios… encapsulate and transmit new information… developing shared mental models… and stretching beyond current assumptions” (p. 51)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Xiang (2014) on ecological wisdom.  </p></li>
<li><p>Bohensky &amp; Maru (2011) on integrating indigenous and scientific knowledge.  </p></li>
<li><p>Schwartz (1996), Wack (1985a,b) on scenario planning.  </p></li>
<li><p>Schwartz &amp; Sharpe (2010) on practical wisdom.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Supporting school leadership decision making with holistic school analytics: Bridging the qualitative-quantitative divide using fuzzy-set qualitative comparative analysis  </p>

<p>Authors: Stylianos Sergis, Demetrios G. Sampson, Michail N. Giannakos  </p>

<p>DOI: https://doi.org/10.1016/j.chb.2018.06.016  </p>

<p>Year: 2018  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Educational Technology / School Leadership  </p>

<p>Subdomain/Topic: School Analytics, Educational Data Analytics, ICT in Education, fsQCA  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 88  </p>

<p>Contains Definition of Actionability: Yes (implicit and explicit in “actionable insights” context)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (School Analytics model)  </p>

<p>Operationalization Present: Yes (fsQCA methodology and configurations)  </p>

<p>Primary Methodology: Quantitative (fsQCA with validation protocols)  </p>

<p>Study Context: European K-12 schools; focus on fostering students’ digital skills through ICT  </p>

<p>Geographic/Institutional Context: Cross-European dataset (~3000 schools)  </p>

<p>Target Users/Stakeholders: School leaders, policymakers, educational researchers  </p>

<p>Primary Contribution Type: Conceptual model and applied methodological demonstration  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: No explicit link  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Supporting school leadership decision making with holistic school analytics: Bridging the qualitative-quantitative divide using fuzzy-set qualitative comparative analysis  </p>

<p><strong>Authors:</strong>  </p>

<p>Stylianos Sergis, Demetrios G. Sampson, Michail N. Giannakos  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1016/j.chb.2018.06.016  </p>

<p><strong>Year:</strong>  </p>

<p>2018  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Educational Technology / School Leadership  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>School Analytics, Educational Data Analytics, ICT in Education, fsQCA  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the challenge of enabling school leaders to make informed strategic decisions by leveraging holistic, multi-layered school data (micro, meso, macro). It focuses on how to generate actionable insights—specifically for enhancing students’ digital skills—using a combination of complexity theory, configuration theory, and fuzzy-set Qualitative Comparative Analysis (fsQCA).  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>European schools (~3000 schools across multiple countries)  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>School leaders, educational policymakers, educational researchers  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative (fsQCA applied to large-scale survey data, with contrarian analysis, predictive validity testing, and t-test verification)  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual model and methodological application  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This study develops and applies a <em>School Analytics</em> model for K-12 educational leadership decision-making, emphasizing the translation of complex school ecosystem data into actionable insights. The case study focuses on identifying conditions that foster students’ digital skills, drawing on survey data from almost 3000 European schools. Using fuzzy-set Qualitative Comparative Analysis (fsQCA), the authors uncover eight distinct configurations of school factors (leadership attitudes, teacher skills, infrastructure, pedagogy, culture, professional development, ICT use) that lead to high digital skills among students. The research bridges qualitative and quantitative approaches through complexity and configuration theories, validates findings via predictive testing and t-tests, and positions fsQCA as a promising analytical tool for educational decision support systems.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>The paper defines actionable insights as <strong>informative suggestions on what decisions need to be made</strong> to improve school performance, derived from complex data analysis that links school ecosystem factors to desired outcomes.</p>

<blockquote>
  <p>“...do not offer support for translating these needs into actionable insights (i.e., informative suggestions on ‘what decisions needs to be made’) for school improvement.” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“…could provide school leaders with actionable insights, in the form of school-wide informative suggestions for improvement…” (p. 3)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Based on comprehensive, holistic data across multiple school layers.</p></li>
<li><p>Identifies specific <em>configurations</em> of conditions, not just isolated factors.</p></li>
<li><p>Links directly to strategic goals (e.g., improving digital skills).</p></li>
<li><p>Supports targeted, context-aware interventions.</p></li>
<li><p>Validated through robust statistical and comparative analysis.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> School Analytics Model + fsQCA methodology  </p></li>
<li><p><strong>Methods/Levers:</strong> Complexity theory, configuration theory, fuzzy-set QCA, contrarian analysis, predictive validity, t-tests.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Define strategic goal (e.g., enhancing digital skills).  </p>

<p> 2. Identify and measure relevant school ecosystem factors.  </p>

<p> 3. Apply fsQCA to identify multiple sufficient configurations for desired outcomes.  </p>

<p> 4. Validate results through predictive testing and statistical comparisons.  </p>

<p> 5. Translate configurations into school-specific improvement pathways.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Multi-actor surveys (leaders, teachers, students), Likert-scale measures of attitudes, skills, infrastructure, pedagogy.  </p></li>
<li><p><strong>Implementation Context:</strong> European K-12 school leadership, ICT integration.  </p></li>
</ul>

<blockquote>
  <p>“…eight distinct configurations of school factors…describe how school leaders can potentially generate nurturing environments for enhancing students' digital skills.” (p. 1)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — insights presented as clear configurations.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — tailored to specific school contexts.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — configurations consider real-world constraints.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No explicit link.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — grounded in theory, configurations explained.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — all configurations tied to strategic improvement goals.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Equifinality, causal asymmetry (from complexity theory).</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Complexity Theory  </p></li>
<li><p>Configuration Theory  </p></li>
<li><p>School Analytics framework (Sergis &amp; Sampson, 2014, 2016)  </p></li>
<li><p>ICT Competence Profiling models (various cited works)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>fsQCA consistency and coverage scores.</p></li>
<li><p>Predictive validity results.</p></li>
<li><p>T-test comparisons between experimental and control groups.</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p><strong>Barriers:</strong>  </p>

<ul>
<li><p>Limited translation of analytics to actionable steps in existing tools.  </p></li>
<li><p>Complexity of multi-layered school ecosystems.  </p></li>
<li><p>Variability in infrastructure, culture, and leadership attitudes.  </p></li>
</ul>

<p><strong>Enablers:</strong>  </p>

<ul>
<li><p>Holistic data collection across micro, meso, macro layers.  </p></li>
<li><p>Theoretical grounding in complexity/configuration.  </p></li>
<li><p>fsQCA’s capacity to reveal multiple valid improvement paths.  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions itself as extending prior ICT-in-schools studies by moving from factor identification to <em>configuration-based actionable insights</em> for leadership decision-making, addressing a gap in the operationalization of educational data analytics.</p>

<hr />

<h2>Summary</h2>

<p>This paper operationalizes the concept of <em>actionability</em> in educational decision-making by defining it as the generation of context-specific, configuration-based insights that directly inform school improvement strategies. Using fsQCA on large-scale European school data, it identifies eight distinct configurations of leadership attitudes, teacher competences, infrastructure, pedagogy, and culture that foster students’ digital skills. The authors provide a clear methodological pathway—from goal-setting through factor identification, analysis, validation, and translation into targeted improvement plans—grounded in complexity and configuration theories. The work bridges qualitative and quantitative traditions, demonstrating how School Analytics can move beyond descriptive dashboards to deliver decision-ready, contextually relevant recommendations.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 — Strong conceptualization of actionability with explicit link to decision-making, robust theoretical framing, and clear features.  </p></li>
<li><p><strong>Operationalization Score:</strong> 88 — Detailed multi-step methodology (fsQCA) with validation, directly tied to achieving actionability.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“...do not offer support for translating these needs into actionable insights (i.e., informative suggestions on ‘what decisions needs to be made’) for school improvement.” (p. 2)  </p></li>
<li><p>“…could provide school leaders with actionable insights, in the form of school-wide informative suggestions for improvement…” (p. 3)  </p></li>
<li><p>“...eight distinct configurations of school factors…describe how school leaders can potentially generate nurturing environments for enhancing students' digital skills.” (p. 1)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Sergis &amp; Sampson (2014, 2016) — School Analytics framework  </p></li>
<li><p>Tondeur et al. (2008), Solar et al. (2013), Aesaert et al. (2015) — ICT integration models  </p></li>
<li><p>Fiss (2007, 2011), Ragin (2000, 2008) — fsQCA and configuration theory  </p></li>
<li><p>Woodside (2014) — Complexity theory and contrarian analysis</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Stream Reasoning for the Internet of Things: Challenges and Gap Analysis  </p>

<p>Authors: Xiang Su, Ekaterina Gilman, Peter Wetz, Jukka Riekki, Yifei Zuo, Teemu Leppänen  </p>

<p>DOI: Not provided (conference proceedings WIMS ’16, Nîmes, France)  </p>

<p>Year: 2016  </p>

<p>Publication Type: Conference  </p>

<p>Discipline/Domain: Computer Science / Internet of Things  </p>

<p>Subdomain/Topic: Stream reasoning, semantic web, IoT data processing  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 88  </p>

<p>Operationalization Score: 70  </p>

<p>Contains Definition of Actionability: Yes (implicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: No  </p>

<p>Contains Interpretability: No  </p>

<p>Contains Framework/Model: Yes (general architecture + experimental IoT system)  </p>

<p>Operationalization Present: Yes (C-SPARQL example implementation)  </p>

<p>Primary Methodology: Conceptual + Experimental  </p>

<p>Study Context: IoT systems in domains such as smart city, intelligent transportation, healthcare, home automation; small-scale smart office prototype  </p>

<p>Geographic/Institutional Context: University of Oulu (Finland), TU Wien (Austria)  </p>

<p>Target Users/Stakeholders: IoT system designers, semantic reasoning researchers, real-time data processing engineers  </p>

<p>Primary Contribution Type: Gap analysis and recommendations for stream reasoning in IoT  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: No  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Stream Reasoning for the Internet of Things: Challenges and Gap Analysis  </p>

<p><strong>Authors:</strong>  </p>

<p>Xiang Su, Ekaterina Gilman, Peter Wetz, Jukka Riekki, Yifei Zuo, Teemu Leppänen  </p>

<p><strong>DOI:</strong>  </p>

<p>Not provided (conference paper WIMS ’16)  </p>

<p><strong>Year:</strong>  </p>

<p>2016  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Internet of Things  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Stream reasoning, semantic web, IoT data processing  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the challenge of producing actionable knowledge from heterogeneous, dynamic IoT data streams. It reviews stream reasoning approaches, evaluates them against IoT-specific requirements, and performs a gap analysis to guide future research.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of Oulu (Finland), TU Wien (Austria)  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>IoT researchers, semantic reasoning system developers, IoT application architects  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual review, comparative analysis, small-scale experimental demonstration  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Gap analysis with recommendations for stream reasoning in IoT  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper examines how stream reasoning can address the need for actionable, real-time insights in IoT applications by combining semantic reasoning and stream processing. It identifies core IoT challenges—data variety, velocity, volume; efficiency; semantic expressiveness; robustness—and reviews state-of-the-art stream reasoners such as C-SPARQL, CQELS, EP-SPARQL, STARQL, and others. Each is evaluated against IoT-specific criteria, including handling heterogeneous data, scalability, integration with background knowledge, and time model flexibility. The authors implement a small smart office IoT prototype using C-SPARQL to demonstrate feasibility and then perform a gap analysis outlining limitations and research needs. Recommendations target scalability, uncertainty handling, richer reasoning capabilities, flexible time models, and benchmarking.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is implicitly framed as the ability to deduce <strong>timely, sufficiently accurate, and reliable knowledge</strong> from IoT streams to enable decision-making and trigger actions in real time.  </p>

<blockquote>
  <p>“It is critical to deduce timely, sufficiently accurate, and reliable knowledge from IoT systems to take actions.” (p.1)  </p>
</blockquote>

<blockquote>
  <p>“Stream reasoning… enables handling of dynamic and heterogeneous data… implementing real-time services.” (p.1)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Timeliness: knowledge generated before it becomes outdated  </p></li>
<li><p>Contextual integration: combining sensor data with domain ontologies and user rules  </p></li>
<li><p>Semantic enrichment: deriving higher-level insights from low-level sensor readings  </p></li>
<li><p>Scalability: ability to handle large, heterogeneous, fast data  </p></li>
<li><p>Robustness: coping with incomplete, out-of-order, or incorrect data  </p></li>
<li><p>Efficiency: low-latency reasoning even in resource-constrained environments  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> General IoT-stream reasoning architecture; experimental smart office system  </p></li>
<li><p><strong>Methods/Levers:</strong> Semantic data modeling (RDF), continuous queries (C-SPARQL), background knowledge integration  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> IoT devices → JSON sensor data → RDF transformation → continuous SPARQL queries with time windows → action triggers  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Sensor data (light, motion, door position, Wi-Fi signal); processing latency, reasoning output correctness  </p></li>
<li><p><strong>Implementation Context:</strong> Smart office proof-of-concept; generalizable to other IoT domains  </p></li>
</ul>

<blockquote>
  <p>“Data streams are processed on-the-fly and do not require a considerable amount of resources to make decisions.” (p.6)  </p>
</blockquote>

<blockquote>
  <p>“Combining on-the-fly several data streams… would enable much more interesting scenarios.” (p.6)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — reasoning results must be unambiguous and interpretable in context.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — data combined with background knowledge/domain ontologies.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — solutions must run on resource-constrained IoT nodes.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — low-latency reasoning emphasized.  </p></li>
<li><p><strong>EX (Explainability):</strong> No explicit discussion.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — reasoning often tied to application-specific user-defined rules.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Robustness, scalability, uncertainty management.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Semantic Web standards (RDF, OWL, SPARQL)  </p></li>
<li><p>Stream reasoning definition by Unel &amp; Roman (2009)  </p></li>
<li><p>Time-aware semantic models (TA-RDF, Temporal RDF, stRDF)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Reasoning latency relative to data arrival  </p></li>
<li><p>Throughput (data processing rate)  </p></li>
<li><p>Accuracy/completeness of inferred knowledge under time constraints  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Limited scalability of current stream reasoners  </p>

<p> - Lack of uncertainty handling  </p>

<p> - Inflexible time models  </p>

<p> - Resource constraints of IoT devices  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Semantic data integration  </p>

<p> - Continuous query models  </p>

<p> - Lightweight/incremental reasoning  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions stream reasoning as an extension to Semantic Web reasoning, addressing IoT’s dynamic, high-volume data requirements. Builds on prior works on C-SPARQL, CQELS, EP-SPARQL, temporal RDF models.</p>

<hr />

<h2>Summary</h2>

<p>This paper presents a comprehensive analysis of how stream reasoning can be used to produce actionable knowledge in IoT contexts. Actionability is implicitly defined as the capacity to transform heterogeneous, high-velocity sensor data into timely, reliable, and contextually relevant knowledge that supports decision-making and automated responses. The authors review leading stream reasoning systems, mapping their capabilities to IoT’s requirements in scalability, efficiency, semantic expressiveness, and robustness. Through an experimental smart office IoT setup using C-SPARQL, they show feasibility but also reveal performance and capability gaps. Recommendations include scalable architectures, richer reasoning beyond simple retrieval, uncertainty modeling, flexible time models, and robust benchmarking.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 — Strong implicit definition of actionability and detailed mapping of necessary features to IoT requirements.  </p></li>
<li><p><strong>Operationalization Score:</strong> 70 — Provides a working prototype and specific implementation steps, though limited to a small-scale scenario.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“It is critical to deduce timely, sufficiently accurate, and reliable knowledge from IoT systems to take actions.” (p.1)  </p></li>
<li><p>“Stream reasoning… enables handling of dynamic and heterogeneous data… implementing real-time services.” (p.1)  </p></li>
<li><p>“Combining on-the-fly several data streams… would enable much more interesting scenarios.” (p.6)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Unel &amp; Roman (2009) — definition of stream reasoning  </p></li>
<li><p>Barbieri et al. — C-SPARQL  </p></li>
<li><p>Koubarakis &amp; Kyzirakos — stRDF  </p></li>
<li><p>Rodríguez et al. — TA-RDF  </p></li>
<li><p>Gutierrez et al. — Temporal RDF</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: SmartReviews: Towards Human- and Machine-Actionable Representation of Review Articles</p>

<p>Authors: Allard Oelen, Markus Stocker, Sören Auer</p>

<p>DOI: https://doi.org/10.1007/978-3-030-91669-5_9</p>

<p>Year: 2021</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Information Science / Digital Libraries</p>

<p>Subdomain/Topic: Semantic Publishing, Scholarly Knowledge Graphs, Review Article Authoring</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 90</p>

<p>Operationalization Score: 95</p>

<p>Contains Definition of Actionability: Yes (implicit via functional characteristics)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual with Implementation and Use Case Demonstration</p>

<p>Study Context: Scholarly review article authoring and publishing</p>

<p>Geographic/Institutional Context: L3S Research Center &amp; TIB Leibniz Information Centre, Germany</p>

<p>Target Users/Stakeholders: Academic authors, publishers, research communities, digital library developers</p>

<p>Primary Contribution Type: Conceptual framework and software tool implementation</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Partial</p>

<p>EX: Partial</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: n/a</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>SmartReviews: Towards Human- and Machine-Actionable Representation of Review Articles  </p>

<p><strong>Authors:</strong>  </p>

<p>Allard Oelen, Markus Stocker, Sören Auer  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1007/978-3-030-91669-5_9  </p>

<p><strong>Year:</strong>  </p>

<p>2021  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Information Science / Digital Libraries  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Semantic Publishing, Scholarly Knowledge Graphs, Review Article Authoring  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses limitations in traditional scholarly review articles—lack of updates, low collaboration, limited machine-actionability—by proposing a semantic, community-maintained, living review format embedded in the Open Research Knowledge Graph (ORKG). Intended for academic communities, it aims to enhance both human and machine accessibility to synthesized research knowledge.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>L3S Research Center &amp; TIB Leibniz Information Centre for Science and Technology, Hannover, Germany  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Academic authors, publishers, research communities, and developers of digital library infrastructure  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework, technical implementation, and demonstration via a use case  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual model, operational framework, and software tool  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper presents <em>SmartReviews</em>, a new authoring and publishing framework for scholarly review articles that are both human- and machine-actionable. Built upon the Open Research Knowledge Graph (ORKG), SmartReviews address key weaknesses of current reviews: lack of updates, limited collaboration, restricted coverage, poor machine-actionability, accessibility issues, and weak systematic representation. The approach involves representing review content in a structured, semantic format, using comparison tables, ontologies, and linked data principles to enhance interoperability and FAIR compliance. A fully implemented tool, supporting community-based authoring and updating of living documents, is demonstrated through a use case on scholarly knowledge graphs. The evaluation shows that SmartReviews improve accessibility, interoperability, and reusability compared to traditional PDF-based reviews.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability here is framed in terms of both <em>human</em> and <em>machine</em> use: a review is actionable if it can be <strong>updated dynamically</strong>, <strong>collaboratively maintained</strong>, <strong>systematically represented</strong>, and <strong>queried or processed by machines</strong> via semantic web standards.  </p>

<blockquote>
  <p>“The key limitation is the inability of machines to access and process knowledge presented within review articles.” (p. 105)  </p>
</blockquote>

<blockquote>
  <p>“The use of these technologies improves the machine-actionability of data and provides a means to make data FAIR.” (p. 107)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Updatable</strong> (living document concept with version control)</p></li>
<li><p><strong>Collaboratively authored</strong> (community-based contributions with provenance tracking)</p></li>
<li><p><strong>Structured &amp; semantic representation</strong> (linked data, ontologies, RDF)</p></li>
<li><p><strong>Accessible</strong> (HTML format, WCAG compliance)</p></li>
<li><p><strong>Interoperable</strong> (machine-readable formats, FAIR data principles)</p></li>
<li><p><strong>Contextually linked</strong> (properties tied to ontologies to enhance interpretability)</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> SmartReviews within ORKG  </p></li>
<li><p><strong>Methods/Levers:</strong> Use of RDF, ontologies (DOCO, Fabio, DEO), semantic comparison tables, living documents, collaborative editing model  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Create sections (text, comparisons, visualizations, ontology tables, resource/property tables)  </p>

<p> 2. Populate with structured, linked data from ORKG  </p>

<p> 3. Maintain head version with version history for updates  </p>

<p> 4. Enable collaborative editing and attribution via acknowledgements  </p></li>
<li><p><strong>Data &amp; Measures:</strong> RDF triples, SPARQL queries for retrieval, ontology-linked properties  </p></li>
<li><p><strong>Implementation Context:</strong> Digital library / semantic publishing infrastructure  </p></li>
</ul>

<blockquote>
  <p>“Comparison sections form the core of each review article.” (p. 108)  </p>
</blockquote>

<blockquote>
  <p>“The data itself can be accessed via… SPARQL endpoint, RDF dump, and REST interface.” (p. 110)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – clear structured representation via tables/visuals  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – ontology linking ensures contextual meaning  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – enabled by ORKG platform and existing ontologies  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial – supports updates but depends on community activity  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial – ontology tables explain properties but not all content  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – aligns with FAIR principles and open science goals  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Accessibility, Collaboration, Coverage</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Living documents concept (Shanahan 2015)  </p></li>
<li><p>Semantic Web and Linked Data principles (Berners-Lee et al., RDF, SPARQL)  </p></li>
<li><p>FAIR data principles (Wilkinson et al., 2016)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Ability to execute SPARQL queries over review content  </p></li>
<li><p>Presence of ontology-linked properties  </p></li>
<li><p>Version history and update frequency  </p></li>
<li><p>Accessibility compliance (HTML, WCAG)</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Researcher habits, resistance to change, lack of incentives for ongoing updates  </p></li>
<li><p><strong>Enablers:</strong> Collaborative platform, attribution system, FAIR data standards, semantic web technologies</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The authors situate their approach within semantic publishing research, citing prior calls for machine-readable scholarly content, living documents, and linked data approaches to overcome PDF limitations.</p>

<hr />

<h2>Summary</h2>

<p>The paper conceptualizes actionability in scholarly reviews as a combination of dynamic updatability, semantic structure, and both human- and machine-readability. SmartReviews operationalize this through a community-driven, living document model embedded in a knowledge graph, using linked data and ontologies to ensure interoperability and FAIR compliance. Actionability features include structured comparison tables, ontology-linked metadata, collaborative editing, and open accessibility. The implementation in ORKG demonstrates both feasibility and clear differentiation from static PDF reviews. While adoption challenges remain, the model offers a concrete, operational framework for transforming review articles into actionable scholarly resources.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 — Strong, detailed implicit definition of actionability with explicit dimensions tied to it.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Full technical and procedural workflow for achieving actionability is provided, demonstrated with a live use case.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“The key limitation is the inability of machines to access and process knowledge presented within review articles.” (p. 105)  </p></li>
<li><p>“Comparison sections form the core of each review article.” (p. 108)  </p></li>
<li><p>“The data itself can be accessed via… SPARQL endpoint, RDF dump, and REST interface.” (p. 110)  </p></li>
<li><p>“The use of these technologies improves the machine-actionability of data and provides a means to make data FAIR.” (p. 107)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Shanahan (2015) — Living documents concept  </p></li>
<li><p>Berners-Lee et al. (2001) — Semantic Web and Linked Data  </p></li>
<li><p>Wilkinson et al. (2016) — FAIR data principles  </p></li>
<li><p>Garcia-Castro et al. (2010) — Semantic living documents in life sciences</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Smart computing based student performance evaluation framework for engineering education  </p>

<p>Authors: Prabal Verma, Sandeep K. Sood, Sheetal Kalra  </p>

<p>DOI: https://doi.org/10.1002/cae.21849  </p>

<p>Year: 2017  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Computer Science / Engineering Education  </p>

<p>Subdomain/Topic: IoT-based performance evaluation, educational data mining, game-theory decision making  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 92  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes (implicit – “turn data into actionable insight” and detailed properties)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (five-layer IoT-based framework)  </p>

<p>Operationalization Present: Yes (detailed algorithms, workflows, decision-making logic)  </p>

<p>Primary Methodology: Conceptual + Experimental  </p>

<p>Study Context: Engineering education, student performance monitoring and evaluation  </p>

<p>Geographic/Institutional Context: Guru Nanak Dev University, Punjab, India  </p>

<p>Target Users/Stakeholders: Engineering college management, faculty, students  </p>

<p>Primary Contribution Type: Conceptual framework + implementation and evaluation  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Smart computing based student performance evaluation framework for engineering education  </p>

<p><strong>Authors:</strong>  </p>

<p>Prabal Verma, Sandeep K. Sood, Sheetal Kalra  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1002/cae.21849  </p>

<p><strong>Year:</strong>  </p>

<p>2017  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Engineering Education  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>IoT-based performance evaluation, educational data mining, game-theory decision making  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses how IoT technologies, combined with cloud computing, RFID sensing, and data mining, can automate and improve student performance evaluation in engineering education. It aims to produce “actionable insight” from continuous student activity monitoring to inform both academic and institutional decision-making.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Guru Nanak Dev University, Punjab, India  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Engineering college management, faculty, students  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual + Experimental  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework + implementation and evaluation  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The study proposes and tests a five-layer IoT-based “smart computing” framework to evaluate engineering students’ performance by integrating daily activity data from wearable sensors and RFID devices with academic records. The layers cover data acquisition, cloud storage and activity classification, daily activity recognition and visualization, data mining-based performance calculation, and game-theory-driven decision making. Activities are classified into daily and occasional, weighted accordingly, and mined using methods such as spatial co-location, PageRank, and HITS. Institutional reputation scores are computed from aggregated student scores, feeding into a game-theoretic model to guide management strategies for student development. Experimental evaluation with 24 students shows that the proposed system improves both student and institutional performance metrics compared to manual evaluation.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as the transformation of IoT-derived student interaction and activity data into insights that directly inform educational and managerial decisions.</p>

<blockquote>
  <p>“IoT technology… allow[s] educators and administrators to turn data into actionable insight” (p. 977)  </p>
</blockquote>

<blockquote>
  <p>“Based on student sessional performance score, decisions are taken by management authority to increase the reputation score of the engineering institution” (p. 977)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Continuous, automated collection of relevant performance data (academic + activity)  </p></li>
<li><p>Integration of diverse datasets into a unified performance score  </p></li>
<li><p>Timely analysis to inform session-based interventions  </p></li>
<li><p>Decision models (game theory) to translate performance metrics into concrete management actions  </p></li>
<li><p>Context-aware activity classification to ensure relevance  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Five-layer IoT-based student performance evaluation framework  </p></li>
<li><p><strong>Methods/Levers:</strong> RFID/GPS/wearable sensing, cloud data preprocessing, Bayesian Belief Network classification, data mining (PageRank, HITS, co-location), game-theory decision modeling  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Data acquisition &amp; synchronization (sensors, RFID, gateway devices)  </p>

<p> 2. Cloud storage &amp; preprocessing (noise removal, classification into daily/occasional activities)  </p>

<p> 3. Activity recognition &amp; temporal visualization  </p>

<p> 4. Data mining &amp; performance score calculation (weighted daily/occasional activity integration)  </p>

<p> 5. Game-theoretic decision making for institutional actions  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Sensor data, attendance logs, activity metadata, academic marks, interaction scores  </p></li>
<li><p><strong>Implementation Context:</strong> Engineering college with RFID-enabled monitoring and cloud analytics  </p></li>
</ul>

<blockquote>
  <p>“Layer 4 computes the student performance score… integrating IoT-based data mining… with academic dataset” (p. 980)  </p>
</blockquote>

<blockquote>
  <p>“Game-based decision component takes automated decisions based on student performance score” (p. 980)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – performance score formula and activity classification are explicitly defined  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – activity types and weights tailored to engineering education context  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – demonstrated with actual deployment and tested scalability  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes – real-time data acquisition and session-based decision-making  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – decision rules, algorithms, and weighting schemes are transparent  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – aligns with improving student performance and institutional reputation  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Integration of behavioral, locational, academic, and interactive data streams  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Ubiquitous learning  </p></li>
<li><p>Educational data mining  </p></li>
<li><p>Game theory (non-cooperative model)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Student Performance Score (PS) – weighted integration of activity and academic scores  </p></li>
<li><p>Reputation Score (RS) – aggregated institutional performance metric  </p></li>
<li><p>Activity-specific participation indices (PageRank, co-location metrics)  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Sensor data noise/incompleteness, integration complexity, privacy/security concerns  </p></li>
<li><p><strong>Enablers:</strong> IoT infrastructure, cloud analytics, established decision-theory models, automated data pipelines  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions itself at the intersection of IoT-based smart learning environments, educational data mining, and decision science, extending prior ubiquitous learning frameworks by integrating automated decision-making using game theory.  </p>

<hr />

<h2>Summary</h2>

<p>This paper operationalizes actionability by systematically linking sensor-derived behavioral and interaction data with academic results, producing composite performance scores that directly inform management decisions. The five-layer IoT-based framework ensures continuous monitoring, context-aware classification, weighted integration, and translation into actionable strategies through game theory. Actionability here is not only about having relevant and timely data, but also embedding analytical and decision-making processes that yield concrete interventions for both students and institutions. The system’s deployment demonstrates improved accuracy, timeliness, and effectiveness over manual evaluations, supporting its scalability and stability in real-world engineering education contexts.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 – Strong implicit and explicit conceptualization of actionability with clear, domain-specific features.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 – Detailed, stepwise methodology, algorithms, and decision logic directly tied to achieving actionability.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“IoT technology… allow[s] educators and administrators to turn data into actionable insight” (p. 977)  </p></li>
<li><p>“Based on student sessional performance score, decisions are taken by management authority…” (p. 977)  </p></li>
<li><p>“Layer 4 computes the student performance score… integrating IoT-based data mining… with academic dataset” (p. 980)  </p></li>
<li><p>“Game-based decision component takes automated decisions based on student performance score” (p. 980)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Kaur &amp; Sood (2015) – Game-theoretic IoT performance evaluation in industry  </p></li>
<li><p>Zhu et al. (2016) – Smart education conceptual framework  </p></li>
<li><p>Wu et al. (2014) – Cognitive IoT paradigm  </p></li>
<li><p>Lauria &amp; Duchessi (2006) – Bayesian belief networks for decision support</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Situation Recognition Using EventShop  </p>

<p>Authors: Vivek K. Singh, Ramesh Jain  </p>

<p>DOI: 10.1007/978-3-319-30537-0  </p>

<p>Year: 2016  </p>

<p>Publication Type: Book  </p>

<p>Discipline/Domain: Computer Science / Information Systems  </p>

<p>Subdomain/Topic: Situation Recognition, Spatiotemporal Data Integration, Actionable Insights  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes (explicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual + System Implementation + Case Studies  </p>

<p>Study Context: Real-time, heterogeneous spatiotemporal multimedia data processing for situation-aware applications  </p>

<p>Geographic/Institutional Context: Applications in USA, Thailand, California; Institutions: Rutgers University, University of California Irvine  </p>

<p>Target Users/Stakeholders: Application designers, data scientists, policy makers, public safety officials, healthcare providers  </p>

<p>Primary Contribution Type: Conceptual framework + operational toolkit (EventShop) + case studies  </p>

<p>CL: Yes – “explicit, computable blueprints” for situation modeling must be clear to enable action-taking (p. 47–49)  </p>

<p>CR: Yes – Situations must be contextually relevant to user needs and local conditions (macro, meso, personal scales) (p. 24–25)  </p>

<p>FE: Yes – Must be feasible through available data sources, computational operators, and real-time processing (p. 23–25)  </p>

<p>TI: Yes – Emphasis on real-time evaluation and data half-life (p. 40)  </p>

<p>EX: Yes – Framework supports explicit mapping from spatiotemporal descriptors to actionable classifications (p. 13)  </p>

<p>GA: Yes – Goal-driven modeling is central; situations are defined for a purpose (p. 29)  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Situation Recognition Using EventShop  </p>

<p><strong>Authors:</strong>  </p>

<p>Vivek K. Singh, Ramesh Jain  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1007/978-3-319-30537-0  </p>

<p><strong>Year:</strong>  </p>

<p>2016  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Book  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Information Systems  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Situation Recognition, Spatiotemporal Data Integration, Actionable Insights  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The book addresses the challenge of deriving actionable insights from heterogeneous, real-time, spatiotemporal multimedia data streams (e.g., social media, sensor networks, satellite imagery). It proposes a computational framework for defining, modeling, recognizing, and acting upon “situations” — abstract, application-specific states of the world — and operationalizes it through EventShop, an open-source toolkit.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Case studies in USA (asthma/allergy alerts, seasonal pattern detection), California (wildfire detection), Thailand (flood evacuation). Authors affiliated with Rutgers University and University of California Irvine.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Application designers, researchers, public safety and health agencies, policy makers, and developers of situation-aware applications.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework development, computational modeling, operational system implementation (EventShop), and multiple real-world case studies.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual + Operational framework for actionable situation recognition.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The book defines “situation” as <em>“an actionable abstraction of observed spatiotemporal descriptors”</em> and grounds this in computational terms. It presents a three-part structure: (1) Understanding and defining situations; (2) a framework for recognizing them; (3) operationalization via the EventShop platform. The framework supports situation modeling (using goal-driven decomposition into computable features), real-time data ingestion and unification, spatiotemporal analysis operators, and personalization for action-taking. Case studies include wildfire detection, flood evacuation alerts, and asthma/allergy recommendations, demonstrating applicability across domains. The work emphasizes “lowering the floor” for non-technical designers and “raising the ceiling” for sophisticated, personalized, and scalable situation-aware systems.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Situations are <em>“actionable abstractions of observed spatiotemporal descriptors”</em> — meaning they are high-level representations derived from measurable space-time data that directly support decision-making in a specific application context. Actionability is linked to:  </p>

<ul>
<li><p>Observability (must be based on measurable data)  </p></li>
<li><p>Abstraction (aggregating raw data into meaningful states)  </p></li>
<li><p>Application-specific decision support (classification into states that trigger actions)  </p></li>
</ul>

<blockquote>
  <p>“An actionable abstraction of observed spatiotemporal descriptors.” (p. 13)  </p>
</blockquote>

<blockquote>
  <p>“Top-level descriptors and abstractions need to be chosen based on the application domain and the associated output state space.” (p. 13)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Goal-based definition:</strong> Purpose-driven modeling for a specific application  </p></li>
<li><p><strong>Spatiotemporal grounding:</strong> Anchored in measurable coordinates and time  </p></li>
<li><p><strong>Observability:</strong> Derived only from observable, sensor-measurable data  </p></li>
<li><p><strong>Abstraction:</strong> Higher-level constructs derived from raw data  </p></li>
<li><p><strong>Relevance:</strong> Must support concrete decision-making  </p></li>
<li><p><strong>Personalization:</strong> Ability to tailor situations to individual contexts  </p></li>
<li><p><strong>Timeliness:</strong> Real-time processing to match data half-life and decision needs  </p></li>
<li><p><strong>Feasibility:</strong> Use of available data sources and computational methods</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> EventShop Situation Recognition Framework  </p></li>
<li><p><strong>Methods/Levers:</strong> Situation-to-Source (S2S) modeling; spatiotemporal data unification; operator-based analysis (filter, aggregate, classify, characterize, pattern-match, learn); personalization via situation-action rules  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Model situation via S2S diagrams (goal-driven feature decomposition)  </p>

<p> 2. Select and ingest relevant data streams  </p>

<p> 3. Unify into STT (space-time-theme) tuples  </p>

<p> 4. Aggregate into E-mages (spatiotemporal grids)  </p>

<p> 5. Apply analysis operators to derive situation classifications  </p>

<p> 6. Personalize using individual-level data streams  </p>

<p> 7. Trigger alerts/actions via E-C-A style rules  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Spatiotemporal descriptors, statistical features, thresholds, similarity metrics, operator outputs  </p></li>
<li><p><strong>Implementation Context:</strong> Real-time heterogeneous data streams, web-based GUI for rapid prototyping  </p></li>
</ul>

<blockquote>
  <p>“Provides a situation modeling kit… translate mental models into explicit, actionable, and computable modules.” (p. 8)  </p>
</blockquote>

<blockquote>
  <p>“Unified representation (E-mage) and situation recognition algebra for diverse spatiotemporal data.” (p. 8)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – Explicit blueprints for situations (p. 47–49)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – Macro, meso, personal scale relevance (p. 24–25)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – Based on available data, unified representation, reusable operators (p. 23–25)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes – Real-time evaluation, data half-life concept (p. 40)  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – Clear mapping from descriptors to actionable classifications (p. 13)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – Goal-driven modeling emphasized (p. 29)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Personalization, scalability, interoperability  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Situation awareness literature (Endsley 1988; Barwise &amp; Perry 1980)  </p></li>
<li><p>GIS, complex event processing, multimedia concept recognition  </p></li>
<li><p>Situation calculus and event calculus from AI  </p></li>
<li><p>E-C-A (event-condition-action) rules  </p></li>
<li><p>Image algebra analogies for spatiotemporal data  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Precision/recall vs. ground truth in case studies (e.g., &gt;90% wildfire detection)  </p></li>
<li><p>Real-time responsiveness (matching data update cycles)  </p></li>
<li><p>Discriminative power of features  </p></li>
<li><p>User adoption/engagement (e.g., retweets in flood alerts)</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Lack of standard definition of “situation”  </p>

<p> - Data heterogeneity and missing values  </p>

<p> - Real-time scalability challenges  </p>

<p> - Privacy concerns for personal data  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Unified STT/E-mage representation  </p>

<p> - Modular operator-based framework  </p>

<p> - GUI-based modeling and prototyping tools  </p>

<p> - Support for personalization and multiple decision scales  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions itself as the first systematic, end-to-end approach for combining heterogeneous, real-time multimedia data into actionable situations, integrating concepts from context-aware systems, GIS, CEP, and multimedia analysis, but with explicit operationalization and a user-accessible toolkit.</p>

<hr />

<h2>Summary</h2>

<p>This work offers a comprehensive, computationally grounded framework for transforming heterogeneous, real-time spatiotemporal data into actionable situations. It defines actionability explicitly, ties it to measurable descriptors, and operationalizes it via EventShop — a modular, GUI-driven toolkit. By “lowering the floor” for non-programmer designers and “raising the ceiling” for advanced applications (through expressive operators, personalization, and scalability), it enables rapid prototyping and deployment across domains such as disaster response, health recommendations, and environmental monitoring. Case studies demonstrate both high accuracy (e.g., &gt;90% wildfire detection) and real-world engagement (flood evacuation alerts retweeted by affected users). The framework’s emphasis on clarity, contextual relevance, feasibility, timeliness, explainability, and goal alignment positions it as a seminal contribution to actionable insight generation from big data.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Explicit, well-grounded definition of actionability, comprehensive list of necessary features, integration with literature.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Detailed, stepwise framework, implemented system, tested across multiple real-world scenarios.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We define a situation as ‘An actionable abstraction of observed spatiotemporal descriptors.’” (p. 13)  </p></li>
<li><p>“Top-level descriptors and abstractions need to be chosen based on the application domain and the associated output state space.” (p. 13)  </p></li>
<li><p>“Provides a situation modeling kit… translate mental models into explicit, actionable, and computable modules.” (p. 8)  </p></li>
<li><p>“Unified representation (E-mage) and situation recognition algebra for diverse spatiotemporal data.” (p. 8)  </p></li>
<li><p>“Lower the floor… Raise the ceiling.” (p. 20)  </p></li>
<li><p>“Generate personalized actionable situations.” (p. 40)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Endsley, M. (1988). <em>Situation awareness global assessment technique</em>.  </p></li>
<li><p>Barwise, J., &amp; Perry, J. (1980). <em>Situations and attitudes</em>.  </p></li>
<li><p>Yau, S., &amp; Liu, J. (2006). <em>Hierarchical situation modeling and reasoning for pervasive computing</em>.  </p></li>
<li><p>Event-condition-action frameworks in active databases.  </p></li>
<li><p>GIS and spatial data analysis literature.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Sharing science through shared values, goals, and stories: an evidence-based approach to making science matter  </p>

<p>Authors: Bethann Garramon Merkle, Evelyn Valdez-Ward, Priya Shukla, Skylar R. Bayer  </p>

<p>DOI: 10.2307/27316303  </p>

<p>Year: 2021  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Science Communication / Human–Wildlife Interactions  </p>

<p>Subdomain/Topic: Values-based science communication, stakeholder engagement, storytelling in science  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 88  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (implicit and explicit through a values-goals-stories model)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (values–goals–stories framework, backward design approach)  </p>

<p>Operationalization Present: Yes (stepwise guidance, tools, worksheets, examples)  </p>

<p>Primary Methodology: Conceptual / Practice-based synthesis  </p>

<p>Study Context: Science communication across academic and non-academic contexts, with emphasis on conservation and applied ecology  </p>

<p>Geographic/Institutional Context: Primarily U.S.-based examples, cross-disciplinary applicability  </p>

<p>Target Users/Stakeholders: Scientists, science communicators, policymakers, community stakeholders  </p>

<p>Primary Contribution Type: Conceptual framework and applied guidance  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Sharing science through shared values, goals, and stories: an evidence-based approach to making science matter</p>

<p><strong>Authors:</strong>  </p>

<p>Bethann Garramon Merkle, Evelyn Valdez-Ward, Priya Shukla, Skylar R. Bayer</p>

<p><strong>DOI:</strong>  </p>

<p>10.2307/27316303</p>

<p><strong>Year:</strong>  </p>

<p>2021</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Science Communication / Human–Wildlife Interactions</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Values-based science communication, stakeholder engagement, storytelling</p>

<p><strong>Contextual Background:</strong>  </p>

<p>This article addresses the persistent challenge of making scientific research relevant and useful to decision-making. It focuses on enhancing the reach and impact of science through centering shared values, articulating clear goals, and using storytelling. The discussion targets scientists and science-allied practitioners seeking to communicate with diverse stakeholders, including those with conflicting values.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Primarily U.S.-based examples; applicable across global contexts.</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Scientists, science communicators, policy makers, educators, local communities, conservation managers.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework supported by practical tools and examples.</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework and applied recommendations.</p>

<h2>General Summary of the Paper</h2>

<p>The paper presents a conceptual and practical approach for making science communication more effective by aligning it with shared values, explicit goals, and compelling stories. Recognizing systemic disincentives, limited training, and sociopolitical complexities, the authors propose a “values–goals–stories” model to bridge divides between scientists and stakeholders. The approach includes identifying mutual values, integrating them into goal setting (ideally at a project’s inception), and using storytelling to foster trust, relevance, and engagement. It is grounded in evidence from communication research and enriched with real-world case studies, worksheets, and resource tools to guide scientists toward actionable communication strategies.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>The paper conceptualizes actionability as the extent to which science communication is designed to connect with stakeholders’ values, align with shared goals, and use stories to foster trust, understanding, and decision relevance. Actionability is framed as purposeful, stakeholder-centered, and embedded in a cyclical process where communication informs and is informed by engagement.  </p>

<blockquote>
  <p>“We emphasize the essential interplay between values, goals, and stories… which scientists can actively work on to build a sense of confidence in achieving shared outcomes with stakeholders.” (p. 599)  </p>
</blockquote>

<blockquote>
  <p>“Actionable recommendations and tools scientists can immediately use to articulate their values, identify shared values… and use storytelling as a means of building and reinforcing relationships…” (p. 598)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Centering communication on <strong>shared values</strong> between scientists and stakeholders.  </p></li>
<li><p>Setting <strong>explicit, stakeholder-informed goals</strong> for science communication.  </p></li>
<li><p>Using <strong>storytelling</strong> to make science relatable and emotionally resonant.  </p></li>
<li><p>Employing <strong>backward design</strong> to ensure activities serve communication goals.  </p></li>
<li><p>Actively <strong>listening to and understanding stakeholder perspectives</strong>.  </p></li>
<li><p>Building <strong>trust and long-term relationships</strong>.  </p></li>
<li><p>Considering <strong>cultural, political, and historical contexts</strong>.</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Values–Goals–Stories framework; Backward Design for Scicomm  </p></li>
<li><p><strong>Methods/Levers:</strong> Values articulation exercises; stakeholder mapping and listening; goal setting tools; story development guides.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Identify and articulate personal and scientific values.  </p>

<p> 2. Learn and integrate stakeholder values.  </p>

<p> 3. Co-develop goals aligned with shared values.  </p>

<p> 4. Use backward design to plan activities.  </p>

<p> 5. Develop and deliver stories that embody values and goals.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Qualitative stakeholder input, values worksheets, narrative feedback.  </p></li>
<li><p><strong>Implementation Context:</strong> Applicable across environmental, policy, education, and outreach settings.  </p></li>
</ul>

<blockquote>
  <p>“We recommend a stepwise process to identify your values, those of your stakeholders, and how to relate the two.” (p. 604)  </p>
</blockquote>

<blockquote>
  <p>“Backward design… prioritizes key concepts that lead to long-term understanding… keeping our focus on the approaches most likely to achieve our goals.” (p. 605)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – Emphasis on plain language, avoiding jargon to reach stakeholders.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – Stakeholder contexts and sociopolitical realities must inform communication.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – Offers stepwise, resource-backed processes adaptable to scientist constraints.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial – Encourages goal setting early in projects, but timeliness is not a primary focus.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – Stresses explaining science in relatable, narrative forms.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – Goals are co-developed or informed by shared values.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Trust-building, inclusivity, cultural awareness.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Backward Design (Wiggins &amp; McTighe, 2004)  </p></li>
<li><p>Science–advocacy continuum (Donner, 2014)  </p></li>
<li><p>Impact identity framework (Risien &amp; Storksdieck, 2018)  </p></li>
<li><p>Narrative persuasion and storytelling literature (Dahlstrom, 2014)</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Presence of stakeholder-informed goals.  </p></li>
<li><p>Evidence of trust and relationship building.  </p></li>
<li><p>Stakeholder use or application of communicated science.  </p></li>
<li><p>Narrative resonance and engagement levels.</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Systemic disincentives in academia; lack of scicomm training; political polarization; inequities in stakeholder engagement; language barriers.  </p></li>
<li><p><strong>Enablers:</strong> Co-production approaches; values alignment; trust-based relationships; accessible tools and worksheets.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>The approach integrates science communication theory, stakeholder engagement principles, and applied storytelling. It builds on critiques of the deficit model, the importance of mutual value recognition, and literature on inclusive communication.</p>

<h2>Summary</h2>

<p>This paper provides a robust conceptual and practical guide to making science actionable through intentional alignment of values, goals, and stories. Actionability is framed not merely as clarity or accuracy, but as stakeholder-centered design grounded in mutual respect and trust. The values–goals–stories model is both a diagnostic and generative tool, helping scientists navigate sociopolitical complexities and adapt communication to diverse contexts. By combining backward design with storytelling, the authors bridge conceptual understanding with field-ready tools, offering a clear pathway to embed actionability in science communication practice.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 – Strong conceptual clarity on actionability via the values–goals–stories framework; multiple features explicitly tied to making communication actionable.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 – Provides explicit, stepwise instructions, tools, and applied examples for achieving actionability.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We emphasize the essential interplay between values, goals, and stories… which scientists can actively work on to build a sense of confidence in achieving shared outcomes with stakeholders.” (p. 599)  </p></li>
<li><p>“Backward design… prioritizes key concepts that lead to long-term understanding… keeping our focus on the approaches most likely to achieve our goals.” (p. 605)  </p></li>
<li><p>“We recommend a stepwise process to identify your values, those of your stakeholders, and how to relate the two.” (p. 604)  </p></li>
<li><p>“Actionable recommendations and tools scientists can immediately use to articulate their values, identify shared values… and use storytelling as a means of building and reinforcing relationships…” (p. 598)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Donner (2014) – Science–advocacy continuum  </p></li>
<li><p>Risien &amp; Storksdieck (2018) – Impact identities framework  </p></li>
<li><p>Wiggins &amp; McTighe (2004) – Backward design  </p></li>
<li><p>Dahlstrom (2014), Dahlstrom &amp; Ho (2012) – Storytelling in science  </p></li>
<li><p>Elliott &amp; Resnik (2014) – Transparency of values in science</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Secondary findings from next-generation sequencing: what does actionable in childhood really mean?  </p>

<p>Authors: Julie Richer, Anne-Marie Laberge  </p>

<p>DOI: https://doi.org/10.1038/s41436-018-0034-4  </p>

<p>Year: 2019  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Medical Genetics  </p>

<p>Subdomain/Topic: Genomic screening, secondary findings, pediatric actionability  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 92  </p>

<p>Operationalization Score: 88  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: No  </p>

<p>Contains Interpretability: No  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual with applied framework review  </p>

<p>Study Context: Evaluation of disorders on ACMG SF v2.0 list for pediatric actionability  </p>

<p>Geographic/Institutional Context: Canada (Children’s Hospital of Eastern Ontario; Université de Montréal; Centre Hospitalier Universitaire Sainte-Justine)  </p>

<p>Target Users/Stakeholders: Clinical geneticists, pediatricians, policy makers, genomic screening committees  </p>

<p>Primary Contribution Type: Conceptual framework and applied disorder evaluation  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: No  </p>

<p>EX: No  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Secondary findings from next-generation sequencing: what does actionable in childhood really mean?  </p>

<p><strong>Authors:</strong>  </p>

<p>Julie Richer, Anne-Marie Laberge  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1038/s41436-018-0034-4  </p>

<p><strong>Year:</strong>  </p>

<p>2019  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Medical Genetics  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Genomic screening, secondary findings, pediatric actionability  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the concept of “actionability” in reporting secondary genetic findings from next-generation sequencing in children, using the ACMG SF v2.0 list as a test case. It applies WHO population screening criteria to evaluate whether and when such findings should be disclosed, emphasizing evidence quality, disease onset patterns, and benefit-risk balance for pediatric disclosure.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Canada — Children’s Hospital of Eastern Ontario, Université de Montréal, CHU Sainte-Justine  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Clinical geneticists, pediatricians, healthcare policy makers, genomic testing guideline committees  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual analysis with applied framework-based review of disorders  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework plus systematic evaluation of conditions  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper critically examines what “actionable in childhood” means in the context of secondary genomic findings, particularly for disorders on the ACMG SF v2.0 list. Using the WHO screening criteria, the authors propose a framework to assess pediatric actionability, incorporating disease onset patterns, availability and quality of evidence for preventive/treatment measures, and potential harms. They categorize disorders by proportion of cases presenting in childhood and evaluate the strength of evidence for intervention effectiveness. The authors argue that disclosure in childhood should be limited to disorders with a majority of cases presenting before adulthood and supported by at least moderate-quality evidence. They conclude with a cautious recommendation to restrict mandatory pediatric disclosure to five conditions (MEN2, retinoblastoma, tuberous sclerosis complex, Marfan syndrome, Wilson’s disease).</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is defined as a disorder for which surveillance and/or preventive/treatment measures are available to significantly improve health outcomes. In pediatric context, it means:  </p>

<p>(i) Childhood onset with measures initiated in childhood, or  </p>

<p>(ii) Adult onset but proven-effective measures when started in childhood.  </p>

<blockquote>
  <p>“An actionable finding can be defined as a disease-causing pathogenic variant for a disorder for which surveillance and preventive and/or treatment measures are available to significantly improve health outcomes…” (p. 125)  </p>
</blockquote>

<blockquote>
  <p>“…we consider a disorder ‘actionable in childhood’ if… the disorder has either (i) childhood onset… or (ii) adult onset, but such measures have been demonstrated to be effective when started in childhood.” (p. 129)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Proportion of cases presenting in childhood  </p></li>
<li><p>Availability of preventive/treatment measures in childhood  </p></li>
<li><p>Demonstrated effectiveness in childhood  </p></li>
<li><p>Quality of supporting evidence  </p></li>
<li><p>Acceptability and risk-benefit balance of interventions  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> WHO screening criteria applied to genomic secondary findings  </p></li>
<li><p><strong>Methods/Levers:</strong> Disorder categorization by onset proportion; evidence grading for interventions; assessment of guideline availability  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Apply WHO criteria related to actionability  </p>

<p> 2. Gather natural history and management data  </p>

<p> 3. Categorize disorders by childhood onset proportion  </p>

<p> 4. Assess evidence quality for interventions  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Published guidelines, GeneReviews, natural history studies  </p></li>
<li><p><strong>Implementation Context:</strong> Pediatric genomic testing in Canadian/Western healthcare systems  </p></li>
</ul>

<blockquote>
  <p>“…we categorized disorders based on the proportion of cases that presented in childhood…” (p. 124)  </p>
</blockquote>

<blockquote>
  <p>“We propose… disclosure in childhood would be limited to disorders for which a majority of cases present in childhood and for which interventions are supported by evidence of at least moderate quality.” (p. 124)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — clear definition of pediatric actionability and decision framework (p. 129)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — applies specifically to pediatric genomic disclosure context (p. 125–126)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — requires availability and acceptability of interventions (p. 126)  </p></li>
<li><p><strong>TI (Timeliness):</strong> No — no explicit link of timeliness as necessary criterion  </p></li>
<li><p><strong>EX (Explainability):</strong> No — explainability not discussed  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — alignment with child’s best medical interests emphasized (p. 126)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Evidence quality threshold, proportion of cases affected, balance of risks and benefits</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>WHO Wilson &amp; Jungner screening criteria  </p></li>
<li><p>Berg et al.’s semiquantitative metric for actionability  </p></li>
<li><p>Distinction between medical vs. patient-initiated actionability</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Proportion of cases with childhood onset  </p></li>
<li><p>Quality of evidence grading (very low, low, moderate, high)  </p></li>
<li><p>Existence and professional consensus of guidelines  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Low or very low quality of evidence for many conditions  </p>

<p> - Variable disease penetrance and expressivity  </p>

<p> - Potential psychological and social harms  </p>

<p> - Resource limitations for opportunistic screening  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Professional guidelines supporting early intervention  </p>

<p> - Evidence of effective prevention/treatment in childhood</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper builds on ACMG recommendations, critiques the lack of pediatric-specific thresholds, and incorporates WHO screening principles to refine decision-making for childhood disclosure. It emphasizes that previous broad definitions of actionability require adaptation for pediatric contexts.</p>

<hr />

<h2>Summary</h2>

<p>Richer and Laberge (2019) present a structured approach to defining and operationalizing “actionable in childhood” for secondary genomic findings. Grounded in WHO screening criteria, their framework considers the proportion of childhood-onset cases, the availability and effectiveness of preventive/treatment measures in children, and the quality of supporting evidence. They argue for a cautious disclosure threshold, recommending mandatory reporting only for disorders with majority pediatric onset and at least moderate-quality intervention evidence, thereby narrowing the ACMG SF v2.0 list to five conditions. This model integrates a rigorous population-screening perspective with ethical considerations of benefit, harm, and resource allocation.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Provides explicit definition, clear pediatric criteria, and detailed dimensions tied to actionability.  </p></li>
<li><p><strong>Operationalization Score:</strong> 88 — Offers an applied framework and systematic evaluation; slightly limited by absence of quantitative scoring system.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[An] actionable finding can be defined as a disease-causing pathogenic variant… to significantly improve health outcomes…” (p. 125)  </p></li>
<li><p>“…the disorder has either (i) childhood onset… or (ii) adult onset, but such measures have been demonstrated to be effective when started in childhood.” (p. 129)  </p></li>
<li><p>“…disclosure in childhood would be limited to disorders for which a majority of cases present in childhood and… evidence of at least moderate quality.” (p. 124)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Berg JS et al. (2016) — Semiquantitative metric for evaluating clinical actionability  </p></li>
<li><p>Moret C et al. (2017) — Categorization of medical vs. patient-initiated actionability  </p></li>
<li><p>Wilson JMG, Jungner G (1968) — WHO screening principles</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Return of non-ACMG recommended incidental genetic findings to pediatric patients: considerations and opportunities from experiences in genomic sequencing  </p>

<p>Authors: Kevin M. Bowling, Michelle L. Thompson, Melissa A. Kelly, Sarah Scollon, Anne M. Slavotinek, Bradford C. Powell, Brian M. Kirmse, Laura G. Hendon, Kyle B. Brothers, Bruce R. Korf, Gregory M. Cooper, John M. Greally, Anna C. E. Hurst  </p>

<p>DOI: https://doi.org/10.1186/s13073-022-01139-2  </p>

<p>Year: 2022  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Genomics / Medical Genetics  </p>

<p>Subdomain/Topic: Incidental findings in pediatric genomic sequencing  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 88  </p>

<p>Operationalization Score: 75  </p>

<p>Contains Definition of Actionability: Yes (implicit, framed in return-of-results context)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: No formal named model, but structured criteria for return  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Mixed Methods (case series across multiple genomic studies + conceptual analysis)  </p>

<p>Study Context: Four pediatric genomic sequencing studies (SouthSeq, KidsCanSeq, P3EGS, COAGS) returning non-ACMG incidental findings  </p>

<p>Geographic/Institutional Context: USA (multiple academic medical centers, diverse patient populations)  </p>

<p>Target Users/Stakeholders: Clinical geneticists, laboratory directors, policy-makers, pediatric healthcare providers  </p>

<p>Primary Contribution Type: Empirical cases + conceptual considerations for return of incidental genetic findings  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Partial  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Return of non-ACMG recommended incidental genetic findings to pediatric patients: considerations and opportunities from experiences in genomic sequencing  </p>

<p><strong>Authors:</strong>  </p>

<p>Kevin M. Bowling, Michelle L. Thompson, et al.  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1186/s13073-022-01139-2  </p>

<p><strong>Year:</strong>  </p>

<p>2022  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Genomics / Medical Genetics  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Incidental findings in pediatric genomic sequencing  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the emerging challenge of incidental genetic findings (IFs) outside ACMG-recommended lists in pediatric genomic sequencing. It draws from four research cohorts to illustrate types of IFs encountered, the decision-making processes for returning them, and conceptual considerations such as actionability, penetrance, severity, and personal utility.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>USA — University of Alabama at Birmingham, Baylor College of Medicine, UCSF, HudsonAlpha Institute for Biotechnology, among others.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Clinical geneticists, genetic counselors, policy-makers, laboratory directors, pediatricians.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed Methods — descriptive case series of 23 IFs in 21 pediatric patients across four genomic studies, combined with conceptual analysis of decision criteria.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical case data + conceptual framework for decision-making in returning non-ACMG IFs in pediatric contexts.  </p>

<h2>General Summary of the Paper</h2>

<p>This study examines the identification and return of incidental genetic findings (IFs) in pediatric patients from four genomic sequencing research projects. Unlike ACMG secondary findings (SFs), these IFs were not deliberately sought and involved genes not on the ACMG SF list. Across 2,246 patients, 23 IFs (0.93%) were identified, with notable variation in detection rates between sites. Conditions ranged from early-onset to adult-onset diseases, with diverse penetrance and severity. The authors discuss key considerations in deciding whether to return IFs: uncertainty of onset, disease severity, age of onset, clinical actionability, and personal utility. They illustrate these points through detailed patient cases, highlighting potential benefits (e.g., timely diagnosis, preventive interventions) and challenges (e.g., anxiety, unclear clinical relevance). They advocate for laboratories to develop internal policies and call for potential cross-laboratory guidelines to reduce variability.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>The paper implicitly defines actionability in the context of IF return as the potential for a genetic finding to influence patient management, enable preventive measures, guide surveillance, or avoid misdiagnosis, even if curative treatment is unavailable.  </p>

<blockquote>
  <p>“If the finding will alter patient care… then return of the result will be useful to the provider, patient, and family, and is warranted.” (p. 11, Table 3)  </p>
</blockquote>

<blockquote>
  <p>“Actionability… exists on a continuum… Actionability may also encompass… awareness… to avoid a future diagnostic odyssey or misdiagnosis.” (p. 14)  </p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Alters patient care (management, treatment, surveillance) in a beneficial way.  </p></li>
<li><p>Potential to prevent adverse outcomes or misdiagnosis.  </p></li>
<li><p>Enables timely screening or monitoring.  </p></li>
<li><p>Associated with conditions where preventive or mitigating actions exist.  </p></li>
<li><p>Can provide important awareness for at-risk family members.  </p></li>
</ul>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> No formal named model; uses structured considerations (Table 3).  </p></li>
<li><p><strong>Methods/Levers:</strong> Case-by-case assessment using penetrance, severity, age of onset, family history, and clinical utility.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Phenotype-independent variant analysis → classification (ACMG-AMP) → determination of relation to indication → IF categorization → decision to return based on actionability criteria.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Variant pathogenicity, disease penetrance estimates, onset age, family history, treatment/prevention options.  </p></li>
<li><p><strong>Implementation Context:</strong> Pediatric genomic sequencing across diverse clinical sites.  </p></li>
</ul>

<blockquote>
  <p>“Laboratories… [should] proactively plan for how they intend to characterize what constitutes an IF and the factors relevant to whether to return incidental results…” (p. 13)  </p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — need to differentiate IFs from primary findings, especially in young patients.  </p>

<p> &gt; “…differentiating incidental and primary findings can be difficult… especially when age of onset is highly variable.” (p. 11)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — family history and patient context inform decision to return.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — considers whether findings are clinically manageable or preventable.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — early-onset conditions prioritized; timing influences utility.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — cases show explanation of variant-disease links, but not a formal emphasis.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — return aligned with patient/family health planning and prevention goals.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Severity of disease, penetrance, personal utility.  </p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>ACMG guidelines for SFs.  </p></li>
<li><p>Ethical discourse on predictive testing in children.  </p></li>
<li><p>Concepts of clinical and personal utility from prior literature (e.g., Bunnik et al. 2015).  </p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Age of onset distribution for the condition.  </p></li>
<li><p>Disease penetrance estimates.  </p></li>
<li><p>Availability of screening or preventive interventions.  </p></li>
<li><p>Severity of condition.  </p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Variable penetrance, uncertain onset, incomplete phenotype data, potential anxiety, lack of consensus guidelines.  </p></li>
<li><p><strong>Enablers:</strong> Clear preventive/treatment pathways, strong family history, high penetrance, severe disease risk.  </p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Builds on debates around returning genomic findings in children, extending from ACMG SF frameworks to IFs, and integrates empirical pediatric case data to move beyond theoretical arguments.</p>

<h2>Summary</h2>

<p>This paper provides one of the most detailed empirical and conceptual analyses of returning non-ACMG incidental findings in pediatric genomic sequencing. It frames actionability broadly, considering not only clinical interventions but also avoidance of misdiagnosis, future planning, and personal utility. Key decision criteria include penetrance, age of onset, severity, clinical actionability, family history, and contextual relevance. Operationalization occurs via a case-by-case review informed by these criteria. While no formal universal framework is proposed, the authors offer a structured set of considerations (Table 3) that could underpin future guidelines. Variability in policies across institutions underscores the need for cross-laboratory consensus.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 — Strong implicit definition of actionability, rich feature set, empirical grounding; slightly reduced due to absence of a formalized named framework.  </p></li>
<li><p><strong>Operationalization Score:</strong> 75 — Detailed process descriptions and decision criteria; operationalized through cases but not a standardized step-by-step model.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[Actionability]… if the finding will alter patient care… then return of the result will be useful…” (p. 11, Table 3)  </p></li>
<li><p>“Actionability… exists on a continuum… may also encompass… awareness… to avoid… misdiagnosis.” (p. 14)  </p></li>
<li><p>“Diferentiating incidental and primary findings can be difficult… especially when… age of onset… is highly variable.” (p. 11)  </p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>ACMG SF v2.0 and v3.0 recommendations (Kalia et al., 2017; Miller et al., 2021)  </p></li>
<li><p>Bunnik EM et al., 2015 (personal utility in genomic testing)  </p></li>
<li><p>NCCN guidelines for cancer screening  </p></li>
<li><p>ClinGen Actionability Working Group protocols</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Reconciling evidence-based medicine and precision medicine in the era of big data: challenges and opportunities  </p>

<p>Authors: Jacques S. Beckmann, Daniel Lew  </p>

<p>DOI: 10.1186/s13073-016-0388-7  </p>

<p>Year: 2016  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Medicine / Clinical Bioinformatics  </p>

<p>Subdomain/Topic: Precision Medicine, Evidence-Based Medicine, Big Data Integration  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 85  </p>

<p>Operationalization Score: 70  </p>

<p>Contains Definition of Actionability: Yes (implicit, in terms of “clinically actionable knowledge”)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Partial (conceptual integration model)  </p>

<p>Operationalization Present: Yes (data integration, bioinformatics workflow)  </p>

<p>Primary Methodology: Conceptual / Review  </p>

<p>Study Context: Integration of precision medicine and evidence-based medicine in big data healthcare  </p>

<p>Geographic/Institutional Context: Switzerland (SIB Swiss Institute of Bioinformatics), global implications  </p>

<p>Target Users/Stakeholders: Clinicians, bioinformaticians, healthcare policymakers, patients/citizens  </p>

<p>Primary Contribution Type: Conceptual framework and challenges/opportunities analysis  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong> Reconciling evidence-based medicine and precision medicine in the era of big data: challenges and opportunities  </p>

<p><strong>Authors:</strong> Jacques S. Beckmann, Daniel Lew  </p>

<p><strong>DOI:</strong> 10.1186/s13073-016-0388-7  </p>

<p><strong>Year:</strong> 2016  </p>

<p><strong>Publication Type:</strong> Journal Article  </p>

<p><strong>Discipline/Domain:</strong> Medicine / Clinical Bioinformatics  </p>

<p><strong>Subdomain/Topic:</strong> Precision Medicine, Evidence-Based Medicine, Big Data Integration  </p>

<p><strong>Contextual Background:</strong> The paper addresses the tension and complementarity between precision medicine (individualized, data-driven care) and evidence-based medicine (population-derived guidelines), proposing a conceptual bridge enabled by big data, clinical bioinformatics, and global data-sharing.  </p>

<p><strong>Geographic/Institutional Context:</strong> Switzerland; global healthcare systems  </p>

<p><strong>Target Users/Stakeholders:</strong> Clinicians, bioinformaticians, policymakers, healthcare IT developers, patients/citizens  </p>

<p><strong>Primary Methodology:</strong> Conceptual / Review  </p>

<p><strong>Primary Contribution Type:</strong> Conceptual framework and challenge–opportunity mapping for integration of precision and evidence-based medicine.</p>

<h2>General Summary of the Paper</h2>

<p>This paper outlines how high-resolution, high-throughput biomedical technologies and big data can drive precision medicine, while highlighting its limitations compared to traditional evidence-based medicine. The authors propose “evidence-based precision medicine,” integrating the statistical robustness of population studies with the individualized tailoring of care enabled by molecular, environmental, and lifestyle data. They stress the role of clinical bioinformatics in converting heterogeneous datasets into clinically actionable knowledge. Key enablers include standardized data formats, interoperability, global data sharing, and patient empowerment. The authors foresee a shift from treatment to prevention, with citizens as active healthcare participants, but also note technical, semantic, ethical, and economic challenges.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>The authors frame actionability as the <strong>translation of big, heterogeneous biomedical datasets into “clinically actionable knowledge”</strong> for individual care and population-level benefit, enabled by clinical bioinformatics.</p>

<blockquote>
  <p>“Proper data mining and translation of the vast datasets into clinically actionable knowledge will require the application of clinical bioinformatics.” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“The real challenge… will be to curate, store, federate, integrate, share, mine, interpret, and transform these extensive heterogeneous data into scalable, medically actionable resources…” (p. 8)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Standardization and interoperability of clinical and laboratory datasets  </p></li>
<li><p>Integration of multi-layered data (genomics, microbiome, lifestyle, environmental)  </p></li>
<li><p>Statistical robustness from large cohorts combined with individual-level granularity  </p></li>
<li><p>Ethical, legal, and privacy safeguards for trust in data sharing  </p></li>
<li><p>Explainable outputs that can guide clinical decisions at the point of care</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Evidence-Based Precision Medicine  </p></li>
<li><p><strong>Methods/Levers:</strong> Big data integration, bioinformatics analysis, interoperability standards, meta-analyses across “N-of-one” and large-scale cohorts  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Data collection (EHR, wearables, genomics, etc.) → Standardization → Interoperable storage → Bioinformatics mining → Clinical decision support → Feedback to patient/clinician  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Omics, imaging, clinical measures, behavioral and lifestyle data, environmental exposure  </p></li>
<li><p><strong>Implementation Context:</strong> Multi-institutional, transnational data-sharing systems  </p></li>
</ul>

<blockquote>
  <p>“…collation and meta-analyses of big data from cross-institutional and transnational large-scale registers and cohorts…” (p. 6)  </p>
</blockquote>

<blockquote>
  <p>“…create sustainable federated, safe data commons or warehouses…” (p. 6)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — data must be interpretable for clinicians and patients.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — personalized care requires context-specific relevance.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — operational constraints considered in prevention focus.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — early detection emphasized, but not deeply operationalized.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — clinical bioinformatics bridges data complexity and clinical understanding.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — alignment to prevention, wellness, and patient-centered care.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Interoperability, standardization, patient empowerment.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Systems medicine (P4: predictive, preventive, personalized, participatory)  </p></li>
<li><p>Holistic integration of biological and environmental determinants of health  </p></li>
<li><p>N-of-one to N-of-many cohort aggregation</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Early detection of symptoms  </p></li>
<li><p>Identification of pre-symptomatic individuals  </p></li>
<li><p>Delay or prevention of disease onset  </p></li>
<li><p>Integration and usability of diverse data streams in decision-making</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Heterogeneous EHR systems, lack of interoperability, semantic complexity, data silos, privacy concerns, high costs, lack of training.  </p></li>
<li><p><strong>Enablers:</strong> Federated safe data commons, standardized vocabularies/ontologies, citizen participation, clinical bioinformatics expertise, wearable/self-monitoring technologies.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions precision and evidence-based medicine as complementary paradigms; builds on P4 medicine, systems biology, and big data health informatics literature.</p>

<h2>Summary</h2>

<p>Beckmann and Lew (2016) argue for integrating the population-level rigor of evidence-based medicine with the personalized depth of precision medicine, creating an “evidence-based precision medicine” paradigm. Actionability here means transforming diverse big data into clinically useful, context-relevant, and feasible recommendations that align with patient goals. This requires standardization, interoperability, large-scale data sharing, and advanced clinical bioinformatics to bridge data complexity and clinical decision-making. Key enablers include patient empowerment, wearable technology, and multi-modal data integration; challenges include semantic heterogeneity, privacy, economic feasibility, and education. The ultimate aim is to shift the focus from reactive treatment to proactive prevention and wellness.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 — Strong conceptual framing of actionability in a healthcare big data context; explicit features and conditions for actionability are present.  </p></li>
<li><p><strong>Operationalization Score:</strong> 70 — Provides a clear conceptual workflow and enabling infrastructure, but lacks detailed operational metrics or tested models.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Proper data mining and translation of the vast datasets into clinically actionable knowledge…” (p. 1)  </p></li>
<li><p>“The real challenge… will be to… transform these extensive heterogeneous data into scalable, medically actionable resources…” (p. 8)  </p></li>
<li><p>“…collation and meta-analyses of big data from cross-institutional and transnational large-scale registers and cohorts…” (p. 6)  </p></li>
<li><p>“Shifting emphasis of medicine more from therapy to prevention, and from disease to wellness” (Table 1, p. 5)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Auffray et al. (2009, 2015) on systems medicine  </p></li>
<li><p>Hood &amp; Price (2014) on prevention-focused precision medicine  </p></li>
<li><p>Schwaederle &amp; Kurzrock (2015) on actionability in oncology  </p></li>
<li><p>Collins (2015) on NIH precision medicine perspective</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Prospective Longitudinal ctDNA Workflow Reveals Clinically Actionable Alterations in Ovarian Cancer  </p>

<p>Authors: Jaana Oikkonen, Kaiyang Zhang, Liina Salminen, Ingrid Schulman, Kari Lavikka, Noora Andersson, Erika Ojanperä, Sakari Hietanen, Seija Grenman, Rainer Lehtonen, Kaisa Huhtinen, Olli Carpén, Johanna Hynninen, Anniina Färkkilä, Sampsa Hautaniemi  </p>

<p>DOI: https://doi.org/10.1200/PO.18.00343  </p>

<p>Year: 2019  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Oncology / Precision Medicine  </p>

<p>Subdomain/Topic: Circulating Tumor DNA (ctDNA) in High-Grade Serous Ovarian Cancer (HGSOC)  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes (implicit, clinically oriented)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (workflow pipeline)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Mixed Methods (prospective clinical cohort, bioinformatics pipeline)  </p>

<p>Study Context: Clinical workflow for longitudinal ctDNA analysis to guide treatment in HGSOC  </p>

<p>Geographic/Institutional Context: Turku University Hospital &amp; University of Helsinki, Finland  </p>

<p>Target Users/Stakeholders: Oncologists, molecular tumor boards, translational cancer researchers  </p>

<p>Primary Contribution Type: Clinical proof-of-concept &amp; open-source workflow  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Prospective Longitudinal ctDNA Workflow Reveals Clinically Actionable Alterations in Ovarian Cancer  </p>

<p><strong>Authors:</strong>  </p>

<p>Jaana Oikkonen, Kaiyang Zhang, Liina Salminen, Ingrid Schulman, Kari Lavikka, Noora Andersson, Erika Ojanperä, Sakari Hietanen, Seija Grenman, Rainer Lehtonen, Kaisa Huhtinen, Olli Carpén, Johanna Hynninen, Anniina Färkkilä, Sampsa Hautaniemi  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1200/PO.18.00343  </p>

<p><strong>Year:</strong>  </p>

<p>2019  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Oncology / Precision Medicine  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>ctDNA analysis in high-grade serous ovarian cancer (HGSOC)  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The study addresses the challenge of guiding treatment in metastatic solid cancers, particularly HGSOC, where tissue sampling is invasive and may not capture tumor heterogeneity. It develops an open-source ctDNA workflow to longitudinally monitor genomic alterations and guide therapy.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of Helsinki &amp; Turku University Hospital, Finland  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Oncologists, molecular tumor boards, translational researchers, precision medicine programs  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed methods — prospective clinical cohort of 12 HGSOC patients (78 plasma samples, 21 tissue samples) + bioinformatics and translational knowledgebase integration  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Clinical proof-of-concept and open-source workflow for actionable ctDNA detection  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This study presents a clinical and bioinformatics workflow for detecting clinically actionable alterations in HGSOC using longitudinal ctDNA sampling. The pipeline integrates &gt;500-gene targeted sequencing, a ctDNA-specific bioinformatics pipeline, and the Translational Oncology Knowledgebase to prioritize alterations based on ESCAT tiers. Across 12 patients, ctDNA mutations and CNAs showed high concordance with tumor tissue findings. Clinically actionable alterations were identified in 58% of patients, guiding therapy in one platinum-resistant case (ERBB2 amplification → trastuzumab + chemo) with significant tumor regression and CA-125 normalization. The workflow demonstrates early detection of poor responders and suggests potential for personalized treatment adaptation.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly defined as the presence of genomic alterations in ctDNA that can be linked to existing therapies, ranked by clinical evidence (ESCAT tiers), and used to guide treatment decisions in real time. Actionability requires reliable detection, clinical relevance, and therapeutic linkage.</p>

<blockquote>
  <p>“Potentially clinically actionable alterations were validated… classified as most prominent (ESCAT… Scale for Clinical Actionability of Molecular Targets)” (p. 3)  </p>
</blockquote>

<blockquote>
  <p>“The provided approach allows the selection of treatment options that target subclones that persist during therapy.” (p. 2)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Direct association with existing or investigational therapies  </p></li>
<li><p>Sufficient evidence of clinical relevance (ESCAT ranking)  </p></li>
<li><p>Persistence in tumor subclones during treatment  </p></li>
<li><p>Validation in tumor tissue (IHC/ISH)  </p></li>
<li><p>Concordance with patient’s mutational profile and disease context  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Clinical ctDNA workflow integrating sequencing, bioinformatics pipeline, and Translational Oncology Knowledgebase  </p></li>
<li><p><strong>Methods/Levers:</strong> &gt;500-gene targeted panel sequencing, variant/CNA calling, filtering, prioritization via knowledgebase, validation via IHC/ISH  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Longitudinal plasma sampling → sequencing → bioinformatics filtering → therapeutic matching (ESCAT) → validation → clinical decision  </p></li>
<li><p><strong>Data &amp; Measures:</strong> VAF dynamics, mutation counts, CNA ratios, CA-125 levels  </p></li>
<li><p><strong>Implementation Context:</strong> Prospective monitoring before, during, after chemotherapy in HGSOC  </p></li>
</ul>

<blockquote>
  <p>“Longitudinal ctDNA sampling can be used to detect response… and identify clinically applicable mutations and copy number alterations.” (p. 2)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — clear link between detected alteration and therapeutic relevance (ESCAT criteria).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — therapy matching based on patient-specific ctDNA profile.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — minimally invasive sampling, open-source tools.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — early detection of poor responders after 1–2 chemo cycles.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — biological pathway context and evidence level for each alteration.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — aligns with goal of improving survival in HGSOC by targeting resistant subclones.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Concordance with tumor tissue; evidence-based prioritization (ESCAT).  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>ESCAT (ESMO Scale for Clinical Actionability of Molecular Targets)  </p></li>
<li><p>Concepts from precision oncology: mTOR, HR deficiency, EGFR pathway targeting  </p></li>
<li><p>Longitudinal biomarker monitoring  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Variant Allele Frequency (VAF) trends  </p></li>
<li><p>CNA ratios  </p></li>
<li><p>CA-125 tumor marker correlation  </p></li>
<li><p>ESCAT evidence tier assignment  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Low VAF subclonal mutations, ctDNA heterogeneity, validation requirements, therapy availability  </p></li>
<li><p><strong>Enablers:</strong> Open-source pipeline, integration with knowledgebase, high plasma-tumor concordance, minimally invasive sampling  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on prior ctDNA monitoring studies (e.g., TP53 tracking in HGSOC) but extends to broad-panel actionable mutation detection and real-time therapeutic adaptation.</p>

<hr />

<h2>Summary</h2>

<p>This paper delivers a robust, clinically relevant framework for using longitudinal ctDNA profiling to guide therapy in HGSOC. Actionability is framed as the ability to detect and therapeutically match validated genomic alterations in a patient’s ctDNA profile, with emphasis on ESCAT evidence ranking and early detection of resistance. The study operationalizes this via a &gt;500-gene targeted sequencing panel, tailored bioinformatics pipeline, and knowledgebase integration, validated in a prospective cohort. The method not only identifies actionable alterations in over half of patients but also demonstrates a real-world therapy change with significant clinical benefit. The framework’s open-source nature enhances feasibility for clinical adoption.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 — Clear conceptualization of clinical actionability and explicit criteria for linking genomic findings to therapies.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Comprehensive, step-by-step clinical workflow integrating sampling, analysis, prioritization, and validation.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We identified high-confidence, potentially clinically actionable mutations or CNAs in seven patients (58%).” (p. 6)  </p></li>
<li><p>“The provided approach allows the selection of treatment options that target subclones that persist during therapy.” (p. 2)  </p></li>
<li><p>“Treatment… was changed on the basis of detection of ERBB2 amplification… followed by significant tumor shrinkage.” (p. 1)  </p></li>
<li><p>“Longitudinal ctDNA sampling can be used… to identify poor-responding patients after first cycles of chemotherapy.” (p. 1)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>ESCAT framework: Mateo et al., 2018  </p></li>
<li><p>TP53 monitoring in HGSOC: Parkinson et al., 2016  </p></li>
<li><p>Pathway-specific targeting references for mTOR, HR deficiency, EGFR, CDK alterations</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Policy Helix and Antecedents of Cybersecurity Policymaking Agility  </p>

<p>Authors: Masoud Afshari-Mofrad, Babak Abedin, Alireza Amrollahi  </p>

<p>DOI: Not provided  </p>

<p>Year: 2023  </p>

<p>Publication Type: Conference Paper  </p>

<p>Discipline/Domain: Information Systems / Cybersecurity Policy  </p>

<p>Subdomain/Topic: Cybersecurity policymaking agility; dynamic policy cycles; organisational resilience  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 88  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (implicitly—actionability as agility in policymaking)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: No  </p>

<p>Contains Framework/Model: Yes (Cybersecurity Policy Helix)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Qualitative (semi-structured expert interviews)  </p>

<p>Study Context: Cybersecurity policymaking in dynamic threat environments  </p>

<p>Geographic/Institutional Context: Australia; Macquarie University; multi-sector expert sample  </p>

<p>Target Users/Stakeholders: Policymakers, CISOs, cybersecurity managers, organisational boards  </p>

<p>Primary Contribution Type: Conceptual framework + empirical antecedents  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: Partial  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Policy Helix and Antecedents of Cybersecurity Policymaking Agility  </p>

<p><strong>Authors:</strong>  </p>

<p>Masoud Afshari-Mofrad, Babak Abedin, Alireza Amrollahi  </p>

<p><strong>DOI:</strong>  </p>

<p>Not provided  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference Paper  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Information Systems / Cybersecurity Policy  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Agility in cybersecurity policymaking; policy-cycle adaptation; cyber resilience  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>Addresses the need for agile cybersecurity policymaking (CSPM) in dynamic cyber threat environments, proposing a “policy helix” approach that integrates continuous sensing, adaptation, and evaluation. Grounded in organisational/digital agility and dynamic policy-cycle literature.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Macquarie University, Australia; expert interview participants from multiple sectors (ICT, finance, telecommunications, cybersecurity solutions).  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Policymakers, CISOs, CIOs, CTOs, cybersecurity managers, boards, risk committees.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Qualitative—inductive thematic analysis of semi-structured expert interviews (n=10).  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual model and empirically derived antecedents of CSPM agility.  </p>

<h2>General Summary of the Paper</h2>

<p>This paper investigates agility in cybersecurity policymaking as a strategic capability for organisations facing dynamic cyber threats. Through ten expert interviews, the authors conceptualise CSPM agility as a <em>dynamic policy helix</em>, where intelligence from internal and external sources continuously informs agenda-setting, formulation, implementation, and evaluation. The study identifies five antecedents: awareness, asset management, change management, vulnerability management, and cyber risk management. The “policy helix” builds on the dynamic policy cycle concept, integrating feedback loops at each stage. The findings stress that agility requires informed decision-makers, structured asset and risk processes, cross-departmental coordination, and ongoing training and awareness.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionability is implicitly framed as <em>policymaking agility</em>—the capacity to promptly adapt cybersecurity policies in response to internal and external signals, risks, and opportunities.  </p>

<blockquote>
  <p>“Policies are not an ideology that cannot be changed… they should instead be perceived as a means to facilitate the harmonious integration of technology and people” (p. 6)  </p>
</blockquote>

<blockquote>
  <p>“CSPM agility… means tailoring policies to both changes in the threat landscape and the organisation’s internal status” (p. 6)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Continuous sensing of threat landscape (internal/external)  </p></li>
<li><p>Policy adaptation to organisational risk appetite and maturity  </p></li>
<li><p>Integration of intelligence into agenda-setting and decision-making  </p></li>
<li><p>Feedback-informed reformulation and implementation  </p></li>
<li><p>Stakeholder awareness and engagement  </p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Cybersecurity Policy Helix  </p></li>
<li><p><strong>Methods/Levers:</strong> Continuous intelligence gathering, iterative agenda-setting, flexible decision-making, embedded evaluation loops  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Sense → Synthesise → Agenda-setting → Policy formulation/decision → Implementation → Evaluation → Loop back as needed  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Threat intelligence (internal/external), vulnerability scans, risk assessments, incident learnings, “top table” simulations  </p></li>
<li><p><strong>Implementation Context:</strong> Cross-sectoral, adaptable to organisational size/maturity  </p></li>
</ul>

<blockquote>
  <p>“Intelligence for policy formulation/reformulation can come from both internal and external sources… The changes need to be implemented and evaluated” (p. 8)  </p>
</blockquote>

<blockquote>
  <p>“Evaluation can occur locally at each stage… results might return to agenda-setting” (p. 8)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — training, awareness, common policy language stressed (p. 9)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — policy must align with organisational maturity and risk appetite (p. 6)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — workarounds for legacy systems and phased maturity building (p. 6)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — adapt policies before scheduled review cycles (p. 6)  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — rationale for changes linked to risk mitigation, though not explicitly framed as “explainability” (p. 9)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — align policy with business risk mitigation and enabling operations (p. 6)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Awareness, adaptability, stakeholder collaboration  </p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Digital agility and organisational agility literature (Pinsonneault &amp; Choi, 2022; Grover, 2022)  </p></li>
<li><p>Policy cycle framework (Lasswell, Brewer, Howlett et al.)  </p></li>
<li><p>Dynamic policy cycle (Valle-Cruz et al., 2020)  </p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Frequency and responsiveness of policy updates  </p></li>
<li><p>Reduction in unmitigated vulnerabilities  </p></li>
<li><p>Employee policy compliance rates  </p></li>
<li><p>Outcomes of “top table” simulations  </p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Board inexperience, lack of asset visibility, resistance to change, poor communication, legacy systems  </p></li>
<li><p><strong>Enablers:</strong> Informed leadership, structured asset/vulnerability management, dedicated risk committees/CRO, iterative training, cross-department collaboration  </p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Builds on organisational agility and dynamic policy cycle research, addressing a gap in operationalising agility specifically for cybersecurity policy. Extends Valle-Cruz et al. (2020) with a domain-specific “policy helix” model.</p>

<h2>Summary</h2>

<p>The paper reframes “actionability” as agility in cybersecurity policymaking, grounded in the ability to integrate continuous intelligence and adapt policies to dynamic threats and organisational conditions. It proposes the “cybersecurity policy helix” model, operationalising this agility through iterative loops between sensing, agenda-setting, formulation, implementation, and evaluation. Five antecedents—awareness, asset management, change management, vulnerability management, and cyber risk management—form the foundation for agility. Explicit links to clarity, contextual relevance, feasibility, timeliness, and goal alignment position agility as a multi-dimensional capability. The model offers both a theoretical lens for IS research and a practical blueprint for policy practitioners seeking cyber resilience.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 — Strong implicit conceptualisation of actionability as policymaking agility; detailed features tied to actionability.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Concrete framework, workflow, and organisational practices directly linked to achieving actionability.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[CSPM agility] means tailoring policies to both changes in the threat landscape and the organisation’s internal status” (p. 6)  </p></li>
<li><p>“Many companies… don’t have an asset management system… If you’re trying to formulate a cybersecurity policy… and you don’t know your assets, that’s not going to go too far” (p. 5)  </p></li>
<li><p>“Evaluation can occur locally at each stage… results might return to agenda-setting” (p. 8)  </p></li>
<li><p>“Change management is necessary… comprehending the risks” (p. 9)  </p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Valle-Cruz et al. (2020) — dynamic policy cycle  </p></li>
<li><p>Pinsonneault &amp; Choi (2022) — digital agility  </p></li>
<li><p>Grover (2022) — digital culture/ambidexterity  </p></li>
<li><p>Siregar &amp; Chang (2019) — cybersecurity agility  </p></li>
<li><p>Malatji et al. (2022) — asset management in cybersecurity</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: PIK3R1 W624R Is an Actionable Mutation in High Grade Serous Ovarian Carcinoma  </p>

<p>Authors: Concetta D’Ambrosio, Jessica Erriquez, Maddalena Arigoni, Sonia Capellero, Gloria Mittica, Eleonora Ghisoni, Fulvio Borella, Dionyssios Katsaros, Silvana Privitera, Marisa Ribotta, Elena Maldi, Giovanna Di Nardo, Enrico Berrino, Tiziana Venesio, Riccardo Ponzone, Marco Vaira, Douglas Hall, Mercedes Jimenez-Linan, Anna L. Paterson, Raffaele A. Calogero, James D. Brenton, Giorgio Valabrega, Maria Flavia Di Renzo, Martina Olivero  </p>

<p>DOI: 10.3390/cells9020442  </p>

<p>Year: 2020  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Oncology / Cancer Genomics  </p>

<p>Subdomain/Topic: Precision oncology; actionable mutations; ovarian cancer; PI3K pathway  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 82  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (explicit and implicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (patient-derived xenograft validation approach)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Experimental (patient-derived xenografts, ex vivo/in vivo drug testing)  </p>

<p>Study Context: High grade serous epithelial ovarian carcinoma (HGS-EOC)  </p>

<p>Geographic/Institutional Context: Italy (Candiolo Cancer Institute, University of Torino) &amp; UK (University of Cambridge, CRUK Cambridge Institute)  </p>

<p>Target Users/Stakeholders: Cancer researchers, molecular oncologists, clinical trial designers, translational oncology labs  </p>

<p>Primary Contribution Type: Empirical validation of rare actionable mutation in ovarian cancer  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: No  </p>

<p>EX: Partial  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Contextual Background:</strong>  </p>

<p>The study focuses on identifying and validating rare but actionable genetic mutations in HGS-EOC, particularly those in the “long tail” of cancer driver alterations. Patient-derived xenograft (PDX) and derived tumour cell (PDTC) models were used to investigate the functional and therapeutic relevance of the PIK3R1 W624R mutation, a rare alteration in the PI3K regulatory subunit.</p>

<h2>General Summary of the Paper</h2>

<p>This paper reports the discovery and validation of a rare PIK3R1 W624R mutation in high-grade serous ovarian carcinoma (HGS-EOC). Using whole exome sequencing, copy number analysis, and pyrosequencing, the authors identified the mutation as truncal in both the original tumour and PDX lines. Functional validation through ex vivo PDTC drug testing and in vivo PDX treatment demonstrated susceptibility of PIK3R1 W624R-carrying tumours to PI3K/AKT/mTOR pathway inhibitors (buparlisib, alpelisib, dactolisib) but not to p110β-specific inhibitors. The study highlights the unique role of PDX models in establishing the actionability of rare driver mutations and supports integrating such models into precision oncology pipelines.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>Actionability is defined as the functional property of a mutation that (1) renders tumour cells dependent (“addicted”) to a specific pathway, (2) has a targeted therapeutic available, and (3) confers responsiveness to such treatment.  </p>

<blockquote>
  <p>“Mutations have also been defined as ‘actionable’, not only because their functional outcome makes carrier cells responsive to a targeted therapy, but also thanks to the availability of a specific targeted drug.” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>The study uses PDX models “to validate low frequency mutations as biomarkers for targeted therapy” (p. 2).</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Functional impact on a key signalling pathway relevant to oncogenesis.  </p></li>
<li><p>Presence of a targeted drug that inhibits the altered pathway.  </p></li>
<li><p>Evidence from functional assays in relevant tumour models (PDX/PDTC).  </p></li>
<li><p>Truncal nature of the mutation (present in all tumour cells).  </p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> PDX–PDTC functional validation pipeline for rare mutations.  </p></li>
<li><p><strong>Methods/Levers:</strong> Whole exome sequencing, pyrosequencing for allele frequency, pathway activation markers (P-S6, P-AKT), ex vivo viability and cytotoxicity assays, in vivo drug efficacy in PDX models.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Identify candidate mutation via WES and CNA analysis.  </p>

<p> 2. Confirm truncal status via allele frequency in tumour and PDX.  </p>

<p> 3. Predict functional consequences via in silico analysis and structural modelling.  </p>

<p> 4. Test pathway activation via immunohistochemistry (P-S6).  </p>

<p> 5. Test drug sensitivity in PDTCs to multiple inhibitors.  </p>

<p> 6. Validate in vivo efficacy in PDX tumour growth and biomarker changes.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Allele frequency, GR metrics in viability assays, IHC quantification of Ki67 and P-S6, tumour volume in vivo.  </p></li>
<li><p><strong>Implementation Context:</strong> HGS-EOC PDX biobank.  </p></li>
</ul>

<blockquote>
  <p>“PDX model… invaluable for functional validation, as it allowed overcoming questionable assays in test tubes or in unrelated cell types.” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“PIK3R1 W624R carrying cells [were] addicted… to inhibitors of the PI3K/AKT/mTOR pathway.” (Abstract)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — functional consequences demonstrated through targeted assays and clear drug-response metrics.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — relevance to ovarian cancer context stressed; rare mutation validated in disease-matched models.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — presence of clinically available inhibitors; mutation is targetable.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No explicit link.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — mechanistic explanation offered but structural modelling inconclusive.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — aligns with precision oncology aim of matching mutations to therapies.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Truncality, pathway addiction.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Precision oncology model of “driver” vs. “passenger” mutations.  </p></li>
<li><p>Concept of mutation “addiction” to specific signalling pathways.  </p></li>
<li><p>Basket/umbrella trial rationale for cross-cancer therapeutic targeting.</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Mutation truncal status.  </p></li>
<li><p>Drug-response curves (GR metrics).  </p></li>
<li><p>Biomarker modulation (P-AKT, P-S6) upon inhibitor treatment.  </p></li>
<li><p>In vivo tumour growth delay and reduced proliferation index.</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Low frequency of mutation; inconclusive structural modelling; lack of prior functional characterisation in ovarian cancer.  </p></li>
<li><p><strong>Enablers:</strong> Availability of relevant inhibitors; PDX/PDTC models mimicking patient tumour biology; high allele frequency indicating truncality.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>The authors note that while PIK3R1 mutations are common in other cancers, they are rare in HGS-EOC. Prior studies lacked functional validation in ovarian models. This study fills that gap, showing that a cSH2 domain mutation (previously unlinked to oncogenesis) can be actionable in this context.</p>

<h2>Summary</h2>

<p>This study identifies and functionally validates a rare PIK3R1 W624R mutation as actionable in high-grade serous ovarian carcinoma. Using a PDX–PDTC pipeline, the authors demonstrate that this truncal mutation activates the PI3K/AKT/mTOR pathway and renders tumour cells dependent on it. The mutation confers sensitivity to PI3K inhibitors (buparlisib, alpelisib, dactolisib) but not to p110β-specific inhibitors. Structural modelling could not fully explain the functional impact, underlining the need for experimental validation in relevant disease models. This work exemplifies how rare mutations in the “long tail” of cancer drivers can be prioritised and operationalised in precision oncology when robust functional models and therapeutic agents are available.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 82 — Clear conceptualisation of actionability with explicit definition, truncal mutation concept, and disease-context specificity.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Detailed, reproducible pipeline from mutation identification to functional validation and therapeutic testing.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Mutations… defined as ‘actionable’, not only because their functional outcome makes carrier cells responsive to a targeted therapy, but also thanks to the availability of a specific targeted drug.” (p. 2)  </p></li>
<li><p>“PIK3R1 W624R carrying cells [were] addicted… to inhibitors of the PI3K/AKT/mTOR pathway.” (Abstract)  </p></li>
<li><p>“PDX model… invaluable for functional validation, as it allowed overcoming questionable assays in test tubes or in unrelated cell types.” (p. 2)  </p></li>
<li><p>“The PIK3R1 W624R #475 PDTCs… were sensitive to… buparlisib… alpelisib… dactolisib… but not… GSK2636771.” (p. 11)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>COSMIC (CGCv84) database [28]  </p></li>
<li><p>DGidb drug–gene interaction database [31]  </p></li>
<li><p>References on PI3K/AKT/mTOR inhibitors in clinical development [20, 48–51]  </p></li>
<li><p>Prior functional studies on PIK3R1 mutations [32, 38–40]</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Opportunity Map: A Visualization Framework for Fast Identification of Actionable Knowledge</p>

<p>Authors: Kaidi Zhao, Bing Liu, Thomas M. Tirpak, Weimin Xiao</p>

<p>DOI: 10.1145/1099554.1099684</p>

<p>Year: 2005</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Computer Science / Information Systems</p>

<p>Subdomain/Topic: Data Mining, Visualization, Actionable Knowledge Discovery</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 88</p>

<p>Operationalization Score: 90</p>

<p>Contains Definition of Actionability: Yes (implicit and explicit elements)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes (Opportunity Map)</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual with applied case study</p>

<p>Study Context: Post-mining analysis of large rule sets from data mining to identify actionable patterns</p>

<p>Geographic/Institutional Context: University of Illinois at Chicago; Motorola Labs (USA)</p>

<p>Target Users/Stakeholders: Data analysts, product designers, decision-makers in industrial contexts</p>

<p>Primary Contribution Type: Visualization framework and interactive analysis method</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Partial</p>

<p>EX: Partial</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong> Opportunity Map: A Visualization Framework for Fast Identification of Actionable Knowledge  </p>

<p><strong>Authors:</strong> Kaidi Zhao, Bing Liu, Thomas M. Tirpak, Weimin Xiao  </p>

<p><strong>DOI:</strong> 10.1145/1099554.1099684  </p>

<p><strong>Year:</strong> 2005  </p>

<p><strong>Publication Type:</strong> Conference  </p>

<p><strong>Discipline/Domain:</strong> Computer Science / Information Systems  </p>

<p><strong>Subdomain/Topic:</strong> Data Mining, Visualization, Actionable Knowledge Discovery  </p>

<p><strong>Contextual Background:</strong> This work addresses the challenge of sifting through large volumes of mined patterns/rules to identify those that are genuinely actionable for a user’s specific application goals. It adapts concepts from Quality Function Deployment’s “House of Quality” to the visualization of rules, enabling systematic prioritization of actionable attributes and classes.  </p>

<p><strong>Geographic/Institutional Context:</strong> University of Illinois at Chicago; Motorola Labs, USA  </p>

<p><strong>Target Users/Stakeholders:</strong> Data analysts, product engineers, product managers, decision-makers in industrial settings  </p>

<p><strong>Primary Methodology:</strong> Conceptual development with real-world industrial case study  </p>

<p><strong>Primary Contribution Type:</strong> Framework/methodology (Opportunity Map) with interactive visualization for post-processing rules  </p>

<h2>General Summary of the Paper</h2>

<p>The paper proposes the <strong>Opportunity Map</strong>, a visual data mining framework designed to quickly identify actionable knowledge from large sets of discovered rules. Drawing inspiration from the “House of Quality” in Quality Function Deployment, the framework organizes rules into a matrix of attributes (technical requirements) vs. classes (customer requirements), sorted by importance and actionability. Key sectors highlight priority opportunities, with drill-down and comparative study capabilities. The method emphasizes post-mining analysis, enabling users to isolate actionable rules by visually exploring their statistical strength (support/confidence) and domain relevance. A Motorola case study demonstrates the system’s ability to identify design-change opportunities that were missed by traditional mining thresholds.  </p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as the ability of a rule or pattern to guide concrete interventions within the user’s domain to achieve desired effects. Attributes are deemed “actionable” if the user can influence them in practice. The focus is on <strong>practical utility</strong>, not just statistical significance.</p>

<blockquote>
  <p>“An attribute is actionable if the user is able to do something with that attribute to achieve some desired effects.” (p. 4)  </p>
</blockquote>

<blockquote>
  <p>“Actionability is the key… It depends on the task that the user wants to perform.” (p. 1)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>The attribute must be controllable within the user’s context.</p></li>
<li><p>The class or problem addressed must be important to the user’s goals.</p></li>
<li><p>The relationship between attribute and class should be clear, strong (support/confidence), and interpretable.</p></li>
<li><p>Patterns must be applicable to real-world decision-making, not just surprising.</p></li>
</ul>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Opportunity Map  </p></li>
<li><p><strong>Methods/Levers:</strong> Visual prioritization matrix; user-driven sorting by importance and actionability; drill-down visualizations; comparative studies.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Mine rules (e.g., with class association rule miner CBA).  </p>

<p> 2. Visualize as attribute–class matrix.  </p>

<p> 3. Arrange classes (by importance) and attributes (by actionability).  </p>

<p> 4. Focus on top-left priority sector (important + actionable).  </p>

<p> 5. Drill down into attribute–class pairs to find finer-grained actionable rules.  </p>

<p> 6. Compare rule sets across subsets (e.g., product versions).  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Support and confidence of rules; number of rules per cell; coverage of data points.  </p></li>
<li><p><strong>Implementation Context:</strong> Post-mining analysis in industrial product design/failure diagnosis.  </p></li>
</ul>

<blockquote>
  <p>“This isolates a small area in the matrix… that may contain actionable rules.” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“The insights from these rules are immediately actionable, as engineers can… identify/propose possible design changes.” (p. 8)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — visualization aids interpretation and explicit linking of attributes to classes.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — prioritization is based on user/application importance.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — actionable attributes are defined as those under user control.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — focuses on efficiency in identification, but not time-to-implementation.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — interpretability via visualization; not formal model explainability.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — prioritization matrix directly aligns with application objectives.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Unexpectedness (as contrast with actionability).</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Quality Function Deployment (House of Quality)  </p></li>
<li><p>Rule interestingness measures (objective vs. subjective) from data mining literature  </p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Support and confidence of rules in priority sectors  </p></li>
<li><p>Number of rules covering key attribute–class intersections  </p></li>
<li><p>Coverage percentage of rules over relevant data points  </p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Imbalanced datasets, non-actionable attributes, overwhelming number of rules  </p></li>
<li><p><strong>Enablers:</strong> Visualization of priorities, interactive drill-down, comparative analysis  </p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>The framework integrates subjective interestingness with visual analytics, diverging from existing visualization techniques that focus on support/confidence alone. Unlike prior methods, it explicitly incorporates actionability as a guiding principle for sorting and interpreting mined rules.</p>

<h2>Summary</h2>

<p>The <strong>Opportunity Map</strong> framework offers a systematic and interactive way to identify actionable knowledge from large rule sets. By mapping attributes against classes and sorting them by user-defined importance and actionability, it isolates the most promising opportunities for intervention. It extends concepts from Quality Function Deployment to data mining, using cell-level visualization to show rule strength and coverage, and supports comparative analysis to uncover performance differences between products or scenarios. The Motorola case study illustrates how it can reveal design insights that traditional rule mining misses due to statistical thresholds. This makes it both a conceptual contribution to defining actionability and a practical tool for operationalizing it.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 — Strong conceptualization of actionability linked to operational needs; integrates subjective and objective criteria; minor limitations in formal definitional precision.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Detailed, step-by-step framework with tooling, workflow, and industrial application; high applicability in practice.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Actionability is the key… It depends on the task that the user wants to perform.” (p. 1)  </p></li>
<li><p>“An attribute is actionable if the user is able to do something with that attribute to achieve some desired effects.” (p. 4)  </p></li>
<li><p>“This isolates a small area in the matrix… that may contain actionable rules.” (p. 2)  </p></li>
<li><p>“The insights from these rules are immediately actionable…” (p. 8)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>[1] Adomavicius &amp; Tuzhilin (1997) — Action hierarchy approach.  </p></li>
<li><p>[17] Liu et al. (2001) — Identifying non-actionable association rules.  </p></li>
<li><p>[22] Piatesky-Shapiro &amp; Matheus (1994) — Interestingness of deviations.  </p></li>
<li><p>[26] Silberschatz &amp; Tuzhilin (1996) — Patterns interestingness framework.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Ontological Approach in the Smart Data Paradigm as a Basis for Open Data Semantic Markup</p>

<p>Authors: Julia Rogushina</p>

<p>DOI: n/a</p>

<p>Year: 2023</p>

<p>Publication Type: Conference Paper</p>

<p>Discipline/Domain: Computer Science / Information Systems</p>

<p>Subdomain/Topic: Smart Data, Semantic Markup, Ontologies, Open Data</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 88</p>

<p>Operationalization Score: 85</p>

<p>Contains Definition of Actionability: Yes (implicit, linked to “Smart Data” as actionable knowledge)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual with Applied Case Study</p>

<p>Study Context: Semantic markup and ontological structuring in Smart Data processing for open data resources</p>

<p>Geographic/Institutional Context: Institute of Software Systems, National Academy of Sciences of Ukraine; Great Ukrainian Encyclopedia portal</p>

<p>Target Users/Stakeholders: Researchers, ontology engineers, open data curators, semantic web developers</p>

<p>Primary Contribution Type: Conceptual framework with practical application</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Partial</p>

<p>EX: Yes</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: n/a</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Ontological Approach in the Smart Data Paradigm as a Basis for Open Data Semantic Markup  </p>

<p><strong>Authors:</strong>  </p>

<p>Julia Rogushina  </p>

<p><strong>DOI:</strong>  </p>

<p>n/a  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference Paper  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Information Systems  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Smart Data, Semantic Markup, Ontologies, Open Data  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper is situated within the Smart Data paradigm, focusing on transforming raw, often unstructured data into actionable knowledge for decision-making, automation, and research purposes. The work emphasizes semantic markup—particularly via ontologies and Semantic MediaWiki—to structure open data for reuse and interoperability.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Institute of Software Systems, National Academy of Sciences of Ukraine; case study on the Great Ukrainian Encyclopedia portal (e-VUE).  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Researchers, semantic data engineers, open data platform managers, cultural heritage digitization projects, ontology developers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework with applied implementation case study.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual modeling + applied system implementation.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper explores how unstructured or semi-structured data can be transformed into Smart Data—data that is processed, analyzed, and converted into actionable knowledge. It emphasizes ontological approaches for semantic markup, enabling structured representation, interoperability, and automated reasoning. The author discusses how ontologies can be tailored (e.g., through task thesauri or reduced ontologies) to optimize semantic markup for domain-specific needs. Semantic MediaWiki (SMW) is presented as a practical platform, with a detailed case study on structuring the Great Ukrainian Encyclopedia’s open data resources. The work formalizes models for Wiki-ontologies and task thesauri, outlines parameters for selecting or adapting ontologies, and proposes automation methods for ontology reduction and integration.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Smart Data is defined as data that has been processed into “actionable insights or knowledge” to support decision-making, automation, and intelligent applications. Actionability here implies:</p>

<ul>
<li><p>Trusted, contextualized, relevant, cognitive, predictive, and consumable data.</p></li>
<li><p>Structured or semi-structured representation enabling machine-actionable use.  </p></li>
</ul>

<blockquote>
  <p>“Smart data mines semantics from Big data and provide information that can be used to make decisions…” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“…transform input ‘raw’ data into machine-understandable, machine-processable, and machine-actionable…” (p. 2)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Semantic enrichment</strong> via ontologies and metadata.  </p></li>
<li><p><strong>Contextual relevance</strong> to specific tasks or domains.  </p></li>
<li><p><strong>Feasibility of processing</strong> (appropriate ontology expressiveness and size).  </p></li>
<li><p><strong>Trust and quality</strong> of data (FAIR principles).  </p></li>
<li><p><strong>Goal alignment</strong> with user needs and analysis objectives.  </p></li>
<li><p><strong>Explainability and interpretability</strong> via formalized semantics.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Semantic markup using ontology-based Smart Data transformation; Semantic MediaWiki-based Wiki-ontology framework.</p></li>
<li><p><strong>Methods/Levers:</strong> Ontology selection/reduction; task thesauri; semantic templates; linking markup tags to domain concepts.</p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Retrieve relevant external ontology.  </p>

<p> 2. Transform/reduce ontology to task needs.  </p>

<p> 3. Map ontology elements to markup tags.  </p>

<p> 4. Implement markup in SMW (categories, templates, semantic properties).  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Metadata completeness, ontology expressiveness, query support.</p></li>
<li><p><strong>Implementation Context:</strong> Great Ukrainian Encyclopedia portal (e-VUE).  </p></li>
</ul>

<blockquote>
  <p>“…formalize models for such special cases of ontologies as Wiki ontology and task thesaurus.” (p. 14)  </p>
</blockquote>

<blockquote>
  <p>“…retrieval of external domain ontology… transformation according to semantic markup requirements… transformation of domain knowledge into markup representation…” (p. 11)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Clear semantic markup rules and ontology alignment.  </p>

<p> &gt; “Understandability of the markup language… standardized notations…” (p. 6)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Ontology must be relevant to task domain.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Ontology size/complexity must allow efficient processing.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Discusses ongoing enrichment but not explicit temporal constraints.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Formal semantics enable reasoning.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Ontology and markup designed per specific information needs.  </p></li>
<li><p><strong>Other Dimensions:</strong> Interoperability (FAIR principles), standard compliance.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>DIKW pyramid adapted for Big Data.  </p></li>
<li><p>FAIR data principles.  </p></li>
<li><p>Ontology theory (Gruber 1993).  </p></li>
<li><p>Semantic Web standards (RDF, OWL).  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Degree of semantic enrichment.  </p></li>
<li><p>Ontology-task alignment (coverage and absence of redundancy).  </p></li>
<li><p>Query expressiveness in SMW.  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Overly large or irrelevant ontologies.  </p>

<p> - Lack of domain standards in ontology form.  </p>

<p> - Computational overhead in complex reasoning.  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Ontology reduction methods.  </p>

<p> - Use of open knowledge sources.  </p>

<p> - SMW semantic templates.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on semantic markup and ontology integration in Smart Data, extending concepts with a formal model for Wiki-ontology and task thesauri. Connects to existing FAIR, Semantic Web, and DIKW discussions.</p>

<hr />

<h2>Summary</h2>

<p>This paper positions “actionability” within the Smart Data paradigm, framing it as the transformation of raw or unstructured data into trusted, contextualized, and machine-actionable knowledge through semantic markup. The author provides explicit formal models for ontology-based markup, focusing on reduced ontologies and task-specific thesauri to maximize relevance and processing feasibility. Semantic MediaWiki is demonstrated as a practical tool, with the Great Ukrainian Encyclopedia serving as a real-world application. Actionability emerges through clarity of semantics, contextual relevance, feasible ontology size, goal alignment, and explainability, underpinned by interoperability standards. The paper’s operationalization score is high due to concrete workflow steps for ontology transformation, markup design, and integration into a semantic wiki environment.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 — Strong conceptualization of actionable data via Smart Data, with systematic features well-defined.  </p></li>
<li><p><strong>Operationalization Score:</strong> 85 — Clear, task-oriented methods for achieving actionability through ontology-based semantic markup, demonstrated in a real system.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Smart data mines semantics from Big data and provide information that can be used to make decisions…” (p. 2)  </p></li>
<li><p>“…transform input ‘raw’ data into machine-understandable, machine-processable, and machine-actionable…” (p. 2)  </p></li>
<li><p>“…retrieval of external domain ontology… transformation according to semantic markup requirements…” (p. 11)  </p></li>
<li><p>“Understandability of the markup language… standardized notations…” (p. 6)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>DIKW hierarchy (Hey, 2004)  </p></li>
<li><p>FAIR data principles (FAIR_data, 2021)  </p></li>
<li><p>Gruber (1993) on ontology specifications  </p></li>
<li><p>Semantic Web foundational works (RDF, OWL)  </p></li>
<li><p>Zeng (2017) on Smart Data for digital humanities</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Next-generation sequencing, should I use anti-HER2 therapy for HER2-amplified tumors off-label? Illustrating an extrapolation framework  </p>

<p>Authors: Doah Cho, Sarah J. Lord, John Simes, Wendy Cooper, Michael Friedlander, Susie Bae, Chee Khoon Lee  </p>

<p>DOI: 10.1177/17588359221112822  </p>

<p>Year: 2022  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Oncology / Precision Medicine  </p>

<p>Subdomain/Topic: HER2-targeted therapy; Off-label treatment decision frameworks  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (implicit and explicit in biomarker–treatment context)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes (biological rationale, biomarker testing validity)  </p>

<p>Contains Framework/Model: Yes (seven-question extrapolation framework)  </p>

<p>Operationalization Present: Yes (detailed framework and application example)  </p>

<p>Primary Methodology: Conceptual / Framework development with illustrative application  </p>

<p>Study Context: Clinical decision-making for off-label HER2-targeted therapy in HER2-amplified cancers without direct RCT evidence  </p>

<p>Geographic/Institutional Context: Australia; University of Sydney and collaborating institutions  </p>

<p>Target Users/Stakeholders: Oncologists, molecular tumor boards, clinical researchers, policymakers  </p>

<p>Primary Contribution Type: Conceptual framework + practical guidance for extrapolation in precision oncology  </p>

<p>CL: Yes — clarity in biomarker definition and testing necessary for actionability  </p>

<p>CR: Yes — explicitly ties contextual relevance to extrapolation appropriateness  </p>

<p>FE: Yes — feasibility linked to cost/access and biomarker testing capability  </p>

<p>TI: Partial — timeliness implied in using current testing and treatment options before disease progression  </p>

<p>EX: Yes — explainability through step-wise rationale and biological plausibility  </p>

<p>GA: Yes — alignment with clinical goals of improved patient outcomes and informed consent  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Next-generation sequencing, should I use anti-HER2 therapy for HER2-amplified tumors off-label? Illustrating an extrapolation framework  </p>

<p><strong>Authors:</strong>  </p>

<p>Doah Cho, Sarah J. Lord, John Simes, Wendy Cooper, Michael Friedlander, Susie Bae, Chee Khoon Lee  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1177/17588359221112822  </p>

<p><strong>Year:</strong>  </p>

<p>2022  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Oncology / Precision Medicine  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>HER2-targeted therapy; Off-label treatment decision frameworks  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>This paper addresses the growing clinical challenge of whether targeted cancer therapies—proven in specific tumor types—should be used off-label for patients whose tumors share the same actionable biomarker but lack direct trial evidence. HER2 amplification and trastuzumab are used as an illustrative case, with focus on next-generation sequencing (NGS)–identified biomarkers.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Australia; National Health and Medical Research Council Clinical Trials Centre, University of Sydney; collaborating hospitals and research centers.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Oncologists, molecular tumor boards, precision oncology decision-makers, clinical researchers, and policymakers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework development with illustrative clinical application.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Decision-making framework for extrapolating biomarker–treatment evidence to off-label contexts.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper presents a structured framework for deciding whether to use targeted therapies off-label when a tumor shares a molecular alteration with a cancer type where the therapy is proven effective. Using HER2 amplification and trastuzumab as a case study, the authors propose seven key questions addressing analytical validity, biomarker criteria, actionability, natural history, activity signals, safety, and shared decision-making. The framework synthesizes biological, clinical, and practical factors, emphasizes uncertainty assessment, and provides guidance for informed consent and ethical considerations. The approach is designed to be generalizable to other biomarker–therapy pairs.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is defined as the co-dependency between a biomarker and a targeted treatment—where selecting treatment based on biomarker status improves outcomes compared to decisions made without it. HER2 amplification is considered actionable where RCTs have shown trastuzumab plus chemotherapy improves survival in certain cancers.  </p>

<blockquote>
  <p>“A biomarker is ‘actionable’ if treatment selection based on biomarker status improves clinical outcomes compared to decisions made without it.” (p. 6)  </p>
</blockquote>

<blockquote>
  <p>“Actionability may differ between cancers due to differences in intratumoral heterogeneity, tumor microenvironment, and compensatory resistance mechanisms.” (p. 6)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Reliable and validated biomarker testing (analytical validity)  </p></li>
<li><p>Clearly defined biomarker positivity criteria for the cancer type  </p></li>
<li><p>Strong evidence from clinical trials or high-quality non-randomized studies linking biomarker presence to improved treatment outcomes  </p></li>
<li><p>Biological plausibility and consistency across tumor types  </p></li>
<li><p>Distinction between prognostic and predictive value  </p></li>
<li><p>Consideration of surrogate endpoint validity  </p></li>
<li><p>Comparable safety profile in new cancer context  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Seven-question extrapolation framework  </p></li>
<li><p><strong>Methods/Levers:</strong> Analytical validity check, biomarker criteria validation, evidence tiering (ESCAT), natural history assessment, surrogate endpoint evaluation, safety review, shared decision-making  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Sequential question-based evaluation; uncertainty scoring for each domain; totality-of-evidence decision; patient consent process  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Concordance metrics (NGS vs. evidentiary standard tests), prevalence data, predictive values, RCT and observational outcome measures, toxicity rates  </p></li>
<li><p><strong>Implementation Context:</strong> Applied by clinicians and molecular tumor boards when trial data are lacking but molecular rationale exists  </p></li>
</ul>

<blockquote>
  <p>“Questions 1 to 6 should be considered individually, and judgment for the level of uncertainty for extrapolation should be made for each.” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“Recommendations should be individualized and consider the estimated benefit versus risks of off-label therapy compared to alternative therapies if available.” (p. 2)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — need for transparent, validated biomarker definition.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — extrapolation must consider tumor-specific biology.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — feasibility tied to cost, access, and testing capabilities.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — urgency implied to decide before disease progression.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — framework explicitly explains rationale for decisions.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — focused on aligning treatment with patient outcome goals.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Safety similarity, surrogate endpoint validity, cost and equity implications.  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>ESMO Scale for Clinical Actionability of molecular Targets (ESCAT)  </p></li>
<li><p>GRADE Evidence-to-Decision (EtD) frameworks  </p></li>
<li><p>PICO model for framing clinical questions  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Concordance rates between NGS and standard HER2 testing  </p></li>
<li><p>Sensitivity, specificity, PPV, and NPV of biomarker assays  </p></li>
<li><p>Survival and response outcomes from RCTs or high-quality observational studies  </p></li>
<li><p>Surrogate endpoint validation status in the cancer type of interest  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Biological heterogeneity; lack of validated criteria in new tumor type; unvalidated surrogates; financial costs; limited access; uncertainty in benefit magnitude.  </p></li>
<li><p><strong>Enablers:</strong> Strong biomarker–treatment evidence in analogous cancers; validated testing; patient willingness; multidisciplinary support.  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions the framework within ongoing discussions about precision oncology actionability, building on ESCAT and other biomarker evidence frameworks, but uniquely integrates cost, safety, and informed consent considerations.</p>

<hr />

<h2>Summary</h2>

<p>This paper develops and illustrates a structured seven-question framework to guide off-label targeted therapy use in biomarker-defined cancers lacking direct trial evidence. Using HER2 amplification and trastuzumab as the exemplar, it operationalizes actionability as the intersection of validated biomarker testing, evidence of benefit, biological plausibility, and patient-centered decision-making. The framework evaluates uncertainty at each step, integrates safety and cost considerations, and stresses the ethical imperative for shared decision-making. It is designed to be adaptable across tumor types and biomarkers, making it a significant practical contribution to precision oncology decision-making.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Strong explicit/implicit definition of actionability, comprehensive feature set linked to actionability.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Detailed and actionable framework with clear application steps, though surrogate endpoint reliance limits certainty in some contexts.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“A biomarker is ‘actionable’ if treatment selection based on biomarker status improves clinical outcomes compared to decisions made without it.” (p. 6)  </p></li>
<li><p>“Have the criteria used to define HER2 positivity been assessed in the cancer type for off-label trastuzumab?” (p. 5)  </p></li>
<li><p>“Questions 1 to 6 should be considered individually, and judgment for the level of uncertainty for extrapolation should be made for each.” (p. 2)  </p></li>
<li><p>“Off-label therapy may be justified if sufficient evidence exists to support a positive benefit-risk assessment.” (p. 8)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>ESCAT (Mateo et al., 2018)  </p></li>
<li><p>Wolff et al., 2018 HER2 testing guidelines  </p></li>
<li><p>Multiple RCTs: Slamon et al., 2001; Bang et al., 2010; Fader et al., 2020  </p></li>
<li><p>Haslam et al., 2019 surrogate endpoint correlation study</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Navigating Uncertainty: Challenges in Visualizing Ensemble Data and Surrogate Models for Decision Systems  </p>

<p>Authors: Kristi Potter, Sam Molnar, J.D. Laurence-Chasen, Yuhan Duan, Julie Bessac, Han-Wei Shen  </p>

<p>DOI: 10.1109/MCG.2025.3549665  </p>

<p>Year: 2025  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Computer Graphics / Visualization  </p>

<p>Subdomain/Topic: Uncertainty visualization, ensemble simulation, surrogate modeling, decision support systems  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 88  </p>

<p>Operationalization Score: 80  </p>

<p>Contains Definition of Actionability: Yes (implicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (conceptual)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual + Case Study (Flood Modeling)  </p>

<p>Study Context: Visualization design for integrating ensemble data and AI-based surrogate models to support decision-making under uncertainty  </p>

<p>Geographic/Institutional Context: National Renewable Energy Laboratory (USA), The Ohio State University (USA)  </p>

<p>Target Users/Stakeholders: Decision-makers, scientists, engineers, emergency planners  </p>

<p>Primary Contribution Type: Conceptual framework + applied case study  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong> Navigating Uncertainty: Challenges in Visualizing Ensemble Data and Surrogate Models for Decision Systems  </p>

<p><strong>Authors:</strong> Kristi Potter, Sam Molnar, J.D. Laurence-Chasen, Yuhan Duan, Julie Bessac, Han-Wei Shen  </p>

<p><strong>DOI:</strong> 10.1109/MCG.2025.3549665  </p>

<p><strong>Year:</strong> 2025  </p>

<p><strong>Publication Type:</strong> Journal  </p>

<p><strong>Discipline/Domain:</strong> Computer Graphics / Visualization  </p>

<p><strong>Subdomain/Topic:</strong> Uncertainty visualization, ensemble simulation, surrogate modeling, decision support systems  </p>

<p><strong>Contextual Background:</strong> The paper addresses how uncertainty visualization can transform ensemble simulation and surrogate model data into actionable insights. It focuses on integrating both data sources in decision-making workflows, emphasizing challenges in representing and reconciling uncertainties.  </p>

<p><strong>Geographic/Institutional Context:</strong> USA – National Renewable Energy Laboratory, The Ohio State University  </p>

<p><strong>Target Users/Stakeholders:</strong> Decision-makers in domains such as disaster response, infrastructure planning, energy systems, healthcare  </p>

<p><strong>Primary Methodology:</strong> Conceptual + applied case study (flood modeling scenario)  </p>

<p><strong>Primary Contribution Type:</strong> Conceptual framing with practical illustration</p>

<h2>General Summary of the Paper</h2>

<p>The paper examines how uncertainty visualization can support decision-making when combining ensemble simulation data with AI-driven surrogate models. It details how each data source presents unique strengths and limitations and explores design considerations for integrating them effectively. The authors provide a case study on flood modeling, demonstrating forward and inverse surrogate use in hazard prediction and planning. Key challenges include clearly communicating uncertainty types, ensuring user trust, and supporting decision tasks such as tradeoff analysis. Recommendations are made for leveraging complementary strengths, differentiating uncertainty sources, and clarifying input–output relationships.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>The authors implicitly define actionability as enabling decision-makers to confidently interpret, navigate, and use uncertainty information from ensemble and surrogate models to guide specific, context-relevant actions.</p>

<blockquote>
  <p>“Uncertainty visualization plays a critical role in transforming ensemble simulation data into actionable insights…” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“…ensuring users can access relevant information, evaluate it accurately, and have confidence in their conclusions.” (p. 4)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Clear communication of uncertainty types (ensemble vs. surrogate)  </p></li>
<li><p>Support for both global exploration (ensembles) and localized queries (surrogates)  </p></li>
<li><p>Ability to interact flexibly with input and output spaces  </p></li>
<li><p>Representation of joint and conditional parameter relationships  </p></li>
<li><p>Support for tradeoff analysis when objectives conflict</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Not named formally, but uses a conceptual integration framework (Figure 1, Figure 3)  </p></li>
<li><p><strong>Methods/Levers:</strong> Visual parameter space exploration, forward and inverse surrogate modeling, widget-based constraints  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Explore ensemble data → Use forward surrogate for prediction → Use inverse surrogate/search for input discovery → Evaluate uncertainty and tradeoffs → Support decisions  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Ensemble simulation outputs, surrogate predictions, quantified uncertainty metrics  </p></li>
<li><p><strong>Implementation Context:</strong> Flood modeling (dam breach scenario)  </p></li>
</ul>

<blockquote>
  <p>“…present the intricate connections between input parameters and output predictions in an intuitive manner…” (p. 4)  </p>
</blockquote>

<blockquote>
  <p>“…highlight sets of inputs that satisfy each output individually as well as input configurations that achieve the best possible compromise.” (p. 7)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Clear representation of uncertainty is essential for decision-making.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Tailoring visualizations to specific decision-makers (engineers vs. emergency planners).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Identifying when scenarios are feasible and when constraints are unrealistic.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Surrogates enable faster exploration but timeliness is not emphasized as a separate principle.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Differentiating uncertainty sources and mapping input–output dependencies.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Linking visualization design to stakeholder objectives.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Tradeoff analysis, interpretability, interactivity.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Ensemble simulation theory  </p></li>
<li><p>Uncertainty visualization literature  </p></li>
<li><p>Surrogate modeling (Gaussian Processes, deep learning)  </p></li>
<li><p>Visual parameter space analysis frameworks</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Degree to which uncertainty is distinguishable (ensemble vs. surrogate)  </p></li>
<li><p>Accuracy and stability of surrogate predictions  </p></li>
<li><p>Ability to generate feasible and goal-consistent input–output configurations</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Surrogate accuracy variability; difficulty reconciling uncertainty types; usability challenges in multi-output constraints; potential for unrealistic constraints.  </p></li>
<li><p><strong>Enablers:</strong> Integration of ensemble + surrogate strengths; interactive constraint setting; visualization of joint parameter distributions.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>The paper extends prior work on uncertainty visualization by focusing on the integration of ensemble and surrogate models, bridging gaps in literature that traditionally treat these separately.</p>

<h2>Summary</h2>

<p>This paper provides a detailed conceptual and applied exploration of how uncertainty visualization can make ensemble simulation and surrogate model outputs actionable for decision-making. Actionability is framed as the ability to confidently interpret and apply model outputs under uncertainty, achieved through clear communication, integration of complementary data strengths, and support for decision-relevant tasks like tradeoff analysis. The authors operationalize this in a flood modeling case, demonstrating forward and inverse surrogate integration with interactive interfaces. Their framework emphasizes clarity, contextual relevance, feasibility, explainability, and goal alignment, making the work a valuable reference for designing decision-support visualization systems in complex, high-dimensional domains.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 — Strong implicit conceptualization of actionability with multiple explicit dimensions tied to decision utility.  </p></li>
<li><p><strong>Operationalization Score:</strong> 80 — Provides a clear applied example (flood modeling) and concrete interaction designs, though not a fully formalized framework.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Uncertainty visualization plays a critical role in transforming ensemble simulation data into actionable insights…” (p. 1)  </p></li>
<li><p>“Communicate diverse uncertainties: Clearly distinguish and convey the different uncertainties associated with ensemble data and surrogate predictions…” (p. 4)  </p></li>
<li><p>“Clarify input–output relationships: Present the intricate connections between input parameters and output predictions in an intuitive manner…” (p. 4)  </p></li>
<li><p>“Highlight sets of inputs that satisfy each output individually as well as input configurations that achieve the best possible compromise.” (p. 7)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Bonneau et al. (2014) – State-of-the-art in uncertainty visualization  </p></li>
<li><p>Sedlmair et al. (2014) – Visual parameter space analysis framework  </p></li>
<li><p>Obermaier &amp; Joy (2014) – Challenges in ensemble visualization  </p></li>
<li><p>Shen et al. (2025) – Flow-based surrogate models for uncertainty quantification</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Multi-Institutional Evaluation of Interrater Agreement of Biomarker-Drug Pair Rankings Based on the ESMO Scale for Clinical Actionability of Molecular Targets (ESCAT) and Sources of Discordance  </p>

<p>Authors: Alexandra Lebedeva, Ekaterina Belova, Alexandra Kavun, Anastasiia Taraskina, Michele Bartoletti, Ivan Bièche, Giuseppe Curigliano, Célia Dupain, Alejandro Rios-Hoyo, Maud Kamal, Claudio Luchini, Stanislav Poyarkov, Christophe Le Tourneau, Egor Veselovsky, Vladislav Mileyko, Maxim Ivanov  </p>

<p>DOI: https://doi.org/10.1007/s40291-024-00748-4  </p>

<p>Year: 2025  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Precision Oncology / Molecular Diagnostics  </p>

<p>Subdomain/Topic: ESCAT framework, biomarker-drug ranking, interrater agreement  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 65  </p>

<p>Contains Definition of Actionability: Yes (explicit via ESCAT definition)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (ESCAT)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Quantitative (statistical analysis of expert rankings)  </p>

<p>Study Context: Multi-institutional assessment of agreement in ranking biomarker-drug pairs by ESCAT Level of Evidence (LOE)  </p>

<p>Geographic/Institutional Context: Multi-national, including institutions in Russia, France, Italy, USA  </p>

<p>Target Users/Stakeholders: Precision oncology experts, molecular tumor boards, guideline developers  </p>

<p>Primary Contribution Type: Empirical evaluation of framework reproducibility  </p>

<p>CL: Yes — clarity is implied as necessary for agreement on LOE rankings  </p>

<p>CR: Yes — contextual relevance to tumor type and biomarker-drug association explicitly tied to actionability  </p>

<p>FE: Yes — feasibility indirectly addressed via standard of care vs. experimental therapy distinction  </p>

<p>TI: Partial — timeliness not central but implied in need for up-to-date literature  </p>

<p>EX: Yes — explainability tied to evidence-based LOE assignment  </p>

<p>GA: Yes — goal alignment with improving clinical decision-making for targeted therapy  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Multi-Institutional Evaluation of Interrater Agreement of Biomarker-Drug Pair Rankings Based on the ESMO Scale for Clinical Actionability of Molecular Targets (ESCAT) and Sources of Discordance  </p>

<p><strong>Authors:</strong>  </p>

<p>Alexandra Lebedeva, Ekaterina Belova, Alexandra Kavun, Anastasiia Taraskina, Michele Bartoletti, Ivan Bièche, Giuseppe Curigliano, Célia Dupain, Alejandro Rios-Hoyo, Maud Kamal, Claudio Luchini, Stanislav Poyarkov, Christophe Le Tourneau, Egor Veselovsky, Vladislav Mileyko, Maxim Ivanov  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1007/s40291-024-00748-4  </p>

<p><strong>Year:</strong> 2025  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Precision Oncology / Molecular Diagnostics  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>ESCAT framework, biomarker-drug ranking, interrater agreement  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The study examines whether the ESMO Scale for Clinical Actionability of Molecular Targets (ESCAT) produces consistent biomarker-drug pair rankings across experts. It evaluates the interrater reliability of ESCAT-based Level of Evidence (LOE) assignments and identifies factors contributing to disagreement, using a dataset of 154 biomarker-drug pairs across 18 tumor types.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Multi-national collaboration (Russia, France, Italy, USA).  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Precision oncology experts, molecular tumor boards, guideline developers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative statistical agreement analysis (Cohen’s kappa, Kolmogorov–Smirnov test, regression analysis).  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical evaluation of framework reproducibility.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This study evaluates how consistently precision oncology experts assign ESCAT Levels of Evidence to biomarker-drug pairs. Fourteen experts ranked 154 pairs across 18 tumor types, covering standard-of-care and experimental options. The analysis showed low overall interrater agreement, with highest concordance for standard-of-care associations (LOE IA) and most disagreement for esophageal cancer pairs. Discrepancies were linked to tumor type, gene function, therapy class, and expert specialty. The study highlights subjectivity in ESCAT LOE assignment and suggests areas for framework refinement, including better handling of negative trial data, resistance biomarkers, and class-effect considerations.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>The paper adopts ESCAT’s definition: actionability reflects the <strong>clinical significance of a biomarker-drug pair based on published evidence</strong>, guiding how genomic findings should be applied in practice.</p>

<blockquote>
  <p>“The ESMO Scale of Clinical Actionability of molecular Targets (ESCAT) classification system… classify molecular aberrations based on the available evidence supporting their value as clinical targets and matching the clinical benefit derived from paired drugs” (p. 92).  </p>
</blockquote>

<blockquote>
  <p>“Framework… designed to provide guidance on how the genomic findings should be used in clinical practice” (p. 92).</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Strong published clinical evidence supporting efficacy of the biomarker-drug pairing.</p></li>
<li><p>Contextual relevance to tumor type.</p></li>
<li><p>Evidence from well-designed clinical trials.</p></li>
<li><p>Alignment with existing guidelines and standard-of-care definitions.</p></li>
<li><p>Consideration of genomic context (multiple biomarkers, resistance mechanisms).</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> ESCAT  </p></li>
<li><p><strong>Methods/Levers:</strong> Literature review, expert evaluation, LOE classification (IA–X).  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Select biomarker-drug pairs (both common and rare).  </p>

<p> 2. Provide tumor type, mutation origin, detection method to experts.  </p>

<p> 3. Experts assign LOE following ESCAT criteria.  </p>

<p> 4. Aggregate responses, determine consensus LOE, calculate agreement statistics.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Consensus LOE, Cohen’s kappa, standard deviation from consensus, regression on influencing factors.  </p></li>
<li><p><strong>Implementation Context:</strong> Multi-institutional expert setting.  </p></li>
</ul>

<blockquote>
  <p>“The median of LOE rankings… was considered the consensus LOE” (p. 93).  </p>
</blockquote>

<blockquote>
  <p>“General agreement rate… estimated using two methods: Cohen’s kappa and the Kolmogorov–Smirnov test” (p. 93).</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — essential for agreement on LOE.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — tumor-specific and biomarker-specific context required.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — addressed through distinction between standard-of-care and experimental therapy.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — literature currency implied but not central.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — LOE assignments tied to strength of evidence.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — aimed at improving targeted therapy selection.  </p></li>
<li><p><strong>Other Dimensions:</strong> Reproducibility, evidence strength, framework consistency.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>ESCAT framework (Mateo et al., 2018).  </p></li>
<li><p>Comparative mention of OncoKB and variant interpretation guidelines.</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>ESCAT Level of Evidence (IA–X).</p></li>
<li><p>Consensus vs. individual LOE deviation.</p></li>
<li><p>Agreement statistics (Cohen’s kappa).</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Subjectivity in LOE assignment; lack of negative trial data consideration; uncertainty in class-effect applicability; difficulty ranking resistance biomarkers; genomic context complexity.  </p></li>
<li><p><strong>Enablers:</strong> Standard-of-care status; clear guideline backing; multidisciplinary tumor board discussions.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions ESCAT as the most comprehensive existing framework but notes parallels with variant interpretation challenges in other oncology and genetics guidelines (AMP/ASCO/CAP, ACMG-AMP).</p>

<hr />

<h2>Summary</h2>

<p>This multi-institutional study critically examines the reproducibility of ESCAT-based biomarker-drug rankings across precision oncology experts. Using a diverse dataset, it identifies low agreement rates outside of standard-of-care scenarios, highlighting subjectivity as a barrier to consistent actionability assessment. The analysis links discrepancies to tumor type, gene function, therapy class, and expert background. While ESCAT provides structured guidance for translating genomic profiling into treatment decisions, its reliance on expert literature interpretation and absence of negative evidence handling limit its reproducibility. The authors advocate for framework refinements, integration with curated knowledge bases, and broader use of multidisciplinary tumor boards to improve consistency and applicability.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 — Explicit definition of actionability, systematic dimensions, and critical evaluation of framework performance.  </p></li>
<li><p><strong>Operationalization Score:</strong> 65 — Clear methodology for LOE assignment and consensus-building, but lacks prescriptive step-by-step for ensuring reproducibility.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[ESCAT] classify molecular aberrations based on the available evidence… and matching the clinical benefit derived from paired drugs” (p. 92).  </p></li>
<li><p>“The most important drawback… is the potential subjectivity of the assigned LOE depending on the person who conducted the literature search” (p. 92).  </p></li>
<li><p>“The median of LOE rankings… was considered the consensus LOE” (p. 93).  </p></li>
<li><p>“Our results outline the concerning rate of discordances when using the ESCAT framework” (p. 99).</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Mateo et al., 2018 — ESCAT framework origin.  </p></li>
<li><p>OncoKB (Chakravarty et al., 2017).  </p></li>
<li><p>AMP/ASCO/CAP guidelines (Sirohi et al., 2020).  </p></li>
<li><p>ACMG-AMP guidelines (Amendola et al., 2020; Lyon et al., 2022).</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Metrics for What, Metrics for Whom: Assessing Actionability of Bias Evaluation Metrics in NLP</p>

<p>Authors: Pieter Delobelle, Giuseppe Attanasio, Debora Nozza, Su Lin Blodgett, Zeerak Talat</p>

<p>DOI: N/A</p>

<p>Year: 2024</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Natural Language Processing / Responsible AI</p>

<p>Subdomain/Topic: Bias evaluation metrics, Actionability in measurement, Fairness in NLP</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 95</p>

<p>Operationalization Score: 90</p>

<p>Actionable/Actionability Used in Paper: Yes — “we define actionability as the degree to which a measurement’s results enable informed action” (p. 1); “Actionability refers to the degree to which a measure’s results enable decision-making or intervention” (p. 2)</p>

<p>Authors Argue for Need for Actionability Without Defining It: No — definition is explicit</p>

<p>Contains Definition of Actionability: Yes — “the degree to which a measure’s results enable informed action” (p. 1)</p>

<p>Contains Systematic Features/Dimensions: Yes — explicit desiderata: motivation, underlying bias construct, interval &amp; ideal result, intended use, reliability</p>

<p>Contains Explainability: Partial — interpretability of measures discussed, but not central</p>

<p>Contains Interpretability: Partial — discussed as related but distinct from actionability</p>

<p>Contains Framework/Model: Yes — conceptual framework of desiderata for actionability</p>

<p>Operationalization Present: Yes — desiderata serve as operationalization criteria</p>

<p>Primary Methodology: Mixed Methods (Conceptual + Systematic Literature Review)</p>

<p>Study Context: Bias evaluation metrics in NLP</p>

<p>Geographic/Institutional Context: Global research community; institutions from Europe, North America, Middle East</p>

<p>Target Users/Stakeholders: NLP researchers, AI practitioners, policymakers, regulators</p>

<p>Primary Contribution Type: Conceptual framework + empirical literature review</p>

<p>CL: Yes — clarity of bias construct, interval, intended use stressed</p>

<p>CR: Yes — emphasis on socio-historical context and matching to user needs</p>

<p>FE: Yes — feasibility implied in intended use and mechanical conditions</p>

<p>TI: Partial — timeliness not explicitly a desideratum but relevant in examples</p>

<p>EX: Partial — interpretability discussed but secondary</p>

<p>GA: Yes — goal alignment via bias construct and intended outcomes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Metrics for What, Metrics for Whom: Assessing Actionability of Bias Evaluation Metrics in NLP  </p>

<p><strong>Authors:</strong>  </p>

<p>Pieter Delobelle, Giuseppe Attanasio, Debora Nozza, Su Lin Blodgett, Zeerak Talat  </p>

<p><strong>DOI:</strong>  </p>

<p>N/A  </p>

<p><strong>Year:</strong>  </p>

<p>2024  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Natural Language Processing / Responsible AI  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Bias evaluation metrics, Actionability in measurement, Fairness in NLP  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses a gap in NLP bias evaluation: while metrics exist, many lack information to enable concrete, informed actions. It develops a conceptual definition of <em>actionability</em> for bias measures, identifies criteria (desiderata) for making measures actionable, and assesses their prevalence in 146 NLP papers.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Work conducted by researchers from KU Leuven, Instituto de Telecomunicações (Lisbon), MilaNLP/Bocconi University, Microsoft Research Montréal, and Mohamed bin Zayed University of AI.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>NLP researchers, AI practitioners, dataset curators, policymakers, regulators.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed Methods — conceptual framework + systematic literature review (PRISMA 2020-guided)  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework and empirical survey  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper formalizes <em>actionability</em> in bias evaluation metrics for NLP as “the degree to which a measurement’s results enable informed action.” Drawing from measurement modeling, fairness research, and AI auditing, the authors define a set of desiderata—motivation, underlying bias construct, interval &amp; ideal result, intended use, and reliability—that make a bias measure actionable. They then conduct a systematic review of 146 papers proposing bias measures, annotating whether each meets these desiderata. Results show widespread gaps: unclear motivations, missing construct definitions, unstated intended use, and little attention to reliability. The authors argue these omissions hinder effective application of bias measures and propose recommendations for clearer reporting, stronger ties to impacts, consistent reliability assessment, and consideration of multiple stakeholders’ capacities to act.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>Yes —  </p>

<ul>
<li><p>“We define actionability as the degree to which a measurement’s results enable informed action” (p. 1)  </p></li>
<li><p>“Actionability refers to the degree to which a measure’s results enable decision-making or intervention” (p. 2)  </p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No — the paper provides an explicit definition.</p>

<hr />

<h2>How Actionability is Understood</h2>

<blockquote>
  <p>“Actionability refers to the degree to which a measure’s results enable decision-making or intervention; that is, results from actionable bias measures should facilitate informed actions with respect to the bias under measurement.” (p. 2)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Clear motivation</strong>  </p>

<p> &gt; “A clearly described motivation can increase a measure’s actionability by helping people… assess whether the bias they seek to measure… are well-matched to the need the measure is intended to address.” (p. 4)  </p></li>
<li><p><strong>Well-defined bias construct</strong>  </p>

<p> &gt; “…clarity in the conceptualization of a bias measure’s underlying construct can increase the measure’s actionability… If the bias construct is not clearly specified… it becomes unclear how the measure’s results speak to any impacts or harms.” (p. 4)  </p></li>
<li><p><strong>Interval and ideal result</strong>  </p>

<p> &gt; “Understanding, and therefore acting, on the results… requires clearly articulated information about the values a result can take on… Proposed bias measures should also specify an ideal result.” (p. 4–5)  </p></li>
<li><p><strong>Intended use</strong>  </p>

<p> &gt; “Proposed bias measures should specify under what circumstances or conditions the measure should be expected to produce meaningful results.” (p. 5)  </p></li>
<li><p><strong>Reliability</strong>  </p>

<p> &gt; “…reliability of a bias measure [is] a prerequisite for actionability.” (p. 5)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Desiderata for actionability in bias measures  </p></li>
<li><p><strong>Methods/Levers:</strong> Conceptual criteria drawn from fairness, measurement modeling, AI auditing  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Specify motivation  </p>

<p> 2. Define bias construct  </p>

<p> 3. Report interval &amp; ideal result  </p>

<p> 4. State intended use (mechanical &amp; socio-historical)  </p>

<p> 5. Assess and report reliability  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Applied to 146 papers from ACL Anthology  </p></li>
<li><p><strong>Implementation Context:</strong> Bias evaluation in NLP  </p></li>
</ul>

<blockquote>
  <p>“We outline desiderata for bias measures—i.e., information that a measure should provide and justify to enhance its actionability.” (p. 4)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — “clarity in the conceptualization… can increase the measure’s actionability” (p. 4)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — “bound… application space… assess whether the measure is appropriate for their use cases” (p. 5)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — implicit in “mechanical conditions” and stakeholder capacity (p. 5, p. 9)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — timeliness not a formal desideratum, but implied in intervention contexts (p. 2)  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — interpretability discussed as distinct but related (p. 2)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — “ideal result… connected to the underlying bias construct and… socio-historical context” (p. 5)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Reliability; transparency; stakeholder empowerment.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Measurement modeling (Jacobs &amp; Wallach, 2021)  </p></li>
<li><p>Validity theory (consequential, predictive, hypothesis validity)  </p></li>
<li><p>Fairness in ML/NLP frameworks  </p></li>
<li><p>AI auditing and accountability literature  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>No quantitative KPI, but binary and qualitative annotation against desiderata (motivation, construct, interval, intended use, reliability).</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Missing motivation; vague or absent construct definition; mismatch between construct and operationalization; unstated intended use; no reliability discussion (p. 6–8)  </p></li>
<li><p><strong>Enablers:</strong> Clear conceptualization; linking results to impacts/harms; specifying applicability; reliability testing; stakeholder consideration (p. 9)</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on prior critiques of bias metric clarity (Blodgett et al., 2020; Jacobs &amp; Wallach, 2021), fairness benchmarks, and AI auditing frameworks. Extends by focusing explicitly on actionability as a distinct concept.</p>

<hr />

<h2>Summary</h2>

<p>This paper pioneers a formal definition of <em>actionability</em> in NLP bias measures and translates it into concrete criteria. Actionability here means enabling informed decisions or interventions based on metric results. The authors identify five desiderata—motivation, bias construct, interval &amp; ideal result, intended use, and reliability—as essential for making measures actionable. They apply these criteria in a systematic review of 146 papers, finding pervasive gaps: unclear or missing motivations, absent construct definitions, few stated intended uses, and minimal reliability analysis. These shortcomings risk misapplication or underuse of metrics. The paper recommends clearer articulation of motivations and constructs, explicit links between metric results and system impacts, consistent reliability testing, and designing metrics with multiple stakeholders’ capabilities in mind. This work provides both a conceptual foundation and an operational checklist for developing bias measures that can genuinely guide action in NLP and beyond.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Strong explicit definition, rich conceptual framework, direct focus on actionability in measurement context.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Clear, detailed desiderata operationalize actionability; some aspects (timeliness, explainability) less developed.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We define actionability as the degree to which a measurement’s results enable informed action” (p. 1)  </p></li>
<li><p>“Actionability refers to the degree to which a measure’s results enable decision-making or intervention” (p. 2)  </p></li>
<li><p>“A clearly described motivation can increase a measure’s actionability…” (p. 4)  </p></li>
<li><p>“Proposed bias measures should specify under what circumstances… the measure should be expected to produce meaningful results” (p. 5)  </p></li>
<li><p>“We view the reliability of a bias measure as a prerequisite for actionability” (p. 5)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Jacobs &amp; Wallach (2021) — Measurement modeling, validity  </p></li>
<li><p>Blodgett et al. (2020, 2021) — Conceptual clarity in bias definitions  </p></li>
<li><p>Raji et al. (2020), Birhane et al. (2024) — AI auditing and accountability  </p></li>
<li><p>Mitchell et al. (2021) — Fairness in ML frameworks</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Managing social media recovery: The important role of service recovery transparency in retaining customers  </p>

<p>Authors: Andreawan Honora, Wen-Hai Chih, Kai-Yu Wang  </p>

<p>DOI: https://doi.org/10.1016/j.jretconser.2021.102814  </p>

<p>Year: 2022  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Marketing / Consumer Services  </p>

<p>Subdomain/Topic: Service recovery, social media transparency, customer forgiveness  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 85  </p>

<p>Contains Definition of Actionability: Yes (implicit — service recovery transparency is treated as actionable through defined mechanisms)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Partial (implicit through transparency and clarity concepts)  </p>

<p>Contains Framework/Model: Yes (conceptual model with mediation and moderation)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Mixed Methods (Survey + Experimental)  </p>

<p>Study Context: Social media service recovery after service failures  </p>

<p>Geographic/Institutional Context: Indonesia; National Dong Hwa University; Brock University  </p>

<p>Target Users/Stakeholders: Service providers, customer service managers, social media teams  </p>

<p>Primary Contribution Type: Empirical validation of conceptual model  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: No  </p>

<p>TI: No  </p>

<p>EX: Yes  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong> Managing social media recovery: The important role of service recovery transparency in retaining customers  </p>

<p><strong>Authors:</strong> Andreawan Honora, Wen-Hai Chih, Kai-Yu Wang  </p>

<p><strong>DOI:</strong> https://doi.org/10.1016/j.jretconser.2021.102814  </p>

<p><strong>Year:</strong> 2022  </p>

<p><strong>Publication Type:</strong> Journal  </p>

<p><strong>Discipline/Domain:</strong> Marketing / Consumer Services  </p>

<p><strong>Subdomain/Topic:</strong> Service recovery, social media transparency, customer forgiveness  </p>

<p><strong>Contextual Background:</strong> The paper investigates how transparency in handling customer complaints on social media can enhance customer forgiveness and reduce switching intentions, with moderation by emotional recovery strategies (apology, explanation).  </p>

<p><strong>Geographic/Institutional Context:</strong> Indonesia; National Dong Hwa University; Brock University  </p>

<p><strong>Target Users/Stakeholders:</strong> Service providers, customer service managers, social media managers  </p>

<p><strong>Primary Methodology:</strong> Mixed methods (Survey + Experiment)  </p>

<p><strong>Primary Contribution Type:</strong> Empirical testing of conceptual model integrating transparency, forgiveness, and recovery strategies  </p>

<h2>General Summary of the Paper</h2>

<p>The paper explores how <em>service recovery transparency</em> — making complaint-handling visible to all on social media — affects customer forgiveness and retention. Drawing on social influence theory, the authors hypothesize that transparency fosters forgiveness, which reduces switchover intentions, and that emotional recovery strategies (apology, explanation) moderate this effect. Study 1 (n=339) used a survey of Indonesian social media complainants; Study 2 (n=149) used a scenario-based experiment with manipulated recovery conditions. Results consistently showed that transparency positively influences forgiveness, which fully mediates the effect on switchover intentions. Apology and explanation attenuate the transparency-forgiveness effect when present, suggesting they can substitute for transparency in fostering forgiveness.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionability is conceptualized implicitly as the capacity of <em>service recovery transparency</em> to trigger customer forgiveness and reduce harmful behaviors like switching. Transparency is framed as an actionable lever in complaint handling: visible, public responses shape emotional reactions and behaviors in a measurable way.</p>

<blockquote>
  <p>“Service recovery transparency refers to the extent to which the responses of a service provider to its customers regarding their complaints can be seen by all viewers on the digital platform.” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“Providing transparent service recovery by handling complaints in the presence of others helps generate customer forgiveness, which, subsequently, reduces switchover intentions.” (p. 7)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Public visibility of complaint handling</p></li>
<li><p>Honesty, clarity, accuracy, and openness in communication</p></li>
<li><p>Creating positive emotional reactions (forgiveness) in customers</p></li>
<li><p>Leveraging social influence via audience effects</p></li>
<li><p>Incorporating emotional recovery elements (apology, explanation) when transparency is low</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Conceptual mediation-moderation model linking transparency, forgiveness, and switching intentions  </p></li>
<li><p><strong>Methods/Levers:</strong> Public replies on social media, offering sincere apologies, providing detailed explanations of failures  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Identify and respond to complaints publicly where possible  </p>

<p> 2. Include emotional recovery strategies if transparency is low or absent  </p>

<p> 3. Monitor forgiveness and switching intentions as key outcomes  </p></li>
<li><p><strong>Data &amp; Measures:</strong> 7-point Likert scales for transparency, forgiveness, switchover intention, apology, and explanation  </p></li>
<li><p><strong>Implementation Context:</strong> Social media complaint handling  </p></li>
</ul>

<blockquote>
  <p>“Public response… enables other consumers access to complaints and allows them to view on social media any recovery processes that were offered by service providers.” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“When an apology/explanation is absent, higher levels of service recovery transparency will be important in generating customer forgiveness.” (p. 5)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — “honesty, clarity, accuracy, and openness” as part of transparency (p. 2)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — recovery process visibility to other customers directly relevant to social media environment  </p></li>
<li><p><strong>FE (Feasibility):</strong> No explicit link to feasibility as part of actionability  </p></li>
<li><p><strong>TI (Timeliness):</strong> Not explicitly linked to actionability in findings (though timeliness noted in prior literature)  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — explanation moderates the effect of transparency on forgiveness (p. 4)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — goal of retaining customers via forgiveness aligns with firm objectives  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Social presence effects; emotional recovery strategies</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Social influence theory (Latane, 1981)  </p></li>
<li><p>Emotional recovery vs. economic recovery distinction</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Customer forgiveness score (Likert scale)  </p></li>
<li><p>Switchover intention score (Likert scale)  </p></li>
<li><p>Measured interaction effects of apology and explanation</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Absence of apology/explanation reduces forgiveness in low-transparency settings; chatbot or generic replies; external causes delaying explanation  </p></li>
<li><p><strong>Enablers:</strong> Public responses; sincerity; open explanations; alignment with customer expectations for transparency</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Extends prior social media recovery studies by focusing on emotional constructs (forgiveness) rather than only cognitive outcomes (satisfaction, quality), and by empirically testing how transparency interacts with emotional recovery strategies.</p>

<h2>Summary</h2>

<p>This paper positions service recovery transparency as a critical, actionable element in social media complaint handling. Transparency — operationalized as public visibility of complaint responses — works through customer forgiveness to reduce switching intentions. Apology and explanation act as moderators, with their absence making transparency more impactful. Two studies (survey and experiment) confirm that high transparency fosters forgiveness, but when emotional recovery strategies are provided, transparency’s incremental effect diminishes. The work advances theory by applying social influence theory to digital complaint handling, operationalizing transparency, and testing interaction effects. For practitioners, it offers a clear, research-backed guide: be visibly transparent in complaint handling, especially when apology or explanation is not provided.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 — Clear conceptualization of transparency as actionable, explicit mediating mechanism, integration with social influence theory  </p></li>
<li><p><strong>Operationalization Score:</strong> 85 — Well-specified model, measured constructs, and actionable steps for implementation</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Service recovery transparency refers to the extent to which the responses of a service provider to its customers regarding their complaints can be seen by all viewers on the digital platform.” (p. 2)  </p></li>
<li><p>“The higher the level of service recovery transparency is, the higher the level of customer forgiveness a service provider will obtain.” (p. 5)  </p></li>
<li><p>“When an apology/explanation is absent, higher levels of service recovery transparency will be important in generating customer forgiveness.” (p. 5)  </p></li>
<li><p>“Providing transparent service recovery… helps generate customer forgiveness, which… reduces switchover intentions.” (p. 7)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Hogreve et al., 2019; Schaefers &amp; Schamari, 2016 — transparency in online recovery  </p></li>
<li><p>Wei et al., 2020 — emotional vs. economic recovery  </p></li>
<li><p>Latane, 1981 — social influence theory  </p></li>
<li><p>Wang et al., 2020 — public vs. private apologies</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Machine Learning-Based Framework for the Analysis of Project Viability  </p>

<p>Authors: Jean Marie Tshimula, Atsushi Togashi  </p>

<p>DOI: 10.1109/CCOMS.2018.8463273  </p>

<p>Year: 2018  </p>

<p>Publication Type: Conference  </p>

<p>Discipline/Domain: Data Science / Development Economics  </p>

<p>Subdomain/Topic: Machine Learning for Investment Decision Support in African Development Projects  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 82  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (implicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: No  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Mixed Methods (Data Mining, Machine Learning, Topic Modeling)  </p>

<p>Study Context: African Development Bank (AfDB) project portfolio analysis for investment guidance  </p>

<p>Geographic/Institutional Context: Africa / AfDB (headquartered in Côte d’Ivoire)  </p>

<p>Target Users/Stakeholders: Investors, policy makers, AfDB analysts  </p>

<p>Primary Contribution Type: Machine Learning workflow for actionable investment guidance  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: No  </p>

<p>EX: Partial  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Machine Learning-Based Framework for the Analysis of Project Viability  </p>

<p><strong>Authors:</strong>  </p>

<p>Jean Marie Tshimula, Atsushi Togashi  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1109/CCOMS.2018.8463273  </p>

<p><strong>Year:</strong>  </p>

<p>2018  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Data Science / Development Economics  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Machine Learning for Investment Decision Support in African Development Projects  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The study focuses on transforming African Development Bank (AfDB) project data into actionable insights to guide investment decisions. Using a dataset of 1,445 AfDB projects, the authors apply Random Forests (RF) for classification and Latent Dirichlet Allocation (LDA) for topic modeling, aiming to identify promising sectors, countries, and projects for investment.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Africa / African Development Bank  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Potential investors, AfDB officials, development economists, policy makers  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed Methods (Machine Learning classification + NLP topic modeling)  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Design and implementation of a machine learning-based workflow for actionable investment recommendations  </p>

<h2>General Summary of the Paper</h2>

<p>The paper presents a machine learning framework designed to process and analyze AfDB project data, converting it into actionable investment insights. The framework automates data collection via a custom R package, structures the data in MongoDB, and uses Random Forests to classify promising sectors and LDA to extract thematic investment opportunities from project descriptions. Results highlight seven key sectors aligned with AfDB’s “High Five” priorities, with agriculture emerging as the most promising. The system is intended to help investors identify viable projects and reduce decision-making risks.  </p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionability is implicitly understood as the ability of the analytical framework to transform raw project data into <strong>clear, sector-specific investment guidance</strong> that helps stakeholders make informed decisions about where to allocate resources.  </p>

<blockquote>
  <p>“…transforming the project data…into actionable insights and…giving investment directions to follow based on the promising sectors.” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“…generate the knowledge required for orienting people…willing to know more details…with insightful guidance.” (p. 2)  </p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Connection to AfDB’s strategic “High Five” priorities  </p></li>
<li><p>Clear identification of sectors and countries with investment potential  </p></li>
<li><p>Data-driven classification of promising projects using RF accuracy and LDA topic extraction  </p></li>
<li><p>Reduction of uncertainty and investment risk through predictive modeling  </p></li>
</ul>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Machine Learning-Based Workflow (AfDB investment analysis)  </p></li>
<li><p><strong>Methods/Levers:</strong> Web scraping (afdbr R package), MongoDB storage, Random Forests, LDA topic modeling  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Data extraction → Structured storage → Data cleaning &amp; translation → RF classification → LDA topic extraction → Sector prioritization  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Project descriptions, status, sector, elapsed time, reappraisal status  </p></li>
<li><p><strong>Implementation Context:</strong> AfDB project portfolio  </p></li>
</ul>

<blockquote>
  <p>“…workflow…consists of two phases: data collection and storage, and analysis module.” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“…built a model with 100 trees…then built an LDA model to outline the data with 20 topics.” (p. 4)  </p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Clear sector classification and thematic topic identification aid understanding.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Links directly to AfDB’s High Five priorities and African market trends.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Uses existing AfDB data and scalable ML methods.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No explicit reference.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — RF feature importance is used, but model interpretability is not deeply addressed.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Explicitly tied to AfDB’s strategic priorities.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Risk reduction, investment prioritization.  </p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>AfDB High Five priorities  </p></li>
<li><p>Random Forest classification theory (Breiman, 2001)  </p></li>
<li><p>LDA topic modeling (Blei et al., 2003)  </p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>RF classification accuracy (99.8%)  </p></li>
<li><p>Identification of top 7 sectors for investment  </p></li>
<li><p>Topic frequency and relevance to strategic priorities  </p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Missing project descriptions (7.1%), language inconsistencies requiring translation  </p></li>
<li><p><strong>Enablers:</strong> Comprehensive AfDB dataset, automated continuous data scraping, alignment with strategic priorities  </p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions itself as extending previous AfDB project evaluation models (e.g., Mubila et al. 2002) by focusing on ongoing and pipeline projects rather than completed ones, and by providing predictive and thematic insights rather than retrospective success factors.  </p>

<h2>Summary</h2>

<p>This paper develops and demonstrates a machine learning-based workflow to make AfDB project data actionable for investment decision-making. Actionability is conceptualized as the capacity to transform semi-structured development project data into clear, sector-specific, and risk-informed investment guidance. The approach operationalizes this via automated data extraction, structured storage, Random Forest classification of promising sectors, and LDA-based extraction of thematic opportunities, aligning outputs with AfDB’s High Five strategic priorities. The model achieves high classification accuracy and identifies agriculture as a flagship sector, alongside six other high-potential sectors. The framework serves as a replicable decision-support tool for investors and policy makers.  </p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 82 — Strong implicit definition of actionability and clear link to features (sector prioritization, risk reduction, goal alignment), but limited discussion of timeliness or deep interpretability.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Detailed workflow, concrete ML methods, data sources, and sector outputs; operational steps are fully described.  </p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Transforming the project data…into actionable insights and…giving investment directions to follow based on the promising sectors.” (p. 1)  </p></li>
<li><p>“…generate the knowledge required for orienting people…with insightful guidance.” (p. 2)  </p></li>
<li><p>“…built a model with 100 trees…then built an LDA model to outline the data with 20 topics.” (p. 4)  </p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Mubila &amp; Lufumpa (2002) — Statistical model for project success factors  </p></li>
<li><p>Blei et al. (2003) — LDA model  </p></li>
<li><p>Breiman (2001) — Random Forests</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Learning analytics dashboard: a tool for providing actionable insights to learners  </p>

<p>Authors: Teo Susnjak, Gomathy Suganya Ramaswami, Anuradha Mathrani  </p>

<p>DOI: https://doi.org/10.1186/s41239-021-00313-7  </p>

<p>Year: 2022  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Educational Technology / Learning Analytics  </p>

<p>Subdomain/Topic: Learning Analytics Dashboards (LADs), Actionable Insights, Predictive and Prescriptive Analytics  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 92  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes (explicit and implicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (proposed LAD integrating descriptive, predictive, prescriptive, interpretability, counterfactuals)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Mixed Methods (Systematic Literature Review + System Design)  </p>

<p>Study Context: Higher Education, learner-facing dashboards  </p>

<p>Geographic/Institutional Context: Massey University, New Zealand  </p>

<p>Target Users/Stakeholders: Students (primary), instructors, higher education institutions  </p>

<p>Primary Contribution Type: Conceptual framework + prototype implementation  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Learning analytics dashboard: a tool for providing actionable insights to learners</p>

<p><strong>Authors:</strong>  </p>

<p>Teo Susnjak, Gomathy Suganya Ramaswami, Anuradha Mathrani</p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1186/s41239-021-00313-7</p>

<p><strong>Year:</strong>  </p>

<p>2022</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Educational Technology / Learning Analytics</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Learning Analytics Dashboards, Actionable Insights, Predictive and Prescriptive Analytics</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the design, capabilities, and challenges of learner-facing Learning Analytics Dashboards (LADs) in higher education. It explores how to move beyond descriptive analytics towards predictive and data-driven prescriptive analytics, incorporating interpretability and explainability to enhance trust and drive behavioral change in learners.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Massey University, New Zealand</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Students (primary), instructors, institutional decision-makers</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed Methods (Systematic Literature Review + Prototype Dashboard Design &amp; Implementation)</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework, synthesis of literature, and novel LAD prototype integrating multiple analytics layers.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The study systematically reviews 17 recently published LADs (2018–2021) to assess their capabilities, focusing on descriptive, predictive, and prescriptive analytics. Findings show most LADs rely on descriptive analytics; few integrate predictive analytics, and none deploy data-driven prescriptive analytics. The authors identify challenges in operationalizing LADs, such as representation &amp; actions, ethics, and agility. Based on identified gaps, they design a state-of-the-art LAD incorporating descriptive, predictive, and prescriptive components, with transparency through model interpretability, explainability, and counterfactuals. This prototype aims to provide learners with actionable insights to adjust learning behaviors. It is currently in pilot trials.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as the LAD’s ability to provide learners with insights that can trigger informed, specific behavioral changes to improve learning outcomes.  </p>

<blockquote>
  <p>“…understand why a model produced given predictions… what insights can be derived… in order to trigger actionable behavioral adjustments.” (p. 8)  </p>
</blockquote>

<blockquote>
  <p>“Prescriptive outputs… tailored to each learner… issue advice on behavioral adjustments and learning strategies… to maximize learning outcomes…” (p. 4)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Interpretability and explainability of predictive models.</p></li>
<li><p>Presentation of counterfactuals showing how specific changes could improve outcomes.</p></li>
<li><p>Contextually relevant, personalized recommendations.</p></li>
<li><p>Evidence-based and data-driven suggestions.</p></li>
<li><p>Clarity and avoidance of cognitive overload.</p></li>
<li><p>Integration of predictive accuracy and confidence communication.</p></li>
<li><p>Goal alignment with learner objectives.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Proposed Multi-Panel LAD with descriptive, predictive, prescriptive, and interpretability layers.  </p></li>
<li><p><strong>Methods/Levers:</strong> Machine learning models (CatBoost, scikit-learn), model interpretability tools (Anchors), counterfactual generation (Dice-ml).  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Data collection from LMS (Moodle) → preprocessing → predictive modeling → feature importance analysis → counterfactual generation → visualization in Power BI dashboard panels.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Engagement metrics, assignment/test scores, demographic info, predictive risk scores, model accuracy, key predictive features, recommended behavioral changes.  </p></li>
<li><p><strong>Implementation Context:</strong> Higher education institution pilot, 20 classes, ~4000 student dataset.  </p></li>
</ul>

<blockquote>
  <p>“…counterfactuals indicate… minimal changes… would produce… more positive outcomes…” (p. 17)  </p>
</blockquote>

<blockquote>
  <p>“…conversion of a black-box predictive model into a glass-box, human interpretable model…” (p. 16)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Minimal use of colors, clear data-to-ink ratio (p. 17).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Learner-specific metrics and comparisons (p. 16).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Recommendations based on minimal changes in controllable factors (p. 17).  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Emphasis on early predictions for timely intervention, but no explicit real-time claim (p. 18).  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Feature importance, anchors, counterfactuals (p. 17–18).  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Advice aimed at maximizing course completion and learning outcomes (p. 4, p. 17).  </p></li>
<li><p><strong>Other Dimensions:</strong> Ethical transparency, cognitive load minimization.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Explainable AI (XAI)</p></li>
<li><p>Counterfactual explanations (Wachter et al., 2017)</p></li>
<li><p>Learning analytics layers (descriptive, predictive, prescriptive)</p></li>
<li><p>Cognitive load theory in dashboard design (Tufte, 2001; Bera, 2016)</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Predictive model accuracy (%)</p></li>
<li><p>Feature importance rankings</p></li>
<li><p>Risk classification (high/low)</p></li>
<li><p>Minimal change thresholds for outcome improvement</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of interpretability in most LADs, technical complexity, concept drift, small datasets, ethical risks of misclassification.  </p></li>
<li><p><strong>Enablers:</strong> Emerging XAI tools, counterfactual generation methods, integrated data sources, agile institutional processes.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions itself as first LAD to fully integrate descriptive, predictive, and data-driven prescriptive analytics with interpretability and counterfactuals. Critiques existing LADs for limited predictive capabilities and lack of actionable, personalized recommendations.</p>

<hr />

<h2>Summary</h2>

<p>This paper identifies significant gaps in the ability of existing LADs to deliver actionable insights, emphasizing that most are confined to descriptive analytics. It defines actionability as the provision of interpretable, explainable, personalized, and contextually relevant recommendations that learners can feasibly implement to improve outcomes. The proposed LAD operationalizes this by integrating descriptive, predictive, and prescriptive analytics, enhanced with model transparency and counterfactual-based recommendations. This combination is intended to bridge the gap between insight generation and behavior change, setting a benchmark for future LAD development in higher education.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Strong conceptual framing of actionability with explicit features and dimensions tied to it.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Fully articulated operational model with specific tools, data sources, processes, and implementation details.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Models need to possess explanatory characteristics… in order to trigger actionable behavioral adjustments.” (p. 8)  </p></li>
<li><p>“Prescriptive outputs… tailored to each learner… advice on behavioral adjustments…” (p. 4)  </p></li>
<li><p>“Counterfactuals indicate… minimal changes… would produce… more positive predictive outcomes.” (p. 17)  </p></li>
<li><p>“Conversion of a black-box predictive model into a glass-box… so that they can understand how their prediction is being derived.” (p. 16)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Wachter et al. (2017) – Counterfactual explanations  </p></li>
<li><p>Ribeiro et al. (2018) – Anchors for interpretability  </p></li>
<li><p>Adadi &amp; Berrada (2018) – Explainable AI  </p></li>
<li><p>Baneres et al. (2019, 2021) – Early warning systems and predictive analytics in LA  </p></li>
<li><p>Rets et al. (2021), Valle et al. (2021) – Need for prescriptive recommendations in LADs</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Latent classes from complex assessments: What do they tell us?  </p>

<p>Authors: Jake McMullen, Ryan W. Lewis, Drew H. Bailey  </p>

<p>DOI: https://doi.org/10.1016/j.lindif.2020.101944  </p>

<p>Year: 2020  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Educational Psychology  </p>

<p>Subdomain/Topic: Latent Class Analysis in Mathematics Achievement Assessment  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 70  </p>

<p>Operationalization Score: 55  </p>

<p>Contains Definition of Actionability: Implicit  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Partial (applied LCA process)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Quantitative  </p>

<p>Study Context: Application of LCA to 5th-grade math benchmark assessments to explore predictive value and instructional usefulness.  </p>

<p>Geographic/Institutional Context: Mid-sized, socioeconomically and racially diverse U.S. school district (Western U.S.)  </p>

<p>Target Users/Stakeholders: Educators, school districts, educational policymakers  </p>

<p>Primary Contribution Type: Empirical study with methodological evaluation  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Partial  </p>

<p>TI: No  </p>

<p>EX: Yes  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong> Latent classes from complex assessments: What do they tell us?  </p>

<p><strong>Authors:</strong> Jake McMullen, Ryan W. Lewis, Drew H. Bailey  </p>

<p><strong>DOI:</strong> https://doi.org/10.1016/j.lindif.2020.101944  </p>

<p><strong>Year:</strong> 2020  </p>

<p><strong>Publication Type:</strong> Journal  </p>

<p><strong>Discipline/Domain:</strong> Educational Psychology  </p>

<p><strong>Subdomain/Topic:</strong> Latent Class Analysis in Mathematics Achievement Assessment  </p>

<p><strong>Contextual Background:</strong> The study tests whether LCA applied to district-wide math benchmark assessments can yield patterns of student knowledge that are both interpretable and educationally actionable, especially for informing targeted interventions.  </p>

<p><strong>Geographic/Institutional Context:</strong> Mid-sized, socioeconomically and racially diverse school district in the Western United States.  </p>

<p><strong>Target Users/Stakeholders:</strong> Educators, curriculum planners, district administrators, policymakers.  </p>

<p><strong>Primary Methodology:</strong> Quantitative  </p>

<p><strong>Primary Contribution Type:</strong> Empirical study evaluating methodological and practical utility of LCA.</p>

<h2>General Summary of the Paper</h2>

<p>This study investigates the practical and predictive value of applying Latent Class Analysis (LCA) to large-scale mathematics benchmark assessments in a diverse U.S. school district. Using pass/fail scores from two 5th-grade benchmark assessments, the authors identified latent knowledge profiles and assessed whether these profiles provided additional predictive power for end-of-year standardized math test scores beyond overall benchmark scores and demographic factors. They examined construct validity through interpretability, distribution across teachers, and predictive associations. While LCA yielded coherent and plausible latent classes, its added predictive value was modest after controlling for overall performance and background variables, with only small residual effects for some groups. The authors conclude that while LCA can enhance interpretability of test scores, its practical utility for actionable instructional guidance from broad assessments is limited without finer-grained measures.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionability is implicitly defined as the ability of latent classes to yield <em>meaningful and useful patterns of student knowledge</em> that can inform instruction and intervention decisions beyond what overall scores provide.  </p>

<blockquote>
  <p>“...such latent classes actually reflects actionable information for educators” (p. 3)  </p>
</blockquote>

<blockquote>
  <p>“…identifying students whose patterns of knowledge suggest they are at greater risk…than their current overall performance implies” (p. 3)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Produces knowledge patterns that explain performance differences <em>beyond</em> overall scores.  </p></li>
<li><p>Identifies groups where targeted instruction in specific skills would be more effective than alternatives.  </p></li>
<li><p>Reflects knowledge states with different causal effects on future learning.  </p></li>
<li><p>Is interpretable in relation to domain theory (e.g., fractions as a pivotal skill).  </p></li>
</ul>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Latent Class Analysis (LCA)  </p></li>
<li><p><strong>Methods/Levers:</strong> Application of LCA to pass/fail benchmark standards to group students by knowledge profiles.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Fit multiple-class LCA models to benchmark pass/fail data.  </p>

<p> 2. Select model based on BIC and interpret profiles.  </p>

<p> 3. Compare profiles with similar overall performance but different knowledge patterns.  </p>

<p> 4. Assess predictive validity for end-of-year standardized tests, controlling for covariates.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Pass/fail by curriculum standard, prior year standardized test scores, demographics, school fixed effects.  </p></li>
<li><p><strong>Implementation Context:</strong> District-level assessments; could be implemented by school systems with existing benchmark data.  </p></li>
</ul>

<blockquote>
  <p>“...gleaning such actionable patterns…would be highly beneficial for educators” (p. 3)  </p>
</blockquote>

<blockquote>
  <p>“...estimate an approximate range of effects…by statistically controlling…” (p. 3)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – Profiles must be interpretable and coherent.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – Linked to specific curriculum standards and grade-level benchmarks.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial – Method is implementable with existing district data, but practical gains are small.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No – Study uses assessments months before the end-of-year exam, but timeliness is not explicitly tied to actionability.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – Classes must be interpretable in terms of cognitive development and curricular content.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial – Supports targeted instruction toward high-leverage skills like fractions.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> None explicitly labeled beyond above.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Integrated theory of numerical development (Siegler et al., 2011)  </p></li>
<li><p>Prior LCA applications in cognitive development tasks (e.g., Piagetian tasks, conceptual change studies)  </p></li>
<li><p>Theories on fractions as critical to mathematical development (Siegler et al., 2012)</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Differences in predictive power of latent classes after controlling for overall performance and covariates.  </p></li>
<li><p>Magnitude of residual effects (SD units) indicating potential causal importance of specific skill deficits.</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Broad, complex tests mask specific cognitive states.  </p>

<p> - Pass/fail aggregation loses fine-grained information.  </p>

<p> - Small added predictive value after controls.  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Coherent, interpretable class structures.  </p>

<p> - Potential for identifying skill-specific deficits relevant to intervention.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions LCA as promising in theory-driven contexts with narrow, well-defined constructs but cautions against assuming strong practical utility from broad achievement tests without finer-grained data. Echoes prior findings that correlations between skills and later achievement may overstate causal importance.</p>

<h2>Summary</h2>

<p>This study evaluates whether latent class analysis applied to broad, curriculum-based math benchmark assessments can generate actionable insights for instructional decision-making. While LCA yielded coherent knowledge profiles aligned with cognitive development theories and sometimes predicted end-of-year performance beyond overall scores, the added value was modest after accounting for prior achievement and demographic factors. The authors argue that true actionability requires profiles that meaningfully guide targeted instruction and have causal links to future learning gains—criteria only partially met here. The work highlights the promise and limitations of scalable, district-level LCA, especially without item-level data or theoretically driven construct mapping.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 70 – Provides implicit, substantive criteria for actionability and ties features to instructional decisions, but lacks a fully explicit, generalizable definition.  </p></li>
<li><p><strong>Operationalization Score:</strong> 55 – Presents a replicable method for deriving and testing actionability from LCA but shows limited real-world effect sizes.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“...such latent classes actually reflects actionable information for educators” (p. 3)  </p></li>
<li><p>“…identifying students whose patterns of knowledge suggest they are at greater risk…than their current overall performance implies” (p. 3)  </p></li>
<li><p>“…gleaning such actionable patterns…would be highly beneficial for educators” (p. 3)  </p></li>
<li><p>“...estimate an approximate range of effects…by statistically controlling…” (p. 3)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Siegler, Thompson, &amp; Schneider (2011) – Integrated theory of numerical development.  </p></li>
<li><p>Siegler et al. (2012) – Fractions as central to math learning.  </p></li>
<li><p>Embretson &amp; Yang (2012) – Theoretically grouped test items.  </p></li>
<li><p>Jansen &amp; van der Maas (1997, 2002) – LCA in Piagetian balance scale tasks.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Knowledge Fusion for Distributed Situational Awareness driven by the WAx Conceptual Framework</p>

<p>Authors: Antonio De Nicola, Maria Luisa Villani, Francesco Costantino, Andrea Falegnami, Riccardo Patriarca</p>

<p>DOI: n/a</p>

<p>Year: 2021</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Crisis Management / Information Systems</p>

<p>Subdomain/Topic: Distributed Situational Awareness, Knowledge Fusion, WAx Framework</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 88</p>

<p>Operationalization Score: 82</p>

<p>Contains Definition of Actionability: Yes (explicit)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes (WAx Framework)</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual with illustrative case study</p>

<p>Study Context: Crisis management with distributed actors in cyber-socio-technical systems</p>

<p>Geographic/Institutional Context: Italy (ENEA, Sapienza University of Rome)</p>

<p>Target Users/Stakeholders: Crisis managers, rescue operators, analysts, decision-makers</p>

<p>Primary Contribution Type: Conceptual framework application and modelling method</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Partial</p>

<p>TI: No</p>

<p>EX: Partial</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: n/a</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Knowledge Fusion for Distributed Situational Awareness driven by the WAx Conceptual Framework  </p>

<p><strong>Authors:</strong>  </p>

<p>Antonio De Nicola, Maria Luisa Villani, Francesco Costantino, Andrea Falegnami, Riccardo Patriarca  </p>

<p><strong>DOI:</strong>  </p>

<p>n/a  </p>

<p><strong>Year:</strong>  </p>

<p>2021  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Crisis Management / Information Systems  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Distributed Situational Awareness, Knowledge Fusion, WAx Framework  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the challenge of achieving distributed situational awareness in large crisis scenarios, where multiple human and cyber agents produce heterogeneous and sometimes conflicting perspectives. It applies the WAx framework—originally from resilience engineering—to model, integrate, and fuse knowledge from diverse actors to produce actionable knowledge for crisis management.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Italy (ENEA, Sapienza University of Rome)  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Crisis managers, rescue operators, analysts, decision-makers  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual with illustrative case study (mountain rescue after avalanche)  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework application and modelling method  </p>

<h2>General Summary of the Paper</h2>

<p>The authors propose a conceptual modelling approach for integrating distributed knowledge in crisis management scenarios, focusing on producing actionable knowledge through the WAx framework. WAx represents different views of work (imagined, done, disclosed, observed, prescribed, normative) and their transformations across agents. The approach models knowledge flows via “knowledge conversion maps” to identify how information is transformed between agents and knowledge states. A mountain rescue case study illustrates the method, identifying key agents, relevant WAx entities, and mapping conversions to reconstruct an integrated situational picture. The paper discusses research challenges, including building platforms for managing WAx entities, automatic coherence detection, and semi-automated analysis of communication patterns.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionable knowledge is defined as the output of knowledge fusion that is “consistent, accurate, and useful for the purpose at hand” in crisis management contexts. The paper frames actionability as the capacity to integrate multiple, possibly conflicting, knowledge entities into a form that supports situational understanding and operational decisions.</p>

<blockquote>
  <p>“We define knowledge fusion as the process of integrating multiple knowledge entities to produce actionable knowledge, which is consistent, accurate, and useful for the purpose at hand.” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“[...] make it actionable requires to achieve a shared understanding among the different involved actors.” (p. 2)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Consistency across multiple knowledge sources.</p></li>
<li><p>Accuracy of information relative to the operational reality.</p></li>
<li><p>Usefulness for the specific decision-making purpose.</p></li>
<li><p>Integration of heterogeneous knowledge entities (human, cyber, tacit, explicit).</p></li>
<li><p>Alignment with operational goals and constraints.</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> WAx Framework with Knowledge Conversion Maps  </p></li>
<li><p><strong>Methods/Levers:</strong> Identification of agents, classification of WAx entities, mapping of knowledge conversions (tacit, explicit, enactment).  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Identify key agents (blunt-end, sharp-end, analysts).  </p>

<p> 2. Identify WAx knowledge entities for each agent.  </p>

<p> 3. Build knowledge conversion map (matrix linking source and target entities with conversion type).  </p></li>
<li><p><strong>Data &amp; Measures:</strong> WAx entity types, knowledge conversion activities (introspection, internalisation, externalisation, conceptualization, reification, socialization, combination).  </p></li>
<li><p><strong>Implementation Context:</strong> Crisis management lifecycle phases (preparedness, response, recovery, mitigation).  </p></li>
</ul>

<blockquote>
  <p>“The final aim is to build a knowledge conversion map for each phase of the crisis management lifecycle.” (p. 4)  </p>
</blockquote>

<blockquote>
  <p>“The imagined reconstructed situation...is originated by a knowledge fusion activity that takes into account all the different knowledge entities generated during on-field operations.” (p. 5)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Actionable knowledge must be interpretable by diverse actors.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Knowledge must fit specific crisis context.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — Implied via operational constraints but not explicitly detailed.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No — Timeliness not explicitly linked to actionability.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — WAx structure promotes traceability but not fully elaborated.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Explicitly aligned to crisis management decision goals.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Consistency, accuracy, usefulness.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>WAx framework (Work-As-x representations from resilience engineering).  </p></li>
<li><p>Nonaka &amp; Konno’s knowledge conversion model (tacit/explicit).  </p></li>
<li><p>Ontology integration for knowledge fusion.</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<p>No formal quantitative metrics; qualitative criteria include coherence, integration completeness, and alignment with operational needs.</p>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Conflicting perspectives, incomplete information, communication losses, differing objectives among agents.  </p></li>
<li><p><strong>Enablers:</strong> Ontology-based shared understanding, structured knowledge conversion mapping, multi-agent modelling.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions itself against prior ontology-based situational awareness approaches by focusing on modelling and reconciling multiple divergent perspectives through structured knowledge fusion.</p>

<h2>Summary</h2>

<p>This paper applies the WAx conceptual framework to the challenge of distributed situational awareness in crisis management, defining actionable knowledge as consistent, accurate, and useful for operational decision-making. Actionability arises from fusing multiple heterogeneous knowledge entities through structured processes, supported by knowledge conversion maps. The method identifies agents, classifies their WAx entity contributions, and maps conversions to reconstruct integrated situational pictures. The mountain rescue case study demonstrates practical application. Distinctive elements include explicit modelling of tacit/explicit/enactment states, tracking inter-agent knowledge flows, and embedding goal alignment and contextual relevance into actionability. While timeliness and quantitative metrics are underdeveloped, the approach offers a strong operationalization pathway for transforming fragmented data into coherent, actionable situational awareness.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 — Strong explicit definition and conceptual clarity on actionability, with systematic feature set.  </p></li>
<li><p><strong>Operationalization Score:</strong> 82 — Clear multi-step method (agent/entity identification, conversion mapping) tied to actionability, though metrics and timeliness are less developed.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We define knowledge fusion as the process of integrating multiple knowledge entities to produce actionable knowledge, which is consistent, accurate, and useful for the purpose at hand.” (p. 2)  </p></li>
<li><p>“Make it actionable requires to achieve a shared understanding among the different involved actors.” (p. 2)  </p></li>
<li><p>“The final aim is to build a knowledge conversion map for each phase of the crisis management lifecycle.” (p. 4)  </p></li>
<li><p>“The imagined reconstructed situation...is originated by a knowledge fusion activity that takes into account all the different knowledge entities generated during on-field operations.” (p. 5)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Nonaka, I., &amp; Konno, N. (1998). <em>The concept of “Ba”</em> — knowledge conversion.  </p></li>
<li><p>Patriarca et al. (2021) — WAx framework.  </p></li>
<li><p>Osman et al. (2021) — ontology integration for knowledge fusion.  </p></li>
<li><p>Benaben et al. (2020) — crisis knowledge meta-model.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Investigating the electric vehicle adoption initiatives for achieving sustainable development goals  </p>

<p>Authors: Shashi Kant Tripathi, Ravi Kant, Ravi Shankar  </p>

<p>DOI: https://doi.org/10.1016/j.sftr.2025.100469  </p>

<p>Year: 2025  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Sustainable Transportation / Industrial Engineering  </p>

<p>Subdomain/Topic: Electric Vehicle Adoption; Sustainable Development Goals; Multi-Criteria Decision-Making  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes (implicit, through prioritization framework and link to SDGs)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Mixed Methods (Systematic Literature Review, Expert Elicitation, MCDM, Machine Learning)  </p>

<p>Study Context: EV sector in India as a case study  </p>

<p>Geographic/Institutional Context: India; Sardar Vallabhbhai National Institute of Technology; Indian Institute of Technology Delhi  </p>

<p>Target Users/Stakeholders: Policymakers, EV manufacturers, charging infrastructure developers, sustainability practitioners  </p>

<p>Primary Contribution Type: Prioritization framework for EV adoption initiatives linked to SDGs  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Investigating the electric vehicle adoption initiatives for achieving sustainable development goals  </p>

<p><strong>Authors:</strong>  </p>

<p>Shashi Kant Tripathi, Ravi Kant, Ravi Shankar  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1016/j.sftr.2025.100469  </p>

<p><strong>Year:</strong>  </p>

<p>2025  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Sustainable Transportation / Industrial Engineering  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Electric Vehicle Adoption; Sustainable Development Goals; Multi-Criteria Decision-Making  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The study focuses on identifying and prioritizing Electric Vehicle Adoption Initiatives (EVAIs) to advance specific Sustainable Development Goals (SDGs) in India. It recognizes the role of EVs in reducing GHG emissions, promoting renewable energy integration, and fostering socio-economic benefits, while addressing adoption barriers.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>India; conducted by SVNIT Surat and IIT Delhi  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>National and state policymakers, EV manufacturers, charging infrastructure developers, environmental regulators, urban planners  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed Methods — Systematic Literature Review (PRISMA), Expert Elicitation, Multi-Criteria Decision-Making (Spherical Fuzzy Bayesian Best-Worst Method), Machine Learning (Spherical Fuzzy C-Means), and Spherical Fuzzy EDAS ranking  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Decision-support framework for aligning EV adoption with prioritized SDG targets  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper develops a hybrid decision-making and machine learning framework to identify, prioritize, and link EV adoption initiatives to specific SDGs in the Indian context. Using a systematic literature review and expert consultation, it categorizes 33 EVAIs across seven thematic areas. The Spherical Fuzzy Bayesian Best-Worst Method (SF-BBWM) is applied to prioritize initiatives, followed by Spherical Fuzzy C-Means clustering to shortlist relevant SDGs. These are ranked using Spherical Fuzzy EDAS. Findings highlight top initiatives such as subsidizing solar-powered EV charging and government incentives for production and purchase, linked most strongly to SDG11.2 (affordable and sustainable transportation), SDG17.14 (policy coherence), and SDG7.2 (renewable energy share). The study offers policy and managerial recommendations for developing nations aiming to leverage EV adoption for sustainable development.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is conceptualized as the ability of initiatives to directly and measurably advance specific SDG targets through structured prioritization and alignment with context-relevant barriers and opportunities in EV adoption.</p>

<blockquote>
  <p>“The priority of these EV adoption initiatives (EVAIs) will aid policymakers and stakeholders in streamlining their focus on critical initiatives to achieve SDGs.” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“These assessments offer valuable insights for EV stakeholders, assisting them in stratifying critical initiatives to enhance EV adaptability and achieve specific SDGs.” (p. 3)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Direct contribution to measurable SDG targets</p></li>
<li><p>Contextual relevance to national sustainability and transport policies</p></li>
<li><p>Feasibility in terms of infrastructure, technology, and socio-economic conditions</p></li>
<li><p>Policy alignment and potential for government or stakeholder support</p></li>
<li><p>Scalability and replicability across regions</p></li>
<li><p>Integration of environmental, social, and economic considerations</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Hybrid Spherical Fuzzy MCDM + Machine Learning Framework  </p></li>
<li><p><strong>Methods/Levers:</strong> Systematic literature review, expert elicitation, SF-BBWM, SF-CM, SF-EDAS  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Identify EVAIs and associated SDG targets via PRISMA-guided SLR and PyPDF2 sentence extraction  </p>

<p> 2. Expert validation and categorization of EVAIs and SDGs  </p>

<p> 3. Prioritization of initiatives using SF-BBWM  </p>

<p> 4. SDG clustering with SF-CM to find most critical ones  </p>

<p> 5. SDG ranking with SF-EDAS  </p>

<p> 6. Sensitivity analysis and method comparison with SF-TOPSIS and SF-CODAS  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Expert weight assignments, linguistic scale to fuzzy number conversion, appraisal score computation  </p></li>
<li><p><strong>Implementation Context:</strong> Indian EV market, national and state policy framework  </p></li>
</ul>

<blockquote>
  <p>“The findings… highlight the top two key initiatives, namely, subsidizing solar-powered EV charging, and offering government incentives for EV production and purchases.” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“SF-BBWM… to prioritize these EVAIs… SF-EDAS ranks the shortlisted SDGs.” (p. 3)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — clearly defined initiative categories and sub-initiatives linked to SDGs (p. 5)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — tailored to Indian EV sector and policy framework (p. 2)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — initiatives assessed on policy, infrastructure, and economic viability (p. 10–12)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — urgent alignment with 2030 SDG targets (p. 2)  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — transparent methodology and ranking process (p. 7–9)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — explicit linkage to specific SDG targets (p. 6–12)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Policy coherence, scalability, environmental impact reduction</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Fuzzy set theory (Zadeh, 1965)</p></li>
<li><p>Spherical fuzzy sets (Kutlu Gündoğdu &amp; Kahraman, 2019)</p></li>
<li><p>Best-Worst Method (Rezaei, 2015) and Bayesian BWM</p></li>
<li><p>Multi-Criteria Decision-Making and clustering methods</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Criteria weights from SF-BBWM</p></li>
<li><p>SDG appraisal scores from SF-EDAS</p></li>
<li><p>Spearman’s rank correlation in sensitivity testing</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Limited charging infrastructure, high upfront costs, coal-dependent charging, low public awareness (p. 2)  </p></li>
<li><p><strong>Enablers:</strong> Government incentives (FAME I &amp; II), renewable integration in charging, battery swapping, public-private partnerships (p. 10–12)</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions itself as filling a gap in linking specific EV initiatives to prioritized SDG targets using a formalized, data-driven prioritization framework. Moves beyond existing studies that either focus narrowly on EV adoption drivers or general SDG connections without structured ranking.</p>

<hr />

<h2>Summary</h2>

<p>This study presents a novel hybrid methodology combining Spherical Fuzzy Bayesian Best-Worst Method, Spherical Fuzzy C-Means clustering, and Spherical Fuzzy EDAS ranking to identify and prioritize EV adoption initiatives for achieving SDGs in India. It identifies 33 initiatives in seven categories and links them to 48 SDG targets, narrowing to 16 critical ones. The top initiatives — subsidizing solar-powered EV charging and government incentives for production and purchase — strongly align with SDG11.2, SDG17.14, and SDG7.2. Actionability is framed as the prioritization of feasible, context-specific, and goal-aligned actions that measurably advance SDGs. The framework is adaptable to other developing nations and supports policymakers, industry stakeholders, and researchers in designing targeted interventions to accelerate sustainable EV adoption.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 — Strong conceptual framing of actionability through explicit linkages to SDG attainment and prioritization; comprehensive set of contextualized features.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Highly detailed, step-by-step operationalization with tested robustness and cross-method validation.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“The priority of these EV adoption initiatives (EVAIs) will aid policymakers and stakeholders in streamlining their focus on critical initiatives to achieve SDGs.” (p. 2)  </p></li>
<li><p>“Identification of the main and sub-categories of EVAIs and the achievable SDGs… Prioritization… Shortlisting… Evaluation and ranking.” (p. 3)  </p></li>
<li><p>“Affordable and sustainable transportation (SDG11.2) is found to be the most significant SDG… followed by policy coherence for sustainability (SDG17.14) and raising global renewable energy proportion (SDG7.2).” (p. 10–12)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Lipu et al. (2022) — EV benefits and SDG alignment  </p></li>
<li><p>Asgarian et al. (2023) — Policy support and sustainable transportation  </p></li>
<li><p>Peng &amp; Bai (2023) — Holistic policy approaches  </p></li>
<li><p>Hannan et al. (2021) — Battery energy storage and SDGs  </p></li>
<li><p>Omahne et al. (2021) — Social aspects and SDG connections</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Individual and Group-level considerations of Actionable Recourse  </p>

<p>Authors: Jayanth Yetukuri, Yang Liu  </p>

<p>DOI: https://doi.org/10.1145/3600211.3604758  </p>

<p>Year: 2023  </p>

<p>Publication Type: Conference  </p>

<p>Discipline/Domain: Artificial Intelligence / Human-Centered Computing  </p>

<p>Subdomain/Topic: Actionable Recourse, Fairness in Machine Learning, User Preferences, Plausibility  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 85  </p>

<p>Operationalization Score: 78  </p>

<p>Contains Definition of Actionability: Yes (explicitly in context of recourse viability)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial (linked to transparency and trust)  </p>

<p>Contains Interpretability: Partial (discussed via counterfactual explanation methods)  </p>

<p>Contains Framework/Model: Yes (proposed optimization approach incorporating preferences and plausibility)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual + Quantitative Experiments  </p>

<p>Study Context: Machine learning decision systems in lending, insurance, hiring  </p>

<p>Geographic/Institutional Context: University of California, Santa Cruz; USA  </p>

<p>Target Users/Stakeholders: Negatively impacted individuals seeking recourse; developers of ML decision systems  </p>

<p>Primary Contribution Type: Conceptual framework + algorithmic method proposal with empirical demonstration  </p>

<p>CL: Yes — “Such a transparent mechanism also builds trust in decision-making by enabling adversely affected individuals to maneuver the recourse generation process.” (p. n/a)  </p>

<p>CR: Yes — “Plausibility draws strong signals from group-level population information, which must be considered…” (p. n/a)  </p>

<p>FE: Yes — “Considering that she belongs to the sub-population of denied single parent, the recourse may not be actionable…” (p. n/a)  </p>

<p>TI: Partial — Timeliness is not explicitly discussed as a feature of actionability.  </p>

<p>EX: Partial — Linked to transparency and trust but not fully unpacked.  </p>

<p>GA: Yes — “Identify specific, actionable steps in agreement with the approved single parent sub-population…” (p. n/a)  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Individual and Group-level considerations of Actionable Recourse  </p>

<p><strong>Authors:</strong>  </p>

<p>Jayanth Yetukuri, Yang Liu  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1145/3600211.3604758  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Artificial Intelligence / Human-Centered Computing  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Actionable Recourse, Fairness in Machine Learning, User Preferences, Plausibility  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses how actionable recourse—recommendations enabling individuals to achieve desired outcomes from ML decision systems—should incorporate both individual preferences and group-level plausibility to enhance fairness, trustworthiness, and societal benefit. It is situated in domains like lending, hiring, and insurance, where algorithmic decisions have significant personal impacts.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of California, Santa Cruz (USA)  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Negatively impacted individuals seeking to reverse unfavorable algorithmic decisions; developers and policymakers concerned with fairness and transparency in ML systems.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework combined with empirical experiments on real-world datasets.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>A conceptual and computational approach integrating user preferences and group-level plausibility into recourse generation.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper explores how actionable recourse in ML decision systems can better account for individual user preferences and group-level plausibility to ensure fairness and feasibility. Current recourse methods optimize for factors like proximity, sparsity, and validity but often ignore personal constraints or socio-demographic context. The authors introduce three forms of user preference—scoring continuous features, ranking categorical features, and bounding feature values—and embed them in the optimization process for generating recourses. At the group level, they propose plausibility constraints based on the distribution of approved cases within the individual’s subgroup, aiming to avoid biased or impractical suggestions. Experimental results show that their method better adheres to individual preferences and mitigates plausibility bias across protected groups.  </p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is defined as the <em>viability of taking a suggested action</em> within the context of recourse for ML decisions. It encompasses both feasibility for the individual (personal constraints, preferences) and plausibility within the socio-demographic group context.  </p>

<blockquote>
  <p>“Ensure the actionability (the viability of taking a suggested action) of recourse.” (p. n/a)  </p>
</blockquote>

<blockquote>
  <p>“Plausibility draws strong signals from group-level population information… to achieve low-cost recourses across protected groups.” (p. n/a)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Alignment with user preferences</strong> (continuous feature scores, categorical rankings, feature bounds)  </p></li>
<li><p><strong>Feasibility</strong> given personal constraints  </p></li>
<li><p><strong>Plausibility</strong> based on similarity to approved cases in the individual’s subgroup  </p></li>
<li><p><strong>Transparency</strong> to build trust  </p></li>
<li><p><strong>Fairness</strong> across groups with different distributional characteristics</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Not formally named, but described as constrained optimization incorporating user preferences and group-level plausibility metrics.  </p></li>
<li><p><strong>Methods/Levers:</strong> Optimization function embedding individual preferences; plausibility score constraint based on subgroup-approved distribution.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Collect individual user preferences (three types).  </p>

<p> 2. Integrate these as constraints in recourse optimization.  </p>

<p> 3. Calculate group-level plausibility score.  </p>

<p> 4. Generate recourse maximizing plausibility while respecting user constraints.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Real-world datasets; plausibility score; recourse cost metrics.  </p></li>
<li><p><strong>Implementation Context:</strong> Lending, insurance, hiring decisions.  </p></li>
</ul>

<blockquote>
  <p>“We propose to capture… three types of user preferences… and embed them into an optimization function for guiding the recourse generation mechanism.” (p. n/a)  </p>
</blockquote>

<blockquote>
  <p>“We quantify plausibility of recourse with respect to the approved sub-population of the individual’s group…” (p. n/a)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — linked to transparency and understandability in recourse generation.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — plausibility relies on subgroup context.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — explicitly tied to personal constraints and preferences.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — not directly addressed as a criterion.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — present via transparency but not deeply analyzed.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — recourse must align with the individual’s goal of entering the approved subgroup.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Plausibility; User Preference Diversity.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Actionable Recourse in Linear Classification (Ustun et al., 2019)  </p></li>
<li><p>Counterfactual explanation generation methods (FACE, GS, CCHVAE)  </p></li>
<li><p>Local feasibility constraints (Mahajan et al., 2019)</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Plausibility score based on proximity to approved subgroup manifold  </p></li>
<li><p>Recourse cost (individual and group-level)  </p></li>
<li><p>Adherence to stated user preferences  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Universal cost metrics ignoring personal constraints  </p>

<p> - Distributional idiosyncrasies across groups  </p>

<p> - Lack of integration of user preferences in current methods  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Explicit collection of user preferences  </p>

<p> - Group-level plausibility constraint  </p>

<p> - Transparent recourse generation</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper builds upon existing counterfactual explanation and actionable recourse literature but extends it by introducing a dual focus on individualized preference capture and group-level plausibility, which addresses fairness and feasibility more holistically than prior distance- or sparsity-based approaches.</p>

<hr />

<h2>Summary</h2>

<p>This paper advances the concept of actionable recourse by explicitly integrating <strong>individual-level preferences</strong> and <strong>group-level plausibility constraints</strong> into the generation process for counterfactual suggestions in ML decision systems. The authors propose an optimization-based framework that embeds user-defined continuous feature scores, categorical rankings, and bounds, while also evaluating the plausibility of recourse relative to the distribution of approved outcomes within the individual’s demographic group. By combining these perspectives, the method aims to enhance feasibility, fairness, and trustworthiness of recourse suggestions. Experimental results on real-world datasets demonstrate improved adherence to personal constraints and mitigation of plausibility bias across protected groups. The approach addresses gaps in current methods that focus mainly on universal cost functions and do not systematically incorporate socio-contextual constraints.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 — Strong conceptual framing of actionability with explicit dimensions (preferences, plausibility, feasibility) and integration of fairness considerations.  </p></li>
<li><p><strong>Operationalization Score:</strong> 78 — Provides a clear methodology for integrating individual and group-level constraints into optimization, though operational details could be expanded for real-world deployment.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[Actionability is] the viability of taking a suggested action…” (p. n/a)  </p></li>
<li><p>“We propose to capture Alice’s three types of user preferences… and embed them into an optimization function…” (p. n/a)  </p></li>
<li><p>“We quantify plausibility of recourse with respect to the approved sub-population of the individual’s group…” (p. n/a)  </p></li>
<li><p>“Considering that she belongs to the sub-population of denied single parent, the recourse may not be actionable…” (p. n/a)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Ustun et al. (2019) — Actionable Recourse in Linear Classification  </p></li>
<li><p>Mahajan et al. (2019) — Local feasibility in counterfactual explanations  </p></li>
<li><p>Mothilal et al. (2020) — Diverse counterfactual explanations  </p></li>
<li><p>Poyiadzi et al. (2020) — FACE method  </p></li>
<li><p>Laugel et al. (2017) — Inverse classification interpretability  </p></li>
<li><p>Pawelczyk et al. (2020) — CCHVAE counterfactual generation</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: In Search of an Alternative Framework for the Creation of Actionable Knowledge: Table-Tennis Research at Ericsson  </p>

<p>Authors: Niclas Adler, Rami Shani  </p>

<p>DOI: n/a  </p>

<p>Year: 2001  </p>

<p>Publication Type: Book Chapter  </p>

<p>Discipline/Domain: Organizational Studies / Management Science  </p>

<p>Subdomain/Topic: Participatory Inquiry, Actionable Knowledge, Knowledge-Based Firms  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (explicit and implicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Partial (through intermediate theories)  </p>

<p>Contains Framework/Model: Yes (Table-Tennis Research process model)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Qualitative, Conceptual with Longitudinal Case Study  </p>

<p>Study Context: Knowledge-based firm (Ericsson), participatory research projects (10 projects over 6 years)  </p>

<p>Geographic/Institutional Context: Sweden (Ericsson HQ), Chalmers University of Technology, Stockholm School of Economics  </p>

<p>Target Users/Stakeholders: Academic researchers, practitioner researchers, organizational leaders in knowledge-intensive firms  </p>

<p>Primary Contribution Type: Conceptual framework and methodological innovation  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong> In Search of an Alternative Framework for the Creation of Actionable Knowledge: Table-Tennis Research at Ericsson  </p>

<p><strong>Authors:</strong> Niclas Adler, Rami Shani  </p>

<p><strong>DOI:</strong> n/a  </p>

<p><strong>Year:</strong> 2001  </p>

<p><strong>Publication Type:</strong> Book Chapter  </p>

<p><strong>Discipline/Domain:</strong> Organizational Studies / Management Science  </p>

<p><strong>Subdomain/Topic:</strong> Participatory Inquiry, Actionable Knowledge, Knowledge-Based Firms  </p>

<p><strong>Contextual Background:</strong> The chapter addresses how actionable knowledge can be generated through a novel participatory research approach — “Table-Tennis Research” — within a knowledge-based firm. It critiques limitations in existing collaborative inquiry models and proposes a boundary-spanning, iterative, real-time methodology, demonstrated through multiple research projects at Ericsson.  </p>

<p><strong>Geographic/Institutional Context:</strong> Sweden; Chalmers University of Technology, Stockholm School of Economics, Ericsson AB  </p>

<p><strong>Target Users/Stakeholders:</strong> Organizational researchers, knowledge managers, R&amp;D leaders, academic-practitioner partnerships  </p>

<p><strong>Primary Methodology:</strong> Qualitative, conceptual with longitudinal case study  </p>

<p><strong>Primary Contribution Type:</strong> Methodological framework and process model</p>

<h2>General Summary of the Paper</h2>

<p>The paper develops and illustrates the “Table-Tennis Research” approach — a participatory inquiry framework designed to generate actionable knowledge by integrating practitioners and academics throughout the research cycle. Drawing on ten projects over six years at Ericsson, the authors identify contextual, focus-related, and process-related factors that enable actionable outcomes. The method emphasizes “red and hot” issues (strategically important and timely), iterative jam sessions for theory building and validation, and the creation of intermediate theories bridging local action and broader theory. The study positions table-tennis research as superior in meeting Habermas’ technical, practical, and emancipatory interests, arguing for its capacity to simultaneously produce scientific and applied value.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionable knowledge is defined as knowledge that both advances scientific understanding and directly informs local theories for action, guiding organizational improvements in real-time.</p>

<blockquote>
  <p>“Actionable knowledge was defined as new knowledge that advances our scientific body of knowledge and simultaneously leads to the development of intermediate theories and local theories of action.” (p. 59)  </p>
</blockquote>

<blockquote>
  <p>“In the context of generating knowledge for action, it is vital that many perspectives are used… and that the ongoing analysis and validation work affect the research design as it evolves.” (p. 53)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Relevance to “red and hot” issues (strategic importance, timeliness, perceived as critical by both academics and practitioners)  </p></li>
<li><p>Iterative testing and refinement of intermediate theories through actual experiments  </p></li>
<li><p>Boundary-spanning integration of perspectives, domains (action/reflection), and phases (design, data, validation)  </p></li>
<li><p>Close alignment with organizational decision-making and strategic discourse  </p></li>
<li><p>Mutual ownership of research questions, process, and interpretation</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name:</strong> Table-Tennis Research  </p></li>
<li><p><strong>Methods/Levers:</strong> Iterative jam sessions, intermediate theories, real-time experimentation, boundary-spanning teams  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify red/hot issues → form mixed teams → conduct jam sessions (data collection, analysis, validation) → develop intermediate theories → test through organizational experiments → refine theories and actions iteratively  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Qualitative data from organizational settings, observations, experimental outcomes, validation in real work context  </p></li>
<li><p><strong>Implementation Context:</strong> Multi-project, multi-year collaboration at Ericsson involving engineers, managers, and academic researchers  </p></li>
</ul>

<blockquote>
  <p>“Research in real-time and on red and hot issues… provides opportunities for validating actionability in knowledge created through simultaneous creation and use.” (p. 51)  </p>
</blockquote>

<blockquote>
  <p>“The jam sessions… act as the enabling context within which actionable knowledge creation occurs.” (p. 58)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — clarity in research focus, intermediate theories, and communication of findings is essential to maintain relevance and momentum.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — must be tied to organizationally strategic “red and hot” issues.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — actionable theories must be testable within organizational constraints.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — focus on issues that are immediately relevant and urgent.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — intermediate theories serve as shared explanatory frameworks between domains.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — mutual goals of scientific contribution and practical improvement.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Boundary-spanning integration, iterative adaptability, mutual trust, and political dynamics management.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Knowledge-based view of the firm (Grant, 1998; Nonaka &amp; Takeuchi, 1995)  </p></li>
<li><p>Action research and participatory inquiry traditions (Lewin, 1946; Argyris &amp; Schön, 1974; Reason, 1995)  </p></li>
<li><p>Habermas’ three cognitive interests (technical, practical, emancipatory)</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Degree to which research produces both scientific publications and local theories for action  </p></li>
<li><p>Uptake of intermediate theories in organizational practices  </p></li>
<li><p>Sustained learning systems post-project</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Loss of red/hot focus, turnover of key decision-makers, role ambiguity, imbalance between academic and practitioner engagement  </p></li>
<li><p><strong>Enablers:</strong> Mutual trust, joint ownership, iterative validation, strategic relevance, boundary-spanning participation</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Builds on and integrates multiple participatory research streams (action science, clinical field research, appreciative inquiry) but emphasizes full integration of practitioners into all research phases, iterative emergence, and dual focus on theory and practice.</p>

<h2>Summary</h2>

<p>Adler and Shani’s chapter advances “Table-Tennis Research” as a participatory methodology optimized for producing actionable knowledge in knowledge-intensive firms. Actionability is understood as the dual capacity to advance theory and guide real-time organizational action. Key enablers include focus on “red and hot” issues, iterative development of intermediate theories, and deeply integrated academic–practitioner teams. The framework operationalizes actionability through boundary-spanning jam sessions, ongoing experimentation, and mutual learning systems. By aligning Habermas’ technical, practical, and emancipatory interests, the approach addresses both scientific rigor and practical relevance, offering a replicable but context-sensitive model.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Explicit definition of actionable knowledge, comprehensive set of enabling features, strong theoretical grounding.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Detailed process model with concrete steps, but context-specific to Ericsson.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Actionable knowledge was defined as new knowledge that advances our scientific body of knowledge and simultaneously leads to the development of intermediate theories and local theories of action.” (p. 59)  </p></li>
<li><p>“Research in real-time and on red and hot issues… provides opportunities for validating actionability in knowledge created through simultaneous creation and use.” (p. 51)  </p></li>
<li><p>“The jam sessions… act as the enabling context within which actionable knowledge creation occurs.” (p. 58)  </p></li>
<li><p>“By integrating practitioners and different academic disciplines to address an organizational issue, the multiple perspectives help develop a better understanding of the phenomena.” (p. 53)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Argyris &amp; Schön (1974) — Action science  </p></li>
<li><p>Nonaka &amp; Takeuchi (1995) — Knowledge creation theory  </p></li>
<li><p>Reason (1995) — Participative inquiry paradigm  </p></li>
<li><p>Habermas (1981) — Cognitive interests framework  </p></li>
<li><p>Gibbons et al. (1994) — Transdisciplinarity</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Implementing evidence-based assertions of clinical actionability in the context of secondary findings: Updates from the ClinGen Actionability Working Group  </p>

<p>Authors: Christine M. Pak, Marian J. Gilmore, Joanna E. Bulkley, Pranesh Chakraborty, Orit Dagan-Rosenfeld, Ann Katherine M. Foreman, Michael H. Gollob, Charisma L. Jenkins, Alexander E. Katz, Kristy Lee, Naomi Meeks, Julianne M. O’Daniel, Jennifer E. Posey, Shannon M. Rego, Neethu Shah, Robert D. Steiner, Andrew B. Stergachis, Sai Lakshmi Subramanian, Tracy Trotter, Kathleen Wallace, Marc S. Williams, Katrina A.B. Goddard, Adam H. Buchanan, Kandamurugu Manickam, Bradford Powell, Jessica Ezzell Hunter; on behalf of the ClinGen Resource  </p>

<p>DOI: https://doi.org/10.1016/j.gim.2024.101164  </p>

<p>Year: 2024  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Genomic Medicine / Clinical Genetics  </p>

<p>Subdomain/Topic: Clinical actionability, secondary genomic findings, evidence-based frameworks  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 98  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual with pragmatic evaluation  </p>

<p>Study Context: Development and implementation of an assertion rubric for clinical actionability in secondary genomic findings  </p>

<p>Geographic/Institutional Context: Primarily U.S.-based with contributions from Canada  </p>

<p>Target Users/Stakeholders: Clinical laboratories, geneticists, policy makers, genomic medicine implementers  </p>

<p>Primary Contribution Type: Framework/methodology for actionability assessment and assertion  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong> Implementing evidence-based assertions of clinical actionability in the context of secondary findings: Updates from the ClinGen Actionability Working Group  </p>

<p><strong>Authors:</strong> Christine M. Pak et al.  </p>

<p><strong>DOI:</strong> https://doi.org/10.1016/j.gim.2024.101164  </p>

<p><strong>Year:</strong> 2024  </p>

<p><strong>Publication Type:</strong> Journal  </p>

<p><strong>Discipline/Domain:</strong> Genomic Medicine / Clinical Genetics  </p>

<p><strong>Subdomain/Topic:</strong> Clinical actionability, secondary genomic findings, evidence-based frameworks  </p>

<p><strong>Contextual Background:</strong> The paper addresses the gap in standardized, evidence-based assessment of clinical actionability for secondary findings from genome sequencing, focusing on how the ClinGen Actionability Working Group (AWG) expanded its framework to include formal “assertions” of actionability to complement semi-quantitative scoring.  </p>

<p><strong>Geographic/Institutional Context:</strong> Primarily U.S.-based research institutions and clinical genetics organizations; some Canadian collaborators.  </p>

<p><strong>Target Users/Stakeholders:</strong> Clinical laboratories, geneticists, health policy makers, genomic medicine implementers.  </p>

<p><strong>Primary Methodology:</strong> Conceptual framework development with iterative refinement and pragmatic evaluation.  </p>

<p><strong>Primary Contribution Type:</strong> Framework/methodology for actionability assessment and assertion.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This article presents the ClinGen AWG’s development of an evidence-based “assertion rubric” to generate standardized statements (assertions) about the clinical actionability of gene–condition pairs in the context of secondary genomic findings. Building on an existing semi-quantitative metric (SQM) scoring four domains (severity, likelihood, effectiveness, nature/burden of intervention), the AWG iteratively refined a rubric through four versions, incorporating feedback from members and pragmatic application to over 350 gene–condition pairs. The final rubric uses a four-tier scale—limited, moderate, strong, and definitive—based on highest-scoring outcome/intervention pairs, with clear criteria and guidelines for adjusting preliminary assertions. It integrates factors such as quality of evidence, intervention feasibility, and clinical adoption. The framework enhances interpretability and consistency, aiming to improve decision-making for returning secondary findings.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>The authors define clinical actionability as the potential for an intervention, informed by genetic findings, to prevent, mitigate, or treat adverse health outcomes, either pre-symptomatically or in ongoing disease contexts.  </p>

<blockquote>
  <p>“Clinical actionability in this context includes interventions that could be implemented to mitigate or prevent associated future health outcomes… as well as changes in care to treat ongoing health outcomes.” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“The assertion process allows the AWG to capture… effectiveness of medical interventions… penetrance of outcomes and the impact of the condition to the individual patient.” (p. 6)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Severity of health outcome  </p></li>
<li><p>Likelihood (penetrance) of outcome  </p></li>
<li><p>Effectiveness of intervention in preventing/mitigating outcome  </p></li>
<li><p>Nature/burden of intervention  </p></li>
<li><p>Strength and quality of supporting evidence  </p></li>
<li><p>Contextual adoption in clinical practice  </p></li>
<li><p>Ethical or feasibility constraints on gathering more evidence</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> ClinGen Actionability Assertion Rubric  </p></li>
<li><p><strong>Methods/Levers:</strong> 4-domain SQM scoring → preliminary assertion → expert discussion → consensus assertion  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Score outcome–intervention pairs in four domains (0–3 each).  </p>

<p> 2. Identify highest-scoring O/I pair for each gene–condition pair.  </p>

<p> 3. Generate preliminary assertion using score thresholds.  </p>

<p> 4. Discuss in AWG meetings; consider additional predefined factors.  </p>

<p> 5. Document rationale for final assertion.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Evidence from systematic reviews, meta-analyses, clinical guidelines; penetrance studies; intervention outcome data.  </p></li>
<li><p><strong>Implementation Context:</strong> Applied to both adult and pediatric gene–condition pairs across 350+ cases.  </p></li>
</ul>

<blockquote>
  <p>“The total score is the sum of the four domain scores… used to generate the preliminary assertion of actionability.” (p. 6)  </p>
</blockquote>

<blockquote>
  <p>“The assertion level can be changed based on… poor-quality evidence… interventions widely used… or when further evidence would be unethical.” (p. 6)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Clear, structured scoring and definition of levels.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Context-specific scoring (adult/pediatric frameworks).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Consideration of real-world clinical adoption and feasibility of interventions.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Timeliness implied via secondary finding reporting priorities.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Rationale documented for each assertion.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Focus on preventing/mitigating health outcomes aligned with patient health goals.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Burden of intervention, ethical considerations for evidence collection.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Builds on ACMG recommendations for secondary finding reporting.  </p></li>
<li><p>Extends the existing ClinGen semi-quantitative metric framework.  </p></li>
<li><p>Incorporates evidence hierarchies (systematic review, meta-analysis, guidelines).</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Total domain score (0–12) for highest-scoring O/I pair  </p></li>
<li><p>Effectiveness score thresholds  </p></li>
<li><p>Tier 1 evidence for “definitive” designation</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Limited/poor-quality evidence; rare/pediatric conditions with limited trial feasibility.  </p></li>
<li><p><strong>Enablers:</strong> Established clinical use; strong guidelines; high-penetrance variants.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions the rubric as a standardization advance over prior ad hoc practices in secondary finding reporting; aligns with ACMG SF list criteria and addresses gaps identified in international guidelines and professional surveys.</p>

<hr />

<h2>Summary</h2>

<p>The paper describes the creation and implementation of the ClinGen Actionability Assertion Rubric, a standardized, evidence-based method for declaring the clinical actionability of gene–condition pairs identified as secondary findings in genome sequencing. Actionability is framed as the capacity for interventions to prevent, mitigate, or treat outcomes, with evaluation based on severity, likelihood, intervention effectiveness, and burden. Through iterative testing and integration into AWG workflows, the rubric now yields one of four assertion categories, supplemented by documented rationales and adjustments for real-world and ethical constraints. This approach operationalizes actionability in a replicable, transparent manner, enhancing its utility for clinical, research, and policy decisions.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 98 — Offers explicit definition, detailed dimensions, and a fully developed framework tied directly to actionability.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Provides clear step-by-step process, criteria, and integration into practice, though timeliness is less explicitly operationalized.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Clinical actionability in this context includes interventions that could be implemented to mitigate or prevent associated future health outcomes…” (p. 2)  </p></li>
<li><p>“The total score is the sum of the four domain scores… used to generate the preliminary assertion of actionability.” (p. 6)  </p></li>
<li><p>“The assertion level can be changed based on… interventions widely used… high-quality evidence not likely forthcoming…” (p. 6)  </p></li>
<li><p>“The assertion process allows the AWG to capture… effectiveness of medical interventions… penetrance of outcomes…” (p. 6)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>ACMG SF v2.0, v3.0, v3.1 policy statements  </p></li>
<li><p>Hunter et al. (2016, 2018, 2022) on clinical actionability assessment protocols  </p></li>
<li><p>Saelaert et al. (2019) on professional perspectives in reporting secondary findings</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Identifying actionable strategies: using Consolidated Framework for Implementation Research (CFIR)-informed interviews to evaluate the implementation of a multilevel intervention to improve colorectal cancer screening  </p>

<p>Authors: Helen Lam, Michael Quinn, Toni Cipriano-Steffens, Manasi Jayaprakash, Emily Koebnick, Fornessa Randal, David Liebovitz, Blasé Polite, Karen Kim  </p>

<p>DOI: https://doi.org/10.1186/s43058-021-00150-9  </p>

<p>Year: 2021  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Implementation Science / Public Health  </p>

<p>Subdomain/Topic: Colorectal cancer screening, evidence-based intervention implementation  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 85  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (implicit, operational focus)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: No  </p>

<p>Contains Framework/Model: Yes (CFIR)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Qualitative  </p>

<p>Study Context: Federally Qualified Health Centers (FQHCs) implementing 3 EBIs for CRC screening  </p>

<p>Geographic/Institutional Context: Large urban FQHC in Chicago, Illinois, USA  </p>

<p>Target Users/Stakeholders: Primary care providers, integrated care specialists (CRC stewards), administrators, implementation teams  </p>

<p>Primary Contribution Type: Empirical study with implementation strategy recommendations  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: No  </p>

<p>EX: Partial  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Identifying actionable strategies: using CFIR-informed interviews to evaluate the implementation of a multilevel intervention to improve colorectal cancer screening</p>

<p><strong>Authors:</strong>  </p>

<p>Helen Lam, Michael Quinn, Toni Cipriano-Steffens, Manasi Jayaprakash, Emily Koebnick, Fornessa Randal, David Liebovitz, Blasé Polite, Karen Kim</p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1186/s43058-021-00150-9</p>

<p><strong>Year:</strong>  </p>

<p>2021</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Implementation Science / Public Health</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Colorectal cancer screening, evidence-based intervention (EBI) implementation</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The study examines how three EBIs—EHR provider reminders, quarterly provider assessment/feedback, and CRC stewards—were implemented in a large, urban FQHC serving low-income, ethnically diverse populations. Guided by CFIR, it identifies barriers/facilitators and proposes actionable strategies for improving adoption and sustainability.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Large urban FQHC in Chicago, Illinois, USA</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Primary care providers, CRC stewards (integrated care specialists), administrators, implementation teams</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Qualitative (semi-structured CFIR-guided interviews, template analysis)</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical study + operational recommendations</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper uses the Consolidated Framework for Implementation Research (CFIR) to analyze the implementation of three EBIs to improve colorectal cancer (CRC) screening in a large urban FQHC. Sixteen interviews with providers, CRC stewards, and administrators revealed barriers (e.g., EHR reminder fatigue, unreliable data, cultural/linguistic challenges, lack of screening goals, poor communication, absence of patient materials) and facilitators (e.g., quarterly feedback reports, workflow integration, HRSA reporting incentives, peer pressure, teamwork culture). The authors propose actionable strategies, including morning huddles, standing orders, improved feedback mechanisms, quality dashboards, and culturally tailored patient materials. The study illustrates how CFIR can guide post-implementation evaluation and generate practical, context-specific strategies.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is understood implicitly as the ability to <strong>translate findings about barriers/facilitators into concrete, context-appropriate strategies that improve EBI adoption and sustainability</strong>. Actionable strategies must address identified contextual determinants, integrate into existing workflows, and support measurable improvement in CRC screening.  </p>

<blockquote>
  <p>“By identifying the contextual determinants, we can then determine implementation strategies to facilitate adoption and move EBIs to daily practice.” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“The ultimate goal… was to identify possible implementation strategies… to promote CRC screening… in FQHC settings.” (p. 11)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Based on clearly identified barriers/facilitators from stakeholders</p></li>
<li><p>Integrates with existing workflows to minimize disruption</p></li>
<li><p>Distributes responsibility (team-based rather than provider-centric)</p></li>
<li><p>Supported by clear goals and performance feedback</p></li>
<li><p>Supported by culturally and linguistically appropriate resources</p></li>
<li><p>Tied to measurable indicators (e.g., screening rates, completion rates)</p></li>
<li><p>Supported by leadership engagement and organizational incentives</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> CFIR-guided post-implementation formative evaluation</p></li>
<li><p><strong>Methods/Levers:</strong> Qualitative interviews; barrier/facilitator mapping; context-specific strategy design</p></li>
<li><p><strong>Operational Steps / Workflow:</strong></p>

<p> - Conduct CFIR-based stakeholder interviews</p>

<p> - Code responses into CFIR constructs</p>

<p> - Identify contextual barriers/facilitators</p>

<p> - Develop targeted strategies (e.g., morning huddles, standing orders, dashboards)</p></li>
<li><p><strong>Data &amp; Measures:</strong> EHR-based screening rates, provider order rates, completion rates, qualitative feedback</p></li>
<li><p><strong>Implementation Context:</strong> Large urban FQHC with diverse patient populations and resource constraints  </p></li>
</ul>

<blockquote>
  <p>“We will tackle the two barriers related to the EHR provider reminder… using a teamwork-based approach…” (p. 12)  </p>
</blockquote>

<blockquote>
  <p>“Goals direct attention and action… Specific and challenging goals can lead to better task performance…” (p. 12–13)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Strategies emphasize clarity in communication, goals, and feedback reports.  </p>

<p> &gt; “Include the target CRC screening rates in the quarterly… report.” (p. 12)</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Strategies tailored to FQHC realities (diverse patients, resource constraints).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Solutions integrate into workflow (e.g., huddles, MA screening updates).  </p></li>
<li><p><strong>TI (Timeliness):</strong> No explicit link to timeliness as a requirement.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — Strategies are explained, but not framed in terms of “explainability.”  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Emphasis on setting clear organizational and clinic-level goals.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Team-based care; cultural/linguistic appropriateness.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Consolidated Framework for Implementation Research (CFIR)</p></li>
<li><p>Goal-setting theory (Locke, Latham)</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>CRC screening order and completion rates</p></li>
<li><p>Provider- and clinic-level performance comparisons</p></li>
<li><p>Achievement of target goals in quarterly feedback</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> EHR reminder fatigue; unreliable data; cultural/linguistic challenges; lack of goals; poor communication; no patient print materials.  </p></li>
<li><p><strong>Enablers:</strong> HRSA reporting incentives; peer pressure; quarterly feedback reports; leadership engagement; teamwork culture.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions CFIR as a pragmatic framework for evaluating and improving EBI implementation in resource-constrained settings; findings align with prior studies on the influence of workflow integration, feedback, and organizational culture on implementation success.</p>

<hr />

<h2>Summary</h2>

<p>This study operationalizes “actionability” as turning contextual analysis of implementation barriers and facilitators into targeted, feasible strategies for improvement. Using CFIR, the authors mapped qualitative interview data to 39 constructs, identified specific challenges in implementing three CRC screening EBIs in an urban FQHC, and designed context-appropriate strategies such as morning huddles, standing orders, technical assistance for dashboards, and culturally tailored patient education. These strategies align with identified needs, integrate into existing workflows, and include measurable goals. The work demonstrates CFIR’s capacity to support actionable change in safety-net healthcare environments.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 — Strong implicit conceptualization of actionability with concrete features tied to context; explicit definition absent but well-inferred.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Detailed, context-specific strategies directly linked to identified barriers and facilitators.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“By identifying the contextual determinants, we can then determine implementation strategies to facilitate adoption and move EBIs to daily practice.” (p. 2)  </p></li>
<li><p>“Use teamwork approach and share the burden… Conduct morning huddles… Implement standing order…” (p. 12)  </p></li>
<li><p>“Include the target CRC screening rates in the quarterly… report… Disseminate… to all members of the clinic.” (p. 12)  </p></li>
<li><p>“Identify and collect culturally and linguistically specific CRC education material.” (p. 12)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>CFIR framework: Damschroder et al. (2009)  </p></li>
<li><p>Goal-setting theory: Locke et al. (1981), Lunenburg (2011)  </p></li>
<li><p>Implementation strategies literature: Proctor et al. (2013), Keith et al. (2017)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Human Resources-Based Organizational Data Mining (HRODM): Themes, Trends, Focus, Future  </p>

<p>Authors: Hila Chalutz-Ben Gal  </p>

<p>DOI: 10.1007/978-3-031-24628-9_36  </p>

<p>Year: 2023  </p>

<p>Publication Type: Book Chapter  </p>

<p>Discipline/Domain: Human Resource Management, Data Science  </p>

<p>Subdomain/Topic: Human Resources Analytics, Organizational Data Mining, ROI-based Analysis  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 92  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes (implicit via “actionable knowledge” definition in ODM/HRODM context)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes (e.g., interpretable actionable insights in recruitment model)  </p>

<p>Contains Framework/Model: Yes (ROI-based approach, LAMP framework)  </p>

<p>Operationalization Present: Yes (ROI-based HRODM process, tool-based implementation examples)  </p>

<p>Primary Methodology: Systematic Literature Review and Synthesis (with conceptual and empirical analysis)  </p>

<p>Study Context: Organizational decision-making in HR using data mining and analytics, ROI lens  </p>

<p>Geographic/Institutional Context: Global, with shift of research focus from Europe to North America  </p>

<p>Target Users/Stakeholders: HR managers, organizational decision-makers, data scientists, researchers  </p>

<p>Primary Contribution Type: Theoretical framework, synthesis, practical implementation guidance  </p>

<p>CL: Yes – clarity/understandability explicitly linked to actionable insight via “meaningful managerial insights” and LAMP “logic” component  </p>

<p>CR: Yes – contextual relevance linked to ROI-based adoption decisions  </p>

<p>FE: Yes – feasibility linked to adoption justification and ROI-driven prioritization  </p>

<p>TI: Yes – timeliness implicit in proactive vs. reactive HRODM application  </p>

<p>EX: Yes – explainability emphasized in interpretable recruitment decision model  </p>

<p>GA: Yes – goal alignment via strategic management tool framing  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Human Resources-Based Organizational Data Mining (HRODM): Themes, Trends, Focus, Future  </p>

<p><strong>Authors:</strong>  </p>

<p>Hila Chalutz-Ben Gal  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1007/978-3-031-24628-9_36  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Book Chapter  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Human Resource Management, Data Science  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Human Resources Analytics, Organizational Data Mining, ROI-based Analysis  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The chapter explores the use of data mining and analytics in human resources (HRODM), situating it within the broader organizational data mining (ODM) domain. It emphasizes the transformation from intuition-based HR to evidence-driven decision-making, framed through a Return on Investment (ROI) perspective to guide adoption.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Global; review shows an increasing North American research dominance post-2011.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>HR professionals, executives, data scientists, management scholars, organizational strategists.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Systematic literature review, conceptual synthesis, and ROI-based framework application.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Theoretical framework and applied guidance for HRODM adoption and implementation.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This chapter reviews and synthesizes the literature on Human Resources-Based Organizational Data Mining (HRODM) through an ROI lens. It traces the evolution of HRODM research from 2000–2016, categorizes contributions into empirical, conceptual, case-based, and technical clusters, and applies the LAMP framework (Logic, Analytics, Measurement, Process) to assess ROI potential. Four dominant trends emerge: HRODM as a strategic management tool, evidence-based approach, decision-making support tool, and management fad. The author argues for prioritizing empirical and conceptual research due to higher ROI outcomes, provides a structured table of HR tasks with tools and expected ROI, and presents two detailed implementation examples: workforce analytics for turnover and a recruitment decision support tool.  </p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as the transformation of HR data into “valuable and actionable knowledge” to improve decision-making and achieve strategic goals. ROI is positioned as a filter for determining the value of actionable insights.</p>

<blockquote>
  <p>“ODM is defined as leveraging… tools… to transform data into valuable and actionable knowledge to gain a strategic competitive advantage” (p. 833).  </p>
</blockquote>

<blockquote>
  <p>HRODM aims “to provide an organization with insights for effectively managing employees… to achieve business goals quickly and efficiently” (p. 834).  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Insights must be relevant to organizational strategy (goal alignment).</p></li>
<li><p>They must be derived from structured analytics (LAMP components).</p></li>
<li><p>ROI must be demonstrable to justify adoption.</p></li>
<li><p>Outputs must be interpretable and implementable by practitioners.</p></li>
<li><p>Contextual fit between analytics tools and organizational challenges.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> ROI-based approach, LAMP framework (Logic, Analytics, Measurement, Process).  </p></li>
<li><p><strong>Methods/Levers:</strong> Systematic literature review; classification of studies; mapping ROI levels to research clusters; application of descriptive and predictive analytics to HR tasks.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify HR challenge → select analytics tools → conduct analysis → interpret results in ROI terms → guide strategic decision-making.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> HR metrics, organizational KPIs, turnover data, satisfaction scores, recruitment success rates.  </p></li>
<li><p><strong>Implementation Context:</strong> Strategic HRM, talent management, workforce planning, recruitment, retention, training, compensation.  </p></li>
</ul>

<blockquote>
  <p>“The ROI-based approach… provides a robust tool to compare and contrast different dilemmas and associated values… supports continuous improvement” (p. 847).  </p>
</blockquote>

<blockquote>
  <p>“Extraction of interpretable and actionable insights” in recruitment decisions (p. 859).</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL:</strong> Yes — “meaningful managerial insights” and “clear connection between analytics investment and organizational effectiveness” (p. 846).  </p></li>
<li><p><strong>CR:</strong> Yes — contextual fit between analytics approach and organizational challenge (p. 848).  </p></li>
<li><p><strong>FE:</strong> Yes — ROI as a feasibility test for adoption (p. 834, 847).  </p></li>
<li><p><strong>TI:</strong> Yes — proactive vs. reactive application influences timeliness (p. 847).  </p></li>
<li><p><strong>EX:</strong> Yes — interpretable recruitment models explicitly mentioned (p. 859).  </p></li>
<li><p><strong>GA:</strong> Yes — strategic management tool framing and KPI alignment (p. 842).  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Evidence-based approach, process efficiency.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>LAMP framework (Boudreau &amp; Ramstad, 2006).</p></li>
<li><p>Contextual approach in organizational research (Johns, 2006, 2018).</p></li>
<li><p>Strategic HRM and ROI literature.</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>ROI percentage/ratio.</p></li>
<li><p>Turnover rates and causes.</p></li>
<li><p>Recruitment success probability.</p></li>
<li><p>Training ROI.</p></li>
<li><p>KPI performance changes post-implementation.</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Limited empirical evidence; lack of structured adoption methods; reactive data use; low ROI in fad-driven initiatives.  </p></li>
<li><p><strong>Enablers:</strong> ROI-based decision framework; integration of LAMP; predictive analytics tools; alignment with strategic goals.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on HR analytics, organizational data mining, and ROI literature; integrates managerial and technical perspectives; emphasizes empirical and conceptual research as high-ROI domains.</p>

<hr />

<h2>Summary</h2>

<p>The chapter positions HRODM as a high-impact approach for transforming HR data into actionable organizational knowledge, framed through ROI to ensure adoption feasibility and strategic relevance. Actionability is linked to contextual relevance, clear logic, interpretability, and measurable business outcomes. By applying the LAMP framework to categorize literature and map ROI potential, the author identifies empirical and conceptual research as the most promising avenues. The operational guidance includes a task–tool–ROI table and real-world implementation cases (turnover analytics, recruitment decision tool) to demonstrate how actionable insights are generated and applied.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Clear implicit definition of actionability, strong linkage to dimensions (clarity, relevance, feasibility, timeliness, explainability, goal alignment), and integration into theoretical framing.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Detailed step-by-step operationalization with ROI metrics, applied tools, and case studies showing actionable implementation.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“ODM is defined as… transforming data into valuable and actionable knowledge to gain a strategic competitive advantage” (p. 833).  </p></li>
<li><p>“To provide an organization with insights for effectively managing employees… to achieve business goals quickly and efficiently” (p. 834).  </p></li>
<li><p>“The ROI-based approach… provides a robust tool to compare and contrast different dilemmas and associated values… supports continuous improvement” (p. 847).  </p></li>
<li><p>“Extraction of interpretable and actionable insights” (p. 859).  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Boudreau &amp; Ramstad (2006) – LAMP framework.  </p></li>
<li><p>Rasmussen &amp; Ulrich (2015) – Adoption challenges and ROI focus.  </p></li>
<li><p>Levenson (2005, 2015) – Strategic HR analytics for goal alignment.  </p></li>
<li><p>Pessach et al. (2020) – Interpretable recruitment decision-making tool.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: How Clinicians Conceptualize “Actionability” in Genomic Screening  </p>

<p>Authors: Kellie Owens, Pamela Sankar, Dina M. Asfaha  </p>

<p>DOI: https://doi.org/10.3390/jpm13020290  </p>

<p>Year: 2023  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Genomic Medicine / Medical Ethics  </p>

<p>Subdomain/Topic: Actionability in population genomic screening  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 75  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: No  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Qualitative  </p>

<p>Study Context: Population genomic screening in primary care  </p>

<p>Geographic/Institutional Context: United States; multiple health systems  </p>

<p>Target Users/Stakeholders: Primary care providers, clinical geneticists, genetic counselors, genomic program designers, policymakers  </p>

<p>Primary Contribution Type: Empirical qualitative analysis  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Partial  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>How Clinicians Conceptualize “Actionability” in Genomic Screening  </p>

<p><strong>Authors:</strong>  </p>

<p>Kellie Owens, Pamela Sankar, Dina M. Asfaha  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.3390/jpm13020290  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Genomic Medicine / Medical Ethics  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Actionability in population genomic screening  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper explores how clinicians define, assess, and operationalize “actionability” in the context of genomic screening for healthy or unselected populations, identifying divergences in evidence standards, actionable interventions, and institutional capacity.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>United States; multiple health systems with varying resources and genomic screening programs.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Primary care providers, clinical geneticists, genetic counselors, public health genomics program managers, policy developers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Qualitative interviews (n=35) with purposive and snowball sampling.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical qualitative analysis.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This qualitative study investigates how clinicians—primary care providers, clinical geneticists, and genetic counselors—conceptualize and apply the notion of “actionability” in genomic screening. Drawing on semi-structured interviews with 35 participants, the authors find significant variation in definitions, ranging from narrow criteria tied to proven interventions to broad interpretations including psychosocial impact. The study identifies two main axes of disagreement: (1) the amount and type of evidence required to deem genomic data actionable, and (2) which clinical actions must be available to justify returning results. Evidence standards vary between specialties, with geneticists focusing on variant classification accuracy and primary care physicians emphasizing population-level trial data. Institutional capacity—especially resource limitations and follow-up care—shapes which results are returned. The authors argue that actionability is as much a social and political construct as a scientific one, and they recommend community-engaged, transparent decision-making for genomic screening programs.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Definitions range from narrow (“pathogenic change with known treatment or surveillance saving lives”) to broad (“any potential to modify life choices or medical treatment, now or in the future, including psychosocial impacts”).  </p>

<blockquote>
  <p>“Actionable would have to be a truly pathogenic change, for which there is a known treatment or surveillance recommendation that impacts a lifetime of medical management and saves lives.” — Clinical geneticist (p. 5)  </p>
</blockquote>

<blockquote>
  <p>“I think of [actionability] really broadly: anything that has the potential, either now or in the future, to modify either life choices or medical treatment… consider the social and emotional aspects… very personal.” — Clinical geneticist (p. 5)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Strong evidence of pathogenicity and penetrance  </p></li>
<li><p>Efficacy, burden, and availability of interventions  </p></li>
<li><p>Severity of potential disease  </p></li>
<li><p>Potential for life modification, clinical trial enrollment, or psychosocial benefit  </p></li>
<li><p>Alignment with patient’s values and personal utility  </p></li>
<li><p>Institutional capacity to act on the result  </p></li>
</ul>

<hr />

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> No formal named framework; draws on ACMG, CDC Tier One, and local institutional guidelines.  </p></li>
<li><p><strong>Methods/Levers:</strong> Variant classification (ClinVar, ClinGen), professional guidelines, institutional policies.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Evidence assessment (now vs. later), determination of available interventions, alignment with institutional capacity, return of results.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Variant pathogenicity, penetrance, disease severity, trial data, population-level screening outcomes.  </p></li>
<li><p><strong>Implementation Context:</strong> Varies by health system—resource-rich systems expand scope; resource-limited systems restrict to high-evidence Tier One conditions.  </p></li>
</ul>

<blockquote>
  <p>“Because we’re a safety net hospital… we would return results on the CDC Tier 1 conditions… probably appropriate to return to all-comers.” — Clinical geneticist (p. 10)  </p>
</blockquote>

<blockquote>
  <p>“We don’t want to leave patients hanging, because… reality happens before the ideal does.” — Genetic counselor (p. 6)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — clarity of variant classification and intervention pathways emphasized.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — tailored to institutional resources and patient population.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — dependent on institutional capacity and follow-up infrastructure.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — tension between acting now vs. waiting for more evidence.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — some emphasis on transparency of evidence and interpretation.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — decisions reflect health system priorities and patient benefit.  </p></li>
<li><p><strong>Other Dimensions:</strong> Personal utility, psychosocial impact, marketability (for some institutions).</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>ACMG actionability guidelines and secondary findings lists  </p></li>
<li><p>CDC Tier One genomic conditions  </p></li>
<li><p>Concepts of clinical validity, clinical utility, and personal utility  </p></li>
<li><p>Precision medicine vs. evidence-based medicine paradigms  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Evidence level for pathogenicity/penetrance  </p></li>
<li><p>Strength of intervention evidence (RCTs for PCPs; mechanistic plausibility for geneticists)  </p></li>
<li><p>Severity of disease outcome  </p></li>
<li><p>Institutional capacity metrics (follow-up care rates)  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of consensus on evidence standards; insufficient infrastructure; provider genetics training gaps; variable lab classification; competing health priorities.  </p></li>
<li><p><strong>Enablers:</strong> Established guidelines (ACMG, CDC Tier One); institutional investment; belief in patient benefit; psychosocial value; market incentives.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on prior patient-centered studies of actionability by focusing on clinician perspectives; confirms that definitions are socially contingent and context-dependent; extends debates on clinical utility by highlighting institutional capacity and values-based judgments.</p>

<hr />

<h2>Summary</h2>

<p>Owens et al. (2023) provide a qualitative investigation into how clinicians conceptualize “actionability” in genomic screening, revealing substantial variability in definitions and operationalization. While some clinicians use restrictive criteria tied to proven, life-saving interventions, others adopt expansive views incorporating future possibilities, psychosocial value, and patient agency. Disagreement centers on the type and amount of evidence required—geneticists prioritizing variant classification accuracy, primary care providers favoring population-level trial data—and the availability of follow-up actions. Institutional capacity emerges as a key determinant, with resource limitations often driving conservative return policies. The study underscores that actionability is as much about social values, institutional context, and political considerations as it is about science, advocating for transparent, community-informed processes in program design.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 — Strong explicit and implicit definitions, systematic features, and clinician-derived attributes of actionability.  </p></li>
<li><p><strong>Operationalization Score:</strong> 75 — Clear description of decision-making processes and contextual factors, though no formalized, replicable framework.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[My definition of] actionable would have to be a truly pathogenic change… that impacts a lifetime of medical management and saves lives.” (p. 5)  </p></li>
<li><p>“Anything that has the potential, either now or in the future, to modify either life choices or medical treatment… important psychologically.” (p. 5)  </p></li>
<li><p>“We don’t want to leave patients hanging… reality happens before the ideal does.” (p. 6)  </p></li>
<li><p>“Because we’re a safety net hospital… we would return results on the CDC Tier 1 conditions.” (p. 10)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Berg et al. (2016) — semiquantitative metric for evaluating clinical actionability  </p></li>
<li><p>ACMG SF v3.1 (Miller et al., 2022)  </p></li>
<li><p>CDC Tier One Genomics Applications  </p></li>
<li><p>Lázaro-Muñoz et al. (2017) — subjective judgments in selecting medically actionable genes  </p></li>
<li><p>Kohler et al. (2017) — personal utility in genomic testing</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Genomically matched therapy in refractory colorectal cancer according to ESMO Scale for Clinical Actionability of Molecular Targets: experience of a comprehensive cancer centre network  </p>

<p>Authors: Núria Mulet Margalef, Carmen Castillo, Miguel Mosteiro, Xavier Pérez, Susana Aguilar, Fiorella Ruíz-Pace, Marta Gil, Carmen Cuadra, Jose Carlos Ruffinelli, Mercedes Martínez, Ferran Losa, Gema Soler, Alex Teulé, Roser Castany, Rosa Gallego, Andrea Ruíz, Elena Garralda, Elena Elez, Ana Vivancos, Josep Tabernero, Ramon Salazar, Rodrigo Dienstmann, Cristina Santos Vivas  </p>

<p>DOI: 10.1002/1878-0261.13444  </p>

<p>Year: 2023  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Oncology  </p>

<p>Subdomain/Topic: Precision oncology; colorectal cancer; genomic profiling; clinical actionability  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 78  </p>

<p>Operationalization Score: 72  </p>

<p>Contains Definition of Actionability: Yes (via ESCAT framework)  </p>

<p>Contains Systematic Features/Dimensions: Yes (ESCAT levels I–IV)  </p>

<p>Contains Explainability: No  </p>

<p>Contains Interpretability: Partial (linked to molecular classification)  </p>

<p>Contains Framework/Model: Yes (ESCAT classification)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Quantitative (retrospective cohort study)  </p>

<p>Study Context: Expanded genomic profiling (EGP) for refractory metastatic colorectal cancer (mCRC) patients to identify druggable alterations and inclusion in biomarker-guided trials.  </p>

<p>Geographic/Institutional Context: Catalan Institute of Oncology and Vall d’Hebron Institute of Oncology, Spain  </p>

<p>Target Users/Stakeholders: Oncologists, molecular tumor boards, clinical trial designers, precision oncology programs  </p>

<p>Primary Contribution Type: Empirical results and application of ESCAT in clinical setting  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: No  </p>

<p>EX: No  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Genomically matched therapy in refractory colorectal cancer according to ESMO Scale for Clinical Actionability of Molecular Targets: experience of a comprehensive cancer centre network  </p>

<p><strong>Authors:</strong>  </p>

<p>Núria Mulet Margalef et al.  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1002/1878-0261.13444  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Oncology  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Precision oncology; colorectal cancer; genomic profiling; clinical actionability  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The study assesses the feasibility and clinical utility of expanded genomic profiling (EGP) in refractory metastatic colorectal cancer (mCRC) patients, using the European Society for Medical Oncology (ESMO) Scale for Clinical Actionability of Molecular Targets (ESCAT) to classify genomic alterations and guide therapy selection.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Catalan Institute of Oncology and Vall d’Hebron Institute of Oncology, Spain.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Oncologists, molecular tumor boards, clinical trial coordinators, policymakers in precision oncology.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative – retrospective cohort analysis.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical evidence applying ESCAT to real-world mCRC genomic profiling.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper reports on a cohort of 187 heavily pretreated mCRC patients enrolled in an expanded genomic profiling program between 2015–2020 to assess prevalence of ESCAT-defined genomic alterations and inclusion in biomarker-guided trials (BGTs). Using next-generation sequencing (NGS) on FFPE tumor samples, alterations were classified per ESCAT levels I–IV. Druggable alterations were identified in 28.9% of patients, most commonly in ESCAT III and IV categories, but only 2.7% were ultimately enrolled in BGTs. Findings highlight the feasibility of EGP in reference centers, the low trial inclusion rate, and suggest improvements such as refining NGS panels, adjusting timing of testing, and integrating liquid biopsy to capture tumor evolution.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is conceptualized through the ESCAT framework, which ranks genomic alterations based on clinical evidence supporting targeted therapy use:</p>

<blockquote>
  <p>“The clinical value according to ESMO Scale for Clinical Actionability of Molecular Targets (ESCAT) classification clearly differs between them” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“ESCAT I… validated in clinical trials… ESCAT IV… preclinical data” (Table 1, p. 2)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Validation in prospective clinical trials (ESCAT I)</p></li>
<li><p>Evidence of response in phase I/II or retrospective studies (ESCAT II)</p></li>
<li><p>Validated in other malignancies (ESCAT III)</p></li>
<li><p>Supported only by preclinical data (ESCAT IV)</p></li>
<li><p>Molecular relevance to drug targeting</p></li>
<li><p>Potential inclusion in biomarker-guided clinical trials</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> ESCAT (ESMO Scale for Clinical Actionability of Molecular Targets)  </p></li>
<li><p><strong>Methods/Levers:</strong> Classification of genomic alterations; NGS profiling; molecular tumor boards; clinical trial matching  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Patient selection → FFPE tumor sample → NGS mutation, CNA, fusion analysis → ESCAT classification → referral to BGTs  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Prevalence of ESCAT I–IV alterations; trial inclusion rates  </p></li>
<li><p><strong>Implementation Context:</strong> Precision oncology in a comprehensive cancer center  </p></li>
</ul>

<blockquote>
  <p>“EGP programmes in patients with advanced CRC are feasible and identify a subset of patients with potentially druggable genomic alterations” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“Final inclusion rate in biomarker-guided clinical trials was 2.7%” (p. 2)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — classification provides a clear, evidence-ranked hierarchy of targets.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — alterations are linked to mCRC therapeutic decisions.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — NGS profiling is feasible in reference centers with adequate tumor tissue.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No explicit link.  </p></li>
<li><p><strong>EX (Explainability):</strong> No explicit link.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — aim to align profiling with targeted therapy inclusion.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Evidence tier, molecular target druggability.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>ESCAT framework (Mateo et al., 2018) for ranking targets.  </p></li>
<li><p>ESMO guidelines on mCRC management and molecular profiling.  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>ESCAT category prevalence per patient cohort.  </p></li>
<li><p>Percentage inclusion in biomarker-guided trials.  </p></li>
<li><p>Mutation prevalence by sidedness and RAS status.</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Low prevalence of high-tier alterations; trial slot unavailability; sample insufficiency; absence of re-biopsy/liquid biopsy; incomplete MMR data.  </p></li>
<li><p><strong>Enablers:</strong> Centralized high-quality NGS analysis; multidisciplinary molecular boards; established clinical trial network.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Aligns with prior reports on low prevalence of high-evidence druggable alterations in mCRC and low trial enrollment rates despite genomic screening; reinforces ESMO’s cautious stance on routine broad NGS in mCRC outside trial contexts.</p>

<hr />

<h2>Summary</h2>

<p>The study applies the ESCAT framework to a real-world cohort of refractory mCRC patients undergoing expanded genomic profiling. Actionability is operationalized as the evidence-based potential for a genomic alteration to guide targeted therapy selection, with ESCAT providing a systematic ranking. While nearly 30% of patients had potentially druggable alterations, the trial inclusion rate remained low (2.7%), underscoring the gap between identification and therapeutic access. Authors call for optimizing testing timing, trial availability, and molecular panel content, as well as integrating liquid biopsies. The work offers a concrete application of ESCAT in clinical practice, providing empirical data on feasibility, limitations, and potential improvements.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 78 — Strong explicit definition via ESCAT and systematic features, though less depth on broader conceptualization.  </p></li>
<li><p><strong>Operationalization Score:</strong> 72 — Clear application of ESCAT in workflow and measurable outputs, but limited exploration of timing/decision-making processes.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“The clinical value according to ESMO Scale for Clinical Actionability of molecular Targets (ESCAT) classification clearly differs between them” (p. 2)  </p></li>
<li><p>“EGP programmes in patients with advanced CRC are feasible and identify a subset of patients with potentially druggable genomic alterations” (p. 1)  </p></li>
<li><p>“Final inclusion rate in biomarker-guided clinical trials was 2.7%” (p. 2)  </p></li>
<li><p>“Reducing tissue and economical costs… reshaping NGS panels periodically… implementing liquid biopsy” (p. 7)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Mateo J. et al., 2018 — Original ESCAT framework definition.  </p></li>
<li><p>Mosele F. et al., 2020 — ESMO NGS recommendations.  </p></li>
<li><p>ESMO Clinical Practice Guidelines for mCRC (Cervantes et al., 2023).</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Generic Project Definitions for Improvement of Health Care Delivery: A Case-Based Approach  </p>

<p>Authors: Gerard C. Niemeijer, Ronald J. M. M. Does, Jeroen de Mast, Albert Trip, Jaap van den Heuvel  </p>

<p>DOI: 10.1097/QMH.0b013e318213e75c  </p>

<p>Year: 2011  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Health Care Management / Quality Improvement  </p>

<p>Subdomain/Topic: Lean Six Sigma; Process Improvement; Case-Based Reasoning; Health Care Delivery Optimization  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes (implicit and explicit through “actionable knowledge” framing)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (CTQ flowdown + operational definitions; 9 generic templates)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Retrospective case-based analysis (Qualitative with quantitative metrics)  </p>

<p>Study Context: 271 Lean Six Sigma projects in hospitals (general, teaching, academic) in the Netherlands &amp; Belgium  </p>

<p>Geographic/Institutional Context: Netherlands, Belgium; University Medical Center Groningen, Erasmus MC, others  </p>

<p>Target Users/Stakeholders: Hospital managers, project leaders, health care professionals (including nurses, doctors, administrators)  </p>

<p>Primary Contribution Type: Case-based templates for defining improvement projects in healthcare delivery  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Partial  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Generic Project Definitions for Improvement of Health Care Delivery: A Case-Based Approach</p>

<p><strong>Authors:</strong>  </p>

<p>Gerard C. Niemeijer, Ronald J. M. M. Does, Jeroen de Mast, Albert Trip, Jaap van den Heuvel</p>

<p><strong>DOI:</strong>  </p>

<p>10.1097/QMH.0b013e318213e75c</p>

<p><strong>Year:</strong>  </p>

<p>2011</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Health Care Management / Quality Improvement</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Lean Six Sigma; Process Improvement; Case-Based Reasoning; Health Care Delivery Optimization</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses improvement of health care delivery via process optimization, using a large-scale retrospective analysis of Lean Six Sigma projects. It aims to make project definitions more effective by providing practitioners with actionable, reusable templates grounded in real-world cases.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Hospitals in the Netherlands and Belgium (general, teaching, academic hospitals).</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Hospital managers, project leaders, quality improvement teams, nurses, doctors, administrators.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Retrospective qualitative analysis with quantitative operational metrics.</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Nine generic project definition templates for process improvement.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This study analyzes 271 Lean Six Sigma process improvement projects from hospitals in the Netherlands and Belgium (2002–2009). The authors use case-based reasoning to distill recurring patterns into nine “generic project definitions” that serve as templates for defining future projects. Each template includes a rationale, a CTQ (critical-to-quality) flowdown, operational definitions, and a prototypical example. The focus is on making project definitions more precise, relevant, and implementable, thus enabling “actionable knowledge” transfer. The templates cover themes such as cost reduction, revenue increase, patient safety, and satisfaction. By stripping case-specific details and focusing on mid-level generality, the authors make the lessons reusable across contexts, supporting practitioners in selecting, defining, and operationalizing improvement initiatives effectively.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<p>The paper explicitly frames its goal as producing “actionable knowledge” for defining and operationalizing healthcare improvement projects. It presents systematic features (clarity, contextual relevance, feasibility, goal alignment) and concrete operational steps.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as the ability to define improvement projects in a way that enables efficient selection, measurable operationalization, and practical implementation using structured, reusable templates derived from real-world cases.</p>

<blockquote>
  <p>“The purpose of this article is to create actionable knowledge, making the definition of process improvement projects in health care delivery more effective.” (p. 152)  </p>
</blockquote>

<blockquote>
  <p>“These templates function as exemplars for future process improvement projects, making the selection, definition, and operationalization of similar projects more efficient.” (p. 152)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Clear linkage between project objectives and organizational strategy</p></li>
<li><p>Explicit operational definitions through CTQ flowdown</p></li>
<li><p>Use of measurable indicators</p></li>
<li><p>Mid-level generality (removing excessive context-specificity)</p></li>
<li><p>Reusability of template structures</p></li>
<li><p>Direct connection to performance dimensions (cost, safety, satisfaction, throughput)</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Lean Six Sigma methodology; Case-Based Reasoning (CBR)  </p></li>
<li><p><strong>Methods/Levers:</strong> CTQ flowdown; standard measurement plans; operational definitions; nine generic templates.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Define → Measure → Analyze → Improve → Control (DMAIC); extract CTQs from strategic goals; match project objectives to template; adapt operational definitions; validate in review.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Critical-to-Quality (CTQ) indicators linked to metrics such as LOS, resource utilization, complication rates, revenue.  </p></li>
<li><p><strong>Implementation Context:</strong> Hospitals in NL and BE, across multiple departments.  </p></li>
</ul>

<blockquote>
  <p>“The CTQ flowdown results in a measurement plan, which operationalizes a project’s objectives.” (p. 154)  </p>
</blockquote>

<blockquote>
  <p>“We identified 9 generic project definition templates… proposed to serve as exemplars.” (p. 155)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Templates and CTQ flowdown explicitly define objectives and metrics.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Tied to hospital strategy and operational context.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Focus on measurable and achievable improvements.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Addresses throughput and waiting time in some templates.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — CTQ flowdowns show logical rationale but limited emphasis on interpretability for non-experts.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Projects aligned with strategic focal points.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Reusability; mid-level generality; evidence-based problem selection.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Lean Six Sigma DMAIC methodology  </p></li>
<li><p>Case-Based Reasoning (CBR) from AI  </p></li>
<li><p>CTQ flowdown as conceptual linking model</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>LOS (Length of Stay)  </p></li>
<li><p>Bed occupation rates  </p></li>
<li><p>Number of unnecessary units used  </p></li>
<li><p>Percentage of missing/unavailable equipment  </p></li>
<li><p>Error rates in registration/invoicing  </p></li>
<li><p>Resource utilization rates  </p></li>
<li><p>Complication/infection rates</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Context differences across hospitals; risk of uncritical application of templates; local knowledge requirements.  </p></li>
<li><p><strong>Enablers:</strong> Structured CTQ flowdown; clear linkage to strategy; reusable templates; measurable indicators.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions contribution as a complement to rule-based Lean Six Sigma methods, adding case-based, mid-level generality templates for project selection and definition. Builds on earlier Lean Six Sigma healthcare applications and CBR theory.</p>

<hr />

<h2>Summary</h2>

<p>Niemeijer et al. (2011) present a case-based reasoning approach to defining healthcare improvement projects. By analyzing 271 Lean Six Sigma projects, they create nine reusable generic templates, each including a CTQ flowdown, operational definitions, and examples. The concept of actionability is embedded in the capacity of these templates to guide precise, relevant, and measurable project definitions aligned with hospital strategy. Actionability here depends on clarity, contextual relevance, feasibility, goal alignment, and measurability. The work operationalizes actionability through structured DMAIC phases, CTQ metrics, and template adaptation. This approach supports practitioners in avoiding vague or overly context-bound project definitions, enabling faster and more effective improvement cycles in healthcare delivery.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 — Strong conceptual and practical integration of actionability through explicit templates, measurable metrics, and strategic alignment.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Highly detailed operational process (DMAIC, CTQ flowdown, metrics) with clear adaptation pathways.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“The purpose of this article is to create actionable knowledge, making the definition of process improvement projects in health care delivery more effective.” (p. 152)  </p></li>
<li><p>“These templates function as exemplars for future process improvement projects, making the selection, definition, and operationalization of similar projects more efficient.” (p. 152)  </p></li>
<li><p>“The CTQ flowdown results in a measurement plan, which operationalizes a project’s objectives.” (p. 154)  </p></li>
<li><p>“We identified 9 generic project definition templates… proposed to serve as exemplars.” (p. 155)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>De Mast J, Does RJMM, De Koning H. <em>Lean Six Sigma for Service and Healthcare</em> (2006)  </p></li>
<li><p>Slade S. <em>Case-based reasoning: a research paradigm</em> (1991)  </p></li>
<li><p>Aamodt A, Plaza E. <em>Case-based reasoning: foundational issues</em> (1994)  </p></li>
<li><p>De Koning H, De Mast J. <em>The CTQ flowdown as a conceptual model of project objectives</em> (2007)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Big data and technology assessment: research topic or competitor?  </p>

<p>Authors: Gernot Rieder, Judith Simon  </p>

<p>DOI: https://doi.org/10.1080/23299460.2017.1360718  </p>

<p>Year: 2017  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Science, Technology, and Society (STS) / Responsible Innovation  </p>

<p>Subdomain/Topic: Big Data governance; Technology Assessment (TA); Responsible Research and Innovation (RRI)  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 87  </p>

<p>Operationalization Score: 75  </p>

<p>Contains Definition of Actionability: Yes (implicit, as provision of actionable knowledge in TA and Big Data)  </p>

<p>Contains Systematic Features/Dimensions: Yes (multiple features tied to actionability such as timeliness, contextual relevance, feasibility, explainability)  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Partial (discussed via TA’s reflexive practices and Big Data’s opacity)  </p>

<p>Contains Framework/Model: No formal named model, but structured comparative framework TA vs Big Data  </p>

<p>Operationalization Present: Yes (discussion of methods, practices, and integration possibilities for achieving actionable knowledge)  </p>

<p>Primary Methodology: Conceptual / Review  </p>

<p>Study Context: Comparative analysis of TA and Big Data analytics as socio-technical practices  </p>

<p>Geographic/Institutional Context: Europe-focused with international references (EU policy, US OTA, global Big Data discourse)  </p>

<p>Target Users/Stakeholders: Policymakers, TA practitioners, data scientists, civil society, industry stakeholders  </p>

<p>Primary Contribution Type: Conceptual comparative analysis and recommendations  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Partial  </p>

<p>TI: Yes  </p>

<p>EX: Yes  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Big data and technology assessment: research topic or competitor?  </p>

<p><strong>Authors:</strong>  </p>

<p>Gernot Rieder, Judith Simon  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1080/23299460.2017.1360718  </p>

<p><strong>Year:</strong>  </p>

<p>2017  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Science, Technology, and Society (STS) / Responsible Innovation  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Big Data governance; Technology Assessment (TA); Responsible Research and Innovation (RRI)  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper examines Big Data not only as a socio-technical phenomenon of interest to TA but also as a potential competitor in producing actionable, future-oriented knowledge for governance. It situates the discussion in the broader context of RRI, European and US technology governance, and socio-political debates on data-driven decision-making.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Primarily European TA landscape, with references to US (OTA), OECD, and global Big Data policy initiatives.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Policy makers, TA practitioners, data scientists, industry actors, civil society organizations.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual / Review  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Comparative conceptual framework and normative recommendations.  </p>

<h2>General Summary of the Paper</h2>

<p>The article explores the dual relationship between Big Data and Technology Assessment (TA): as a research topic and as a competitor in providing actionable, future-oriented advice to policy. It reviews TA’s experience in interdisciplinary, participatory, and anticipatory governance, positioning it as well-equipped to address Big Data’s societal, ethical, and political challenges. The authors argue, however, that Big Data analytics may rival TA in assessing public opinion, exploring futures, and producing actionable knowledge—often faster, cheaper, and with perceived objectivity. They analyze overlaps and divergences in epistemology, methods, and outputs, highlighting the risks of displacement of TA’s role. The paper concludes with recommendations for collaboration, mutual learning, and integrating Big Data methods into TA under an RRI framework, emphasizing multidisciplinarity, inclusive participation, reflexivity about future-making, and context-sensitive, situated knowledge production.  </p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as the provision of <strong>reliable, relevant, and usable knowledge</strong> to inform political decision-making in contexts of uncertainty, high stakes, and contested values. Both TA and Big Data claim to offer such actionable, future-oriented knowledge, though through different epistemologies and methods.  </p>

<blockquote>
  <p>“Providing actionable knowledge and advice for democratic decision-making in cases where the stakes are high, facts are uncertain, and values are in dispute” (p. 236)  </p>
</blockquote>

<blockquote>
  <p>“Big Data’s key promise… the provision of actionable, future-oriented knowledge” (p. 235)  </p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Timely delivery of knowledge in decision-relevant windows.  </p></li>
<li><p>Contextual relevance to stakeholders’ needs and policy environments.  </p></li>
<li><p>Reflexivity in anticipating future trajectories and their desirability.  </p></li>
<li><p>Inclusivity and deliberation to capture diverse perspectives.  </p></li>
<li><p>Ability to translate complex socio-technical dynamics into decision guidance.  </p></li>
<li><p>Feasibility and implementability of recommendations.  </p></li>
<li><p>Transparency/explainability to support trust and legitimacy.  </p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Not a named model, but comparative TA vs Big Data operational modes.  </p></li>
<li><p><strong>Methods/Levers:</strong> Multi-, inter-, and transdisciplinary research; participatory foresight; scenario exercises; deliberative engagement; Big Data’s real-time analytics, sentiment analysis, predictive forecasting.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Problem scoping, multidisciplinary synthesis, participatory engagement, anticipation of impacts, translation into policy advice.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Combination of qualitative deliberation outputs, stakeholder inputs, and computational analytics.  </p></li>
<li><p><strong>Implementation Context:</strong> Governance of emerging technologies, particularly Big Data, under RRI principles.  </p></li>
</ul>

<blockquote>
  <p>“Participatory engagement can be considered a vital element for a more ‘anticipatory’ and ‘reflexive’ governance…” (p. 237)  </p>
</blockquote>

<blockquote>
  <p>“Big Data technologies estimate probable future trajectories… rendering the future knowable and its outcome optimizable” (p. 239)  </p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – actionable advice must be clear and comprehensible to decision-makers.  </p>

<p> &gt; “Providing independent, high-quality knowledge about techno-scientific developments…” (p. 240)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – relevance to stakeholder needs is central in TA and challenged by Big Data’s decontextualized analytics.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial – implied in TA’s role of offering viable options, but less explicitly tied to feasibility as a formal criterion.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes – timely advice is critical in high-stakes contexts; Big Data’s real-time capabilities are highlighted.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – TA’s transparency vs Big Data’s opacity (algorithmic black boxes) discussed.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial – alignment with societal goals is implicit in RRI framing.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Inclusivity, reflexivity, sustainability, public trust.  </p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Responsible Research and Innovation (RRI) framework.  </p></li>
<li><p>Anticipatory governance (Guston 2014).  </p></li>
<li><p>Technology futures (Grunwald 2012).  </p></li>
<li><p>Post-normal science (Funtowicz &amp; Ravetz 1993).  </p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<p>No formal quantitative indicators; emphasis on qualitative criteria such as inclusivity, reflexivity, contextual fit, and uptake in decision processes.  </p>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Big Data opacity; overreliance on algorithmic objectivity; displacement of deliberative processes; lack of public trust; speed and cost advantages of Big Data undermining TA.  </p></li>
<li><p><strong>Enablers:</strong> Integration of computational analytics into TA; multidisciplinary collaboration; genuine participatory engagement; alignment with RRI.  </p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions Big Data as a socio-technical phenomenon with both epistemic and political implications, extending debates in STS, data ethics, and innovation governance. Draws on TA literature, critical Big Data studies, and RRI discourse to bridge fields.  </p>

<h2>Summary</h2>

<p>This paper provides a conceptual comparison of TA and Big Data as providers of actionable, future-oriented knowledge. It argues that Big Data, while a valuable research topic for TA, also competes with TA in key functions: assessing public opinion, exploring future trajectories, and delivering actionable policy advice. TA’s strength lies in inclusive, reflexive, and context-sensitive engagement, while Big Data offers speed, scale, and perceived objectivity. The authors warn of risks if TA is displaced by computational approaches without critical oversight, especially for RRI goals. They recommend a collaborative, hybrid approach—integrating data science tools into TA’s participatory and anticipatory practices—to enhance both fields’ capacity to support responsible, democratic governance of technology.  </p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 87 – Strong conceptualization of actionability (explicitly named, linked to TA’s advisory role and Big Data’s promises), with systematic features discussed.  </p></li>
<li><p><strong>Operationalization Score:</strong> 75 – Detailed discussion of methods and integration pathways, though no formalized operational model or metrics.  </p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Providing actionable knowledge and advice for democratic decision-making…” (p. 236)  </p></li>
<li><p>“Big Data’s key promise… the provision of actionable, future-oriented knowledge” (p. 235)  </p></li>
<li><p>“Participatory engagement… vital element for more ‘anticipatory’ and ‘reflexive’ governance…” (p. 237)  </p></li>
<li><p>“Big Data technologies… rendering the future knowable and its outcome optimizable” (p. 239)  </p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Funtowicz &amp; Ravetz (1993) – post-normal science.  </p></li>
<li><p>Guston (2014) – anticipatory governance.  </p></li>
<li><p>Grunwald (2012) – technology futures.  </p></li>
<li><p>Abelson et al. (2003) – public deliberation design.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Facilitation of Entrepreneurial Discovery Processes by Policymakers: An Actionable Definition of Roles and Challenges  </p>

<p>Authors: Miren Estensoro, Miren Larrea  </p>

<p>DOI: https://doi.org/10.1007/s13132-022-00906-1  </p>

<p>Year: 2023  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Regional Development / Innovation Policy  </p>

<p>Subdomain/Topic: Smart Specialisation Strategies (S3/S4), Entrepreneurial Discovery Processes (EDP), Policy Facilitation  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 92  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes (explicit and implicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: No  </p>

<p>Contains Framework/Model: Yes (Six Roles of Facilitative Policymakers)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Action Research  </p>

<p>Study Context: Bilbao Next Lab, urban S3 strategy with EDP facilitation in Bilbao, Spain  </p>

<p>Geographic/Institutional Context: Bilbao City Council, Bilbao Ekintza (city development agency), Basque Country, Spain  </p>

<p>Target Users/Stakeholders: Policymakers, entrepreneurs, researchers, quadruple helix actors  </p>

<p>Primary Contribution Type: Conceptual framework with operationalization  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Partial  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong> Facilitation of Entrepreneurial Discovery Processes by Policymakers: An Actionable Definition of Roles and Challenges  </p>

<p><strong>Authors:</strong> Miren Estensoro, Miren Larrea  </p>

<p><strong>DOI:</strong> https://doi.org/10.1007/s13132-022-00906-1  </p>

<p><strong>Year:</strong> 2023  </p>

<p><strong>Publication Type:</strong> Journal  </p>

<p><strong>Discipline/Domain:</strong> Regional Development / Innovation Policy  </p>

<p><strong>Subdomain/Topic:</strong> Smart Specialisation Strategies (S3/S4), Entrepreneurial Discovery Processes (EDP), Policy Facilitation  </p>

<p><strong>Contextual Background:</strong> Focuses on how policymakers can operationally facilitate EDPs within S3/S4 strategies, moving beyond conceptual definitions to concrete, context-tested roles and challenges, using the Bilbao Next Lab project as a case.  </p>

<p><strong>Geographic/Institutional Context:</strong> Bilbao City Council and Bilbao Ekintza, Basque Country, Spain.  </p>

<p><strong>Target Users/Stakeholders:</strong> Policymakers, entrepreneurs, quadruple helix actors, researchers.  </p>

<p><strong>Primary Methodology:</strong> Action Research  </p>

<p><strong>Primary Contribution Type:</strong> Actionable conceptual framework.</p>

<h2>General Summary of the Paper</h2>

<p>The paper develops and tests an actionable framework for the roles of policymakers in facilitating Entrepreneurial Discovery Processes (EDPs) within Smart Specialisation Strategies (S3), based on an action research case in Bilbao. Recognising a gap in the literature—plenty of emphasis on EDP features but limited guidance on policymakers’ concrete roles—the authors co-generated knowledge with policymakers during the Bilbao Next Lab’s “Futurable” pilot EDP on wearable technologies. The study identifies six facilitative roles for policymakers, connects them to real-world dilemmas and challenges, and discusses the importance of capability-building for policymakers themselves. It emphasises learning as both a policymaker and entrepreneurial function, and integrates facilitation theory into S3 practice. The result is a detailed, context-tested, operational guide linking conceptual literature with actionable practice.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as the ability for policymakers’ roles in EDPs to be <strong>directly implementable</strong> in practice through clearly defined functions connected to real dilemmas, tensions, and contexts. It moves beyond generic role definitions to embed “how-to” elements.</p>

<blockquote>
  <p>“Our contribution is oriented… not exclusively in the theoretical… but also in how they can address its challenges together.” (p. 1323)  </p>
</blockquote>

<blockquote>
  <p>“We connect… the roles with the dilemmas, efforts, tensions, needs, power issues, challenges, risks… which increase their actionability.” (p. 1323)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Roles are <strong>linked to concrete actions</strong>, decisions, and facilitation techniques.</p></li>
<li><p>Grounded in <strong>real-world dilemmas</strong> and capacity gaps policymakers face.</p></li>
<li><p>Context-specific learning integrated into process design.</p></li>
<li><p>Inclusion of <strong>both substance knowledge</strong> (technical field) and <strong>process knowledge</strong> (trust, shared vision).</p></li>
<li><p>Built-in <strong>monitoring and systematisation</strong> for ongoing improvement.</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Six Roles of Facilitative Policymakers in EDPs.  </p></li>
<li><p><strong>Methods/Levers:</strong> Action research co-generation; facilitation techniques; collaborative governance; strategic selection of participants; integration of outside knowledge.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Choose field to explore  </p>

<p> 2. Learn about the field  </p>

<p> 3. Engage stakeholders  </p>

<p> 4. Attract outside knowledge  </p>

<p> 5. Develop shared vision  </p>

<p> 6. Monitor, evaluate, systematise  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Process indicators, documentation of lessons learned, stakeholder engagement records.  </p></li>
<li><p><strong>Implementation Context:</strong> Bilbao’s Futurable pilot EDP on wearable technologies.  </p></li>
</ul>

<blockquote>
  <p>“Participants considered that the first step… was to have a clear definition of their roles…” (p. 1332)  </p>
</blockquote>

<blockquote>
  <p>“Monitoring systems should include process indicators… and systematisation of experiences…” (p. 1337)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — clear role definitions and functions.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — tailored to Bilbao’s specific EDP context.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — tested in practice with policymakers.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — emphasis on continuous adaptation but less on strict time-bound delivery.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — roles explained, but mechanisms sometimes implicit.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — aligned with S3/S4 innovation and collaborative governance goals.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Trust-building, conflict management, integration of external knowledge.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Smart Specialisation and EDP literature (Foray et al., 2012; Lepore &amp; Spigarelli, 2018)</p></li>
<li><p>Facilitation theory (Costamagna &amp; Larrea, 2018)</p></li>
<li><p>Collaborative governance (Ansell &amp; Gash, 2008)</p></li>
<li><p>Action research methodology.</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Process indicators (number of workshops, participant diversity)</p></li>
<li><p>Evidence of stakeholder collaboration</p></li>
<li><p>Recorded lessons learned and systematisation outputs.</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of policymaker facilitation skills; limited knowledge of technical domains; power-sharing challenges; risk of process stagnation.  </p></li>
<li><p><strong>Enablers:</strong> Embedded capability-building; action research support; proactive stakeholder engagement; external knowledge integration.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions itself as filling the gap between conceptual EDP role descriptions and practical operationalisation, especially by embedding facilitation theory and connecting roles to dilemmas and capacity-building.</p>

<h2>Summary</h2>

<p>This paper operationalises the facilitation role of policymakers in Entrepreneurial Discovery Processes within Smart Specialisation Strategies by identifying six actionable roles, tested in the Bilbao “Futurable” case. It uniquely integrates facilitation theory with S3 practice through an action research methodology, ensuring roles are grounded in real-world challenges and capacity needs. Actionability stems from combining concrete role definitions with embedded learning, stakeholder engagement, trust-building, conflict management, and systematic evaluation. The work bridges theory and practice, offering a replicable yet adaptable framework for other regions adopting collaborative governance in EDPs.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Strong conceptual clarity on actionability, fully integrated with operational features, directly relevant to policymakers in S3/EDP contexts.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Detailed, field-tested workflow with concrete, replicable steps and clear role definitions.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We connect… the roles with the dilemmas, efforts, tensions, needs… which increase their actionability.” (p. 1323)  </p></li>
<li><p>“Participants considered that the first step… was to have a clear definition of their roles…” (p. 1332)  </p></li>
<li><p>“Monitoring systems should include process indicators… and systematisation of experiences…” (p. 1337)  </p></li>
<li><p>“The knowledge… has a more actionable nature than the theoretical concepts…” (p. 1338)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li>Foray et al. (2012); Lepore &amp; Spigarelli (2018); Costamagna &amp; Larrea (2018); Ansell &amp; Gash (2008); Periánez-Forte et al. (2016).</li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Explaining Aggregate Behaviour in Cognitive Agent Simulations Using Explanation  </p>

<p>Authors: Tobias Ahlbrecht, Michael Winikoff  </p>

<p>DOI: https://doi.org/10.1007/978-3-030-30391-4_8  </p>

<p>Year: 2019  </p>

<p>Publication Type: Conference  </p>

<p>Discipline/Domain: Artificial Intelligence, Multi-Agent Systems  </p>

<p>Subdomain/Topic: Cognitive agents, Explainable AI, Agent-based simulation  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 87  </p>

<p>Operationalization Score: 85  </p>

<p>Contains Definition of Actionability: Yes (implicit, tied to usefulness of explanations for simulation refinement and decision-making)  </p>

<p>Contains Systematic Features/Dimensions: Yes (implicit through explanation properties such as specificity, contextual relevance, and testability)  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (aggregation mechanism for explanations)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual + Simulation-based demonstration  </p>

<p>Study Context: Traffic simulation with cognitive BDI agents  </p>

<p>Geographic/Institutional Context: TU Clausthal, Germany; Victoria University of Wellington, New Zealand  </p>

<p>Target Users/Stakeholders: Simulation developers, researchers, possibly decision-makers using simulation results  </p>

<p>Primary Contribution Type: Methodological framework and proof-of-concept  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Partial  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Explaining Aggregate Behaviour in Cognitive Agent Simulations Using Explanation  </p>

<p><strong>Authors:</strong>  </p>

<p>Tobias Ahlbrecht, Michael Winikoff  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1007/978-3-030-30391-4_8  </p>

<p><strong>Year:</strong>  </p>

<p>2019  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Artificial Intelligence, Multi-Agent Systems  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Cognitive agents, Explainable AI, Agent-based simulation  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper is situated in the context of developing and refining cognitive agent-based simulations, where understanding specific aggregate behaviours—such as emergent traffic congestion patterns—can guide debugging, validation, and scenario testing. The intended users are simulation developers and possibly applied researchers who need detailed, actionable insight into why groups of agents behave in particular ways.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>TU Clausthal (Germany) and Victoria University of Wellington (New Zealand)  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Simulation developers, AI researchers, decision analysts relying on simulation outcomes  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual development with simulation-based illustration (traffic scenario)  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>A method for aggregating individual agent explanations to interpret collective behaviour in simulations  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper presents a method for obtaining actionable understanding of aggregate behaviour in cognitive agent-based simulations by aggregating individual agent explanations. Built on the BDI (Belief-Desire-Intention) agent model and an explanation mechanism for single-agent behaviour, the approach combines explanations from multiple agents to answer queries about collective actions or emergent phenomena. A traffic simulation case study demonstrates the method: explanations for why agents choose specific routes are aggregated to reveal behavioural patterns, test hypotheses (e.g., effect of bridge closures), and detect unrealistic decision-making logic. The authors also outline a process where human analysts use aggregated explanations iteratively to refine questions, run counterfactual tests, and improve simulations.  </p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>The paper implicitly defines actionability as the capacity of aggregated explanations to support simulation developers in understanding, validating, and improving simulations—particularly by enabling specific, testable insights about group behaviour. Actionability arises when explanations help identify causes, guide counterfactual experimentation, and inform targeted changes.  </p>

<blockquote>
  <p>“...obtain useful (and actionable) insight into the behaviour of agent-based simulation...” (p. 129)  </p>
</blockquote>

<blockquote>
  <p>“...this link would become less used. This hypothesis was therefore tested by re-running the simulation...” (p. 140)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Specific to the scenario and time frame (not just generic dynamics)  </p></li>
<li><p>Links aggregate behaviour to identifiable causal factors  </p></li>
<li><p>Supports hypothesis testing via simulation modification  </p></li>
<li><p>Enables detection of unintended or unrealistic behaviours  </p></li>
<li><p>Relates factors directly to agent decision logic and environment conditions  </p></li>
</ul>

<hr />

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Aggregated Explanation Mechanism  </p></li>
<li><p><strong>Methods/Levers:</strong> Logging explanatory factors in agent code; aggregating factors across relevant agents; frequency analysis to identify key drivers  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Pose a query about aggregate behaviour  </p>

<p> 2. Identify relevant agents  </p>

<p> 3. Generate individual explanations using BDI-based mechanism  </p>

<p> 4. Aggregate factors and count frequencies  </p>

<p> 5. Filter and interpret most common factors  </p>

<p> 6. Optionally run counterfactual simulations to test hypotheses  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Counts of explanatory factor occurrences per agent for a given query  </p></li>
<li><p><strong>Implementation Context:</strong> Applied to a simplified traffic simulation with road network, bridges, and route-choice agents  </p></li>
</ul>

<blockquote>
  <p>“A straightforward way to aggregate explanations is to count the occurrences of all explanatory factors that are related to a query, and list the most common ones.” (p. 138)  </p>
</blockquote>

<blockquote>
  <p>“...we might modify c (or the parameters) and re-run the simulation to check...” (p. 138)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Explanations are explicitly linked to decision logic, making cause understandable.  </p>

<p> &gt; “...preferred the road from 1 to 2 over the road from 1 to 3 because there was traffic...” (p. 137)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Explanations are scenario- and query-specific.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — Hypotheses can be tested via simulation reruns.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Insights are generated in sync with simulation analysis.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Mechanism based on BDI folk psychology concepts.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — Explanations align with agents’ stated goals (e.g., reach destination).  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Testability, specificity, frequency-based relevance.  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>BDI model of cognitive agents  </p></li>
<li><p>Folk psychology explanation concepts (Malle, 2004)  </p></li>
<li><p>Explanation frameworks in AI (Winikoff et al., 2018)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Frequency of explanatory factors across relevant agents  </p></li>
<li><p>Presence of causal, scenario-specific factors in top-ranked list  </p></li>
<li><p>Change in observed behaviour after modifying implicated conditions  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Noise from less relevant factors; difficulty in filtering relevant factors; unrealistic agent logic producing misleading explanations.  </p></li>
<li><p><strong>Enablers:</strong> Structured logging of decision rationale; aggregation process; human-in-the-loop query refinement and counterfactual testing.  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on work explaining single-agent behaviour (e.g., Winikoff et al., 2018) and extends to independent multi-agent aggregates—addressing a gap where prior work lacked mechanisms for aggregating explanations.  </p>

<hr />

<h2>Summary</h2>

<p>The authors propose a method to explain aggregate behaviour in cognitive agent-based simulations by aggregating individual agent explanations derived from BDI-based decision models. Actionability here means the ability to produce scenario-specific, testable insights into collective behaviour that aid simulation refinement and debugging. The method operationalizes actionability through a structured process: pose a query, collect and aggregate explanations, identify common causal factors, and, if needed, test them via simulation modifications. The traffic simulation case study illustrates how this approach can reveal whether route choices result from congestion, infrastructure status, or flawed logic, leading to targeted fixes. Key actionable features include clarity, contextual relevance, testability, and goal alignment. The framework provides both a conceptual contribution and a practical demonstration, scoring high in relevance and operationalization due to its explicit link between explanation mechanisms and actionable insight generation.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 87 — Strong implicit definition of actionability tied to explanation usefulness, clear dimensions, and systematic process.  </p></li>
<li><p><strong>Operationalization Score:</strong> 85 — Detailed step-by-step process with implemented case study; robust enough for replication in similar simulation contexts.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“...obtain useful (and actionable) insight into the behaviour of agent-based simulation...” (p. 129)  </p></li>
<li><p>“A straightforward way to aggregate explanations is to count the occurrences of all explanatory factors...” (p. 138)  </p></li>
<li><p>“...preferred the road from 1 to 2 over the road from 1 to 3 because there was traffic...” (p. 137)  </p></li>
<li><p>“This hypothesis was therefore tested by re-running the simulation...” (p. 140)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Malle, B.F. (2004) — Folk psychology framework for explanation  </p></li>
<li><p>Winikoff et al. (2018) — Single-agent explanation mechanism  </p></li>
<li><p>Harbers et al. (2010) — Early proposal for explaining collective behaviour</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Evidential Reasoning Approach for Predicting Popularity of Instagram Posts  </p>

<p>Authors: L. Rivadeneira, I. Loor  </p>

<p>DOI: 10.1109/ACCESS.2024.3510637  </p>

<p>Year: 2024  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Computer Science / Social Media Analytics  </p>

<p>Subdomain/Topic: Predictive modelling of social media engagement using evidential reasoning  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 78  </p>

<p>Operationalization Score: 85  </p>

<p>Contains Definition of Actionability: Yes (implicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (MAKER)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Quantitative / Predictive Modelling (Machine Learning)  </p>

<p>Study Context: Instagram post popularity prediction using visual and textual features  </p>

<p>Geographic/Institutional Context: Harvard University (USA) &amp; University of Oxford (UK) Instagram accounts  </p>

<p>Target Users/Stakeholders: Social media managers, marketing professionals, academic institutions, content strategists  </p>

<p>Primary Contribution Type: Methodological framework and comparative evaluation  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Partial  </p>

<p>TI: No  </p>

<p>EX: Yes  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Evidential Reasoning Approach for Predicting Popularity of Instagram Posts  </p>

<p><strong>Authors:</strong>  </p>

<p>L. Rivadeneira, I. Loor  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1109/ACCESS.2024.3510637  </p>

<p><strong>Year:</strong>  </p>

<p>2024  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Social Media Analytics  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Predictive modelling of social media engagement using evidential reasoning  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper evaluates the MAKER (Maximum likelihood evidential reasoning) approach for predicting Instagram post popularity, using data from Harvard and Oxford’s official accounts. The focus is on achieving predictive accuracy while ensuring transparency and interpretability—key challenges for machine learning in social media analytics. The study addresses how features like emojis, sentiment, hashtags, mentions, seasons, image type, time of day, and dominant colour affect engagement.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>United States (Harvard University) and United Kingdom (University of Oxford).  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Social media managers, marketing teams, academic communication officers, influencers, and analytics researchers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative — predictive modelling with machine learning algorithms (MAKER, DT, SVM, KNN).  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Methodological framework and empirical validation.  </p>

<h2>General Summary of the Paper</h2>

<p>The study applies the MAKER algorithm, grounded in evidential reasoning, to predict the popularity of Instagram posts (binary classification: high/low based on median likes). Using 2022 data from Harvard and Oxford, two models are built for each institution—one using textual features (emojis, sentiment, hashtags, mentions, season) and the other using visual features (image type, time of day, dominant colour). MAKER is compared against decision trees, SVM, and KNN, achieving higher precision and interpretability. The paper not only evaluates predictive performance but also extracts actionable patterns, such as Harvard’s popular posts tending toward vibrant, scenic images in certain seasons, and Oxford’s benefiting from emoji use and specific content structures.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>Implicitly defined as the capacity of model outputs to guide content strategy decisions through transparent, interpretable insights that reveal which post attributes are most likely to increase engagement.  </p>

<blockquote>
  <p>“MAKER’s interpretability means that it provides actionable insights… help users make informed decisions based on its insights and improve content strategies by revealing which features most influence engagement.” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“While this study focuses on proposing a model for prediction purposes, it is essential to translate these findings into actionable strategies for decision-makers…” (p. 13)  </p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Ability to identify specific post attributes correlated with higher popularity.</p></li>
<li><p>Transparency in reasoning (weights, reliabilities, evidence interdependencies).</p></li>
<li><p>Interpretability enabling justification of model outputs.</p></li>
<li><p>Context-specific feature patterns rather than one-size-fits-all rules.</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> MAKER (Maximum likelihood evidential reasoning).  </p></li>
<li><p><strong>Methods/Levers:</strong> Integration of textual and visual post features into interpretable evidential reasoning models; optimisation of evidence weights and reliabilities.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Data collection → Preprocessing → Feature extraction (textual/visual) → Model training/testing (5-fold split) → MAKER optimisation → Comparative performance evaluation → Pattern extraction for actionable strategies.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Median likes threshold, emoji/hashtag/mention counts, sentiment, season, image type, dominant colour, time of day.  </p></li>
<li><p><strong>Implementation Context:</strong> Official university Instagram accounts.  </p></li>
</ul>

<blockquote>
  <p>“This transparency yields an interpretable model… examining the relationship between output and input variables, as well as the rationale behind the assignment of weights and reliabilities…” (p. 3)  </p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — outputs are interpretable and grounded in transparent parameter assignment.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — feature influence patterns are institution-specific.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — focuses on achievable content adjustments but omits resource constraints.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No explicit link.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — full traceability of decision process.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — aligns model with engagement improvement goals but not broader organisational KPIs.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Transparency, interpretability, data completeness handling.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Evidential reasoning (ER) rule, based on Dempster-Shafer theory.</p></li>
<li><p>Transparency and interpretability in AI (Rudin, 2019).</p></li>
<li><p>Multimodal content engagement theory from prior social media analytics research.</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Precision, recall, F1-score, AUC, RMSE (used to assess predictive reliability).</p></li>
<li><p>Likelihood scores for evidence patterns.</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> API restrictions limiting automated data collection; exclusion of non-picture post formats; limited engagement metrics; manual feature categorisation.  </p></li>
<li><p><strong>Enablers:</strong> MAKER’s robustness to incomplete data; integration of multimodal features; transparent modelling process.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Extends prior predictive models for Instagram by addressing interpretability and transparency gaps. Unlike black-box models (e.g., CNNs, fusion networks), MAKER enables actionable feature-level insights.</p>

<h2>Summary</h2>

<p>The paper demonstrates how MAKER—a maximum likelihood evidential reasoning approach—can deliver not only accurate predictions of Instagram post popularity but also actionable, interpretable insights for content strategy. By modelling both textual and visual features, and optimising evidence weights/reliabilities, the approach surfaces institution-specific patterns (e.g., seasonal effects, colour palettes, emoji usage) linked to higher engagement. Actionability here is tied to the transparency and contextual relevance of outputs, empowering decision-makers to adjust strategies based on identified drivers of popularity. Compared to decision trees, SVM, and KNN, MAKER offers superior precision and interpretability, making it a valuable tool for data-informed social media management.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 78 — Strong implicit definition of actionability and systematic feature linkages; slightly less emphasis on broader contextual constraints.  </p></li>
<li><p><strong>Operationalization Score:</strong> 85 — Clear step-by-step operational process tied directly to achieving actionability; validated through comparative performance and feature interpretation.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“MAKER’s interpretability means that it provides actionable insights… help users make informed decisions based on its insights…” (p. 1)  </p></li>
<li><p>“Transparency yields an interpretable model… examining the relationship between output and input variables…” (p. 3)  </p></li>
<li><p>“It is essential to translate these findings into actionable strategies for decision-makers…” (p. 13)  </p></li>
<li><p>“Harvard’s popular posts typically show positive or neutral sentiment… Oxford’s popular posts… use more emojis, hashtags, and mentions.” (p. 11)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Rudin, C. (2019) on interpretable models vs. black-box AI.  </p></li>
<li><p>Yang &amp; Xu (2017) on inferential modelling with data in evidential reasoning.  </p></li>
<li><p>Aramendia-Muneta et al. (2021) on key image attributes for engagement.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Enhancing Student Digital Skills: Adopting an Ecosystemic School Analytics Approach</p>

<p>Authors: Stylianos Sergis, Demetrios G. Sampson, Michail Giannakos</p>

<p>DOI: 10.1109/ICALT.2017.87</p>

<p>Year: 2017</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Educational Technology / Learning Analytics</p>

<p>Subdomain/Topic: School Analytics, Digital Skills, Educational Decision-Making</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 85</p>

<p>Operationalization Score: 80</p>

<p>Contains Definition of Actionability: Yes (implicit and explicit in decision-making framing)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Quantitative (fsQCA), Conceptual-empirical</p>

<p>Study Context: K-12 schools, cross-European dataset</p>

<p>Geographic/Institutional Context: Europe (2995 schools; EU Commission study)</p>

<p>Target Users/Stakeholders: School leaders, policymakers, educators</p>

<p>Primary Contribution Type: Methodological and empirical model for deriving actionable school improvement insights</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Partial</p>

<p>TI: No</p>

<p>EX: Yes</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: n/a</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Enhancing Student Digital Skills: Adopting an Ecosystemic School Analytics Approach</p>

<p><strong>Authors:</strong>  </p>

<p>Stylianos Sergis, Demetrios G. Sampson, Michail Giannakos</p>

<p><strong>DOI:</strong>  </p>

<p>10.1109/ICALT.2017.87</p>

<p><strong>Year:</strong>  </p>

<p>2017</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Educational Technology / Learning Analytics</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>School Analytics, Digital Skills, Educational Decision-Making</p>

<p><strong>Contextual Background:</strong>  </p>

<p>Focuses on enabling K-12 school leaders to use <em>School Analytics</em>—a layered, ecosystemic data framework—to identify, analyze, and act on factors influencing student learning outcomes, specifically digital skills. Targets leadership decision-making across micro (classroom), meso (staff practices), and macro (organizational) layers.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>European cross-national dataset from an EU Commission survey.</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>School leaders, educational policymakers, teacher professional development coordinators.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative (fsQCA), supported by conceptual framework building.</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Development and validation of a School Analytics ecosystemic factor model + demonstration of fsQCA for generating actionable school improvement strategies.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper introduces a School Analytics approach integrating an ecosystemic factor model with fuzzy-set Qualitative Comparative Analysis (fsQCA) to identify configurations of school-level conditions that foster high student digital skills. Drawing on a large European dataset (2995 schools, 7897 teachers, 42135 students), the authors validate their factor model and apply fsQCA to uncover eight distinct causal configurations linking school leadership attitudes, teacher practices, resources, and culture to digital skills outcomes. The results are positioned as <em>actionable insights</em> for school leaders, enabling targeted interventions tailored to the unique combination of factors present in their schools.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is conceptualized as <em>the translation of school ecosystem data into targeted, evidence-based interventions</em> that school leaders can implement to improve specific learning outcomes.</p>

<blockquote>
  <p>“[…] translate these analyses to specific remedying actions for targeted improvement” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“[…] inform leaders on the specific school areas to improve to meet their goal” (p. 2)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Derived from <strong>holistic, multi-layered data</strong> spanning micro, meso, and macro school levels.</p></li>
<li><p><strong>Configurable causality</strong>: recognition that multiple different factor combinations can lead to the same outcome.</p></li>
<li><p><strong>Alignment with desired goals</strong> (here: improving digital skills).</p></li>
<li><p>Clear identification of <strong>specific factor configurations</strong> present/absent that produce the target outcome.</p></li>
<li><p>Context-sensitive applicability—school-specific diagnosis.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> School Analytics Ecosystemic Factor Model + fsQCA-based decision support.</p></li>
<li><p><strong>Methods/Levers:</strong> Collect data across school layers; calibrate factors into fuzzy sets; run fsQCA to identify effective configurations; match school’s profile to these configurations to generate targeted recommendations.</p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Define factor model (macro, meso, micro).  </p>

<p> 2. Collect and validate data (survey-based, Likert-scale).  </p>

<p> 3. Calibrate into fuzzy sets.  </p>

<p> 4. Run fsQCA to extract configurations linked to high digital skills.  </p>

<p> 5. Interpret results for leadership decision-making.</p></li>
<li><p><strong>Data &amp; Measures:</strong> 4-point Likert survey items; principal attitudes, teacher practices, equipment, culture, pedagogy.</p></li>
<li><p><strong>Implementation Context:</strong> EU schools, ICT integration and digital skills development.</p></li>
</ul>

<blockquote>
  <p>“[…] outline which configurations of the factors… can explain high levels of students’ digital skills, and therefore inform leaders on the specific school areas to improve” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“[…] eight distinct configurations… lead to high students’ digital skills” (p. 4)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – model clearly identifies factor relationships and configurations.  </p>

<p> &gt; “[…] outline… specific school areas to improve” (p. 2)</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – configurations are context-specific to school ecosystem profiles.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial – feasibility is implied through practical applicability of identified configurations, but not empirically tested in implementation.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No explicit reference.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – causal configurations and underlying factors are transparent.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – directly tied to improving student digital skills.</p></li>
</ul>

<p><strong>Other Dimensions Named by Authors:</strong> Coverage and consistency metrics to assess robustness.</p>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>School Analytics conceptual framework (Sergis &amp; Sampson, 2016).  </p></li>
<li><p>Extensive Digital Competence (EDC) model.  </p></li>
<li><p>ICT Competence Profiling framework.  </p></li>
<li><p>Configurational theory via fsQCA (Ragin, 2000, 2008).</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>fsQCA coverage (analogous to R²).  </p></li>
<li><p>fsQCA consistency (adequacy of causal configuration).  </p></li>
<li><p>Reliability &amp; validity measures (Cronbach’s alpha, AVE).  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of integrated data systems; absence of certain enabling factors (e.g., ICT equipment, professional development).  </p></li>
<li><p><strong>Enablers:</strong> Strong leadership attitudes; positive teacher attitudes; supportive culture; sufficient ICT infrastructure.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions itself as moving beyond descriptive ICT adoption studies to <strong>prescriptive, configuration-based decision support</strong>. Builds on prior factor models (EDC, ICT competence profiling) but adds actionable output through fsQCA.</p>

<hr />

<h2>Summary</h2>

<p>This paper offers a robust, empirically validated method for converting multi-level school data into actionable leadership guidance. Actionability is framed as the ability to identify and implement targeted interventions based on the unique combination of school factors influencing digital skills. By applying fsQCA to a comprehensive school ecosystem model, the authors show that there are multiple pathways—each a distinct factor configuration—leading to the same high-level outcome. This configurational approach enhances explainability, ensures contextual relevance, and aligns directly with leadership goals, although feasibility and timeliness are less explicitly addressed. The study’s contribution is methodological (integrating School Analytics with fsQCA) and practical (generating actionable insights for policy and practice).</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 – Strong implicit definition of actionability tied to targeted decision-making; clear features and attributes linked to actionability; multi-layer contextual approach.  </p></li>
<li><p><strong>Operationalization Score:</strong> 80 – Provides a detailed process and tool (fsQCA) to derive actionable insights; operational workflow well described; lacks direct implementation evidence.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[…] translate these analyses to specific remedying actions for targeted improvement” (p. 1)  </p></li>
<li><p>“[…] outline which configurations… can explain high levels of students’ digital skills” (p. 2)  </p></li>
<li><p>“The fsQCA analysis revealed 8 distinct configurations… which can lead to high students’ digital skills” (p. 4)  </p></li>
<li><p>“[…] inform leaders on the specific school areas to improve to meet their goal” (p. 2)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Sergis &amp; Sampson (2016) – School Analytics framework.  </p></li>
<li><p>Aesaert et al. (2015) – EDC model.  </p></li>
<li><p>Ragin (2000, 2008) – fsQCA methodology.  </p></li>
<li><p>Pappas et al. (2016, 2015) – fsQCA applications in other domains.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Enhancing Enterprise Decisions through Organizational Data Mining</p>

<p>Authors: Hamid R. Nemati, Christopher D. Barko</p>

<p>DOI: 10.1080/08874417.2002.11647049</p>

<p>Year: 2002</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Information Systems / Data Mining</p>

<p>Subdomain/Topic: Organizational Data Mining (ODM), Decision Support, CRM</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 85</p>

<p>Operationalization Score: 80</p>

<p>Contains Definition of Actionability: Yes</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: No</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Mixed Methods (Conceptual framing + industry survey)</p>

<p>Study Context: Industry adoption of Organizational Data Mining across sectors</p>

<p>Geographic/Institutional Context: USA; University of North Carolina at Greensboro</p>

<p>Target Users/Stakeholders: Executives, decision-makers, analysts, CRM managers</p>

<p>Primary Contribution Type: Conceptual elaboration + empirical industry survey</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Partial</p>

<p>EX: Partial</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: n/a</p>

<!--META_END-->

<p><strong>Title:</strong> Enhancing Enterprise Decisions through Organizational Data Mining  </p>

<p><strong>Authors:</strong> Hamid R. Nemati, Christopher D. Barko  </p>

<p><strong>DOI:</strong> 10.1080/08874417.2002.11647049  </p>

<p><strong>Year:</strong> 2002  </p>

<p><strong>Publication Type:</strong> Journal  </p>

<p><strong>Discipline/Domain:</strong> Information Systems / Data Mining  </p>

<p><strong>Subdomain/Topic:</strong> Organizational Data Mining (ODM), Decision Support, CRM  </p>

<p><strong>Contextual Background:</strong> Focuses on how ODM transforms raw data into actionable knowledge to improve enterprise decision-making and gain competitive advantage; explores applications, techniques, adoption trends, and success factors.  </p>

<p><strong>Geographic/Institutional Context:</strong> USA; UNC Greensboro  </p>

<p><strong>Target Users/Stakeholders:</strong> Executives, analysts, CRM specialists, decision-makers in customer-centric organizations  </p>

<p><strong>Primary Methodology:</strong> Mixed methods (conceptual explanation + survey of 106 industry practitioners)  </p>

<p><strong>Primary Contribution Type:</strong> Conceptual framing of ODM + empirical industry findings  </p>

<h2>General Summary of the Paper</h2>

<p>This paper defines Organizational Data Mining (ODM) as the strategic use of data mining tools to transform data into actionable knowledge for enhanced decision-making and competitive advantage. It frames ODM within organizational knowledge management—linking sense-making, knowledge-making, and decision-making—and positions it as a critical enabler for timely, relevant, and informed choices. The authors present findings from a survey of 106 industry professionals, detailing current ODM applications, techniques, adoption trends, and critical success factors. They highlight CRM and customer intelligence as leading ODM application areas, with decision trees, clustering, and market-basket analysis being the most used techniques. The paper identifies barriers (e.g., underutilization of external data) and enablers (e.g., executive sponsorship, quality data preparation), concluding that ODM projects often exceed expectations and are poised for significant growth.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionability is understood as the transformation of data into “valuable actionable knowledge” that directly supports decision-making and creates a “strategic competitive advantage.” ODM aims to provide timely, relevant, and valuable insights that influence organizational choices.  </p>

<blockquote>
  <p>“Organizational Data Mining (ODM) is defined as leveraging data mining (DM) tools and technologies to enhance the decision-making process by transforming data into valuable actionable knowledge and a strategic competitive advantage.” (p. 21)  </p>
</blockquote>

<blockquote>
  <p>“ODM… enhances an organization’s ability to identify, analyze, and implement an optimal decision.” (p. 21)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Timeliness and relevance of information  </p></li>
<li><p>Value to decision-making (strategic advantage)  </p></li>
<li><p>Contextual fit to organizational goals and environment  </p></li>
<li><p>Clarity and interpretability for decision-makers  </p></li>
<li><p>Feasibility of implementation (supported by resources, technology, and processes)  </p></li>
<li><p>Derived from integrated sense-making, knowledge-making, and decision-making processes</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Organizational Data Mining (ODM) methodology (integrating sense-making, knowledge-making, decision-making)  </p></li>
<li><p><strong>Methods/Levers:</strong> CRM systems, customer intelligence tools, OLAP, market-basket analysis, clustering, decision trees, ANN, regression, data warehousing  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Data acquisition → data integration (internal + external) → analytical processing (ODM techniques) → insight generation → decision implementation  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Customer profiles, transaction data, demographic data, web clickstreams, financial metrics, behavioral models  </p></li>
<li><p><strong>Implementation Context:</strong> Cross-industry; especially banking, e-commerce, retail, healthcare  </p></li>
</ul>

<blockquote>
  <p>“Sense-making… Knowledge-making… Decision-making… are integrated in a cascade of information seeking that moves the organization… to the selection and implementation of a knowledgeable course of action.” (p. 21)  </p>
</blockquote>

<blockquote>
  <p>“The most critical factors… are garnering the sponsorship of an executive… and preparing the data for analysis.” (p. 25)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Information must be interpretable for decision-makers.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Insights must be relevant to organizational environment and goals.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Requires appropriate infrastructure and resources.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Mentioned as critical for competitive advantage but not fully elaborated.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — Techniques like decision trees aid interpretability; ANN less so.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Must support strategic competitive advantage.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Integration with organizational knowledge management processes.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Choo’s <em>Knowing Organization</em> model (sense-making, knowledge-making, decision-making)  </p></li>
<li><p>Knowledge management literature  </p></li>
<li><p>Decision support system theory</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>ROI via cost/benefit analysis  </p></li>
<li><p>Customer retention rates  </p></li>
<li><p>Profitability improvements  </p></li>
<li><p>Market share changes  </p></li>
<li><p>Project outcome vs. expectations</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Underutilization of external data, low data warehouse integration, insufficient knowledge infrastructure  </p></li>
<li><p><strong>Enablers:</strong> Executive sponsorship, quality data preparation, CRM integration, multiple ODM techniques, internal + external data combination</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>The paper builds on knowledge management theory and prior data mining studies but shifts emphasis to the organizational decision-making context. It reinforces the need for integrating technical and organizational perspectives to make insights actionable.</p>

<h2>Summary</h2>

<p>Nemati and Barko (2002) conceptualize ODM as the deliberate application of data mining within a knowledge management framework to transform raw data into actionable knowledge for enterprise decision-making. Actionability, in their framing, requires timeliness, contextual relevance, clarity, feasibility, and strategic alignment. They operationalize ODM through integrated processes—sense-making, knowledge-making, decision-making—and via specific tools like CRM, customer intelligence, and analytical models. Their industry survey confirms high satisfaction rates, growing adoption, and clear enablers such as executive sponsorship and high-quality data preparation. Barriers remain in data integration and external data use, but the authors foresee ODM’s expansion alongside CRM, personalization, and e-business strategies. This work is relevant for understanding actionability as both a conceptual goal and an operational practice in data-driven organizations.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 — Strong explicit definition of actionability, multiple systematically linked features; minor gaps in theoretical depth on timeliness/explainability.  </p></li>
<li><p><strong>Operationalization Score:</strong> 80 — Clear process and tools described; lacks fully formalized framework but provides concrete implementation levers.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“ODM… enhancing the decision-making process by transforming data into valuable actionable knowledge…” (p. 21)  </p></li>
<li><p>“Sense-making… Knowledge-making… Decision-making… integrated… to the selection and implementation of a knowledgeable course of action.” (p. 21)  </p></li>
<li><p>“The most critical factors… are garnering the sponsorship of an executive… and preparing the data for analysis.” (p. 25)  </p></li>
<li><p>“Underutilization of… external data… presents an opportunity to improve the quality, consistency, and robustness of data for projects.” (p. 26)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Choo, C.W. <em>The Knowing Organization</em>  </p></li>
<li><p>Groth, R. <em>Data Mining: A Hands-on Approach for Business Professionals</em>  </p></li>
<li><p>Banasiewicz, A.D. (2000) “Keeping Your Best Customers Through Brand Loyalty”</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Efficient Action Extraction with Many-to-Many Relationship between Actions and Features</p>

<p>Authors: Jianfeng Du, Yong Hu, Charles X. Ling, Ming Fan, Mei Liu</p>

<p>DOI: N/A</p>

<p>Year: 2011</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Computer Science / Artificial Intelligence</p>

<p>Subdomain/Topic: Actionable Knowledge Discovery, Cost-Minimal Action Set Extraction</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 82</p>

<p>Operationalization Score: 90</p>

<p>Contains Definition of Actionability: Yes (implicit)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual + Experimental</p>

<p>Study Context: Software project risk management</p>

<p>Geographic/Institutional Context: China, Canada, USA</p>

<p>Target Users/Stakeholders: Decision-makers in business/risk management</p>

<p>Primary Contribution Type: Methodological innovation for efficient extraction of actionable knowledge</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: No</p>

<p>EX: No</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Efficient Action Extraction with Many-to-Many Relationship between Actions and Features  </p>

<p><strong>Authors:</strong>  </p>

<p>Jianfeng Du, Yong Hu, Charles X. Ling, Ming Fan, Mei Liu  </p>

<p><strong>DOI:</strong>  </p>

<p>N/A  </p>

<p><strong>Year:</strong>  </p>

<p>2011  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Artificial Intelligence  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Actionable Knowledge Discovery, Cost-Minimal Action Set Extraction  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the gap in actionable knowledge discovery methods that typically assume a one-to-one relationship between actions and features. The authors target real-world decision-making scenarios—especially those involving complex, many-to-many relationships—by proposing a method to extract cost-minimal action sets from classifiers.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>China, Canada, USA (authors’ affiliations)  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Business decision-makers, software risk managers, data mining practitioners  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework with algorithmic design and experimental evaluation  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Methodological approach for efficiently extracting cost-minimal, actionable strategies from classifiers (specifically random forests)  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper proposes a method for extracting actionable knowledge—specifically, cost-minimal action sets—from classifiers when actions and features have many-to-many relationships. Unlike prior approaches that restrict action-feature mapping to one-to-one correspondences, the authors’ method models realistic situations where actions affect multiple features and features are influenced by multiple actions. They encode both the classification process and the action execution process as rules, converting the problem into a Linear Pseudo-Boolean Optimization problem, solvable via existing pseudo-Boolean solvers. Applied to software project risk management, the method efficiently identifies minimal-cost interventions to reach a preferred classification outcome. Experimental results show substantial speed and scalability improvements over generate-and-test methods.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is understood as the capacity to identify and apply a set of actions that transforms an instance’s state into a preferred state, as determined by a classifier, while minimizing execution cost.  </p>

<blockquote>
  <p>“Actions… render a state of an instance into a preferred state, where a state is represented by feature values… preferred… determined by a classifier.” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“A preferred action set… is a set of actions that render the state of the instance into a preferred state…” (p. 1)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Ability to transform a current state into a preferred state according to a classifier  </p></li>
<li><p>Consideration of execution cost (minimization)  </p></li>
<li><p>Accommodation of many-to-many action-feature relationships  </p></li>
<li><p>Contextual applicability to real-world problems (e.g., risk mitigation)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Cost-minimal action set extraction via Linear Pseudo-Boolean Optimization  </p></li>
<li><p><strong>Methods/Levers:</strong> Encode classifier and action execution as rules; transform into SAT and pseudo-Boolean optimization  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Encode classification and action execution rules  </p>

<p> 2. Formulate as a Linear Pseudo-Boolean Optimization problem  </p>

<p> 3. Use pseudo-Boolean solvers to find minimal-cost action set  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Costs associated with each action; preferred class output by classifier  </p></li>
<li><p><strong>Implementation Context:</strong> Demonstrated with random forest in software project risk management  </p></li>
</ul>

<blockquote>
  <p>“…propose an efficient method to extract a cost-minimal action set from a classifier… based on… SAT techniques…” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“…reduction… to an extended SAT problem, called Linear Pseudo-Boolean Optimization problem…” (p. 2)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Actions and states must be explicitly representable via features and rules  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Problem framed in real-world decision contexts like risk management  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Feasibility framed in terms of execution cost minimization  </p></li>
<li><p><strong>TI (Timeliness):</strong> No — Not explicitly discussed  </p></li>
<li><p><strong>EX (Explainability):</strong> No — No emphasis on model or action explainability  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Goal defined as reaching a preferred classification outcome at minimal cost  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Scalability, efficiency  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Domain-driven actionable knowledge discovery (Cao et al., 2007)  </p></li>
<li><p>Action extraction from decision trees (Yang et al., 2007)  </p></li>
<li><p>Random forest classification (Breiman, 2001)  </p></li>
<li><p>Pseudo-Boolean optimization (Manquinho &amp; Roussel, 2006)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Minimal total execution cost of actions  </p></li>
<li><p>Achievement of preferred classification outcome  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Inefficiency of generate-and-test methods with large action sets  </p>

<p> - Complexity of many-to-many action-feature relationships  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Encoding into SAT/optimization frameworks  </p>

<p> - Use of pseudo-Boolean solvers for scalability  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Extends prior actionable knowledge discovery research by removing the one-to-one restriction between actions and features, improving applicability to real-world problems. Builds on decision-tree-based action extraction, adapting it to random forests and optimization contexts.</p>

<hr />

<h2>Summary</h2>

<p>The paper introduces a method for efficiently extracting cost-minimal action sets from classifiers when actions and features interact in a many-to-many manner. Actionability is defined implicitly as the ability to transition an instance from its current state to a preferred state, as determined by a classifier, with minimal execution cost. The authors operationalize this through a rule-based encoding of both classification and action execution processes, reformulated as a Linear Pseudo-Boolean Optimization problem. Applied to software project risk management, the approach outperforms traditional generate-and-test methods by orders of magnitude in efficiency and scalability. The work makes a significant contribution by aligning computational efficiency with practical constraints of real-world decision-making.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 82 — Strong implicit definition and identification of key features (cost minimization, transformation to preferred state), though lacking timeliness and explainability dimensions.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Highly detailed and computationally implementable method with explicit steps and tested application.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Actions… render a state of an instance into a preferred state…” (p. 1)  </p></li>
<li><p>“A preferred action set… is a set of actions that render the state… into a preferred state…” (p. 1)  </p></li>
<li><p>“…propose an efficient method to extract a cost-minimal action set from a classifier…” (p. 2)  </p></li>
<li><p>“…reduction… to an extended SAT problem, called Linear Pseudo-Boolean Optimization problem…” (p. 2)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Cao et al., 2007 — Domain-driven actionable knowledge discovery  </p></li>
<li><p>Yang et al., 2007 — Action extraction from decision trees  </p></li>
<li><p>Breiman, 2001 — Random forests  </p></li>
<li><p>Manquinho &amp; Roussel, 2006 — Pseudo-Boolean solvers</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Efficacy of molecularly targeted agents given in the randomised trial SHIVA01 according to the ESMO Scale for Clinical Actionability of molecular Targets  </p>

<p>Authors: A. Moreira, J. Masliah-Planchon, C. Callens, S. Vacher, C. Lecerf, M. Frelaut, E. Borcoman, N. Torossian, F. Ricci, S. Hescot, M.P. Sablin, P. Tresca, D. Loirat, S. Melaabi, O. Trabelsi-Grati, G. Pierron, D. Gentien, V. Bernard, A. Vincent Salomon, N. Servant, I. Bieche, C. Le Tourneau, M. Kamal  </p>

<p>DOI: https://doi.org/10.1016/j.ejca.2019.09.001  </p>

<p>Year: 2019  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Oncology / Precision Medicine  </p>

<p>Subdomain/Topic: Clinical actionability, molecularly targeted agents, ESCAT scale, SHIVA01 trial  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 75  </p>

<p>Operationalization Score: 70  </p>

<p>Contains Definition of Actionability: Yes (explicit via ESCAT framework)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (ESCAT)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Quantitative (retrospective analysis of trial data)  </p>

<p>Study Context: Retrospective classification of molecular alterations from SHIVA01 trial according to ESCAT and correlation with clinical outcomes (PFS, OS)  </p>

<p>Geographic/Institutional Context: Institut Curie, France  </p>

<p>Target Users/Stakeholders: Clinical oncologists, precision medicine researchers, trial designers  </p>

<p>Primary Contribution Type: Empirical evaluation of actionability framework (ESCAT) applied to existing trial data  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: No  </p>

<p>EX: Partial  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Efficacy of molecularly targeted agents given in the randomised trial SHIVA01 according to the ESMO Scale for Clinical Actionability of molecular Targets</p>

<p><strong>Authors:</strong>  </p>

<p>A. Moreira et al.</p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1016/j.ejca.2019.09.001</p>

<p><strong>Year:</strong>  </p>

<p>2019</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Oncology / Precision Medicine</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Clinical actionability, molecularly targeted agents, ESCAT scale, SHIVA01 trial</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper re-evaluates the SHIVA01 precision medicine trial by applying the European Society for Medical Oncology’s Scale for Clinical Actionability of molecular Targets (ESCAT) to classify molecular alterations (MAs) that guided treatment allocation. This retrospective classification aims to understand how actionability levels correlate with clinical outcomes.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Institut Curie, France</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Oncologists, trial designers, policy-makers in precision oncology</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative retrospective analysis</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical reassessment of trial outcomes through an actionability framework</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The SHIVA01 trial compared molecularly targeted agents (MTAs) selected by a treatment algorithm based on tumour molecular profiling versus conventional therapy in patients with refractory metastatic solid tumours. It found no significant PFS benefit. This study retrospectively classifies MAs from SHIVA01 according to ESCAT tiers, which grade the strength of evidence linking MAs to drug efficacy. Most MAs were tier IIIA (efficacy shown in other tumour types). Worst OS was observed for tier IIIB (alterations of a different type in known actionable genes). The analysis highlights the importance of precise alteration type and evidence strength in predicting treatment benefit.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is explicitly framed through ESCAT as the degree of clinical evidence supporting the use of a targeted therapy for a given molecular alteration in a specific cancer type, graded from tier I (highest) to V (no benefit).  </p>

<blockquote>
  <p>“ESCAT… defined criteria to prioritise molecular alterations (MAs) to select anticancer drugs.” (p. 202)  </p>
</blockquote>

<blockquote>
  <p>“We… classified [MAs] according to the ESCAT by assessing the level of evidence in the literature.” (p. 203)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Supported by clinical trial evidence in the same tumour type (higher ESCAT tier)  </p></li>
<li><p>Type of alteration must match that shown to confer benefit (mutation vs amplification)  </p></li>
<li><p>Evidence from other tumour types (lower tier) less predictive  </p></li>
<li><p>Preclinical or in silico evidence can guide classification when clinical data is lacking  </p></li>
<li><p>Drug-target affinity and specificity influence actionability beyond ESCAT tier  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> ESMO Scale for Clinical Actionability of molecular Targets (ESCAT)  </p></li>
<li><p><strong>Methods/Levers:</strong> Literature review for evidence of benefit of MA-targeted MTA  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify MA → Search same-cancer evidence → If absent, search cross-cancer evidence → If absent, preclinical/in silico data → Assign ESCAT tier  </p></li>
<li><p><strong>Data &amp; Measures:</strong> PFS, OS, ESCAT tier classification, patient demographics  </p></li>
<li><p><strong>Implementation Context:</strong> Retrospective re-analysis of SHIVA01 patient data  </p></li>
</ul>

<blockquote>
  <p>“For each MA, we… searched for clinical trials… in the same tumour type… then… other tumour types… then… preclinical and in silico data… Classified as tier V if no clinically meaningful benefit was reported.” (p. 203)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — ESCAT tiers are explicitly defined and applied  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Same vs other tumour type evidence distinguishes tiers  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Relates to whether drugs are usable in context based on evidence strength  </p></li>
<li><p><strong>TI (Timeliness):</strong> No — Not addressed directly  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — ESCAT rationale is given, but biological mechanisms less discussed  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — Implicit alignment with precision oncology goals  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Type of alteration specificity, drug-target affinity</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>ESCAT framework (Mateo et al., 2018)  </p></li>
<li><p>Prior actionability scales (OncoKB, AMP/ASCO/CAP guidelines)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>ESCAT tier assignment (I–V)  </p></li>
<li><p>Clinical endpoints: PFS, OS stratified by tier  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Low ESCAT tier prevalence, misclassification of alteration type, lack of tumour-type-specific data, coexisting resistance mutations, variability in literature interpretation  </p></li>
<li><p><strong>Enablers:</strong> In vitro/in vivo functional validation, drug specificity, comprehensive molecular profiling</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions ESCAT as the latest in a series of actionability frameworks and demonstrates its application to re-interpret trial results. Highlights need to refine trial algorithms with higher-tier MAs.</p>

<hr />

<h2>Summary</h2>

<p>This paper retrospectively applies the ESCAT actionability framework to the SHIVA01 trial, showing that most targeted therapies were based on alterations with low or indirect evidence (tier IIIA). The poorest OS was linked to tier IIIB cases, underscoring the critical role of precise alteration type and tumour-specific evidence in achieving clinical benefit. The work operationalizes actionability by systematically classifying MAs through literature evidence levels, providing a model for refining precision oncology trial design.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 75 — Strong conceptual clarity through ESCAT, explicit linkage of features to actionability  </p></li>
<li><p><strong>Operationalization Score:</strong> 70 — Detailed process for applying ESCAT tiers; however, not a prospective operationalization</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[ESCAT] defined criteria to prioritise molecular alterations (MAs) to select anticancer drugs.” (p. 202)  </p></li>
<li><p>“Most MAs… were shown to improve outcomes in other tumour types (tier IIIA). Worst outcome… in tier IIIB…” (p. 206)  </p></li>
<li><p>“For each MA, we… searched for clinical trials… in the same tumour type… other tumour types… preclinical and in silico data…” (p. 203)  </p></li>
<li><p>“This highlights the crucial importance of the type of alteration beyond the gene and/or signalling pathway itself.” (p. 207)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Mateo J et al., 2018 — ESCAT  </p></li>
<li><p>Chakravarty D et al., 2017 — OncoKB  </p></li>
<li><p>Li MM et al., 2017 — AMP/ASCO/CAP guidelines  </p></li>
<li><p>Meric-Bernstam F et al., 2015 — Decision support framework</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Dissecting Generalizability and Actionability of Disease-Associated Genes From 20 Worldwide Ethnolinguistic Cultural Groups  </p>

<p>Authors: Emile R. Chimusa, Shatha Alosaimi, Christian D. Bope  </p>

<p>DOI: 10.3389/fgene.2022.835713  </p>

<p>Year: 2022  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Genetics / Genomic Medicine  </p>

<p>Subdomain/Topic: Clinical actionability of disease-associated genes, population genomics, genetic diversity  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 85  </p>

<p>Contains Definition of Actionability: Yes (explicit and comparative definitions)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (comparative genomic analysis framework)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Quantitative (Population genetics analysis using WGS/WES data)  </p>

<p>Study Context: Genetic diversity and actionability of disease-associated genes across 20 ethnolinguistic cultural groups worldwide  </p>

<p>Geographic/Institutional Context: Global, with emphasis on African populations (Bantu, Khoesan) and comparative groups from other continents  </p>

<p>Target Users/Stakeholders: Genomic researchers, clinical geneticists, public health practitioners, policy makers in precision medicine  </p>

<p>Primary Contribution Type: Empirical study with conceptual framing  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Dissecting Generalizability and Actionability of Disease-Associated Genes From 20 Worldwide Ethnolinguistic Cultural Groups  </p>

<p><strong>Authors:</strong>  </p>

<p>Emile R. Chimusa, Shatha Alosaimi, Christian D. Bope  </p>

<p><strong>DOI:</strong>  </p>

<p>10.3389/fgene.2022.835713  </p>

<p><strong>Year:</strong>  </p>

<p>2022  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Genetics / Genomic Medicine  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Clinical actionability of disease-associated genes, population genomics, genetic diversity  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The study evaluates whether “actionable” genes identified by the American College of Medical Genetics and Genomics (ACMG) and known disease-associated genes for four high-burden African diseases (HIV/AIDS, tuberculosis, malaria, sickle cell disease) are equally applicable (“generalizable”) across 20 global ethnolinguistic cultural groups.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Global genomic datasets, particularly African Genome Variation Project and 1000 Genomes Project; strong focus on African populations (Bantu, Khoesan)  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Genomic researchers, clinical geneticists, healthcare policymakers, precision medicine initiatives  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative population genomics analysis using large-scale whole-exome/whole-genome sequencing  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical genomic analysis with conceptual framing on actionability and generalizability  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper investigates the distribution and clinical actionability of disease-associated genetic variants across 20 worldwide ethnolinguistic cultural groups, emphasizing African populations. Using WGS/WES data from the African Genome Variation Project and 1000 Genomes Project, the authors analyze SNP frequencies, proportions of pathogenic variants, derived allele distributions, and heterozygosity in genes linked to HIV/AIDS, TB, malaria, sickle cell disease, and ACMG-designated actionable genes. They find that African groups—particularly Bantu and Khoesan—display the highest genetic diversity but that many ACMG actionable genes have low derived allele proportions in African populations, raising concerns about the transferability of current actionable gene lists. The study advocates for population-specific actionable gene lists to improve equity in genomic medicine.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is framed through multiple authoritative definitions:  </p>

<ul>
<li><p>ClinGen: clinically prescribed interventions effective for prevention, reduced clinical burden, delayed onset, or improved outcomes in undiagnosed adults.  </p></li>
<li><p>100,000 Genomes Project: variants that, if identified pre-symptomatically, can significantly prevent or mitigate severe, life-threatening, and clinically significant diseases.  </p></li>
<li><p>Also operationally tied to classification processes involving ethical approval, annotation databases, pathogenicity scoring, and allele frequency considerations.  </p></li>
</ul>

<blockquote>
  <p>“Actionability as clinically prescribed interventions to a genetic disorder that is effective for prevention, lowered clinical burden or delay for a clinical disease, or improved clinical treatments and outcomes…” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“…variants that can significantly prevent (or result in illness…if identified before symptoms become apparent.” (p. 2)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Clinically preventable or mitigable before symptom onset  </p></li>
<li><p>Severity and clinical significance of condition  </p></li>
<li><p>Established interventions exist with proven benefit  </p></li>
<li><p>Variant classification supported by evidence and ethical review  </p></li>
<li><p>Population-specific allele frequency and pathogenicity evidence  </p></li>
<li><p>Functional impact predictions from multiple annotation tools  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Comparative population genomics actionability assessment  </p></li>
<li><p><strong>Methods/Levers:</strong> Joint variant calling across global ethnolinguistic groups; functional annotation via ANNOVAR; filtering by deleteriousness consensus (≥17/21 prediction tools)  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Identify disease-associated and ACMG actionable genes from curated databases (GWAS Catalog, DisGeNET, ACMG list)  </p>

<p> 2. Extract relevant SNPs from WGS/WES datasets  </p>

<p> 3. Perform quality control, phasing, and haplotype inference  </p>

<p> 4. Analyze genetic structure (PCA), pathogenicity proportions, derived allele frequencies, MAF distributions  </p>

<p> 5. Compare patterns across 20 ethnolinguistic groups  </p></li>
<li><p><strong>Data &amp; Measures:</strong> SNP counts, proportion pathogenic, derived allele proportion, heterozygosity metrics  </p></li>
<li><p><strong>Implementation Context:</strong> Global, cross-population genomic comparatives  </p></li>
</ul>

<blockquote>
  <p>“…combine many annotation pipelines during filtering and prioritization of mutations…” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“…proportion of pathogenic variants within ACG-specific genes from ethnolinguistic cultural groups…” (p. 4)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — clear variant classification processes are necessary (p. 2)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — population-specific allele frequency and disease relevance critical (p. 6–8)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — intervention must be possible and effective (p. 2)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — early/pre-symptomatic detection mentioned but not deeply operationalized  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — reliance on multiple annotation tools and known pathogenicity databases (p. 2, 9)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — alignment with improved global healthcare equity and personalized medicine (p. 1, 8)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Transferability/generalizability, genetic diversity, pathogenicity burden  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>ClinGen actionability framework  </p></li>
<li><p>100,000 Genomes Project protocol  </p></li>
<li><p>ACMG actionable gene list standards  </p></li>
<li><p>Population genomics concepts of genetic diversity, derived allele frequencies, linkage disequilibrium  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Proportion of pathogenic variants per gene in a population  </p></li>
<li><p>Minor allele frequency (MAF) distributions  </p></li>
<li><p>Proportion of derived alleles  </p></li>
<li><p>Gene-specificity of SNP frequency  </p></li>
<li><p>Observed vs. expected heterozygosity  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Limited transferability of ACMG actionable gene lists to African populations  </p>

<p> - Knowledge bias in existing variant databases toward non-African populations  </p>

<p> - Variation in derived allele distributions affecting predictive validity  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - High-quality population-specific genomic data  </p>

<p> - Multi-tool annotation consensus  </p>

<p> - Cross-population comparative frameworks  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on prior work highlighting disparities in actionable variant frequencies between European and African populations (e.g., Dorschner et al. 2016; Amendola et al. 2015). Expands by integrating multi-continental ethnolinguistic perspectives and four African high-burden diseases.</p>

<hr />

<h2>Summary</h2>

<p>The study critically assesses the global generalizability of ACMG’s actionable gene list and known disease-associated genes for HIV/AIDS, TB, malaria, and sickle cell disease. It reveals that African populations, particularly Bantu and Khoesan, have the highest genetic diversity but often lower derived allele proportions in ACMG actionable genes, challenging the transferability of current lists. Actionability is framed as dependent on clinical preventability, disease severity, intervention feasibility, population relevance, and robust pathogenicity evidence. Operationalization involves large-scale genomic data integration, multi-tool variant annotation, and cross-population analysis of pathogenic burden, allele frequencies, and genetic diversity. The findings argue for population-specific actionable gene lists to improve equity in precision medicine.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 — strong explicit and implicit conceptual framing, comparative definitions, and systematic features tied to actionability.  </p></li>
<li><p><strong>Operationalization Score:</strong> 85 — detailed methodology linking genetic metrics to actionability, though some dimensions (e.g., timeliness) less fully developed.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Actionability as clinically prescribed interventions… effective for prevention, lowered clinical burden…” (p. 2)  </p></li>
<li><p>“…classification of variants to be clinically actionable… can only emerge during the process of seeking ethical approval…” (p. 2)  </p></li>
<li><p>“…high genetic diversity in the present actionable and known disease-associated genes… suggesting the limitation of transferability…” (p. 1)  </p></li>
<li><p>“…combine many annotation pipelines during filtering and prioritization…” (p. 2)  </p></li>
<li><p>“…proportion of pathogenic variants within ACG-specific genes…” (p. 4)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Hunter et al., 2016 — ClinGen actionability assessment protocol  </p></li>
<li><p>Bope et al., 2019 — in silico mutation prediction challenges in African genomes  </p></li>
<li><p>Dorschner et al., 2016; Amendola et al., 2015 — disparities in actionable variants between populations  </p></li>
<li><p>ACMG-73 actionable genes list</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Development of the Patient Education Materials Assessment Tool (PEMAT): A new measure of understandability and actionability for print and audiovisual patient information</p>

<p>Authors: Sarah J. Shoemaker, Michael S. Wolf, Cindy Brach</p>

<p>DOI: 10.1016/j.pec.2014.05.027</p>

<p>Year: 2014</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Health Communication / Health Literacy</p>

<p>Subdomain/Topic: Patient education materials evaluation</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 95</p>

<p>Operationalization Score: 90</p>

<p>Contains Definition of Actionability: Yes</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Instrument development and validation (Mixed Methods)</p>

<p>Study Context: Development of an assessment tool for evaluating understandability and actionability of patient education materials</p>

<p>Geographic/Institutional Context: USA (multi-institutional, including Abt Associates, Northwestern University, and AHRQ)</p>

<p>Target Users/Stakeholders: Health professionals, patient educators, lay users, policymakers</p>

<p>Primary Contribution Type: Measurement instrument (PEMAT)</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: No</p>

<p>EX: Partial</p>

<p>GA: No</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Development of the Patient Education Materials Assessment Tool (PEMAT): A new measure of understandability and actionability for print and audiovisual patient information  </p>

<p><strong>Authors:</strong>  </p>

<p>Sarah J. Shoemaker, Michael S. Wolf, Cindy Brach  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1016/j.pec.2014.05.027  </p>

<p><strong>Year:</strong>  </p>

<p>2014  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Health Communication / Health Literacy  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Patient education materials evaluation  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The study responds to the U.S. National Action Plan to Improve Health Literacy, which calls for health and safety information to be “accurate, accessible, and actionable.” Many existing assessment tools fail to address “actionability,” have limited reliability, or only apply to print materials. This research develops and validates a tool usable by lay and professional audiences for both print and audiovisual materials.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>USA; collaboration among Abt Associates, Northwestern University, and AHRQ  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Health professionals, patient educators, clinicians, medical librarians, lay assessors, policymakers  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Instrument development and validation (Mixed Methods — expert panel review, reliability testing, consumer testing, readability comparison)  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Measurement instrument (PEMAT)  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper presents the development and validation of the Patient Education Materials Assessment Tool (PEMAT), designed to evaluate the understandability and actionability of both printable and audiovisual patient education materials. Guided by a multidisciplinary expert panel, the study compiled items from existing instruments, refined them through four rounds of inter-rater reliability testing, and established construct validity via consumer testing and readability comparisons. The PEMAT includes two scales—understandability (19 items) and actionability (7 items)—with separate versions for print and audiovisual formats. Results show strong internal consistency, moderate-to-strong inter-rater agreement, and significant correlations between PEMAT actionability scores and consumer comprehension. The tool is user-friendly, requires no training, and supports the National Action Plan’s goal of making health information accurate, accessible, and actionable.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is defined as the extent to which patient education materials enable consumers “to identify what they can do based on the information presented,” regardless of diverse backgrounds or health literacy levels.  </p>

<blockquote>
  <p>“Patient education materials are actionable when consumers … can identify what they can do based on the information presented.” (p. 396)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Clearly identifies at least one specific action the user can take.  </p></li>
<li><p>Addresses the user directly when describing actions.  </p></li>
<li><p>Breaks down actions into manageable, explicit steps.  </p></li>
<li><p>Provides tangible tools (e.g., checklists, planners).  </p></li>
<li><p>Offers simple calculation instructions where relevant.  </p></li>
<li><p>Explains how to use visual or data elements to take action.  </p></li>
<li><p>Uses visual aids to facilitate acting on instructions.</p></li>
</ul>

<hr />

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Patient Education Materials Assessment Tool (PEMAT)  </p></li>
<li><p><strong>Methods/Levers:</strong> Expert panel review, iterative reliability testing, untrained rater usability, consumer comprehension and numeric rating comparisons, readability analysis.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Rate each material against defined PEMAT items (scales for understandability and actionability).  </p>

<p> 2. Calculate percentage score per scale (excluding N/A items).  </p>

<p> 3. Compare against a threshold (≥70% considered actionable).  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Inter-rater reliability (kappa, Gwet’s AC1), Cronbach’s alpha, consumer comprehension scores, numeric ease-of-use ratings, readability grade levels.  </p></li>
<li><p><strong>Implementation Context:</strong> Designed for use by both professionals and laypersons without training, applicable to print and audiovisual materials.  </p></li>
</ul>

<blockquote>
  <p>“The material clearly identifies at least one action the user can take.” (p. 398)  </p>
</blockquote>

<blockquote>
  <p>“The material breaks down any action into manageable, explicit steps.” (p. 398)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — common language, active voice, visual cues.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — aligns instructions with user needs and capacities.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — explicit steps, tangible tools, manageable instructions.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No explicit link.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — explains use of visuals and data for action.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> No explicit link.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Use of visual aids to facilitate action.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>U.S. National Action Plan to Improve Health Literacy (accuracy, accessibility, actionability).  </p></li>
<li><p>Health literacy frameworks recognizing both individual skills and systemic demands.  </p></li>
<li><p>Prior patient education material suitability and comprehension assessment tools.</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>PEMAT actionability score (0–100 scale).  </p></li>
<li><p>Threshold of ≥70% considered actionable (provisional, not empirically fixed).  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Use of jargon/medical terms without definition; lack of captions for visuals; complex instructions; absence of actionable steps.  </p></li>
<li><p><strong>Enablers:</strong> Clear visual aids with captions; direct user address; provision of tools and checklists; breaking actions into steps.  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The PEMAT addresses gaps in prior instruments by:  </p>

<ol>
<li><p>Measuring actionability explicitly.  </p></li>
<li><p>Validating with untrained raters and consumers.  </p></li>
<li><p>Applying to both print and audiovisual materials.  </p></li>
<li><p>Demonstrating psychometric robustness (internal and external consistency).  </p></li>
</ol>

<hr />

<h2>Summary</h2>

<p>Shoemaker et al. (2014) advance the field of health literacy by developing the PEMAT, the first rigorously validated instrument to assess both understandability and actionability of patient education materials across print and audiovisual formats. Actionability is defined as enabling users to identify concrete actions from presented information. The PEMAT operationalizes actionability through seven explicit, observable criteria (e.g., clear actions, explicit steps, tangible tools). Validation involved expert panel review, iterative reliability testing with untrained raters, consumer testing, and readability comparisons. Findings show strong internal consistency and significant correlations between actionability scores and consumer comprehension. The tool’s ease of use, lack of training requirements, and applicability to multiple media formats make it practical for widespread adoption in health communication and patient education.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Clear, explicit definition of actionability, robust conceptual framing, detailed actionable features.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Detailed operational steps, scoring system, and validated use cases; threshold provisional.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Patient education materials are actionable when consumers … can identify what they can do based on the information presented.” (p. 396)  </p></li>
<li><p>“The material clearly identifies at least one action the user can take.” (p. 398)  </p></li>
<li><p>“The material breaks down any action into manageable, explicit steps.” (p. 398)  </p></li>
<li><p>“The material provides a tangible tool (e.g., menu planners, checklists) whenever it could help the user take action.” (p. 398)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>U.S. Department of Health and Human Services. National Action Plan to Improve Health Literacy (2010).  </p></li>
<li><p>Kaphingst et al. (2012) — Health Literacy INDEX.  </p></li>
<li><p>CDC Clear Communication Index (2013).</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Development of actionable quality indicators and an action implementation toolbox for appropriate antibiotic use at intensive care units: A modified-RAND Delphi study  </p>

<p>Authors: Marlot C. Kallen, Marie-Jose Roos-Blom, Dave A. Dongelmans, Jeroen A. Schouten, Wouter T. Gude, Evert de Jonge, Jan M. Prins, Nicolette F. de Keizer  </p>

<p>DOI: https://doi.org/10.1371/journal.pone.0207991  </p>

<p>Year: 2018  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Medical Informatics / Intensive Care Medicine  </p>

<p>Subdomain/Topic: Antibiotic stewardship, quality indicators, ICU performance improvement  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 92  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: No  </p>

<p>Contains Framework/Model: Yes (modified-RAND Delphi, Flottorp et al. checklist)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Mixed Methods (systematic literature review + expert consensus + framework-based implementation)  </p>

<p>Study Context: Adult ICU antibiotic use quality measurement and improvement  </p>

<p>Geographic/Institutional Context: Netherlands, multicenter ICU context  </p>

<p>Target Users/Stakeholders: ICU clinicians, microbiologists, pharmacists, stewardship teams, policy makers  </p>

<p>Primary Contribution Type: Development of actionable quality indicators + implementation toolbox  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Partial  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Development of actionable quality indicators and an action implementation toolbox for appropriate antibiotic use at intensive care units: A modified-RAND Delphi study  </p>

<p><strong>Authors:</strong>  </p>

<p>Marlot C. Kallen, Marie-Jose Roos-Blom, Dave A. Dongelmans, Jeroen A. Schouten, Wouter T. Gude, Evert de Jonge, Jan M. Prins, Nicolette F. de Keizer  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1371/journal.pone.0207991  </p>

<p><strong>Year:</strong>  </p>

<p>2018  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Medical Informatics / Intensive Care Medicine  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Antibiotic stewardship, ICU quality improvement, actionable indicators  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the challenge of inappropriate antibiotic use in intensive care units (ICUs), a driver of antimicrobial resistance. It focuses on creating measurable, actionable quality indicators (QIs) and a practical toolbox to help ICUs identify and overcome barriers to appropriate antibiotic use. The intended users are ICU healthcare professionals and stewardship teams seeking targeted, evidence-based quality improvement.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Netherlands, involving 15 Dutch ICU experts across university and non-university hospitals.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>ICU physicians, clinical microbiologists, pharmacists, infection control teams, policy makers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed Methods — modified-RAND Delphi consensus with systematic literature review, guideline extraction, and barrier-strategy mapping using Flottorp et al.’s checklist.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework and tool development (quality indicators + action implementation toolbox).  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This study develops a set of four actionable quality indicators (QIs) and one quantity metric to guide and improve appropriate antibiotic use in adult ICUs. Using a four-round modified-RAND Delphi procedure with 15 multidisciplinary Dutch ICU experts, potential QIs were identified through expert input, literature, and guideline reviews. Indicators were rated for relevance, actionability, and feasibility, refined through consensus meetings, and operationalized with definitions, targets, and measurement methods. The final set includes three process indicators, one structure indicator, and a quantity metric. The authors also created an “action implementation toolbox” listing 24 barriers and 37 improvement strategies, organized into four categories, with some supported by materials (e.g., posters). This toolbox supports tailored interventions based on local barriers. The framework emphasizes electronic health record (EHR) data feasibility and integration into the Dutch NICE registry for benchmarking.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is explicitly defined as an indicator offering <strong>clear direction to improve performance in daily practice</strong>, contributing directly to the success of quality improvement initiatives.</p>

<blockquote>
  <p>“Actionability, meaning that the indicator offers clear direction to improve performance in daily practice, specifically contributes to the success of quality improvement” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“Indicators with a median score… on actionability were defined as potentially suitable” (p. 3)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Relevance to patient outcomes or healthcare efficiency.  </p></li>
<li><p>Clear direction for quality improvement.  </p></li>
<li><p>Feasibility of data collection (preferably from routine EHR/PDMS data).  </p></li>
<li><p>Defined target values (100% for process indicators).  </p></li>
<li><p>Specificity to ICU context where possible.  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Modified-RAND Delphi procedure; Flottorp et al. checklist for barriers and strategies.  </p></li>
<li><p><strong>Methods/Levers:</strong> Expert consensus, literature &amp; guideline synthesis, barrier identification, strategy mapping.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Identify potential indicators (expert input + literature + guidelines).  </p>

<p> 2. Online rating for relevance &amp; actionability.  </p>

<p> 3. Face-to-face consensus refining and feasibility assessment.  </p>

<p> 4. Develop detailed indicator definitions, numerators, denominators, and targets.  </p>

<p> 5. Build toolbox: map barriers to strategies using checklist.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> EHR/PDMS-derived metrics, process &amp; structure measures, DOT for benchmarking.  </p></li>
<li><p><strong>Implementation Context:</strong> Dutch ICU registry (NICE) integration for feedback dashboards.  </p></li>
</ul>

<blockquote>
  <p>“Targets for indicator 1, 2 and 3 were set at 100%, which is a theoretical optimum…” (p. 7)  </p>
</blockquote>

<blockquote>
  <p>“…toolbox displays the suggested improvement strategies associated with the selected barriers.” (p. 9)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — indicators have explicit operational definitions and targets.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — ICU-specific, clinically grounded.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — prioritization of electronically extractable data.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — targets set for frequency (e.g., biannual meetings) but less emphasis on rapid data turnaround.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — rationale provided but no deep interpretability framework.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — aligned with stewardship goals and resistance reduction.  </p></li>
<li><p><strong>Other Dimensions:</strong> Reliability (implicitly required), Benchmarking value (explicit for quantity metric).  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>OECD and AHRQ criteria for good quality indicators.  </p></li>
<li><p>Flottorp et al. framework for determinants of practice.  </p></li>
<li><p>Tailored intervention literature (Wensing et al.).  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p><strong>Indicators:</strong>  </p>

<p> 1. Blood cultures before empirical therapy (100%).  </p>

<p> 2. Therapeutic drug monitoring within 48h for vancomycin/aminoglycosides (100%).  </p>

<p> 3. Surveillance cultures if SDD/SOD applied (100%).  </p>

<p> 4. Biannual ICU-microbiology meetings on resistance (≥2/year).  </p></li>
<li><p><strong>Quantity Metric:</strong> DOT per 100 patient-days or admissions (no fixed target).  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Inadequate local guidelines, insufficient familiarity with protocols, poor ICU team communication, lack of resources (e.g., culture bottles).  </p></li>
<li><p><strong>Enablers:</strong> Standardized protocols, interdisciplinary meetings, educational materials, EHR integration, benchmarking dashboards.  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The study builds on ICU quality measurement literature but distinguishes itself by <strong>explicitly integrating actionability</strong> as a selection criterion, unlike prior works which often yielded static structure indicators without improvement direction.  </p>

<hr />

<h2>Summary</h2>

<p>This study delivers a rigorously developed, ICU-specific set of four actionable quality indicators and one benchmarking metric for antibiotic stewardship, alongside an implementation toolbox mapping 24 barriers to 37 improvement strategies. By defining actionability as offering clear direction for daily practice improvement, the authors operationalize it through precise definitions, measurable targets, and feasibility for automated EHR data extraction. The toolbox facilitates tailored, context-sensitive interventions, aiming to improve antibiotic appropriateness while addressing local constraints. Integration with the Dutch NICE registry ensures benchmarking and feedback, strengthening continuous quality improvement. The approach is methodologically robust and generalizable beyond the Netherlands.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Strong explicit definition of actionability, clear criteria, ICU-specific operationalization.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Detailed process, measurable targets, integrated barrier-strategy toolbox, practical implementation plan.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Actionability, meaning that the indicator offers clear direction to improve performance in daily practice…” (p. 2)  </p></li>
<li><p>“Targets for indicator 1, 2 and 3 were set at 100%…” (p. 7)  </p></li>
<li><p>“…toolbox displays the suggested improvement strategies associated with the selected barriers.” (p. 9)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Flottorp SA et al., 2013 — Determinants of practice checklist.  </p></li>
<li><p>OECD, 2006; AHRQ, 2011 — Criteria for quality indicators.  </p></li>
<li><p>Wensing M et al., 2011; 2010 — Tailored implementation for chronic diseases and overcoming barriers.  </p></li>
<li><p>van den Bosch CM et al., 2014; 2016 — Antibiotic treatment indicators.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Development of Actionable Insights for Regulating Students’ Collaborative Writing of Scientific Texts  </p>

<p>Authors: Christian Hoffmann, Nadine Mandran, Cédric d’Ham, Sébastien Rebaudo, Mohamed Anis Haddouche  </p>

<p>DOI: https://doi.org/10.1007/978-3-031-16290-9_47  </p>

<p>Year: 2022  </p>

<p>Publication Type: Conference Paper  </p>

<p>Discipline/Domain: Learning Analytics / Educational Technology  </p>

<p>Subdomain/Topic: Collaborative Writing, Teacher Dashboards, Educational Collaboration Analytics  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 82  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (via Jørnø &amp; Gynther, 2018 and Martinez-Maldonado et al., 2021)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (Mapping “From Clicks to Constructs”)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Design-Based Research (Iterative User-Centered Design)  </p>

<p>Study Context: Web-based science learning environment (LabNbook) for collaborative writing of scientific texts  </p>

<p>Geographic/Institutional Context: Univ. Grenoble Alpes (France), IMT Atlantique (France)  </p>

<p>Target Users/Stakeholders: Teachers in secondary and higher education  </p>

<p>Primary Contribution Type: Indicators and visualizations for actionable insights in collaborative writing  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: No  </p>

<p>TI: No  </p>

<p>EX: Partial  </p>

<p>GA: No  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong> Development of Actionable Insights for Regulating Students’ Collaborative Writing of Scientific Texts  </p>

<p><strong>Authors:</strong> Christian Hoffmann, Nadine Mandran, Cédric d’Ham, Sébastien Rebaudo, Mohamed Anis Haddouche  </p>

<p><strong>DOI:</strong> https://doi.org/10.1007/978-3-031-16290-9_47  </p>

<p><strong>Year:</strong> 2022  </p>

<p><strong>Publication Type:</strong> Conference Paper  </p>

<p><strong>Discipline/Domain:</strong> Learning Analytics / Educational Technology  </p>

<p><strong>Subdomain/Topic:</strong> Collaborative Writing, Teacher Dashboards, Educational Collaboration Analytics  </p>

<p><strong>Contextual Background:</strong> The study focuses on supporting teachers in monitoring and regulating students’ collaborative writing (CW) of scientific texts within online learning environments (OLEs). It proposes indicators and visualizations that turn trace data into actionable insights for teachers via a learning analytics dashboard (LAD).  </p>

<p><strong>Geographic/Institutional Context:</strong> Univ. Grenoble Alpes, CNRS, LIG, France; IMT Atlantique, LABSTICC, France  </p>

<p><strong>Target Users/Stakeholders:</strong> Teachers (secondary and higher education) using OLEs for science education  </p>

<p><strong>Primary Methodology:</strong> Design-Based Research (iterative, user-centered design with interviews, focus groups, mockups)  </p>

<p><strong>Primary Contribution Type:</strong> Development of computational indicators and visualizations for CW actionability  </p>

<h2>General Summary of the Paper</h2>

<p>The paper develops a set of computationally calculable indicators and visualizations to provide teachers with actionable insights for regulating students’ collaborative writing of scientific texts in the LabNbook online platform. Drawing from collaboration analytics theory and CSCW concepts, the authors define two key educational sub-constructs—symmetry in action and territorial functioning—and map them from raw data traces to teacher-facing dashboard elements. Using a design-based research approach, the team iterated through indicator and visualization design with teacher input. The resulting system allows teachers to distinguish between summative and integrative writing strategies and better assess collaboration dynamics. Lessons learned stress the importance of simplicity, iterative design, multiple complementary indicators, and ensuring teacher understanding.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>Actionable insights are defined (via Jørnø &amp; Gynther, 2018) as “data that allows a corrective procedure, or feedback loop, established for a set of actions.” Martinez-Maldonado et al. (2021) frame actionability as mapping low-level data to educationally meaningful higher-order constructs interpretable by educators.</p>

<blockquote>
  <p>“The challenge for designers of LADs is to provide teachers with actionable group insights defined… as ‘data that allows a corrective procedure, or feedback loop…’” (p. 535)  </p>
</blockquote>

<blockquote>
  <p>“They emphasize the role of a clear ‘mapping from low-level data to higher-order constructs…’” (p. 535)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Clear mapping from trace data to meaningful educational constructs  </p></li>
<li><p>Relevance to teacher goals (e.g., assessing collaboration strategies)  </p></li>
<li><p>Understandable by the intended user (teacher)  </p></li>
<li><p>Presented in a way that supports immediate pedagogical decisions</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Mapping “From Clicks to Constructs”  </p></li>
<li><p><strong>Methods/Levers:</strong> Use of educational sub-constructs (symmetry in action, territorial functioning) derived from CSCW research  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Collect authorship, timestamp, and version data  </p>

<p> 2. Calculate indicators (turn taking, writing time, contribution scores, cowriting score)  </p>

<p> 3. Visualize indicators in teacher-friendly timelines and panels  </p>

<p> 4. Teachers interpret in context to diagnose collaboration strategy  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Words added (difflib), editor changes, sentence-level overlap detection  </p></li>
<li><p><strong>Implementation Context:</strong> LabNbook platform in science education  </p></li>
</ul>

<blockquote>
  <p>“Our analytics are based on… symmetry in action and territorial functioning… translated… into computationally calculable indicators.” (p. 537)  </p>
</blockquote>

<blockquote>
  <p>“Visualization… allows a teacher to get a wealth of information about how the report was co-constructed…” (p. 539)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Simplicity and clear indicator definitions stressed (p. 540)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Indicators tied directly to collaborative writing processes (p. 535)  </p></li>
<li><p><strong>FE (Feasibility):</strong> No explicit link  </p></li>
<li><p><strong>TI (Timeliness):</strong> No explicit link  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — Mapping framework provides interpretability, but some computational steps abstracted from teachers (p. 537)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> No explicit link  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Complementarity of indicators, avoidance of aggregation</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Jørnø &amp; Gynther’s definition of actionable insights  </p></li>
<li><p>Martinez-Maldonado et al.’s collaboration analytics model (five-step mapping)  </p></li>
<li><p>CSCW constructs: symmetry in action (Dillenbourg, 1999), territorial functioning (Larsen-Ledet &amp; Korsgaard, 2019)  </p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Turn taking (number of editor changes)  </p></li>
<li><p>Writing time (active editing time in 30s windows)  </p></li>
<li><p>Contribution scores (words added)  </p></li>
<li><p>Cowriting score (percentage of sentences modified by multiple authors)</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Over-aggregation of indicators, complex visualizations reducing interpretability  </p></li>
<li><p><strong>Enablers:</strong> Iterative teacher feedback, complementary indicators, simple visualizations, on-demand details</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Builds on CSCW collaborative writing strategy distinctions (summative vs integrative), extends Martinez-Maldonado’s mapping model to sentence-level analytics, adapts actionability concepts to science education OLEs.</p>

<h2>Summary</h2>

<p>The authors present a design-based research approach to developing actionable insights for regulating students’ collaborative writing of scientific texts. Using the LabNbook OLE, they operationalize CSCW concepts—symmetry in action and territorial functioning—into computational indicators such as turn taking, writing time, contribution scores, and cowriting percentage. These are visualized in a teacher dashboard, allowing quick assessment of collaboration strategies (summative vs integrative) and team dynamics. Actionability is understood as data enabling corrective pedagogical actions, achieved through clear mappings from trace data to educationally meaningful constructs. Iterative co-design with teachers informed indicator choice, visualization style, and usability considerations. The work contributes a replicable mapping framework and concrete, transferable dashboard elements.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 82 — Strong conceptual link to actionability, with clear definitions and dimensions; could be improved with more explicit coverage of timeliness, feasibility, and goal alignment.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Comprehensive explanation of how to calculate, visualize, and interpret indicators for actionable teacher decisions.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[Actionable insights]… ‘data that allows a corrective procedure, or feedback loop…’” (p. 535)  </p></li>
<li><p>“They emphasize the role of a clear ‘mapping from low-level data to higher-order constructs…’” (p. 535)  </p></li>
<li><p>“Our analytics are based on… symmetry in action and territorial functioning…” (p. 537)  </p></li>
<li><p>“Visualization… allows a teacher to get a wealth of information about how the report was co-constructed…” (p. 539)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Jørnø &amp; Gynther (2018) — Definition of actionable insights  </p></li>
<li><p>Martinez-Maldonado et al. (2021) — Collaboration analytics model  </p></li>
<li><p>Dillenbourg (1999) — Symmetry in action  </p></li>
<li><p>Larsen-Ledet &amp; Korsgaard (2019) — Territorial functioning in collaborative writing</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Development and Actionability of the Dutch COVID-19 Dashboard: Descriptive Assessment and Expert Appraisal Study</p>

<p>Authors: Véronique L. L. C. Bos, Tessa Jansen, Niek S. Klazinga, Dionne S. Kringos</p>

<p>DOI: 10.2196/31161</p>

<p>Year: 2021</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Public Health / Health Communication</p>

<p>Subdomain/Topic: COVID-19 dashboards, performance intelligence, public reporting</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 87</p>

<p>Operationalization Score: 78</p>

<p>Contains Definition of Actionability: Yes</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Mixed Methods (Descriptive assessment + expert appraisal)</p>

<p>Study Context: Dutch COVID-19 government dashboard development and adaptation over pandemic phases</p>

<p>Geographic/Institutional Context: Netherlands / Ministry of Health, Welfare and Sport</p>

<p>Target Users/Stakeholders: Policymakers, general public, public health experts</p>

<p>Primary Contribution Type: Empirical case study with conceptual framing</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Partial</p>

<p>TI: Yes</p>

<p>EX: Yes</p>

<p>GA: Partial</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Development and Actionability of the Dutch COVID-19 Dashboard: Descriptive Assessment and Expert Appraisal Study  </p>

<p><strong>Authors:</strong>  </p>

<p>Véronique L. L. C. Bos, Tessa Jansen, Niek S. Klazinga, Dionne S. Kringos  </p>

<p><strong>DOI:</strong>  </p>

<p>10.2196/31161  </p>

<p><strong>Year:</strong>  </p>

<p>2021  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Public Health / Health Communication  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>COVID-19 dashboards, performance intelligence, public reporting  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>Examines the development of the Dutch government’s COVID-19 dashboard from June 2020 to January 2021, with a focus on how its actionability evolved in content, structure, and communication strategy to serve both policymakers and the public.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Netherlands / Ministry of Health, Welfare and Sport  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Policymakers, general public, public health experts  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed Methods (Descriptive assessment + expert appraisal)  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical case study with conceptual framing  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This study investigates the evolution of the Dutch COVID-19 dashboard, assessing its actionability through a descriptive checklist and expert appraisal. Initially designed for policymakers, the dashboard shifted focus toward the general public, adding features such as a homepage, news-like explanations, and more granular geographic and indicator data. The evaluation applies seven features of highly actionable dashboards identified in prior international research, finding strengths in transparency, timeliness, and epidemiological detail, but gaps in health system capacity indicators, socioeconomic impact measures, and subgroup disaggregation (e.g., sex, socioeconomic status, ethnicity). Recommendations include expanding indicator coverage, improving data disaggregation, and enabling interoperability between health, social, and economic data.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is defined as the potential of a dashboard to inform decision-making by being:</p>

<ul>
<li><p><strong>Fit for purpose</strong>: meeting a specific information need.</p></li>
<li><p><strong>Fit for use</strong>: delivering the right information to the right audience at the right time, in an understandable way.</p></li>
</ul>

<blockquote>
  <p>“Information can be actionable only if it is fit for purpose and fit for use.” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“Actionability refers to a dashboard’s potential to inform decision making by way of providing information that is both fit for purpose… and fit for use…” (p. 2)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Knowing the audience and their needs</p></li>
<li><p>Managing type, volume, and flow of information</p></li>
<li><p>Clear data sources and methods</p></li>
<li><p>Linking time trends to policy</p></li>
<li><p>Providing data “close to home”</p></li>
<li><p>Disaggregation into relevant subgroups</p></li>
<li><p>Storytelling and visual cues</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Seven common features of highly actionable dashboards (Ivanković et al., 2021)</p></li>
<li><p><strong>Methods/Levers:</strong> Descriptive monitoring, actionability scoring, reflection meetings with dashboard developers</p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Iterative adaptation, feedback integration, thematic navigation, indicator expansion, public understanding research</p></li>
<li><p><strong>Data &amp; Measures:</strong> Epidemiological indicators, health system metrics, behavioral surveys, sewage testing data</p></li>
<li><p><strong>Implementation Context:</strong> Netherlands, government-led pandemic monitoring tool  </p></li>
</ul>

<blockquote>
  <p>“The dashboard has been designed for… high-frequency (daily) updates…” (p. 7)  </p>
</blockquote>

<blockquote>
  <p>“Transparency of data was maximized by making it largely available as open source.” (p. 7)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Efforts to explain indicators; news-like items for public understanding.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Geographic and thematic tailoring, audience shift to public.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — Constraints due to data access, privacy, and resources.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — Daily updates, responsive to pandemic phases.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Narratives and visual cues to aid interpretation.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — Aligned with public health monitoring goals, but not fully integrated with socioeconomic policy goals.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Transparency, granularity, equity focus (through subgroup data).</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Lasswell’s Model of Communication (1948)</p></li>
<li><p>Performance intelligence in health</p></li>
<li><p>WHO pandemic monitoring framework (public health, health system, behavioral, socioeconomic)</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Availability of disaggregation</p></li>
<li><p>Indicator variety (epidemiological, health system, socioeconomic)</p></li>
<li><p>Navigation and usability features</p></li>
<li><p>Timeliness of updates</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Limited access to neighborhood-level data  </p>

<p> - Privacy constraints on granular data  </p>

<p> - Lack of integrated socioeconomic and ethnicity data</p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Open-source data  </p>

<p> - Political commitment to transparency  </p>

<p> - Ongoing public understanding research</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on Ivanković et al. (2021) framework for actionable COVID-19 dashboards, adapting it to the Dutch context and extending by analyzing decision-making processes behind dashboard design.</p>

<hr />

<h2>Summary</h2>

<p>The Dutch COVID-19 dashboard transitioned from a policy-focused monitoring tool to a public-facing communication platform, guided by the principle of delivering fit-for-purpose and fit-for-use information. Applying the seven-feature actionability framework revealed strong performance in transparency, timeliness, and contextual relevance, but weaknesses in breadth of indicators (especially health system capacity and socioeconomic impact) and population subgroup disaggregation. Operationalization involved iterative adjustments, thematic navigation, public comprehension research, and clear data sourcing. Recommendations target expanding indicator coverage, enabling data interoperability, and improving granularity to enhance actionability for both pandemic and future public health challenges.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 87 — Strong conceptual clarity, clear criteria, and framework application to a concrete case; minor gaps in explicit linkage to policy outcomes.</p></li>
<li><p><strong>Operationalization Score:</strong> 78 — Provides a structured approach to achieving actionability with practical examples, but implementation is constrained by data access and policy choices.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Actionability refers to a dashboard’s potential to inform decision making by way of providing information that is both fit for purpose… and fit for use…” (p. 2)</p></li>
<li><p>“Seven common features… knowing the audience… managing the type, volume… linking time trends to policy decisions… using storytelling and visual cues.” (p. 3)</p></li>
<li><p>“Transparency of data was maximized by making it largely available as open source.” (p. 7)</p></li>
<li><p>“Two of the four key components advised by WHO… were still missing: indicators of available capacity… and indicators of social and economic impact.” (p. 8)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Ivanković et al. (2021) – Features Constituting Actionable COVID-19 Dashboards  </p></li>
<li><p>Barbazza et al. (2021) – Actionability of healthcare performance indicators  </p></li>
<li><p>WHO (2020) – Pandemic transition monitoring framework</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Design of Information and Warfare Analytics using MapReduce and Machine Learning</p>

<p>Authors: Pallaw Kumar Mishra</p>

<p>DOI: n/a</p>

<p>Year: 2017</p>

<p>Publication Type: Conference Paper</p>

<p>Discipline/Domain: Defense Informatics / Military Data Science</p>

<p>Subdomain/Topic: Warfare analytics, big data, actionable intelligence, MapReduce, social network analysis</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 90</p>

<p>Operationalization Score: 88</p>

<p>Contains Definition of Actionability: Yes (implicit)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual + System Design</p>

<p>Study Context: Development of an integrated information and warfare analytics system for military decision-making</p>

<p>Geographic/Institutional Context: India / Defence Research and Development Organisation (DRDO)</p>

<p>Target Users/Stakeholders: Military decision-makers, defense analysts, cyber security teams, intelligence agencies</p>

<p>Primary Contribution Type: Conceptual framework and system design proposal</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Partial</p>

<p>EX: Partial</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: n/a</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Design of Information and Warfare Analytics using MapReduce and Machine Learning  </p>

<p><strong>Authors:</strong>  </p>

<p>Pallaw Kumar Mishra  </p>

<p><strong>DOI:</strong>  </p>

<p>n/a  </p>

<p><strong>Year:</strong>  </p>

<p>2017  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference Paper  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Defense Informatics / Military Data Science  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Warfare analytics, big data, actionable intelligence, MapReduce, social network analysis  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the growing need for real-time, data-driven decision support in modern warfare, leveraging big data analytics, MapReduce (via Spark), and machine learning to integrate multi-source battlefield, cyber, and social network intelligence for actionable insights.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>India / Defence Research and Development Organisation (DRDO)  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Military decision-makers, defense analysts, cyber security teams, intelligence agencies  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual + System Design  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework and system design proposal  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper proposes a comprehensive “Information and Warfare Analytics System” to provide meaningful, real-time actionable insights from multi-source military, cyber, and social network data. Leveraging MapReduce via Spark, the architecture integrates hardware, distributed computing, big data preprocessing, data mining, machine learning, and social network analysis. The system aims to quantify threats, assess own and enemy capabilities, track war progress, and anticipate events. It defines relevant warfare metrics for conventional, cyber, and social network domains, and outlines challenges in multi-source data integration. The design emphasizes scalability, resilience, and real-time processing, supporting predictive, tactical, and strategic decision-making in both wartime and peacetime.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>The paper frames actionability as the ability of the system to provide <strong>real-time, contextual, and predictive insights</strong> that directly inform decisions in warfare, cyber defense, and social influence monitoring.  </p>

<blockquote>
  <p>“Real time quantitative measure of warfare scenario is an essential input to top decision maker for understanding the situation, determining causes, envisaging next likely event and recommending the best action to take.” (Abstract)  </p>
</blockquote>

<blockquote>
  <p>“...provide meaningful and real-time actionable insight.” (Abstract)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Integration of multi-source, heterogeneous data (battlefield, cyber, social)</p></li>
<li><p>Use of predictive models and metrics tailored to warfare contexts</p></li>
<li><p>Contextualization of raw data into threat posture, vulnerabilities, and operational readiness</p></li>
<li><p>Real-time processing and alerting to anticipate events</p></li>
<li><p>Feasibility through scalable, distributed computing infrastructure</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Information and Warfare Analytics System  </p></li>
<li><p><strong>Methods/Levers:</strong> Big data processing via Spark MapReduce; MLlib for scalable machine learning; integration of geospatial, simulation, MASINT, and OSINT data; social network and sentiment analysis; custom warfare metrics.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Data generation &amp; collection from multiple military, cyber, and open sources  </p>

<p> 2. Preprocessing via ETL and Big Data Toolbox  </p>

<p> 3. Distributed processing &amp; analytics via Spark  </p>

<p> 4. Application of statistical, ML, and SNA algorithms  </p>

<p> 5. Computation of warfare metrics  </p>

<p> 6. Visualization and decision support output  </p></li>
<li><p><strong>Data &amp; Measures:</strong> GIS, battlefield exercises, simulations, MASINT, HUMINT, OSINT; conventional warfare metrics (OLI, WEI, Lanchester, Adaptive Dynamic Model), cyber vulnerability metrics (Base, Temporal, Environmental), SNA metrics (centrality, density, sentiment).  </p></li>
<li><p><strong>Implementation Context:</strong> Military decision support in both active conflict and peacetime intelligence monitoring.  </p></li>
</ul>

<blockquote>
  <p>“...integration of Data Mining, Social Network Analysis, statistical and analytics techniques...” (Section III)  </p>
</blockquote>

<blockquote>
  <p>“...develop comprehensive set of warfare metrics.” (Abstract)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Outputs must be interpretable to top decision makers.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Contextualization of multi-domain data into decision-ready insights.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Emphasis on scalable, commodity-hardware-based cluster solutions.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Near real-time capability mentioned but not exhaustively defined.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — Models’ logic partially described; domain-specific metrics aid interpretability.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Explicit aim to support military strategic and tactical objectives.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Predictive ability, resilience to data quality issues, multi-domain integration.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Network Centric Warfare (NCW)  </p></li>
<li><p>Information Age Combat Models  </p></li>
<li><p>Graph Theory for SNA  </p></li>
<li><p>Lanchester and Adaptive Dynamic Models for combat  </p></li>
<li><p>CVSS vulnerability metrics for cyber warfare  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Conventional warfare: OLI, WEI, Lanchester, Adaptive Dynamic, Situational Force Strength  </p></li>
<li><p>Cyber warfare: Base, Temporal, Environmental metrics; probability of attack; system vulnerability; threat level  </p></li>
<li><p>Social network: Centrality, Density, Diameter, Prestige, Sentiment, Topic Value, Scale Shift  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Data heterogeneity, incomplete/missing data, sensor inaccuracies, cross-vendor incompatibilities, inconsistent units.  </p></li>
<li><p><strong>Enablers:</strong> Distributed computing (Spark MapReduce), data preprocessing toolkit, integration of ML/SNA, tailored warfare metrics.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper builds on practical military analytics cases (e.g., NATO’s use of Twitter for intelligence, electronic countermeasure mining) but proposes a more generalized, proactive, and integrated architecture capable of addressing diverse operational contexts.</p>

<hr />

<h2>Summary</h2>

<p>The paper conceptualizes a comprehensive architecture for military decision support that operationalizes actionability through real-time, context-aware, and predictive analytics. By combining distributed big data processing, machine learning, and tailored warfare metrics across conventional, cyber, and social domains, it seeks to transform heterogeneous raw data into decision-ready intelligence. The operationalization is detailed through hardware/software architecture, data workflows, and multi-domain metric design. The work is distinctive in its integration of diverse data sources, scalability on commodity clusters, and alignment of analytics outputs with strategic and tactical military goals. Limitations lie in partial elaboration on explainability and timeliness dimensions.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 — Strong, integrated conceptualization of actionability, with explicit link to decision-making and systematic features.  </p></li>
<li><p><strong>Operationalization Score:</strong> 88 — Detailed framework and workflow; some aspects (timeliness, explainability) less fully developed.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“...provide meaningful and real-time actionable insight.” (Abstract)  </p></li>
<li><p>“Real time quantitative measure of warfare scenario is an essential input to top decision maker...” (Abstract)  </p></li>
<li><p>“...develop comprehensive set of warfare metrics.” (Abstract)  </p></li>
<li><p>“...integration of Data Mining, Social Network Analysis, statistical and analytics techniques...” (Section III)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>NATO social media intelligence collection (Ackerman, 2011)  </p></li>
<li><p>CVSS vulnerability scoring (First.org, 2015)  </p></li>
<li><p>Social Network Analysis theory (McCulloh et al., 2013)  </p></li>
<li><p>Lanchester and Adaptive Dynamic Models (Jaiswal, 1997)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Defining and Conceptualizing Actionable Insight: A Conceptual Framework for Decision-centric Analytics  </p>

<p>Authors: Shiang-Yen Tan, Taizan Chan  </p>

<p>DOI: n/a  </p>

<p>Year: 2015  </p>

<p>Publication Type: Conference Paper  </p>

<p>Discipline/Domain: Information Systems  </p>

<p>Subdomain/Topic: Data Analytics, Decision Support, Problem Solving  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (HIVE framework)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual/Theoretical Development  </p>

<p>Study Context: Decision-centric data analytics  </p>

<p>Geographic/Institutional Context: Queensland University of Technology, Australia  </p>

<p>Target Users/Stakeholders: Data analysts, decision makers, system designers  </p>

<p>Primary Contribution Type: Conceptual framework and definition  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Defining and Conceptualizing Actionable Insight: A Conceptual Framework for Decision-centric Analytics  </p>

<p><strong>Authors:</strong>  </p>

<p>Shiang-Yen Tan, Taizan Chan  </p>

<p><strong>DOI:</strong>  </p>

<p>n/a  </p>

<p><strong>Year:</strong>  </p>

<p>2015  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference Paper  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Information Systems  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Data Analytics, Decision Support, Problem Solving  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the lack of a systematic, theory-driven definition of “actionable insight” in data analytics. It introduces the HIVE conceptual framework, grounded in theories from complex problem solving, decision making, and sensemaking, to define actionable insight as a multi-component concept (analytic, synergic, and prognostic insights) aimed at enabling decision-centric analytics systems.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Queensland University of Technology, Australia  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Data analysts, decision makers, system designers  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual/Theoretical Development  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework and definition  </p>

<h2>General Summary of the Paper</h2>

<p>This paper proposes a theory-driven, multi-component definition of actionable insight for decision-centric analytics. Drawing from diverse literatures, the authors conceptualize actionable insight as comprising analytic insight (specific data-derived observations), synergic insight (integration of analytic insights and contextual knowledge into a coherent situation model), and prognostic insight (predictions of future states under various actions and scenarios). The HIVE framework organizes these components hierarchically, describing their informational, computational, and cognitive requirements. The framework highlights the interactions between components, their roles in problem solving, and the gaps in current analytics systems, which often stop at providing analytic insight. The authors outline design considerations for supporting each component and suggest computational techniques to operationalize them, ultimately aiming to build decision-centric analytics systems that fully realize actionable insight.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionable insight is defined as:  </p>

<blockquote>
  <p>“A cohesive set of understandings about the problem situation based on prognostic insights derived from synergic understanding of analytical results which enables the user to make an informed decision to solve the problem.” (p. 3)  </p>
</blockquote>

<p>It is conceptualized as reasoning artefacts gained through the analytics process, contextualized, internalized, and used to devise and choose optimal solutions.</p>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Derived from integrating analytic, synergic, and prognostic insights.</p></li>
<li><p>Contextualized to the user’s objectives, constraints, and domain.</p></li>
<li><p>Involves internalization of results into mental models.</p></li>
<li><p>Supports confident, informed decision making for problem solving.</p></li>
</ul>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> HIVE Framework  </p></li>
<li><p><strong>Methods/Levers:</strong> Hierarchical insight layering, integration of analytic results with soft evidence, situation modeling, hypothesis generation, scenario simulation.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Derive <strong>analytic insights</strong> from data queries/analysis.  </p>

<p> 2. Synthesize into <strong>synergic insight</strong> via chains of arguments and situation models.  </p>

<p> 3. Generate hypotheses and predict future states for <strong>prognostic insight</strong>.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Quantitative analytical results, qualitative domain knowledge, soft evidence, scenario variations.  </p></li>
<li><p><strong>Implementation Context:</strong> Decision-centric analytics systems.  </p></li>
</ul>

<blockquote>
  <p>“Support structured reasoning with the aids of advanced analytics techniques.” (p. 8)  </p>
</blockquote>

<blockquote>
  <p>“Provide flexible analytics environment that supports the natural flow-of-thoughts of the users.” (p. 9)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — insights must be interpretable and structured for reasoning.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — must align with user’s objectives, constraints, and domain knowledge.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — solution alternatives and predictions must be actionable in practice.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — addressed via anticipatory strategies and faster insight cycles, but not a primary focus.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — reasoning artefacts, chains of arguments, and situation models explicitly link evidence to conclusions.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — objectives and constraints are explicitly embedded in situation models.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Objectivity, scope, granularity, domain value, human reasoning involvement.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Complex problem solving  </p></li>
<li><p>Naturalistic decision making  </p></li>
<li><p>Sensemaking theory  </p></li>
<li><p>Situation awareness  </p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<p>No explicit quantitative KPIs; operational indicators implied through completeness of the three insight components and integration with decision-making processes.</p>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of synthesis support; cognitive overload; weak probabilistic reasoning without aids; reliance on low-level analytics; fragmented evidence.  </p></li>
<li><p><strong>Enablers:</strong> Computational reasoning aids (e.g., fuzzy cognitive maps, Bayesian networks); flexible analytics environments; integrated modeling and scenario analysis tools.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Builds on prior fragmented definitions of actionable insight, integrating them into a systematic, multi-component model grounded in decision support and cognitive theories. Contrasts with purely technical definitions by emphasizing context, integration, and predictive reasoning.</p>

<h2>Summary</h2>

<p>Tan and Chan (2015) define actionable insight as the integration of analytic, synergic, and prognostic insights, enabling informed, contextually grounded decision making. Their HIVE framework provides a hierarchical, theory-based structure describing each component’s cognitive, computational, and informational needs. Analytic insight captures specific, objective observations from data; synergic insight synthesizes them with contextual knowledge into a situation model; prognostic insight projects future states under different actions and scenarios, offering the highest degree of actionability. The paper details design considerations for each layer, critiques the current analytics landscape’s overemphasis on analytic insight, and proposes computational and interface supports to achieve decision-centric analytics. Its conceptual clarity and operational focus make it a strong reference for both defining and implementing actionability in analytics.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Strong, explicit definition with systematic, theory-informed features.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Clear methods for achieving actionability via HIVE, though lacking empirical validation.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Actionable Insight: A cohesive set of understandings about the problem situation… enables the user to make an informed decision to solve the problem.” (p. 3)  </p></li>
<li><p>“Insight is the result of information internalization process… contextualized in a specific situation…” (p. 3)  </p></li>
<li><p>“Design consideration: Support the users in constructing computation-friendly situation model…” (p. 6)  </p></li>
<li><p>“Prognostic insight has the highest extent of actionability as it provides users with the knowledge necessary to decide on the most favourable course of actions…” (p. 8)  </p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Saraiya et al. (2005) — insight-based evaluation methodology.  </p></li>
<li><p>Thomas &amp; Cook (2005) — visual analytics research agenda.  </p></li>
<li><p>Ribarsky et al. (2009) — analytical reasoning.  </p></li>
<li><p>Weick (1995) — sensemaking theory.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Decision making for health-related research outcomes that alter diagnosis: A model from paediatric brain tumours  </p>

<p>Authors: Jessica C. Pickles, Kristian Aquilina, Jane Chalker, Christine Dahl, Abel Devadass, Kshitij Mankad, Ashirwad Merve, Munaza Ahmed, James A. R. Nicoll, Tabitha Bloom, David A. Hilton, Neil J. Sebire, Darren Hargrave, Thomas S. Jacques  </p>

<p>DOI: https://doi.org/10.1111/nan.12994  </p>

<p>Year: 2024  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Neuropathology, Medical Ethics, Oncology  </p>

<p>Subdomain/Topic: Paediatric brain tumours, health-related findings, diagnostic revision frameworks  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 85  </p>

<p>Operationalization Score: 80  </p>

<p>Contains Definition of Actionability: Yes (explicit and implicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Mixed Methods (case review with expert multidisciplinary team, framework development)  </p>

<p>Study Context: Archival paediatric brain tumour cohort (UK), retrospective diagnostic reassessment under updated WHO CNS guidelines  </p>

<p>Geographic/Institutional Context: United Kingdom; BRAIN UK virtual tissue bank; Great Ormond Street Hospital; multiple UK neuropathology centres  </p>

<p>Target Users/Stakeholders: Researchers, clinical MDTs, pathologists, neuro-oncologists, ethics committees, tissue banks  </p>

<p>Primary Contribution Type: Conceptual framework and decision-making model for reporting clinically actionable diagnostic research findings  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: Yes  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Decision making for health-related research outcomes that alter diagnosis: A model from paediatric brain tumours  </p>

<p><strong>Authors:</strong>  </p>

<p>Jessica C. Pickles et al.  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1111/nan.12994  </p>

<p><strong>Year:</strong>  </p>

<p>2024  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Neuropathology, Medical Ethics, Oncology  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Paediatric brain tumours, health-related findings, diagnostic revision frameworks  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The study addresses how to determine when research findings from retrospective analyses of archival diagnostic tissue — specifically paediatric brain tumour samples — should be fed back to clinical teams if they indicate a change in diagnosis. The issue is framed within the context of evolving WHO CNS tumour classifications, ethics of health-related findings (HRFs), and operational constraints of anonymised linked archival tissue.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>United Kingdom; BRAIN UK virtual tissue bank; Great Ormond Street Hospital; multiple UK neuropathology centres  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Researchers, clinical MDTs, pathologists, neuro-oncologists, ethics committees, tissue banks  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed Methods — review of 73 reclassified paediatric brain tumour cases via surrogate MDT, qualitative synthesis of decision-making factors, framework development  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework and operational model for assessing and reporting clinically actionable diagnostic HRFs  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This study develops a structured decision-making framework for determining whether revised diagnoses from retrospective research using archival paediatric brain tumour samples should be reported back to clinical teams. Using 73 reclassified tumour cases from a prior study, the authors convened a surrogate multidisciplinary neuro-oncology team to assess the clinical actionability of findings under updated WHO guidelines. Key determinants included anticipated change to patient management, time since initial diagnosis, likelihood of survival, and whether updated pathology already existed. None of the cases were deemed actionable, primarily due to the cohort’s historic nature and poor prognosis. Two frameworks were proposed: one for determining clinical actionability and another for managing the feedback process. The approach is adaptable to other rare disease contexts using archival tissue.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is defined as the potential for research findings to lead to meaningful changes in active patient management, based on analytical validity, clinical utility, and context-specific assessment.  </p>

<blockquote>
  <p>“Health-related translational research studies… may uncover incidental or pertinent findings with clinical implications… feedback [is] appropriate… when the potential benefits outweigh the risks” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“Clinical actionability was initially determined by identifying theoretical changes to active patient management… additional factors impacted actionability: patient status… and time elapsed since presentation” (p. 5)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Evidence supports a <strong>change in active patient management</strong> (e.g., altered follow-up, treatment de-escalation/escalation).  </p></li>
<li><p>Patient is <strong>likely alive</strong>.  </p></li>
<li><p><strong>Time since diagnosis</strong> is short enough that changes could affect management (≤10 years generally).  </p></li>
<li><p>No subsequent pathology reviews have already updated the diagnosis.  </p></li>
<li><p>Sufficient evidence exists to <strong>validate findings in a clinical setting</strong>.  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Framework A (Determine Clinical Actionability), Framework B (Mechanism to Feedback HRFs)  </p></li>
<li><p><strong>Methods/Levers:</strong> Surrogate MDT case review; triaging by survival likelihood, elapsed time, and clinical management implications  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. MDT identifies potential management change.  </p>

<p> 2. Assess disease progression risk, survival likelihood, and elapsed time.  </p>

<p> 3. Check for subsequent pathology updates.  </p>

<p> 4. If actionable, report to tissue bank (BRAIN UK) → clinical validation → neuro-oncology MDT discussion → potential feedback to patient/family.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> WHO 2016 CNS classification; linked-anonymised case data; tumour-specific outcome knowledge.  </p></li>
<li><p><strong>Implementation Context:</strong> UK archival paediatric CNS tumour research under BRAIN UK ethical approval.  </p></li>
</ul>

<blockquote>
  <p>“Framework for assessing actionability and managing diagnostic HRFs… Any research findings would need to be validated by appropriate clinical testing… and discussed by the appropriate MDT before reporting back to families” (p. 5)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Must be clearly linked to patient management change.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Decision depends on tumour type, prognosis, and elapsed time.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Only feasible if patient is alive and institutional pathways exist for feedback.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — Feedback only useful if within time window to affect care.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — MDT discussion requires clear explanation of clinical significance.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — Alignment with patient benefit is implied but not explicitly formalised.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Analytical validity; clinical utility; ethical appropriateness.  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>WHO CNS tumour classification updates  </p></li>
<li><p>UKRI/MRC framework on health-related findings  </p></li>
<li><p>Ethical guidelines from CIOMS and Declaration of Helsinki  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Time since diagnosis (&lt;10 years typical threshold)  </p></li>
<li><p>Patient survival likelihood  </p></li>
<li><p>Predicted change in tumour risk classification  </p></li>
<li><p>Evidence of relapse or follow-up pathology  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Historic/poor prognosis cohorts; lack of patient survival; absence of clinical validation capacity; lack of outcome data for rare entities; anonymisation constraints.  </p></li>
<li><p><strong>Enablers:</strong> MDT expertise; tumour-specific outcome knowledge; linked anonymisation allowing follow-up; tissue bank protocols for feedback.  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Authors note that prior archival tissue studies rarely address feedback of revised diagnoses; most literature on HRFs relates to prospective consented studies. Their model fills a gap for retrospective, anonymised, pathology-driven research.</p>

<hr />

<h2>Summary</h2>

<p>The paper offers a clear, ethically grounded, and operationally detailed framework for determining whether research-driven diagnostic revisions in archival paediatric brain tumour cases should be communicated to clinical teams. Actionability is defined by the potential to alter current patient management, moderated by factors such as survival likelihood, elapsed time since diagnosis, and absence of prior diagnostic updates. The proposed two-framework approach ensures both robust decision-making and a structured feedback pathway, requiring validation in clinical settings before patient/family contact. While no actionable cases were found in this historic, high-risk cohort, the model is adaptable to other rare disease contexts, providing reassurance for tissue banks and guiding ethical oversight.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 — Clear conceptualisation of actionability and explicit feature set; grounded in a real clinical-ethical scenario.  </p></li>
<li><p><strong>Operationalization Score:</strong> 80 — Provides detailed frameworks and steps for implementation, though not fully tested in cases with actual feedback events.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[Clinical actionability was] determined by identifying theoretical changes to active patient management… additional factors impacted actionability: patient status… and time elapsed” (p. 5)  </p></li>
<li><p>“Patients who were over 10 years from their initial diagnosis were considered unlikely to require a change in management” (p. 3)  </p></li>
<li><p>“Framework… discussed by the appropriate MDT before reporting back to families” (p. 5)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>MRC Framework on feedback of health-related findings (2014)  </p></li>
<li><p>WHO CNS tumour classifications (2016, 2021)  </p></li>
<li><p>Prior work on genomic predisposition in paediatric CNS tumours (e.g., Waszak et al., 2018; Zhang et al., 2015)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Data-Driven Machine Learning-Informed Framework for Model Predictive Control in Vehicles  </p>

<p>Authors: Edgar Amalyan, Shahram Latifi  </p>

<p>DOI: https://doi.org/10.3390/info16060511  </p>

<p>Year: 2025  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Electrical and Computer Engineering / Automotive Control Systems  </p>

<p>Subdomain/Topic: Hybrid Machine Learning–Model Predictive Control (ML–MPC) for vehicle subsystems  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 88  </p>

<p>Contains Definition of Actionability: Yes (explicitly in terms of “transforming ML outputs into actionable commands” for MPC)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes (MPC’s transparency offsets ML’s black-box nature)  </p>

<p>Contains Interpretability: Yes (hybrid design enables interpreting ML outputs through MPC)  </p>

<p>Contains Framework/Model: Yes (machine learning–informed MPC hybrid framework)  </p>

<p>Operationalization Present: Yes (detailed multi-step workflow for training, inference, sliding-window smoothing, weighting, and integration with MPC)  </p>

<p>Primary Methodology: Experimental + Conceptual Framework Development  </p>

<p>Study Context: Performance vehicle suspension as primary subsystem case study; extensible to other systems like braking and traction  </p>

<p>Geographic/Institutional Context: University of Nevada, Las Vegas, USA  </p>

<p>Target Users/Stakeholders: Automotive engineers, control system designers, autonomous vehicle developers, performance vehicle tuners  </p>

<p>Primary Contribution Type: Conceptual + Technical Framework with proof-of-concept implementation and evaluation  </p>

<p>CL: Yes — “MPC translates ML outputs into actionable commands” ensuring clear operational meaning (p. 3)  </p>

<p>CR: Yes — Actionability tied to real-time contextual vehicle state awareness (p. 16)  </p>

<p>FE: Yes — Feasibility discussed in terms of real-time latency, computational load, and integration with existing ECUs (p. 13, p. 17)  </p>

<p>TI: Yes — Sliding-window and exponential weighting for timely response (p. 12)  </p>

<p>EX: Yes — MPC provides explainable layer for ML’s black box outputs (p. 3)  </p>

<p>GA: Yes — Goal alignment through mode-specific constraint tuning for performance, safety, comfort (p. 16)  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Data-Driven Machine Learning-Informed Framework for Model Predictive Control in Vehicles  </p>

<p><strong>Authors:</strong>  </p>

<p>Edgar Amalyan, Shahram Latifi  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.3390/info16060511  </p>

<p><strong>Year:</strong>  </p>

<p>2025  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Electrical and Computer Engineering / Automotive Control Systems  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Hybrid ML–MPC framework for adaptive, self-optimizing vehicle control  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper develops a data-driven ML module to interpret vehicle subsystem states from sensor data, producing real-time semantic mode predictions that inform MPC systems. Suspension control is used as a case study, but applicability extends to braking, traction, and energy systems.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of Nevada, Las Vegas, USA  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Vehicle control engineers, autonomous vehicle designers, motorsport engineers, component manufacturers  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Experimental sensor-data collection + ML model training + integration concept for MPC  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual and technical framework with performance validation  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper proposes and validates a machine learning–informed framework to enhance Model Predictive Control (MPC) in vehicles. Using a BMW M240i test platform, inertial data from accelerometers and gyroscopes were collected during controlled driving maneuvers. An XGBoost-based prototype classifier was trained on curated “seed” maneuver data, then used to pseudo-label a much larger “exemplar” dataset, enabling a robust inference model. The model classifies vehicle modes (e.g., braking, cornering) in real time with 97.6% accuracy. To ensure stability and responsiveness, predictions are processed using overlapping sliding windows and reverse exponential weighting. The paper details how such semantic mode predictions can feed into MPC systems for adaptive constraint tuning and control strategy updates. Applications span suspension adjustment, braking, traction, and energy management for conventional and autonomous vehicles.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>The authors explicitly define actionability as the transformation of ML outputs into real-world control actions via MPC, ensuring they are interpretable, safe, and optimally tuned for current vehicle conditions.  </p>

<blockquote>
  <p>“MPC in the hybrid approach translates ML outputs into actionable commands in the real world.” (p. 3)  </p>
</blockquote>

<blockquote>
  <p>“By grading each subsystem’s real-world status and feeding those semantic modes into the optimizer, the approach generalizes effortlessly…” (p. 16)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Interpretability through MPC translating ML outputs into constraints and control commands  </p></li>
<li><p>Contextual relevance to current driving conditions  </p></li>
<li><p>Real-time responsiveness without destabilizing oscillations  </p></li>
<li><p>Feasibility for deployment on automotive ECUs  </p></li>
<li><p>Goal alignment with performance, safety, and comfort objectives  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> ML-informed MPC hybrid control framework  </p></li>
<li><p><strong>Methods/Levers:</strong> Sensor fusion (accelerometer, gyroscope), XGBoost classification, pseudo-labeling, real-time inference pipeline  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Collect curated “seed” maneuver data  </p>

<p> 2. Train prototype classifier  </p>

<p> 3. Pseudo-label large exemplar dataset  </p>

<p> 4. Train inference model  </p>

<p> 5. Real-time operation using overlapping sliding window + reverse exponential weighting  </p>

<p> 6. Feed mode predictions to MPC for constraint/parameter updates  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Six inertial features (GForceX/Y/Z, GyroX/Y/Z) with defined sign conventions and physical meaning  </p></li>
<li><p><strong>Implementation Context:</strong> Performance suspension tuning case study; extensible to brakes, traction, energy  </p></li>
</ul>

<blockquote>
  <p>“An overlapping sliding-window grading approach with reverse exponential weighting smooths transient fluctuations while preserving responsiveness.” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“The controller can adjust its own internal constraints…based on the inferred driving mode.” (p. 16)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — ML outputs interpreted via MPC into explicit commands (p. 3)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Predictions reflect real-time driving modes for adaptive control (p. 16)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Tested with latency measurements; hardware considerations discussed (p. 13, p. 17)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — Sliding window + weighting ensures rapid yet stable response (p. 12)  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — MPC’s rule-based transparency provides explainability (p. 3)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Constraints tuned for performance, safety, comfort (p. 16)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Stability through constraint management; robustness to sensor anomalies  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Model Predictive Control theory (receding horizon optimization, constraints)  </p></li>
<li><p>Semi-supervised ML (pseudo-labeling)  </p></li>
<li><p>Feature importance metrics from gradient-boosted decision trees  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Real-time classification accuracy (97.6%)  </p></li>
<li><p>Latency (~119 µs inference + 32 µs aggregation)  </p></li>
<li><p>F1-scores per maneuver class  </p></li>
<li><p>Confusion matrix diagonality (low cross-mode error)  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Mislabeling under-represented scenarios  </p>

<p> - Trade-off between window size and responsiveness  </p>

<p> - Computational load on ECUs  </p>

<p> - Limited coverage of rare driving conditions in datasets  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - MPC’s safeguard role against erroneous ML outputs  </p>

<p> - Modular adaptability across vehicle subsystems  </p>

<p> - High accuracy and generalization via pseudo-labeling  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions itself as a practical, data-driven integration of ML and MPC, leveraging MPC’s transparency to offset ML’s opaqueness while using ML’s predictive adaptability to overcome MPC’s reliance on static models. Builds on prior work in ML for automotive perception and MPC for control, adding a structured hybridization pipeline.</p>

<hr />

<h2>Summary</h2>

<p>This paper offers a complete methodology for making ML outputs actionable in automotive control through MPC integration. Actionability is explicitly framed as the transformation of predictive insights into interpretable, constraint-adjusted commands. The proposed pipeline—seed data collection, prototype classification, pseudo-labeling, inference model training, sliding-window smoothing, and reverse exponential weighting—ensures timely, context-relevant, and safe control adjustments. The authors test the system on suspension control in a performance vehicle, achieving high accuracy and low latency, and argue that the approach generalizes to other vehicle subsystems. The framework’s strength lies in its balance between predictive adaptability and rule-based transparency, enabling both human interpretability and machine responsiveness.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 — Strong explicit conceptualization of actionability, well-linked features, clear hybrid framework.  </p></li>
<li><p><strong>Operationalization Score:</strong> 88 — Detailed, multi-step technical pipeline with performance metrics; lacks only direct integration and field trials with MPC to be complete.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“MPC…translates ML outputs into actionable commands in the real world.” (p. 3)  </p></li>
<li><p>“By grading each subsystem’s real-world status and feeding those semantic modes into the optimizer, the approach generalizes effortlessly…” (p. 16)  </p></li>
<li><p>“An overlapping sliding-window grading approach with reverse exponential weighting smooths transient fluctuations while preserving responsiveness.” (p. 1)  </p></li>
<li><p>“The controller can adjust its own internal constraints…based on the inferred driving mode.” (p. 16)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Norouzi et al. (2023) — ML–MPC integration review  </p></li>
<li><p>Maiworm et al. (2021) — Online learning-based MPC with stability guarantees  </p></li>
<li><p>Goel et al. (2023) — Semantically informed MPC for context-aware control  </p></li>
<li><p>Ribeiro et al. (2016) — Explaining predictions of classifiers</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Data Driven Science for Clinically Actionable Knowledge in Diseases  </p>

<p>Authors: Daniel R. Catchpoole, Simeon J. Simoff, Paul J. Kennedy, Quang Vinh Nguyen (eds.)  </p>

<p>DOI: 10.1201/9781003292357  </p>

<p>Year: 2024  </p>

<p>Publication Type: Edited Book (Multiple Chapters)  </p>

<p>Discipline/Domain: Health Informatics / Biomedical Data Science  </p>

<p>Subdomain/Topic: Data-driven analytics for actionable clinical insights in disease diagnosis, treatment, and policy  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 85  </p>

<p>Operationalization Score: 80  </p>

<p>Contains Definition of Actionability: Yes (implicit and partial explicit in Preface)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Mixed Methods (case studies, computational methods, literature reviews)  </p>

<p>Study Context: Multiple diseases (diabetes, COVID-19, tuberculosis, Parkinson’s, cancer), computational analytics, visual analytics, rare disease data contexts  </p>

<p>Geographic/Institutional Context: Australia (primary), multi-country contexts for specific studies  </p>

<p>Target Users/Stakeholders: Clinicians, health policymakers, biomedical researchers, data scientists  </p>

<p>Primary Contribution Type: Conceptual synthesis + applied case studies + methodological frameworks  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Data Driven Science for Clinically Actionable Knowledge in Diseases  </p>

<p><strong>Authors:</strong>  </p>

<p>Daniel R. Catchpoole, Simeon J. Simoff, Paul J. Kennedy, Quang Vinh Nguyen (eds.)  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1201/9781003292357  </p>

<p><strong>Year:</strong>  </p>

<p>2024  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Edited Book  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Health Informatics / Biomedical Data Science  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Data-driven analytics for actionable clinical insights in disease diagnosis, treatment, and policy  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The volume addresses the intersection of computational, biological, and medical sciences, focusing on how data-driven methods can generate <em>clinically actionable knowledge</em> to improve diagnosis, treatment selection, and health policy. It integrates case studies, methodological frameworks, and emerging tools in visual analytics, explainable AI, and multimodal biomedical data processing.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Primarily Australian studies (notably NSW), with global relevance and examples.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Clinicians, health policymakers, biomedical researchers, computational and data scientists.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed methods — applied computational models, literature reviews, methodological frameworks, and empirical case studies.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual and applied synthesis for operationalizing data-driven actionable healthcare insights.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This edited collection explores state-of-the-art computational and visual analytics methods to produce <em>clinically actionable knowledge</em> in disease contexts, from chronic disease management to rare conditions. It includes large-scale cohort studies (e.g., diabetes patient journeys), methodological frameworks for biomedical data analysis, AI-based diagnostic systems, and visual explainability approaches. The Preface frames <em>actionable knowledge</em> as the output of “close-the-loop” analytical processes that improve decision-making, select optimal treatments, and generate clinical certainty. Across ten chapters, the book addresses computational pipelines, harmonization of biomedical imaging, explainable AI, and the human factors of trust and interpretability in healthcare analytics.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as the capacity of data-driven insights to directly support <strong>clinical actions</strong> in real-world settings — improving decisions, specifying diagnoses, selecting treatments, and generating certainty. It is linked to “close the loop” processes, where analytics feed directly into practice and policy.  </p>

<blockquote>
  <p>“…focuses on ‘close the loop’ analytical processes to enrich and lead actionable knowledge” (Preface, p. xiv)  </p>
</blockquote>

<blockquote>
  <p>“…computational and visual analytics… for discovering actionable knowledge in support of clinical actions in real environments” (p. 4)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Direct linkage to clinical decision points  </p></li>
<li><p>Context relevance to patient journeys or population health  </p></li>
<li><p>Timeliness of insights (e.g., early diagnosis or intervention)  </p></li>
<li><p>Interpretability for clinical stakeholders  </p></li>
<li><p>Integration into existing healthcare workflows  </p></li>
<li><p>Feasibility with available data and resources  </p></li>
<li><p>Trustworthiness of analysis outputs  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Close-the-loop analytical process; methodological framework for biomedical data analysis and visualization.  </p></li>
<li><p><strong>Methods/Levers:</strong> Data integration (multi-source clinical, genomic, imaging), computational modeling (ML, statistical), visual analytics, explainable AI, interactive visualization.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Data linkage, feature engineering, model training, interpretable output generation, clinician interaction, iterative feedback.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Linked health records (e.g., Lumos dataset), imaging data, genomic/RNA-seq data, structured/unstructured EHR.  </p></li>
<li><p><strong>Implementation Context:</strong> Clinical decision-making, public health policy, personalized medicine, rare disease management.  </p></li>
</ul>

<blockquote>
  <p>“…integral analysis… for discovering actionable knowledge in support of clinical actions in real environments” (p. 4)  </p>
</blockquote>

<blockquote>
  <p>“…visual analytics… enabling the effective exploration and interpretation of complex biomedical data” (Ch. 8 summary, p. xvii)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><strong>CL (Clarity):</strong> Yes — clear, interpretable outputs required for adoption.  </li>
</ul>

<blockquote>
  <p>“…meaningful visualisation and human–information interaction” (p. xiv)  </p>
</blockquote>

<ul>
<li><strong>CR (Contextual Relevance):</strong> Yes — grounded in specific patient cohorts and health system contexts.  </li>
</ul>

<blockquote>
  <p>“…linked patient records for generating clinically actionable knowledge” (p. xv)  </p>
</blockquote>

<ul>
<li><p><strong>FE (Feasibility):</strong> Yes — focus on methods applicable within real healthcare settings.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — emphasis on early prescriptions, rapid diagnostics, timely policy inputs.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — multiple chapters on explainable ML and visualization (Ch. 9).  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — alignment with improved health outcomes, policy goals.  </p></li>
<li><p><strong>Other Dimensions Named:</strong> Trust, interpretability, user engagement (Ch. 10).</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Close-the-loop analytics in health systems  </p></li>
<li><p>Explainable AI and interpretable ML frameworks  </p></li>
<li><p>Human-information interaction theory  </p></li>
<li><p>Decision support and trust in visualization literature  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Reduction in unplanned hospital admissions  </p></li>
<li><p>Mortality rate changes within defined periods  </p></li>
<li><p>Model accuracy, false positive/negative rates  </p></li>
<li><p>Timeliness of intervention post-diagnosis  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Data silos, inter-site variability, trust issues, lack of interpretability, small sample sizes for rare diseases.  </p></li>
<li><p><strong>Enablers:</strong> Data linkage initiatives (e.g., Lumos), harmonization techniques, visual explainability tools, clinician engagement.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The editors situate their approach within a growing body of work on data-driven healthcare, emphasizing integration of computational modeling with human-centric visualization. They extend prior definitions of actionability by embedding trust, explainability, and workflow integration as necessary conditions.</p>

<hr />

<h2>Summary</h2>

<p>The volume <em>Data Driven Science for Clinically Actionable Knowledge in Diseases</em> synthesizes methods, case studies, and conceptual frameworks for transforming diverse biomedical data into insights that directly inform clinical and policy decisions. Actionability is implicitly defined as the quality of insights that can “close the loop” between analytics and real-world action, requiring contextual relevance, timeliness, clarity, feasibility, and alignment with healthcare goals. Multiple chapters operationalize this via linked datasets, ML pipelines, explainable visualizations, and decision-support frameworks. Notably, it covers both population health analytics and rare disease contexts, demonstrating how technical rigor, interpretability, and stakeholder trust combine to make analytics truly actionable.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 — Strong implicit definition and consistent feature articulation across chapters, though no single unified formal definition.  </p></li>
<li><p><strong>Operationalization Score:</strong> 80 — Multiple concrete frameworks, workflows, and applied cases showing “how to” achieve actionability.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“...for discovering actionable knowledge in support of clinical actions in real environments” (p. 4)  </p></li>
<li><p>“...focuses on ‘close the loop’ analytical processes to enrich and lead actionable knowledge” (p. xiv)  </p></li>
<li><p>“...linked patient records for generating clinically actionable knowledge” (p. xv)  </p></li>
<li><p>“...meaningful visualisation and human–information interaction” (p. xiv)  </p></li>
<li><p>“...guidance on improving interpretability and trust in health models and visualisations” (p. xviii)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>NSW Health Lumos program studies on GP attendance and hospital visits  </p></li>
<li><p>Visual analytics frameworks for biomedical and genomic data  </p></li>
<li><p>Explainable AI surveys and visualization literature in health contexts  </p></li>
<li><p>Machine learning applications for diagnostics and treatment selection</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Creating actionable knowledge one step at a time: An analytical framework for tracing systems and agency in niche innovation pathways  </p>

<p>Authors: Katharina Hölscher, Julia M. Wittmayer, Alfred Olfert, Martin Hirschnitz-Garbers, Jörg Walther, Georg Schiller  </p>

<p>DOI: https://doi.org/10.1016/j.eist.2022.11.007  </p>

<p>Year: 2023  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Sustainability Transitions / Environmental Studies  </p>

<p>Subdomain/Topic: Actionable knowledge, niche innovations, coupled infrastructures, analytical frameworks  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 92  </p>

<p>Operationalization Score: 88  </p>

<p>Contains Definition of Actionability: Yes (explicit and implicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes (linked to understanding innovation dynamics and options for action)  </p>

<p>Contains Interpretability: Yes (narrative/process tracing approach)  </p>

<p>Contains Framework/Model: Yes (multi-dimensional analytical framework)  </p>

<p>Operationalization Present: Yes (four-step analytical process with applied cases)  </p>

<p>Primary Methodology: Mixed Methods (conceptual framework + applied case studies + qualitative interviews)  </p>

<p>Study Context: German infrastructure innovation projects (energy, water, mobility, ICT)  </p>

<p>Geographic/Institutional Context: Germany (national, regional, local policy and practice contexts)  </p>

<p>Target Users/Stakeholders: Policy actors, practitioners, planners, utilities, infrastructure developers  </p>

<p>Primary Contribution Type: Analytical framework for generating actionable knowledge in sustainability transitions  </p>

<p>CL: Yes — clarity in understanding pathways, contexts, and agency is positioned as essential for actionability  </p>

<p>CR: Yes — contextual relevance embedded in system definition, system factors, and agency analysis  </p>

<p>FE: Yes — feasibility linked to technical, institutional, and socio-cultural system factors  </p>

<p>TI: Yes — timeliness addressed via sequencing of development moments and anticipation of opportunities  </p>

<p>EX: Yes — explainability achieved through narrative, process tracing, and explicit system–agency integration  </p>

<p>GA: Yes — goal alignment via sustainability and transformative impact criteria  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Creating actionable knowledge one step at a time: An analytical framework for tracing systems and agency in niche innovation pathways  </p>

<p><strong>Authors:</strong>  </p>

<p>Katharina Hölscher, Julia M. Wittmayer, Alfred Olfert, Martin Hirschnitz-Garbers, Jörg Walther, Georg Schiller  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1016/j.eist.2022.11.007  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Sustainability Transitions / Environmental Studies  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Actionable knowledge, niche innovations, coupled infrastructures, analytical frameworks  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>This paper is situated in sustainability transitions research, focusing on producing knowledge that both explains transition dynamics and supports practical interventions. It introduces an analytical framework designed to make existing transition theories more applicable for policy and practice, especially in developing “coupled” infrastructure solutions in Germany.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Germany; national ministries, federal agencies, municipalities, utilities, and infrastructure developers  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Policy-makers, planners, public utilities, infrastructure developers, practitioners in sustainability transitions  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed Methods — conceptual framework design, applied case studies, qualitative interviews, document analysis  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>A multi-dimensional, practice-oriented analytical framework for tracing niche innovation development pathways to generate actionable knowledge  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors present a stepwise, iterative analytical framework that integrates system-centred and agency-centred perspectives to trace the development pathways of niche innovations. Designed in the context of Germany’s TRAFIS project on coupled infrastructures, the framework identifies critical development moments, system factors, actor roles, and activities, and assesses contributions to sustainability transitions. Applied to three diverse infrastructure cases (wastewater heat utilisation, solar village, virtual power system), the framework yielded actionable knowledge for policy and practice by revealing how innovations evolve, which factors support or hinder them, and how actors mobilise or react to these factors. The paper reflects on knowledge-first and process-oriented uses of the framework, highlighting tensions between complexity and policy usability.  </p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionable knowledge is “knowledge that supports actors’ understanding of how to create transformative change towards sustainability” related to the design, agency, and realisation of actions.  </p>

<blockquote>
  <p>“The generation of actionable knowledge … can be supported through connecting system-centred and agency-centred perspectives into a single analytical framework” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“Our premise was … to offer an understanding of the complex dynamics of niche innovations … and in this way support the formulation of action recommendations” (p. 12)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Integration of system and agency perspectives to reveal both complexity and options for action  </p></li>
<li><p>Clear identification of development pathways, contextual factors, and actor roles  </p></li>
<li><p>Linking insights to sustainability and transformative impact criteria  </p></li>
<li><p>Involving policy and practice actors for contextual relevance and uptake potential  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name:</strong> Analytical framework for tracing systems and agency in niche innovation pathways  </p></li>
<li><p><strong>Methods/Levers:</strong> Process tracing, multi-level perspective (MLP), multi-actor perspective (MAP), multi-level governance (MLG), agency capacities, sustainability assessment  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Define system boundaries and elements  </p>

<p> 2. Identify critical development moments  </p>

<p> 3. Identify system factors influencing those moments  </p>

<p> 4. Identify actors and activities  </p>

<p> 5. Assess sustainability and transformative impact  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Qualitative interviews, grey literature review, sustainability criteria matrix  </p></li>
<li><p><strong>Implementation Context:</strong> German coupled infrastructure innovation projects  </p></li>
</ul>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — understanding pathways, contexts, and roles is essential for actionability.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — system factors and actor roles are analysed in relation to the specific context.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — addresses technical, institutional, and socio-cultural feasibility explicitly.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — development moments mapped over time to identify opportunities and risks.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — narrative and visualisation of pathways aid comprehension.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — explicitly linked to sustainability and transformative goals.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Sustainability impact, transformative impact  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Multi-Level Perspective (MLP)  </p></li>
<li><p>Multi-Actor Perspective (MAP)  </p></li>
<li><p>Multi-Level Governance (MLG)  </p></li>
<li><p>Pathways concept (Leach et al., 2010)  </p></li>
<li><p>Agency capacities frameworks  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Sustainability criteria (performance, resilience, resource efficiency, social/economic viability)  </p></li>
<li><p>Transformative impact (extent of regime challenge/shift)  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Conflicting regulations, institutional misalignment, technological immaturity, financial insecurity, complex stakeholder interests  </p></li>
<li><p><strong>Enablers:</strong> Political leadership, aligned sustainability strategies, funding programmes, technical feasibility, knowledge transfer  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on transition theories but addresses their limited operational utility for practice by integrating system and agency perspectives in a single framework designed for applied contexts.  </p>

<hr />

<h2>Summary</h2>

<p>This paper develops and applies a multi-dimensional analytical framework to generate actionable knowledge for sustainability transitions, focusing on niche innovation pathways in coupled infrastructures. Actionability is conceptualised as the capacity of knowledge to inform transformative action by revealing both systemic complexity and practical levers. The framework operationalises actionability through five iterative steps, supported by established transition concepts (MLP, MAP, MLG). Applied to three German case studies, it identified critical development moments, system factors, actor activities, and sustainability impacts. While effective in generating deep insights, the framework’s complexity posed uptake challenges in policy settings, highlighting the trade-off between nuance and usability. Its strength lies in fostering systemic understanding, anticipatory capacity, and stakeholder reflection — key enablers for transformative action.  </p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Strong conceptual clarity on actionability, explicit integration of features, and robust linkage to sustainability transitions theory.  </p></li>
<li><p><strong>Operationalization Score:</strong> 88 — Fully operationalised with clear steps, data collection methods, and applied cases, though perceived as complex by some end-users.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Actionable knowledge … supports actors’ understanding of how to create transformative change towards sustainability” (p. 2)  </p></li>
<li><p>“The generation of actionable knowledge … can be supported through connecting system-centred and agency-centred perspectives into a single analytical framework” (p. 2)  </p></li>
<li><p>“Our premise was … to offer an understanding of the complex dynamics of niche innovations … and in this way support the formulation of action recommendations” (p. 12)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Caniglia et al. (2020) — pluralistic, integrated approach to action-oriented knowledge  </p></li>
<li><p>Mach et al. (2020) — actionable knowledge and engagement  </p></li>
<li><p>Frantzeskaki &amp; Rok (2018) — co-producing sustainability transitions knowledge  </p></li>
<li><p>Leach et al. (2010) — pathways concept in sustainability  </p></li>
<li><p>Geels &amp; Schot (2007) — MLP in socio-technical transitions</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Coproducing water-energy-food Nexus actionable knowledge: Lessons from a multi-actor collaborative learning school in Uganda, East Africa  </p>

<p>Authors: Djenontin, Ida N.S.; Daher, Bassel; Johnson, Jacob W.; Adule, Kenan; Hishe, Birhanu K.; Kekirunga, Patience; King, Vanessa; Mullaney, Emma Gaalaas; Nimushaba, Patience; Jacobson, Michael G.; Huber-Lee, Annette; Kayendeke, Ellen J.; Konak, Abdullah; Morrone, Vicki L.; Obonyo, Esther; Sanya, Losira N.; Schmitt Olabisi, Laura; Ulloa Jiménez, Silvia; Scott, Christopher A.  </p>

<p>DOI: https://doi.org/10.1016/j.envsci.2025.104028  </p>

<p>Year: 2025  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Environmental Science and Policy  </p>

<p>Subdomain/Topic: Water-Energy-Food Nexus; Transdisciplinary Co-Production; Stakeholder Engagement; Uganda  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 93  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes (implicit, contextualized through co-production process and criteria for pathways to change)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (Collaborative Learning School – CLS)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Mixed Methods (qualitative participatory processes + evaluation surveys)  </p>

<p>Study Context: WEF Nexus in smallholder and peri-urban farming contexts in Uganda; Buikwe District case study  </p>

<p>Geographic/Institutional Context: Uganda – Makerere University collaboration with U.S. and E.U. universities  </p>

<p>Target Users/Stakeholders: Farmers, local authorities, district-level officers, national policymakers, NGOs, extension agents  </p>

<p>Primary Contribution Type: Applied case study and methodological innovation  </p>

<p>CL: Yes — “fit for purpose, including relevance and affordable to the community at stake”  </p>

<p>CR: Yes — “context-driven… pathways for problem-solving-oriented knowledge co-production”  </p>

<p>FE: Yes — “cost-effective (low input and build on existing institutions)”  </p>

<p>TI: Yes — “importance on short, medium, and long-term for farmers’ livelihood”  </p>

<p>EX: Yes — “systems mapping and causal loop diagrams… to understand root causes and interactions”  </p>

<p>GA: Yes — “alignment with district and national goals… considered for integration into existing policies”  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Coproducing water-energy-food Nexus actionable knowledge: Lessons from a multi-actor collaborative learning school in Uganda, East Africa  </p>

<p><strong>Authors:</strong>  </p>

<p>Ida N.S. Djenontin, Bassel Daher, Jacob W. Johnson, Kenan Adule, Birhanu K. Hishe, Patience Kekirunga, Vanessa King, Emma Gaalaas Mullaney, Patience Nimushaba, Michael G. Jacobson, Annette Huber-Lee, Ellen J. Kayendeke, Abdullah Konak, Vicki L. Morrone, Esther Obonyo, Losira N. Sanya, Laura Schmitt Olabisi, Silvia Ulloa Jiménez, Christopher A. Scott  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1016/j.envsci.2025.104028  </p>

<p><strong>Year:</strong>  </p>

<p>2025  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Environmental Science and Policy  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Water-Energy-Food Nexus; Transdisciplinary Co-Production; Stakeholder Engagement; Uganda  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>This paper examines how actionable WEF Nexus knowledge can be co-produced through a <em>Collaborative Learning School</em> (CLS) in Uganda’s Buikwe District. The process integrates systems thinking and design thinking to co-create context-driven solutions across scales—from farmers to national policymakers.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Uganda; collaboration between Makerere University, U.S., and E.U. universities, local NGOs, and government institutions.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Smallholder and peri-urban farmers, agricultural cooperatives, district officers, national ministries, NGOs, extension agents, and academic researchers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed Methods (participatory qualitative processes, systems/design thinking workshops, causal loop diagrams, political economy analysis, post-surveys, and interviews).  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Applied methodological case study demonstrating operational pathways for producing actionable WEF Nexus solutions.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors introduce the <em>Collaborative Learning School</em> (CLS) as a transdisciplinary, multi-actor process for producing actionable WEF Nexus solutions. Tested in Uganda’s Buikwe District, the CLS engages farmers, local/district/national authorities, NGOs, and researchers in a four-phase process: problem identification, systems mapping &amp; solution ideation, solution prototyping, and validation. Using integrated design and systems thinking, the process co-created village-specific “pathways to change” (e.g., cooperatives, farmer field schools, drip irrigation). Political Economy Analysis at district and national levels explored feasibility, scaling, and alignment with policy goals. Evaluations from farmers and policymakers indicate strong perceived value, feasibility, and replicability. The approach demonstrates how context-driven, cross-scale stakeholder engagement can operationalize WEF Nexus theory into actionable, scalable solutions.  </p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is implicitly framed as knowledge and solutions that are:</p>

<ul>
<li><p>Co-created with stakeholders at multiple governance levels.</p></li>
<li><p>Contextually relevant, fit for purpose, and feasible for local adoption.</p></li>
<li><p>Operationalized into implementable “pathways to change” validated by both end-users and decision-makers.  </p></li>
</ul>

<blockquote>
  <p>“…support participatory co-creations of context-driven multi-scalar WEF-Nexus pathways for problem-solving-oriented knowledge co-production” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“…fit for purpose, including relevance and affordable to the community at stake” (p. 7)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Fit for purpose and community relevance.</p></li>
<li><p>Feasibility and affordability using existing institutions.</p></li>
<li><p>Co-created with diverse stakeholders, incorporating local and technical knowledge.</p></li>
<li><p>Sustainability (short, medium, long-term impacts).</p></li>
<li><p>Potential for scaling and policy integration.</p></li>
<li><p>Immediate visible results to build trust.</p></li>
<li><p>Capacity building and intergenerational collaboration.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Collaborative Learning School (CLS)  </p></li>
<li><p><strong>Methods/Levers:</strong> Systems thinking, design thinking, political economy analysis, participatory mapping, cooperative formation, prototype development.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Community problem identification (focus groups, transects, interviews).  </p>

<p> 2. Systems mapping &amp; solution ideation (causal loop diagrams, brainstorming).  </p>

<p> 3. Solution prototyping (physical models).  </p>

<p> 4. Validation (community, district, national workshops).  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Post-evaluation surveys, interviews, observational data, stakeholder feedback on feasibility/sustainability.  </p></li>
<li><p><strong>Implementation Context:</strong> Multi-scalar engagement from local farmers to national ministries.  </p></li>
</ul>

<blockquote>
  <p>“…systems mapping and causal loop diagrams… envisage innovative solutions collaboratively with the stakeholders” (p. 6)  </p>
</blockquote>

<blockquote>
  <p>“…prototyped models… facilitated presenting complex ideas to various stakeholders, furthering understanding and gathering feedback for validation” (p. 7)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL:</strong> Yes — Clarity through shared understanding, visual mapping, and tangible prototypes.  </p></li>
<li><p><strong>CR:</strong> Yes — Solutions directly emerged from locally identified WEF Nexus issues.  </p></li>
<li><p><strong>FE:</strong> Yes — Emphasis on cost-effectiveness and building on existing institutions.  </p></li>
<li><p><strong>TI:</strong> Yes — Importance across short, medium, long-term livelihoods.  </p></li>
<li><p><strong>EX:</strong> Yes — Systems mapping to clarify cause-effect relationships and trade-offs.  </p></li>
<li><p><strong>GA:</strong> Yes — District and national alignment discussed and sought for integration.  </p></li>
<li><p><strong>Other Dimensions:</strong> Trust-building, inclusivity, capacity development.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>WEF Nexus framework.  </p></li>
<li><p>Systems thinking (causal loop diagrams, holistic problem framing).  </p></li>
<li><p>Design thinking (human-centered iterative problem-solving).  </p></li>
<li><p>Political Economy Analysis.</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Stakeholder-perceived feasibility, relevance, and alignment with goals.  </p></li>
<li><p>Willingness to implement and allocate resources.  </p></li>
<li><p>Immediate visible results to build trust.</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p><strong>Barriers:</strong>  </p>

<ul>
<li><p>Limited access to extension services.  </p></li>
<li><p>Lack of farmer cooperation.  </p></li>
<li><p>Gaps between community priorities and national programs.  </p></li>
<li><p>Funding constraints.  </p></li>
<li><p>Weak communication channels between governance levels.  </p></li>
</ul>

<p><strong>Enablers:</strong>  </p>

<ul>
<li><p>Cooperative formation and farmer organization.  </p></li>
<li><p>Integration into existing policy frameworks.  </p></li>
<li><p>Multi-level stakeholder engagement.  </p></li>
<li><p>Local knowledge and technical expertise integration.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The CLS builds on farmer field school approaches, transdisciplinary WEF Nexus research, and co-production theory. It extends these by integrating design and systems thinking with explicit multi-scalar governance engagement, filling operationalization gaps noted in prior WEF Nexus critiques.</p>

<hr />

<h2>Summary</h2>

<p>This paper offers a fully articulated, operational framework (CLS) for producing actionable WEF Nexus knowledge. Actionability is embedded in the co-creation process, which ensures contextual relevance, feasibility, and alignment with governance structures. The CLS integrates systems and design thinking, causal loop diagrams, cooperative-based solutions, and political economy analysis to generate and validate multi-scalar “pathways to change.” The approach not only conceptualizes actionability but also operationalizes it through tangible prototypes, cross-scale workshops, and feedback loops. Barriers (e.g., extension service gaps, policy disconnects) are acknowledged, with enablers identified to enhance adoption and scaling. The result is a transferable methodology with demonstrated potential for replication in similar contexts.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 93 — Strong implicit definition of actionability, detailed features tied to the concept, clear alignment with WEF Nexus theory and stakeholder co-production literature.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Provides a concrete, tested, and replicable process with clear steps, tools, and multi-scalar engagement mechanisms.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[CLS]…support participatory co-creations of context-driven multi-scalar WEF-Nexus pathways for problem-solving-oriented knowledge co-production” (p. 1)  </p></li>
<li><p>“Fit for purpose, including relevance and affordable to the community at stake” (p. 7)  </p></li>
<li><p>“Systems mapping and causal loop diagrams… envisage innovative solutions collaboratively with the stakeholders” (p. 6)  </p></li>
<li><p>“Prototyped models… facilitated presenting complex ideas to various stakeholders, furthering understanding and gathering feedback for validation” (p. 7)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Djenontin &amp; Meadow (2018) — Co-production guidance.  </p></li>
<li><p>Naidoo et al. (2021) — WEF Nexus operationalization methodology.  </p></li>
<li><p>Hamidov et al. (2022) — Nexus summer school model.  </p></li>
<li><p>Johnson &amp; Karlberg (2017) — Participatory WEF modeling.  </p></li>
<li><p>Purwanto et al. (2019); Rich et al. (2018) — Group model building and stakeholder engagement in Nexus contexts.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Conceptual Framework for Prescriptive Analytics Based on Decision Theory in Smart Factories  </p>

<p>Authors: Julian Weller, Martin Kohlhase, Nico Migenda, Wolfram Schenck, Arthur Wegel, Roman Dumitrescu  </p>

<p>DOI: 10.1109/ADACIS59737.2023.10424368  </p>

<p>Year: 2023  </p>

<p>Publication Type: Conference  </p>

<p>Discipline/Domain: Industrial Engineering / Data Analytics  </p>

<p>Subdomain/Topic: Prescriptive Analytics, Decision Theory, Smart Factories  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 80  </p>

<p>Contains Definition of Actionability: Yes (implicit via prescriptive analytics definition and decision theory integration)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: No explicit mention  </p>

<p>Contains Framework/Model: Yes (four-step conceptual framework)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual + Literature Review  </p>

<p>Study Context: Prescriptive analytics for decision-making in smart factories, integrating decision theory and data-driven approaches  </p>

<p>Geographic/Institutional Context: Germany (Fraunhofer Institute, Bielefeld University of Applied Sciences)  </p>

<p>Target Users/Stakeholders: Researchers, industrial practitioners, smart factory decision-makers  </p>

<p>Primary Contribution Type: Conceptual framework  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Partial  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Conceptual Framework for Prescriptive Analytics Based on Decision Theory in Smart Factories  </p>

<p><strong>Authors:</strong>  </p>

<p>Julian Weller, Martin Kohlhase, Nico Migenda, Wolfram Schenck, Arthur Wegel, Roman Dumitrescu  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1109/ADACIS59737.2023.10424368  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Industrial Engineering / Data Analytics  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Prescriptive Analytics, Decision Theory, Smart Factories  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the lack of a comprehensive conceptual framework for prescriptive analytics in smart factories, emphasizing the integration of decision theory to enhance actionable decision-making in manufacturing environments.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Germany; Fraunhofer Institute for Mechatronic Systems Design, Bielefeld University of Applied Sciences  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Researchers, industrial data scientists, manufacturing process engineers, smart factory decision-makers  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual + structured literature review  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors propose a four-step conceptual framework for prescriptive analytics in smart factories, grounded in decision theory and supported by literature-derived requirements. The work bridges human-centric prescriptive decision theory and data-driven prescriptive analytics to better structure and modularize decision-making processes. The framework—comprising Conditional Trigger, Prescription (assessment and selection), and Execution—ensures adaptability, modularity, and feedback integration. It accounts for decision complexity, environmental constraints, and various degrees of automation. While the framework is validated against multiple use cases, the authors note limitations such as dependency on high-quality data and the need for further methodology to select implementation strategies.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as the capacity of prescriptive analytics to provide data-driven, context-aware recommendations that enable or automate decision-making in real-world smart factory environments. This integrates the “prescriptive” element from decision theory—offering concrete decision options—into analytics systems.  </p>

<blockquote>
  <p>“Prescriptive analytics… examines data or content to answer the question: What should be done?” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“The conceptual framework… aims at optimizing decision-making processes integrating knowledge extracted from data in alignment with… strategies and goals.” (p. 1)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Clear decision triggers linked to validated data</p></li>
<li><p>Contextual alignment with factory strategies, constraints, and operational goals</p></li>
<li><p>Feasible and implementable prescriptions within environmental constraints</p></li>
<li><p>Ability to select among alternatives and adapt via feedback loops</p></li>
<li><p>Modularity to suit various decision types (structured, semi-structured, unstructured)</p></li>
<li><p>Support for different levels of automation and human-machine collaboration</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Four-Step Conceptual Framework for Prescriptive Analytics in Smart Factories  </p></li>
<li><p><strong>Methods/Levers:</strong> Integration of decision theory models (Simon, Panagiotou), data analytics maturity levels (Gartner), modular architecture, feedback loops  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. <strong>Conditional Trigger</strong> – Identify and validate decision triggers from system data (descriptive, diagnostic, predictive analytics)  </p>

<p> 2. <strong>Prescription</strong> – Assess alternatives using a knowledge representation; select optimal prescription  </p>

<p> 3. <strong>Execution</strong> – Implement or automate decision; optional feedback loop for learning  </p>

<p> 4. <strong>Knowledge Representation</strong> – Central repository of decision-relevant constraints, strategies, and system characteristics  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Historical, live, or batch data; system characteristics; performance metrics for feedback loops  </p></li>
<li><p><strong>Implementation Context:</strong> Smart factory decision processes (quality, production, maintenance, logistics)  </p></li>
</ul>

<blockquote>
  <p>“A prescription is only valid if the trigger is valid… alternatives… drawn from a given knowledge representation…” (p. 4)  </p>
</blockquote>

<blockquote>
  <p>“An optional feedback loop… create a learning system… the decision-effect relation serves as a parameter changing the current system under observation.” (p. 4)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – Decisions must be explicit and grounded in validated triggers.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – Must incorporate strategies, constraints, and environmental context.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – Prescriptions must be implementable under given constraints.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial – Framework implies real-time or near-real-time potential but not as a formal requirement.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial – Knowledge representation enables traceability, but explicit explainability mechanisms are not detailed.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – Explicit integration with operational and strategic goals.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Modularity, adaptability, automation flexibility.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Decision Theory (normative, descriptive, prescriptive approaches)</p></li>
<li><p>Simon’s intelligence-design-choice-implementation model</p></li>
<li><p>Panagiotou’s goal-driven framework</p></li>
<li><p>Gartner’s analytics maturity model</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Validity of triggers  </p></li>
<li><p>Performance of implemented prescriptions  </p></li>
<li><p>Feedback loop outcomes (accuracy, efficiency, goal alignment)  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Data quality issues; lack of methodology for selecting implementation strategy; unclear automation integration; insufficient domain-specific case study evidence  </p></li>
<li><p><strong>Enablers:</strong> Modular architecture; adaptability across decision types; integration of human and machine decision-making; knowledge representation  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper uniquely integrates prescriptive decision theory concepts into prescriptive analytics for smart factories—a gap identified in prior work. It diverges from the prevalent case-study and algorithm-focused literature by providing a structured, domain-specific conceptual framework.</p>

<hr />

<h2>Summary</h2>

<p>This paper presents a structured four-step framework for prescriptive analytics in smart factories, integrating principles from prescriptive decision theory to enhance actionability. By linking validated decision triggers to context-aware prescriptions and executable actions, the framework emphasizes clarity, contextual relevance, feasibility, goal alignment, and adaptability. Knowledge representation and feedback loops enable iterative improvement and modular application across different decision types and automation levels. While the framework offers strong conceptual grounding and operational guidance, limitations include reliance on high-quality data, absence of a full implementation methodology, and need for further case-based validation. The work advances the understanding of actionability by connecting human-centric decision theory with data-driven analytics in manufacturing.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 – Strong implicit and explicit articulation of actionability features; clear integration of decision theory principles.  </p></li>
<li><p><strong>Operationalization Score:</strong> 80 – Provides detailed, adaptable workflow steps but lacks complete methodological guidelines for implementation.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Prescriptive Analytics… examines data or content to answer the question: What should be done?” (p. 1)  </p></li>
<li><p>“The conceptual framework needs to incorporate existing and established patterns of decision making… Possible learning and feedback loops…” (p. 3)  </p></li>
<li><p>“A pres</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Competitive intelligence embeddedness: Drivers and performance consequences  </p>

<p>Authors: Amiram Markovich, Kalanit Efrat, Daphne R. Raban, Anne L. Souchon  </p>

<p>DOI: https://doi.org/10.1016/j.emj.2019.04.003  </p>

<p>Year: 2019  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Management / Marketing / Information &amp; Knowledge Management  </p>

<p>Subdomain/Topic: Competitive Intelligence (CI), Knowledge Management, Organizational Capabilities  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 85  </p>

<p>Operationalization Score: 80  </p>

<p>Contains Definition of Actionability: Yes (explicit link to actionable knowledge in CI process)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: No explicit mention  </p>

<p>Contains Framework/Model: Yes (CI Embeddedness conceptual model with antecedents and consequences)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Quantitative (Survey, SEM)  </p>

<p>Study Context: Competitive Intelligence use in Israeli firms  </p>

<p>Geographic/Institutional Context: Israel; firms with ≥10 employees and annual sales ≥ $1M  </p>

<p>Target Users/Stakeholders: Managers, decision-makers, CI practitioners, knowledge managers  </p>

<p>Primary Contribution Type: Empirical model testing antecedents and effects of CI Embeddedness  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: No  </p>

<p>TI: No  </p>

<p>EX: Partial  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Competitive intelligence embeddedness: Drivers and performance consequences  </p>

<p><strong>Authors:</strong>  </p>

<p>Amiram Markovich, Kalanit Efrat, Daphne R. Raban, Anne L. Souchon  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1016/j.emj.2019.04.003  </p>

<p><strong>Year:</strong>  </p>

<p>2019  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Management / Marketing / Information &amp; Knowledge Management  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Competitive Intelligence (CI), Knowledge Management, Organizational Capabilities  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The study addresses how competitive intelligence (CI) becomes embedded into organizational processes and culture — termed Competitive Intelligence Embeddedness (CIE) — and how this embeddedness influences performance outcomes, particularly through customer satisfaction.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Israeli firms, spanning SMEs and large corporations, across various industries.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Managers, decision-makers, CI practitioners, competitive strategy teams, knowledge managers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative survey of 124 mid- and senior-level managers, analyzed with Structural Equation Modeling (SEM).  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical testing of a conceptual model linking antecedents (information quality, alliances, biased use types) to CIE and performance outcomes.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper conceptualizes and measures Competitive Intelligence Embeddedness (CIE) as the degree to which competitive intelligence processes permeate an organization’s culture, decision-making, and daily routines. Using data from 124 managers in Israeli firms, the study examines how perceived quality of web-based CI sources and various forms of information use (including alliances with information providers and biased uses) influence CIE. Findings show that both “Analyze” and “Formal” categories of web source quality and alliances with information providers significantly enhance CIE, while resistance, inaccuracy, and political use of information do not. CIE positively impacts customer satisfaction but not directly firm performance; instead, customer satisfaction partially mediates the CIE–performance link. The study situates CIE within the knowledge management and capabilities frameworks, highlighting managerial implications for fostering CI culture and processes.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as the transformation of competitive and market data into <em>actionable strategic knowledge</em> that enables informed decision-making and competitive advantage. CIE ensures that such actionable knowledge permeates the organization so that decisions are consistently informed by relevant competitive information.  </p>

<blockquote>
  <p>“Competitive intelligence (CI) is a process that produces and disseminates actionable information… in order to help managers in decision-making and to achieve a competitive advantage” (p. 708).  </p>
</blockquote>

<blockquote>
  <p>“CI embeddedness… so that strategic and tactical decisions can be made in the knowledge of all relevant external competitive information” (p. 708).  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Integration into daily routines and organizational culture.</p></li>
<li><p>Awareness and acceptance of CI by decision-makers and employees.</p></li>
<li><p>Support from senior management (legitimacy, resources, accountability).</p></li>
<li><p>High perceived quality of information sources.</p></li>
<li><p>Timely dissemination to relevant organizational levels.</p></li>
<li><p>Goal alignment with competitive positioning and customer satisfaction.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> CI Embeddedness (CIE) Capability Model.  </p></li>
<li><p><strong>Methods/Levers:</strong> Use of high-quality web CI sources (“Analyze” and “Formal”), alliances with information providers, knowledge management practices, cultural integration.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Assess and source high-quality competitive intelligence from web-based sources.  </p>

<p> 2. Build strategic alliances with reliable information providers.  </p>

<p> 3. Embed CI dissemination processes across organizational levels.  </p>

<p> 4. Integrate CI into both strategic and tactical decision-making.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Likert-scale survey assessing web source quality, information use patterns, CIE presence, customer satisfaction, and firm performance.  </p></li>
<li><p><strong>Implementation Context:</strong> Multi-industry Israeli firms with active CI functions.  </p></li>
</ul>

<blockquote>
  <p>“CIE… refers to the incorporation of CI awareness and processes in the firm… Various staff levels are aware of the importance of information about competitors” (p. 711).  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> <strong>Yes</strong> — Clear, accessible dissemination to relevant levels.  </p>

<p> &gt; “…distribution of reviews on competitors and managers’ awareness of CI’s importance” (p. 711).</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> <strong>Yes</strong> — Tailoring to competitive environment and organizational needs.  </p>

<p> &gt; “…so that strategic and tactical decisions can be made in the knowledge of all relevant… information” (p. 708).</p></li>
<li><p><strong>FE (Feasibility):</strong> <strong>No explicit link</strong> — Feasibility implied via integration into existing processes, but not labeled as an actionability criterion.  </p></li>
<li><p><strong>TI (Timeliness):</strong> <strong>No explicit link</strong> — Speed emphasized in web sourcing but not framed as a necessary actionability condition.  </p></li>
<li><p><strong>EX (Explainability):</strong> <strong>Partial</strong> — Actionable knowledge is implied to be understandable and interpretable by decision-makers.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> <strong>Yes</strong> — Linked to customer satisfaction and competitive advantage.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Alliances, perceived information quality, organizational culture, management support.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Resource-Based View (RBV) — CIE as a firm-specific capability.  </p></li>
<li><p>Knowledge Management Framework.  </p></li>
<li><p>Intelligence Cycle (planning, collection, analysis, communication).</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Degree of CI awareness at various staff levels.  </p></li>
<li><p>Distribution frequency and coverage of CI reports.  </p></li>
<li><p>Perceived quality scores of information sources.  </p></li>
<li><p>Customer satisfaction indices (loyalty, complaint rates).  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Information overload, political or inaccurate use of information, resistance to information.  </p></li>
<li><p><strong>Enablers:</strong> High-quality CI sources, strong alliances with providers, management support, cultural integration.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on Bernhardt (1994) definition of CI as producing actionable knowledge, integrates CI with knowledge management literature, and extends prior studies on web source quality by linking it to organizational culture and embeddedness.</p>

<hr />

<h2>Summary</h2>

<p>The paper introduces Competitive Intelligence Embeddedness (CIE) as a capability ensuring actionable competitive insights permeate organizational decision-making. Actionability is understood as the transformation and integration of competitive data into knowledge that informs strategic and tactical choices. The study operationalizes CIE through quality web sources, alliances with information providers, and organizational processes that ensure broad dissemination and awareness. Empirical results confirm that perceived web source quality and alliances significantly enhance CIE, which improves customer satisfaction — a mediator of firm performance. This work advances understanding of actionability by tying it to organizational culture, knowledge management, and performance outcomes.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 — Strong conceptual and empirical articulation of actionability within CI, with explicit criteria and cultural embedding.  </p></li>
<li><p><strong>Operationalization Score:</strong> 80 — Clear model, measurement, and implementation steps for embedding actionable intelligence; could improve on timeliness and feasibility criteria.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Competitive intelligence… produces and disseminates actionable information… to help managers in decision-making” (p. 708).  </p></li>
<li><p>“CIE… so that strategic and tactical decisions can be made in the knowledge of all relevant… information” (p. 708).  </p></li>
<li><p>“Perceived quality of Web information sources is positively related to competitive intelligence embeddedness” (p. 711).  </p></li>
<li><p>“Alliances with information providers… positively related to competitive intelligence embeddedness” (p. 711).  </p></li>
<li><p>“CIE showed the expected positive influence on customer satisfaction” (p. 712).  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Bernhardt (1994) — Actionable strategic knowledge definition.  </p></li>
<li><p>Saayman et al. (2008) — Organizational culture and CI support.  </p></li>
<li><p>Ho (2008) — Linking learning, knowledge management, and performance.  </p></li>
<li><p>Rouach &amp; Santi (2001) — CI as a capability for competitive advantage.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: CARE: Coherent Actionable Recourse based on Sound Counterfactual Explanations  </p>

<p>Authors: Peyman Rasouli, Ingrid Chieh Yu  </p>

<p>DOI: https://doi.org/10.1145/nnnnnnn.nnnnnnn  </p>

<p>Year: 2021  </p>

<p>Publication Type: Conference  </p>

<p>Discipline/Domain: Computer Science / Artificial Intelligence  </p>

<p>Subdomain/Topic: Interpretable Machine Learning, Counterfactual Explanations, Actionable Recourse  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual with empirical evaluation  </p>

<p>Study Context: Model-agnostic counterfactual and recourse generation for classification and regression on tabular data  </p>

<p>Geographic/Institutional Context: University of Oslo, Norway  </p>

<p>Target Users/Stakeholders: End-users seeking actionable guidance from ML predictions; researchers in explainable AI  </p>

<p>Primary Contribution Type: Modular explanation framework (CARE) integrating model-level and user-level constraints for actionable recourse  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: No  </p>

<p>EX: Partial  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong> CARE: Coherent Actionable Recourse based on Sound Counterfactual Explanations  </p>

<p><strong>Authors:</strong> Peyman Rasouli, Ingrid Chieh Yu  </p>

<p><strong>DOI:</strong> https://doi.org/10.1145/nnnnnnn.nnnnnnn  </p>

<p><strong>Year:</strong> 2021  </p>

<p><strong>Publication Type:</strong> Conference  </p>

<p><strong>Discipline/Domain:</strong> Computer Science / Artificial Intelligence  </p>

<p><strong>Subdomain/Topic:</strong> Interpretable Machine Learning, Counterfactual Explanations, Actionable Recourse  </p>

<p><strong>Contextual Background:</strong> The paper addresses the limitations of existing counterfactual explanation methods in machine learning by introducing a modular, multi-objective optimization framework (CARE) that generates actionable recourse grounded in realistic, coherent, and user-specific constraints.  </p>

<p><strong>Geographic/Institutional Context:</strong> University of Oslo, Norway  </p>

<p><strong>Target Users/Stakeholders:</strong> ML end-users needing recourse (e.g., loan applicants), explainable AI researchers  </p>

<p><strong>Primary Methodology:</strong> Conceptual with empirical evaluation  </p>

<p><strong>Primary Contribution Type:</strong> New modular framework for counterfactual and recourse generation</p>

<h2>General Summary of the Paper</h2>

<p>The authors propose CARE, a modular, model-agnostic explanation framework for generating actionable recourse based on sound counterfactual explanations. CARE integrates four modules—Validity, Soundness, Coherency, and Actionability—organized hierarchically to address both model-level and user/domain-level requirements. Validity ensures minimal changes for achieving the desired outcome; Soundness enforces proximity and connectedness to real data; Coherency preserves correlations between features; and Actionability incorporates user-defined constraints with importance weights. Using a multi-objective optimization approach (NSGA-III), CARE generates multiple, diverse counterfactuals for classification and regression tasks with mixed data types. Experiments on standard datasets show CARE’s superior performance in realism, coherency, and user compliance compared to DiCE and CFPrototype.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionability is defined as satisfying global and local user/domain-specific preferences through constraints on features (e.g., immutable/mutable status, value ranges), enabling recourse that is realistic, feasible, and aligned with the user’s circumstances.  </p>

<blockquote>
  <p>“A counterfactual should satisfy some global and local preferences that are domain-specific and defined by the end-user.” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“An actionable explanation… takes into account the user’s preferences containing the name of mutable/immutable features, possible values, and their importance…” (p. 3)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Alignment with user-specified constraints (mutable/immutable features, allowed ranges/values)</p></li>
<li><p>Preservation of feature coherency under constraints</p></li>
<li><p>Feasibility in real-world terms (not recommending impossible changes)</p></li>
<li><p>Respecting constraint importance (prioritizing non-violable constraints)</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> CARE  </p></li>
<li><p><strong>Methods/Levers:</strong> Modular hierarchy with four modules; multi-objective optimization using NSGA-III  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. <strong>VALIDITY:</strong> Enforce minimal, sparse changes to achieve the desired outcome.  </p>

<p> 2. <strong>SOUNDNESS:</strong> Ensure proximity and connectedness to real, same-class data points.  </p>

<p> 3. <strong>COHERENCY:</strong> Use correlation models to preserve feature relationships.  </p>

<p> 4. <strong>ACTIONABILITY:</strong> Apply user-defined constraints with importance weighting.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Gower distance, Local Outlier Factor, HDBSCAN clustering, correlation measures (Pearson’s R, Cramer’s V), constraint satisfaction checks.  </p></li>
<li><p><strong>Implementation Context:</strong> Model-agnostic; applicable to tabular classification/regression; handles mixed features.  </p></li>
</ul>

<blockquote>
  <p>“We propose a constraint language… and the notion of constraint importance to weigh the constraints according to their importance for the user.” (p. 6)  </p>
</blockquote>

<blockquote>
  <p>“CARE… generates actionable recourse by fulfilling the mentioned desiderata through objective functions organized in a modular hierarchy…” (p. 2)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — minimal, interpretable feature changes improve understandability (p. 3).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — proximity and connectedness ensure alignment with domain data (p. 2).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — coherent changes preserve real-world plausibility (p. 2–3).  </p></li>
<li><p><strong>TI (Timeliness):</strong> No — not explicitly addressed.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — explanations are inherent but focus is on actionable counterfactuals, not full causal interpretability.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — constraints ensure user goals/preferences are respected (p. 6).  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Coherency, proximity, connectedness.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Counterfactual explanations in XAI (Wachter et al., 2017)  </p></li>
<li><p>Proximity and connectedness metrics (Laugel et al., 2019)  </p></li>
<li><p>Actionable recourse frameworks (Ustun et al., 2019; Karimi et al., 2020)  </p></li>
<li><p>Multi-objective optimization (NSGA-III)</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Actionability cost (sum of violated constraint importance values)</p></li>
<li><p>Proximity and connectedness scores to assess plausibility</p></li>
<li><p>Coherency rate (preservation of feature correlations)</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Conflicting constraints; lack of coherent feature changes; artifacts in model space (p. 2–3).  </p></li>
<li><p><strong>Enablers:</strong> Modular structure allowing selective enforcement of properties; weighting of constraints by importance; correlation-based coherency preservation.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>The paper extends prior counterfactual explanation methods by integrating seldom-addressed properties (connectedness, coherency) with actionability. Unlike works that equate proximity with connectedness, CARE treats them as complementary. It also operationalizes coherency, which previous methods neglected.</p>

<h2>Summary</h2>

<p>CARE is a modular, model-agnostic framework for generating actionable recourse grounded in sound counterfactual explanations. It operationalizes four hierarchical properties—Validity, Soundness, Coherency, and Actionability—through specific objective functions optimized via NSGA-III. Validity ensures minimal, sparse changes; Soundness enforces proximity and connectedness to real, same-class data; Coherency preserves correlations between features; and Actionability integrates user-defined constraints with importance weighting. The approach applies to both classification and regression tasks with mixed-feature datasets. Empirical results show CARE outperforms DiCE and CFPrototype in producing coherent, realistic, and user-compliant recourse while maintaining diversity. The framework can serve as a benchmark for future actionable recourse research.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Provides explicit and nuanced definition of actionability with multiple properties tied to it; integrates underexplored aspects like coherency.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Fully details how to implement actionability in practice through constraints, optimization, and evaluation metrics.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“A counterfactual should satisfy some global and local preferences that are domain-specific and defined by the end-user.” (p. 2)  </p></li>
<li><p>“We introduce a novel notion of actionability that can cover various constraints and prioritize different preferences.” (p. 2)  </p></li>
<li><p>“Our proposed objective function… computes the actionability cost… according to the user’s preference.” (p. 6)  </p></li>
<li><p>“An actionable explanation… takes into account the user’s preferences containing the name of mutable/immutable features, possible values, and their importance…” (p. 3)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Ustun, Spangher, Liu (2019) — Actionable recourse in linear classification  </p></li>
<li><p>Karimi et al. (2020) — Algorithmic recourse  </p></li>
<li><p>Wachter et al. (2017) — Counterfactual explanations  </p></li>
<li><p>Laugel et al. (2019) — Proximity and connectedness in counterfactuals  </p></li>
<li><p>Dandl et al. (2020) — Multi-objective counterfactual explanations</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Bridging the knowledge–action gap: A framework for co-producing actionable knowledge  </p>

<p>Authors: Aleksi Räsänen, Simo Sarkki, Olli Haanpää, Maria Isolahti, Hanna Kekkonen, Karoliina Kikuchi, Ville Koukkari, Katri Kärk­käinen, Janne Miettinen, Erkki Mäntymaa, Mika Nieminen, Riina Rahkila, Anna Ruohonen, Sakari Sarkkola, Matti Välimäki, Kaisa Yliperttula, Hannu I. Heikkinen  </p>

<p>DOI: https://doi.org/10.1016/j.envsci.2024.103929  </p>

<p>Year: 2024  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Environmental Science / Sustainability Science  </p>

<p>Subdomain/Topic: Knowledge co-production, catchment governance, transdisciplinary research  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 92  </p>

<p>Contains Definition of Actionability: Yes (explicit and process-based)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (three-process integrated framework)  </p>

<p>Operationalization Present: Yes (nine-step, four-phase process)  </p>

<p>Primary Methodology: Mixed Methods (qualitative, quantitative, participatory, collaborative autoethnography)  </p>

<p>Study Context: Transdisciplinary project in Kiiminkijoki river catchment, Finland  </p>

<p>Geographic/Institutional Context: Northern Finland; multiple municipalities and stakeholder groups  </p>

<p>Target Users/Stakeholders: Researchers, policymakers, local communities, administrative bodies, civil society, landowners  </p>

<p>Primary Contribution Type: Conceptual framework + empirical case study  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Partial  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Bridging the knowledge–action gap: A framework for co-producing actionable knowledge</p>

<p><strong>Authors:</strong>  </p>

<p>Aleksi Räsänen et al.</p>

<p><strong>DOI:</strong>  </p>

<p><a href="https://doi.org/10.1016/j.envsci.2024.103929">10.1016/j.envsci.2024.103929</a></p>

<p><strong>Year:</strong>  </p>

<p>2024</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Environmental Science / Sustainability Science</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Knowledge co-production, catchment governance, transdisciplinary research</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses how transdisciplinary research can bridge the persistent gap between knowledge generation and real-world action, specifically in environmental management. The case study focuses on sustainable land-use planning and governance in the Kiiminkijoki river catchment, Finland.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Northern Finland, involving municipal authorities, NGOs, research institutions, and local landowners.</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Researchers, policymakers, local communities, administrative actors, civil society groups, landowners, and interest organizations.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed Methods — qualitative interviews, participatory workshops, GIS analysis, forestry simulations, literature review, and collaborative autoethnography.</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework integrated with empirical application.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors critique the dominant output-focused concept of actionable knowledge and instead conceptualize it as a continuous process that is <strong>cumulative, iterative, and coevolutionary</strong>. Using a transdisciplinary case study in the Kiiminkijoki river catchment, they integrate three perspectives—knowledge accumulation, iterative feedback cycles, and knowledge–action coevolution—into a unified framework. They operationalize this via a <strong>four-phase process</strong> (making sense together, validation, usable outputs, boundary spanning) and a <strong>nine-step roadmap</strong> for actionable knowledge co-production. Empirical findings show that meaningful action emerged throughout the process, not just after final outputs. The framework is proposed as a generalizable approach for bridging the knowledge–action gap in sustainability transformations.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionable knowledge is defined as a <strong>process</strong>—not merely outputs—characterized by:</p>

<ol>
<li><p><strong>Cumulative and stepwise</strong> phases that build towards catalyzing action.</p></li>
<li><p><strong>Iterative and cyclical</strong> interactions that allow reframing and adaptation.</p></li>
<li><p><strong>Coevolutionary</strong> dynamics where knowledge and action continuously shape each other.  </p></li>
</ol>

<blockquote>
  <p>“We instead propose to understand actionable knowledge as a process that has (1) cumulative and stepwise, (2) iterative and cyclical, and (3) coevolutionary characteristics.” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“Actionable knowledge… is not the output per se but the process of actionable knowledge production and use.” (p. 11)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Integration of diverse knowledge systems (scientific, local, administrative).</p></li>
<li><p>Co-definition of problems aligned with societal agendas.</p></li>
<li><p>Societal validation and experimentation (pilots, participatory assessments).</p></li>
<li><p>Usable, solution-oriented outputs grounded in co-production.</p></li>
<li><p>Boundary spanning to sustain momentum and coordinate across actors.</p></li>
<li><p>Contextual alignment with stakeholder values, priorities, and governance structures.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p><strong>Framework/Approach Name(s):</strong>  </p>

<p>Four-phase process + Nine-step roadmap</p>

<p><strong>Methods/Levers:</strong>  </p>

<p>Participatory workshops, semi-structured interviews, GIS analysis, forestry simulations, pilot projects, collaborative autoethnography.</p>

<p><strong>Operational Steps / Workflow:</strong>  </p>

<ol>
<li><p>Problem definition  </p></li>
<li><p>Stakeholder identification  </p></li>
<li><p>Background data collection  </p></li>
<li><p>Pilot measures for validation  </p></li>
<li><p>Visioning desirable futures  </p></li>
<li><p>Impact assessment of measures  </p></li>
<li><p>Stakeholder deliberation of results  </p></li>
<li><p>Synthesis into roadmap  </p></li>
<li><p>Establishment of catchment coordinator (boundary spanning)</p></li>
</ol>

<p><strong>Data &amp; Measures:</strong>  </p>

<p>GIS spatial datasets, water quality data, forestry growth and carbon simulations, participatory mapping, survey responses.</p>

<p><strong>Implementation Context:</strong>  </p>

<p>Catchment-scale land-use governance with overlapping environmental, social, and economic objectives.</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Roadmap synthesis reduced complexity into accessible format.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Problem reframed to match local water quality priorities.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Measures assessed for technical, social, and economic viability.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Iterative process responsive to emerging opportunities, but long-term cycles acknowledged.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — Process transparency emphasized; less focus on formal explainability metrics.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Co-defined goals and integration of stakeholder visions.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Legitimacy, credibility, usability, and societal validation.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Cash et al. (2003) attributes of knowledge (credibility, legitimacy, relevance)  </p></li>
<li><p>Co-production and social robustness literature (Nowotny 2003; Roux et al. 2006)  </p></li>
<li><p>Coevolutionary theory (Jasanoff 2004; Klenk 2018)  </p></li>
<li><p>Transdisciplinary research cycle models (Jahn et al. 2012; Hoffmann et al. 2019)  </p></li>
<li><p>Meshwork concept (Deleuze &amp; Guattari 1987; Ingold 2011)</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Uptake and implementation of roadmap measures.</p></li>
<li><p>Establishment of a permanent catchment coordinator.</p></li>
<li><p>Stakeholder engagement breadth and continuity.</p></li>
<li><p>Reduction in environmental impact indicators (modeled/monitored).</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p><strong>Barriers:</strong>  </p>

<ul>
<li><p>Divergent priorities (e.g., climate vs. water quality).  </p></li>
<li><p>Limited scientific certainty for some measures.  </p></li>
<li><p>Fragmented governance and land ownership.  </p></li>
<li><p>Resistance from economically focused actors.</p></li>
</ul>

<p><strong>Enablers:</strong>  </p>

<ul>
<li><p>Early stakeholder engagement and trust building.  </p></li>
<li><p>Pilot projects demonstrating feasibility.  </p></li>
<li><p>Clear, co-created vision and roadmap.  </p></li>
<li><p>Dedicated boundary spanning role.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions itself against the dominant “knowledge-first” linear model by integrating cumulative, iterative, and coevolutionary approaches into a unified process model. Extends frameworks such as Holscher et al. (2023) by embedding them in a concrete procedural roadmap.</p>

<hr />

<h2>Summary</h2>

<p>This paper reconceptualizes actionable knowledge as an ongoing process rather than discrete outputs. Using a Finnish catchment management project, it shows how cumulative knowledge building, iterative feedback loops, and coevolutionary dynamics can operate simultaneously. Actionability is achieved through integrating diverse knowledge systems, aligning with local priorities, validating through pilots, producing usable outputs, and sustaining coordination via boundary spanning. The nine-step roadmap operationalizes this in practice. The proposed framework is generalizable to other sustainability transformation contexts.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Strong conceptualization of actionability with explicit process framing, linked to features and attributes; grounded in empirical detail.  </p></li>
<li><p><strong>Operationalization Score:</strong> 92 — Clear nine-step, four-phase operationalization with concrete methods, though long-term impact evaluation is pending.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We instead propose to understand actionable knowledge as a process that has (1) cumulative and stepwise, (2) iterative and cyclical, and (3) coevolutionary characteristics.” (p. 1)  </p></li>
<li><p>“Actionable knowledge… is not the output per se but the process of actionable knowledge production and use.” (p. 11)  </p></li>
<li><p>“Without a shared problem, there cannot be shared problem solving, and collective action becomes impossible.” (p. 12)  </p></li>
<li><p>“Integration of diverse systems of knowledge… increases potential to generate action.” (p. 11)  </p></li>
<li><p>“The catchment coordinator… should be the central node for knowledge and action within the catchment area.” (p. 10)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Cash et al. (2003) — Credibility, legitimacy, relevance framework  </p></li>
<li><p>Nowotny (2003) — Socially robust knowledge  </p></li>
<li><p>Roux et al. (2006) — Knowledge interfacing  </p></li>
<li><p>Jasanoff (2004) — Co-production of science and social order  </p></li>
<li><p>Jahn et al. (2012) — Transdisciplinary phases  </p></li>
<li><p>Hoffmann et al. (2019) — Iterative processes in transdisciplinary research  </p></li>
<li><p>Klenk (2018) — Meshwork concept</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Big data analytics: transforming data to action  </p>

<p>Authors: Daniel Bumblauskas, Herb Nold, Paul Bumblauskas, Amy Igou  </p>

<p>DOI: 10.1108/BPMJ-03-2016-0056  </p>

<p>Year: 2017  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Business Process Management, Data Analytics  </p>

<p>Subdomain/Topic: Actionable Knowledge from Big Data, Dashboard Decision Support  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (explicit via Argyris, applied to big data)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes (tied to actionability)  </p>

<p>Contains Interpretability: Partial (interpretation implied in conversion process)  </p>

<p>Contains Framework/Model: Yes (Actionable Knowledge Model + Performance Triangle + Dashboard Framework)  </p>

<p>Operationalization Present: Yes (detailed processes, tools, and case)  </p>

<p>Primary Methodology: Conceptual + Case Application  </p>

<p>Study Context: Big Data analytics in operations, decision-making, and business process management  </p>

<p>Geographic/Institutional Context: USA; ESP International case  </p>

<p>Target Users/Stakeholders: Business managers, operations managers, decision-makers, analysts  </p>

<p>Primary Contribution Type: Conceptual model and applied case study  </p>

<p>CL: Yes — “Humans give data meaning by adding context and reference points… relevant and purposeful” (p. 709)  </p>

<p>CR: Yes — “Information must be valid, timely, and relevant to the changing business world” (p. 708)  </p>

<p>FE: Yes — “Ability to make informed choices” and “monitoring implementation” (p. 708)  </p>

<p>TI: Yes — “Valid and timely information” (p. 708)  </p>

<p>EX: Yes — “Interpret meaning in the data and communicate effectively” (p. 710)  </p>

<p>GA: Yes — “Action with positive outcomes that add value to the organization” (p. 708)  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Big data analytics: transforming data to action  </p>

<p><strong>Authors:</strong>  </p>

<p>Daniel Bumblauskas, Herb Nold, Paul Bumblauskas, Amy Igou  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1108/BPMJ-03-2016-0056  </p>

<p><strong>Year:</strong>  </p>

<p>2017  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Business Process Management, Data Analytics  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Actionable Knowledge from Big Data, Dashboard Decision Support  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses how organizations can convert vast big data sets into <em>actionable knowledge</em> that leads to improved decision-making and organizational performance. It builds a conceptual model linking data, information, knowledge, and action, integrates the <em>Performance Triangle</em> framework, and applies these in a dashboard-driven case study from ESP International.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>USA; case study with ESP International in Cedar Rapids, Iowa.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Business process managers, operations managers, decision-makers, analysts, executives handling large datasets.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual + Case Application  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual model + applied example  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors propose a conceptual framework for transforming big data into actionable knowledge, addressing both the opportunities and risks of big data analytics (BDA). They integrate Argyris’s concept of actionable knowledge, the <em>Performance Triangle</em> (culture, leadership, systems), and dashboards as visualization tools to facilitate decision-making. The model emphasizes that raw data gains value only when contextualized, interpreted, and acted upon. They identify “viruses” — organizational and systemic barriers that degrade decision-making — and propose mechanisms to detect and mitigate them. The ESP International case illustrates how dashboards convert KPI streams into actionable insights for supplier management. The paper addresses timeliness, validity, feasibility, and goal alignment as critical features, and warns against information overload, KPI irrelevance, and flawed data leading to flawed actions.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionable knowledge is explicitly defined per Argyris (1995) as:  </p>

<blockquote>
  <p>“Information that actors could use… to craft conversations that communicate the meanings they intend… specify how to produce meanings but leave actors free to select the specific words” (p. 708).  </p>
</blockquote>

<p>Actionability here means the ability to derive meaning from data that leads to informed, timely, and relevant actions with positive organizational impact.  </p>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Valid and timely information  </p></li>
<li><p>Ability to make informed choices  </p></li>
<li><p>Vigilant monitoring of input validity and implementation outcomes  </p></li>
<li><p>Continuous re-evaluation of data in changing contexts  </p></li>
<li><p>Human interpretation and integration of multiple data sources  </p></li>
<li><p>Alignment of decisions with organizational goals and value creation  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong>  </p>

<p> - Data → Information → Knowledge → Actionable Knowledge conversion model  </p>

<p> - <em>Performance Triangle</em> (Culture, Leadership, Systems)  </p>

<p> - Dashboard framework with KPIs  </p></li>
<li><p><strong>Methods/Levers:</strong>  </p>

<p> - Data contextualization, KPI selection, dashboard visualization, virus identification &amp; mitigation  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Acquire and clean data  </p>

<p> 2. Add context to create information  </p>

<p> 3. Integrate and interpret to form knowledge  </p>

<p> 4. Convert to actionable knowledge via decision-making frameworks  </p>

<p> 5. Use dashboards to visualize KPIs linked to performance drivers  </p>

<p> 6. Monitor and adjust continuously  </p></li>
<li><p><strong>Data &amp; Measures:</strong>  </p>

<p> - KPIs relevant to revenue, working capital, expenses, opportunity costs, risk  </p></li>
<li><p><strong>Implementation Context:</strong>  </p>

<p> - ESP International dashboards for supplier performance monitoring  </p></li>
</ul>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — “Humans give data meaning by adding context… relevant and purposeful” (p. 709)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — “Information must be valid, timely, and relevant to the changing business world” (p. 708)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — “Ability to make informed choices” and “monitoring implementation” (p. 708)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — “Valid and timely information” (p. 708)  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Leaders must “interpret meaning in the data and communicate effectively” (p. 710)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — “Action with positive outcomes that add value to the organization” (p. 708)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Risk awareness, adaptability, feedback loops  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Argyris (1993, 1995, 1996) on actionable knowledge  </p></li>
<li><p>Davenport &amp; Prusak (1998) on data–information–knowledge hierarchy  </p></li>
<li><p>Michel’s <em>Performance Triangle</em> model  </p></li>
<li><p>KPI theory and dashboard design principles (Few, 2006)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Validity and timeliness of input data  </p></li>
<li><p>Causal link between KPIs and performance outcomes  </p></li>
<li><p>Evidence of positive organizational change from decisions  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Information overload, data “viruses” (obsolete systems, irrelevant data, low trust culture, outdated leadership)  </p>

<p> - Poorly designed dashboards, irrelevant KPIs  </p>

<p> - Security breaches and data privacy risks  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Valid, timely, relevant data  </p>

<p> - Strong culture of trust, leadership interpretive skills  </p>

<p> - Effective dashboard design and KPI alignment  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on BDA literature (Chen et al., 2012; Fosso Wamba et al., 2015) and integrates management science concepts of actionable knowledge into big data practice. Extends prior BI&amp;A approaches by explicitly connecting them to operational decision-making frameworks and visualization tools.</p>

<hr />

<h2>Summary</h2>

<p>This paper bridges big data analytics theory and practical decision-making by providing a framework for converting raw data into actionable knowledge. Grounded in Argyris’s actionable knowledge theory, it introduces a four-step data–information–knowledge–action process, the <em>Performance Triangle</em> model for organizational alignment, and a dashboard visualization approach to communicate critical KPIs. It stresses that actionability depends on validity, timeliness, contextual relevance, feasibility, explainability, and goal alignment. The ESP International case demonstrates operationalization in supplier management. The model addresses barriers like information overload, irrelevant metrics, and systemic “viruses,” and outlines enablers such as trust-based culture, skilled leadership, and KPI relevance. The work contributes a structured, operationalizable method for turning big data into meaningful, value-adding actions.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Strong explicit definition of actionability, rich conceptual framing, multiple systematic features tied to actionability.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Clear, detailed process and applied example; could be enhanced by more empirical performance validation.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Information that actors could use… to craft conversations that communicate the meanings they intend” (p. 708)  </p></li>
<li><p>“Having valid and timely information; the ability to make informed choices; and vigilant monitoring of both the validity of input information and implementation of decisions” (p. 708)  </p></li>
<li><p>“Leaders who are able to interpret meaning in the data and communicate effectively are essential elements needed to maximize BDA” (p. 710)  </p></li>
<li><p>“Dashboards… provide the information that leads to actionable knowledge” (p. 713)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Argyris, C. (1993, 1995, 1996)  </p></li>
<li><p>Davenport, T., Prusak, L. (1998)  </p></li>
<li><p>Michel, L. (2013) <em>The Performance Triangle</em>  </p></li>
<li><p>Few, S. (2006) <em>Information Dashboard Design</em></p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: AWARENESS-IN-ACTION: A Critical Integralism for the Challenges of Our Times  </p>

<p>Authors: Daniel J. O’Connor  </p>

<p>DOI: n/a  </p>

<p>Year: 2013  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Integral Theory, Interdisciplinary Studies  </p>

<p>Subdomain/Topic: Critical Integral Meta-paradigm; Actionable Knowledge; Interdisciplinary Response to Complex Challenges  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 85  </p>

<p>Operationalization Score: 70  </p>

<p>Contains Definition of Actionability: Yes (implicit and partial explicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (meta-paradigmatic framing)  </p>

<p>Operationalization Present: Yes (meta-paradigmatic approach across domains)  </p>

<p>Primary Methodology: Conceptual/Theoretical  </p>

<p>Study Context: Development of a meta-paradigm for human awareness-in-action applicable across political, economic, social, ecological challenges.  </p>

<p>Geographic/Institutional Context: United States  </p>

<p>Target Users/Stakeholders: Scholars, policymakers, activists, journalists, social workers, interdisciplinary practitioners  </p>

<p>Primary Contribution Type: Conceptual framework linking awareness practices to actionable knowledge  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Partial  </p>

<p>TI: Partial  </p>

<p>EX: Partial  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>AWARENESS-IN-ACTION: A Critical Integralism for the Challenges of Our Times</p>

<p><strong>Authors:</strong>  </p>

<p>Daniel J. O’Connor</p>

<p><strong>DOI:</strong>  </p>

<p>n/a</p>

<p><strong>Year:</strong>  </p>

<p>2013</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Integral Theory, Interdisciplinary Studies</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Critical Integral Meta-paradigm; Actionable Knowledge; Interdisciplinary Response to Complex Challenges</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper proposes <em>Awareness-in-Action</em> as a meta-paradigm integrating presupposed perspectives and practices of human awareness across disciplines and sectors. It aims to equip practitioners in diverse fields with meta-level tools for generating actionable knowledge to address interconnected societal and ecological challenges.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>United States</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Scholars, policymakers, activists, journalists, social workers, interdisciplinary practitioners</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual/Theoretical</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Meta-paradigmatic framework</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>O’Connor’s <em>Awareness-in-Action</em> framework is presented as a critical integral meta-paradigm that connects the presupposed perspectives and practices of human awareness-in-action across multiple contexts—politics, governance, economics, sociology, journalism, activism, and more. The framework encompasses any human activity, whether purposeful or spontaneous, mental or physical, independent or interdependent. It emphasizes crossing disciplinary and institutional boundaries to address interlinked political, economic, social, and ecological challenges. Drawing from Jürgen Habermas’s critical theory, Ken Wilber’s Integral Theory, and Chris Argyris’s action science, the paper positions <em>Awareness-in-Action</em> as both a diagnostic and generative tool for producing actionable knowledge.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is implicitly defined as the capacity to generate “actionable knowledge within, across, and beyond established disciplinary and institutional boundaries” to enable effective responses to interconnected societal challenges.  </p>

<blockquote>
  <p>“Awareness-In-Action may therefore provide the meta-paradigmatic means to create actionable knowledge…” (Abstract, p. n/a)  </p>
</blockquote>

<blockquote>
  <p>“…so that those of us concerned with such matters might learn how to respond more effectively to the interdependent political, economic, social, and ecological challenges of our time.” (Abstract, p. n/a)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Integration of perspectives and practices of human awareness-in-action.</p></li>
<li><p>Cross-disciplinary applicability.</p></li>
<li><p>Responsiveness to interconnected political, economic, social, and ecological challenges.</p></li>
<li><p>Grounding in validated presuppositions that serve as premises for inquiry and hypothesis formation.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Awareness-in-Action meta-paradigm  </p></li>
<li><p><strong>Methods/Levers:</strong> Integration of meta-theoretical and meta-practical reconstructions.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Summarization of primary features, philosophical grounding, application across domains.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Not empirical; conceptual synthesis.  </p></li>
<li><p><strong>Implementation Context:</strong> Political, economic, social, ecological spheres, and various professions (journalism, activism, governance).  </p></li>
</ul>

<blockquote>
  <p>“…summarize the primary features of Awareness-in-Action before elaborating on some of its philosophical implications…” (Abstract, p. n/a)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — The framework seeks to clarify presuppositions across contexts.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Tailored to diverse and interconnected fields.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — Feasibility implied via meta-level applicability, but not operationally detailed.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Linked to urgent societal challenges, though not time-bounded.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — Philosophical grounding aids explainability, but lacks explicit operational explanation.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Explicitly tied to responding effectively to pressing global challenges.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Interdisciplinarity, reflexivity.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Jürgen Habermas’s Critical Theory  </p></li>
<li><p>Ken Wilber’s Integral Theory  </p></li>
<li><p>Chris Argyris’s Action Science</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>No quantitative metrics; actionability is judged through conceptual fit and cross-disciplinary utility.</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Disciplinary silos, entrenched institutional boundaries.  </p></li>
<li><p><strong>Enablers:</strong> Meta-paradigmatic integration, philosophical grounding, cross-sector dialogue.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions itself at the intersection of integral theory and critical theory, extending their applicability to actionable, cross-disciplinary knowledge production.</p>

<hr />

<h2>Summary</h2>

<p>The paper presents <em>Awareness-in-Action</em> as a meta-paradigm designed to unify diverse perspectives and practices of human awareness-in-action across disciplines, creating actionable knowledge to address complex global challenges. Drawing from Habermas, Wilber, and Argyris, O’Connor frames actionability as arising from the ability to integrate these perspectives into coherent, cross-disciplinary responses. While rich in theoretical framing, operational details are less developed, limiting its practical feasibility score. Nonetheless, its conceptual clarity, contextual relevance, and explicit goal alignment make it a significant contribution to actionability discourse.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 — Strong conceptualization and features tied to actionability; implicit definition supported by clear dimensions.  </p></li>
<li><p><strong>Operationalization Score:</strong> 70 — Provides a meta-paradigmatic pathway but lacks concrete implementation steps or measurable indicators.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Awareness-In-Action may therefore provide the meta-paradigmatic means to create actionable knowledge…” (Abstract)  </p></li>
<li><p>“…so that those of us concerned with such matters might learn how to respond more effectively to the interdependent political, economic, social, and ecological challenges of our time.” (Abstract)  </p></li>
<li><p>“…summarize the primary features of Awareness-in-Action before elaborating on some of its philosophical implications…” (Abstract)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Jürgen Habermas’s Critical Theory  </p></li>
<li><p>Ken Wilber’s Integral Theory  </p></li>
<li><p>Chris Argyris’s Action Science</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: An Open-Source Tool-Box for Asset Management Based on the Asset Condition for the Power System</p>

<p>Authors: Gopal Lal Rajora, Miguel A. Sanz-Bobi, Carlos Mateo Domingo, Lina Bertling Tjernberg</p>

<p>DOI: 10.1109/ACCESS.2025.3551663</p>

<p>Year: 2025</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Electrical Engineering / Power Systems</p>

<p>Subdomain/Topic: Asset Management, Predictive Maintenance, Machine Learning for Power Grids</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 90</p>

<p>Operationalization Score: 95</p>

<p>Contains Definition of Actionability: Yes (implicit and explicit operational framing)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual + Quantitative Case Study</p>

<p>Study Context: European ATTEST project; predictive maintenance for TSOs and DSOs</p>

<p>Geographic/Institutional Context: Spain (Universidad Pontificia Comillas), Sweden (KTH), European partners</p>

<p>Target Users/Stakeholders: Transmission System Operators (TSOs), Distribution System Operators (DSOs)</p>

<p>Primary Contribution Type: Framework + Open-source Tool</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Yes</p>

<p>EX: Partial</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: n/a</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>An Open-Source Tool-Box for Asset Management Based on the Asset Condition for the Power System  </p>

<p><strong>Authors:</strong>  </p>

<p>Gopal Lal Rajora, Miguel A. Sanz-Bobi, Carlos Mateo Domingo, Lina Bertling Tjernberg  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1109/ACCESS.2025.3551663  </p>

<p><strong>Year:</strong>  </p>

<p>2025  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Electrical Engineering / Power Systems  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Asset Management, Predictive Maintenance, Machine Learning for Power Grids  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>Developed under the European ATTEST project, the toolbox targets proactive asset management for electrical infrastructure, addressing challenges like aging grids, renewable integration, and cost-efficient maintenance. Intended for operational decision-making by TSOs and DSOs.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Spain (Universidad Pontificia Comillas), Sweden (KTH Royal Institute of Technology), EU partners.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Transmission and Distribution System Operators.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework with quantitative case study (real-world and synthetic datasets).  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Modular open-source software integrating AI-based analytics for asset condition assessment and strategy optimization.  </p>

<h2>General Summary of the Paper</h2>

<p>The paper introduces an open-source asset management toolbox designed for TSOs and DSOs, integrating machine learning, clustering, and reinforcement learning to assess and optimize asset maintenance strategies. The method is structured into three modules: (1) characterization of asset health using multi-dimensional data (life assessment, health condition, maintenance, economic impact), (2) derivation of condition indicators from heterogeneous data, and (3) strategy recommendation via reinforcement learning (Q-learning). The toolbox enables proactive maintenance planning, resource optimization, and lifecycle extension. Case studies using 92 real-world transformers and synthetic datasets validate scalability and practical applicability. The system aligns with sustainable energy goals by improving grid reliability and operational efficiency.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>The paper explicitly links “actionable insights” to the ability to inform prioritized, effective maintenance strategies based on asset condition data. Actionability is defined through the generation of <strong>condition indicators</strong> and <strong>strategic recommendations</strong> that operators can directly implement.  </p>

<blockquote>
  <p>“The toolbox provides actionable insights for planning maintenance strategies and optimizing resource allocation.” (Abstract)  </p>
</blockquote>

<blockquote>
  <p>“Each asset’s condition is evaluated… facilitating effective prioritization and decision-making for maintenance and management strategies.” (p. 6)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Measurable condition indicators across four dimensions: Life Assessment, Health Condition, Maintenance, Economic Impact.</p></li>
<li><p>Ability to compare across heterogeneous assets.</p></li>
<li><p>Prioritization thresholds for intervention.</p></li>
<li><p>Integration of predictive analytics (clustering + SOM) for early identification of risks.</p></li>
<li><p>Strategy recommendation system (Q-learning) that adapts to changes without manual rule rewriting.</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> ATTEST Asset Management Toolbox  </p></li>
<li><p><strong>Methods/Levers:</strong> Data normalization, clustering (K-means, SOM), condition indicator computation, reinforcement learning for decision support.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Identify critical asset data.  </p>

<p> 2. Compute multi-dimensional condition indicators.  </p>

<p> 3. Cluster assets for pattern recognition.  </p>

<p> 4. Apply Q-learning to recommend optimal actions.  </p>

<p> 5. Simulate long-term strategies (Monte Carlo).  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Asset age, failure probability, internal temperature, dissolved gas analysis, MTTR, MTBF, maintenance costs, undelivered energy.  </p></li>
<li><p><strong>Implementation Context:</strong> Tested on European TSO/DSO datasets; compatible with CIM, IEC 61850, MATPOWER formats.  </p></li>
</ul>

<blockquote>
  <p>“This Module compares assets… recommending the most convenient actions… simulate and quantify the evolution… under different management strategies.” (p. 6–7)  </p>
</blockquote>

<blockquote>
  <p>“The Q-learning algorithm… suggests actions with the highest potential reward.” (p. 8)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Explicit, interpretable indicators for each dimension.  </p>

<p> &gt; “Comparable condition indicators… allowing identification of assets requiring special attention.”  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Indicators adaptable to available data and operational context.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Prioritized strategies feasible given operational constraints.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — Short-term and long-term analyses inform timely interventions.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — While results are interpretable, underlying ML models’ inner workings are not deeply unpacked.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Optimizes for reliability, cost-efficiency, and sustainability goals.  </p></li>
<li><p><strong>Other Dimensions:</strong> Adaptability (tool modularity and format compatibility).</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Condition-based maintenance theory.</p></li>
<li><p>AI/ML for predictive asset management.</p></li>
<li><p>Reinforcement learning (Q-learning) for adaptive strategy optimization.</p></li>
<li><p>Multi-criteria decision analysis.</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Multi-dimensional condition indicators (0–1 scale).</p></li>
<li><p>Total Indicator threshold (e.g., &gt;0.75 for critical attention).</p></li>
<li><p>Cluster patterns denoting asset health states.</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Data incompleteness, heterogeneity of formats, variability in monitoring availability.  </p></li>
<li><p><strong>Enablers:</strong> Open-source modular design, integration with industry standards, compatibility with multiple data formats.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions itself as advancing AI-driven asset management from descriptive analytics to prescriptive decision-making, integrating clustering and RL for operational use.</p>

<h2>Summary</h2>

<p>The paper offers a comprehensive, modular, open-source framework for transforming raw asset condition data into actionable maintenance and management strategies for power systems. Actionability here is operationalized as the process of quantifying multi-dimensional condition indicators, clustering similar assets for pattern recognition, and recommending specific interventions via reinforcement learning. The approach is designed to be adaptable to diverse data sources, scalable across network sizes, and integrable into existing operational platforms. This combination of predictive assessment and prescriptive recommendation directly supports timely, relevant, feasible, and goal-aligned decision-making for TSOs and DSOs, making the contribution both conceptually strong and practically implementable.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 — Clear conceptualization of actionability through explicit condition-based decision criteria, multi-dimensional indicators, and prioritization logic.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Detailed, replicable methodology with workflow, algorithms, metrics, and real-world validation.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“The toolbox provides actionable insights for planning maintenance strategies and optimizing resource allocation.” (Abstract)  </p></li>
<li><p>“Comparable condition indicators… allowing identification of assets requiring special attention.” (p. 6)  </p></li>
<li><p>“Optimal actions are determined using a Q-matrix… suggests actions with the highest potential reward.” (p. 7–8)  </p></li>
<li><p>“Assets are categorized as requiring priority attention and maintenance when the Total Indicator is nearly or exactly equal to one.” (p. 6)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Rajora et al. (2024) — AI-based ML models for asset management.  </p></li>
<li><p>Žarković et al. (2021) — ML for transformer diagnostics.  </p></li>
<li><p>Li et al. (2023) — ML + blockchain in power management.  </p></li>
<li><p>Aminifar et al. (2022) — ML for asset management and protection.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: An Age-Based Framework for Evaluating Genome-Scale Sequencing Results in Newborn Screening  </p>

<p>Authors: Laura V. Milko, Julianne M. O’Daniel, Daniela M. DeCristo, Stephanie B. Crowley, Ann Katherine M. Foreman, Kathleen E. Wallace, Lonna F. Mollison, Natasha T. Strande, Zahra S. Girnary, Lacey J. Boshe, Arthur S. Aylsworth, Muge Gucsavas-Calikoglu, Dianne M. Frazier, Neeta L. Vora, Myra I. Roche, Bradford C. Powell, Cynthia M. Powell, Jonathan S. Berg  </p>

<p>DOI: https://doi.org/10.1016/j.jpeds.2018.12.027  </p>

<p>Year: 2019  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Medical Genetics, Pediatrics, Genomic Medicine  </p>

<p>Subdomain/Topic: Newborn Screening, Clinical Actionability, Next-Generation Sequencing (NGS)  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (explicit and implicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (ASQM – Age-based Semiquantitative Metric)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual + Comparative Validation Study  </p>

<p>Study Context: Evaluation of gene–disease pairs for genomic newborn screening using a standardized actionability metric  </p>

<p>Geographic/Institutional Context: North Carolina, USA; University of North Carolina at Chapel Hill  </p>

<p>Target Users/Stakeholders: Policy-makers, clinicians, genetic counselors, parents, newborn screening programs  </p>

<p>Primary Contribution Type: Conceptual framework with validation against existing panels  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Contextual Background:</strong>  </p>

<p>The study is grounded in the public health context of newborn screening (NBS) in the United States, specifically evaluating how genomic sequencing could expand detection of actionable pediatric-onset conditions. It builds on existing NBS frameworks and addresses policy, ethical, and clinical decision-making challenges in implementing genome-scale sequencing for healthy newborns.</p>

<h2>General Summary of the Paper</h2>

<p>This paper introduces and validates the Age-based Semiquantitative Metric (ASQM), a framework for assessing clinical actionability of gene–disease pairs in the context of newborn genomic screening. The ASQM expands a previously developed semiquantitative metric by integrating age-of-onset and age-at-intervention, categorizing conditions into four groups based on actionability and timing. The study applied the ASQM to 822 curated gene–disease pairs, compared classifications with the Recommended Uniform Screening Panel (RUSP) and the BabySeq project, and demonstrated strong concordance with high-actionability conditions. The framework provides a structured approach for deciding which genomic findings should be returned in newborn screening and could inform policy and parental decision-making.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<p>The paper explicitly defines clinical actionability, operationalizes it through a standardized scoring system, and identifies systematic features directly tied to the authors’ conceptualization of actionability.</p>

<h2>How Actionability is Understood</h2>

<p>The authors define actionability through five explicit criteria: severity, likelihood (penetrance), efficacy of intervention, acceptability of intervention, and knowledge base of the gene–disease association, all adapted for newborn and pediatric contexts.</p>

<blockquote>
  <p>“Each gene–disease pair was scored (0–3 points) on 5 criteria: severity… likelihood… efficacy… acceptability… knowledge base…” (p. 69–70)  </p>
</blockquote>

<blockquote>
  <p>“Gene–disease pairs were placed into… pediatric conditions with high actionability… pediatric conditions with low or no actionability… adult conditions with high actionability… adult conditions with low or no actionability.” (p. 69)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>High severity of potential outcome  </p></li>
<li><p>High likelihood of disease manifestation  </p></li>
<li><p>Highly effective interventions available  </p></li>
<li><p>Interventions are acceptable in terms of burden and risk  </p></li>
<li><p>Strong knowledge base and clinical consensus on gene–disease relationship</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name:</strong> Age-based Semiquantitative Metric (ASQM)  </p></li>
<li><p><strong>Methods/Levers:</strong> Structured scoring (0–3) for five actionability criteria; consensus review by multidisciplinary committee  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Literature curation → preliminary scoring → consensus meetings → categorization into 4 groups  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Severity, penetrance, intervention efficacy, intervention acceptability, knowledge base; age-of-onset and age-at-intervention data  </p></li>
<li><p><strong>Implementation Context:</strong> Newborn genomic screening; policy and parental decision-making  </p></li>
</ul>

<blockquote>
  <p>“The ASQM allows a priori categorization… to facilitate decision-making about incorporating genomic sequencing into the care of newborns.” (p. 69)  </p>
</blockquote>

<blockquote>
  <p>“Gene–disease pairs… placed into 1 of 4 categories…” (p. 69)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – explicit scoring rubric with defined terms (p. 70)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – pediatric onset and intervention timing central to classification (p. 69)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – considers intervention efficacy and acceptability (p. 70)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial – age-of-onset and age-at-intervention incorporated (p. 69)  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – transparent scoring and rationale for classification (p. 70, Fig. 1B)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial – implicit in alignment with NBS goals  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Knowledge base strength; ethical principle of preserving future autonomy for children</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Builds on prior Semiquantitative Metric (Berg et al., 2016)  </p></li>
<li><p>Aligns with public health screening principles (Wilson and Jungner, updated for genomics)  </p></li>
<li><p>Compares to RUSP and BabySeq frameworks</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Total ASQM score (0–15) across five criteria  </p></li>
<li><p>Cut-offs for automatic category assignment (≥12 for high actionability, &lt;9 for low)</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of effective interventions, insufficient knowledge base, controversial evidence  </p></li>
<li><p><strong>Enablers:</strong> Strong clinical evidence, existing practice guidelines, early intervention potential</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions ASQM as a more integrated and age-aware framework compared to BabySeq’s validity/onset/penetrance model and validates it against RUSP’s established high-actionability conditions.</p>

<h2>Summary</h2>

<p>Milko et al. (2019) present the ASQM, an evidence-based, age-sensitive framework for scoring and classifying the actionability of genetic conditions in newborn screening. Incorporating five explicit criteria—severity, likelihood, efficacy, acceptability, and knowledge base—alongside onset and intervention timing, the ASQM categorizes conditions into four groups to guide disclosure decisions. Applied to 822 gene–disease pairs, the ASQM demonstrated strong alignment with RUSP’s core actionable conditions and provided nuanced differentiation for borderline cases. The framework operationalizes actionability with clear metrics and consensus processes, offering a scalable and transparent tool for integrating genome-scale sequencing into newborn screening programs while balancing ethical considerations.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 – Provides explicit, multidimensional definition of actionability, systematic feature set, and clear conceptual grounding.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 – Offers fully articulated scoring system, workflow, and validation, though some criteria for timeliness and goal alignment are implicit.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[Each gene–disease pair was scored… on 5 criteria: severity… likelihood… efficacy… acceptability… knowledge base.]” (p. 69–70)  </p></li>
<li><p>“[Gene–disease pairs were placed into… 4 categories… based on final ASQM score, age of onset/actionability, and consensus review.]” (p. 69)  </p></li>
<li><p>“[Lack of effective intervention and/or insufficient knowledge… common reasons… not meet criteria for disclosure.]” (p. 71)  </p></li>
<li><p>“[Validated our framework against the… RUSP… high ASQM scores assigned to most RUSP conditions…]” (p. 73)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Berg et al., 2016 – Semiquantitative Metric for Evaluating Clinical Actionability  </p></li>
<li><p>Wilson &amp; Jungner screening criteria updates (Andermann et al., 2008)  </p></li>
<li><p>Ceyhan-Birsoy et al., 2017 – BabySeq curated gene list  </p></li>
<li><p>RUSP methodology references (Kemper et al., 2014)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: AI-Driven Whole-Exome Sequencing: Advancing Variant Interpretation and Precision Medicine  </p>

<p>Authors: Faisal Aburub, Mayyas Al-Remawi, Rami A. Abdel-Rahem, Faisal Al-Akayleh, Ahmed S.A. Ali Agha  </p>

<p>DOI: 10.1109/ICCIAA65327.2025.11013653  </p>

<p>Year: 2025  </p>

<p>Publication Type: Conference Proceeding  </p>

<p>Discipline/Domain: Bioinformatics / Genomic Medicine  </p>

<p>Subdomain/Topic: Whole-Exome Sequencing, AI for Variant Interpretation, Precision Medicine  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 85  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (implicit, as clinically actionable insights in genomic medicine)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (AI-driven WES pipeline with multi-omics integration and XAI)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual / Review with applied case studies  </p>

<p>Study Context: AI-enhanced WES in clinical genetic diagnostics  </p>

<p>Geographic/Institutional Context: University of Petra, The University of Jordan (Jordan); applied references from Taiwan, South Korea, USA, etc.  </p>

<p>Target Users/Stakeholders: Clinicians, genomic researchers, bioinformaticians, healthcare policymakers  </p>

<p>Primary Contribution Type: Conceptual framework with practical application examples for AI-driven WES  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>AI-Driven Whole-Exome Sequencing: Advancing Variant Interpretation and Precision Medicine  </p>

<p><strong>Authors:</strong>  </p>

<p>Faisal Aburub, Mayyas Al-Remawi, Rami A. Abdel-Rahem, Faisal Al-Akayleh, Ahmed S.A. Ali Agha  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1109/ICCIAA65327.2025.11013653  </p>

<p><strong>Year:</strong>  </p>

<p>2025  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference Proceeding  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Bioinformatics / Genomic Medicine  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Whole-Exome Sequencing, AI for Variant Interpretation, Precision Medicine  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the integration of AI—particularly ML and DL—into WES workflows to improve clinical actionability in genetic diagnostics. It frames actionability in terms of transforming raw genomic data into clinically relevant, interpretable, and timely recommendations that can guide treatment and personalized medicine.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of Petra (Jordan), The University of Jordan; case studies and tools from Taiwan, South Korea, USA, and Europe.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Clinical geneticists, bioinformaticians, precision medicine practitioners, healthcare institutions.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework with review of applied AI tools and comparative performance results.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework and application roadmap for AI-driven WES in clinical precision medicine.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper presents an AI-driven framework for whole-exome sequencing (WES) that aims to improve variant interpretation, pathogenicity prediction, and clinical decision-making in precision medicine. It reviews traditional and AI-based WES pipelines, compares WES and whole-genome sequencing, and outlines AI methods for variant calling, annotation, and prioritization. Key AI tools discussed include DeepVariant, DANN, ClinPred, and EVIDENCE. The framework integrates multi-omics data, phenotype-genotype correlations, and explainable AI (XAI) to enhance interpretability and trust. The authors also address ethical, legal, and implementation challenges such as privacy, bias, and regulatory compliance, recommending federated learning and fairness audits.  </p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>The authors implicitly define actionability as the transformation of WES data into clinically relevant, timely, and trustworthy recommendations that can inform diagnosis, prognosis, and treatment in precision medicine.  </p>

<blockquote>
  <p>“AI… can pinpoint disease-associated variants, discover novel biomarkers, and guide personalized treatment strategies” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“Integrating multi-omics data and correlating genotype with phenotype further enable personalized interventions, expediting the translation of WES findings into actionable treatments” (p. 4)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Accurate identification of pathogenic variants  </p></li>
<li><p>Contextual relevance through phenotype-genotype correlation  </p></li>
<li><p>Timely reporting and reduced turnaround times  </p></li>
<li><p>Interpretability and transparency in AI decision-making  </p></li>
<li><p>Integration of multi-omics data for holistic variant assessment  </p></li>
<li><p>Feasibility in clinical workflows (automation, reduced manual curation)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> AI-driven WES pipeline with XAI  </p></li>
<li><p><strong>Methods/Levers:</strong> ML/DL models (DeepVariant, DANN, AI Variant Prioritizer, EVIDENCE), phenotype extraction, multi-omics integration, federated learning  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Data preprocessing → AI variant calling → AI-based annotation → Phenotypic data integration → Prioritization → Explainable output for clinicians  </p></li>
<li><p><strong>Data &amp; Measures:</strong> WES datasets, HPO terms, population frequency databases, functional impact scores, multi-omics profiles  </p></li>
<li><p><strong>Implementation Context:</strong> Clinical genetic diagnostics and research workflows  </p></li>
</ul>

<blockquote>
  <p>“An AI-powered WES pipeline… improved diagnostic yield to 41% for trio-WES cases and 28% for singletons, reducing reporting time to one week” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“Federated learning enables secure genomic data sharing… maintaining privacy and compliance” (p. 2)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – Output must be interpretable for clinicians via XAI.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – Integration of patient metadata and multi-omics.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – Automation and reduced turnaround time.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial – Reporting time reduced to one week in tested pipelines.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – SHAP, LIME for AI transparency.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – Prioritization aligned with clinical diagnostic objectives.  </p></li>
<li><p><strong>Other Dimensions:</strong> Ethical compliance, fairness, reproducibility.  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>AI interpretability frameworks (SHAP, LIME)  </p></li>
<li><p>Federated learning privacy models  </p></li>
<li><p>Prior variant prioritization frameworks (ClinPred, REVEL, CADD)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Diagnostic yield percentage  </p></li>
<li><p>Top-N ranking accuracy for causative variants  </p></li>
<li><p>Turnaround time (e.g., 1 week)  </p></li>
<li><p>Percentage increase in pathogenic/likely pathogenic classification after AI integration  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Data security, black-box AI, bias in training datasets, lack of regulatory clarity.  </p></li>
<li><p><strong>Enablers:</strong> XAI frameworks, federated learning, inclusive datasets, standardization of AI pipelines.  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions AI-driven WES as an evolution over traditional variant interpretation pipelines, improving diagnostic yield and speed while addressing trust and transparency concerns. Builds on prior variant prioritization and annotation tools, extending them with multi-omics integration and ethical safeguards.  </p>

<hr />

<h2>Summary</h2>

<p>This paper conceptualizes actionability in WES as the delivery of accurate, relevant, interpretable, and timely genetic insights that directly inform patient care. By leveraging AI for variant calling, annotation, and prioritization—and integrating phenotype and multi-omics data—the framework operationalizes actionability through automation, accuracy gains, and interpretability tools like SHAP and LIME. The authors provide evidence of improved diagnostic yield and reduced turnaround time, while addressing ethical and implementation barriers such as bias, privacy, and transparency. Their proposed pipeline aligns closely with clinical goals, demonstrating how AI can bridge the gap between raw genomic data and actionable medical decisions.  </p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 — Strong implicit definition of actionability tied to AI-enhanced variant interpretation; comprehensive features included.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Detailed pipeline description with tools, workflows, and metrics explicitly aimed at achieving actionability in clinical settings.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“AI… can pinpoint disease-associated variants, discover novel biomarkers, and guide personalized treatment strategies” (p. 1)  </p></li>
<li><p>“An AI-powered WES pipeline… improved diagnostic yield to 41% for trio-WES cases and 28% for singletons, reducing reporting time to one week” (p. 2)  </p></li>
<li><p>“Integrating multi-omics data and correlating genotype with phenotype further enable personalized interventions, expediting the translation of WES findings into actionable treatments” (p. 4)  </p></li>
<li><p>“Federated learning enables secure genomic data sharing… maintaining privacy and compliance” (p. 2)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Huang et al. (2022) – AI Variant Prioritizer for integrating WES and phenotypic data  </p></li>
<li><p>Graham et al. (2018) – WES + metabolomics for variant prioritization  </p></li>
<li><p>Barcelona-Cabeza et al. (2021) – WES + RNA-Seq for improved variant detection  </p></li>
<li><p>Rusch et al. (2018) – Multi-omics integration in oncology  </p></li>
<li><p>Pinxten &amp; Howard (2014) – Ethical issues in genome sequencing</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Actionable mutations in early-stage ovarian cancer according to the ESMO Scale for Clinical Actionability of molecular Targets (ESCAT): a descriptive analysis on a large prospective cohort  </p>

<p>Authors: F. Camarda, L. Mastrantoni, C. Parrillo, A. Minucci, F. Persiani, D. Giannarelli, T. Pasciuto, F. Giacomini, E. De Paolis, M. Manfredelli, C. Marchetti, G.F. Zannoni, A. Fagotti, G. Scambia, C. Nero  </p>

<p>DOI: https://doi.org/10.1016/j.esmoop.2024.104090  </p>

<p>Year: 2025  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Oncology / Precision Medicine  </p>

<p>Subdomain/Topic: Early-stage epithelial ovarian cancer, genomic profiling, actionable mutations, ESCAT  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 85  </p>

<p>Operationalization Score: 80  </p>

<p>Contains Definition of Actionability: Yes (via ESCAT framework)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: No  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (ESCAT classification tiers I–III)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Quantitative (prospective cohort, genomic profiling)  </p>

<p>Study Context: Clinical oncology, early-stage epithelial ovarian cancer, targeted therapy potential  </p>

<p>Geographic/Institutional Context: Fondazione Policlinico Universitario Agostino Gemelli IRCCS, Rome, Italy  </p>

<p>Target Users/Stakeholders: Oncologists, clinical researchers, precision medicine practitioners, policy-makers in oncology  </p>

<p>Primary Contribution Type: Empirical study with framework application (ESCAT)  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: No  </p>

<p>EX: No  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Actionable mutations in early-stage ovarian cancer according to the ESMO Scale for Clinical Actionability of molecular Targets (ESCAT): a descriptive analysis on a large prospective cohort</p>

<p><strong>Authors:</strong>  </p>

<p>F. Camarda, L. Mastrantoni, C. Parrillo, A. Minucci, F. Persiani, D. Giannarelli, T. Pasciuto, F. Giacomini, E. De Paolis, M. Manfredelli, C. Marchetti, G.F. Zannoni, A. Fagotti, G. Scambia, C. Nero</p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1016/j.esmoop.2024.104090</p>

<p><strong>Year:</strong>  </p>

<p>2025</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Oncology / Precision Medicine</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Early-stage epithelial ovarian cancer, genomic profiling, actionable mutations, ESCAT</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The study focuses on early-stage epithelial ovarian cancer (EOC), assessing the prevalence and distribution of actionable genomic alterations according to the ESCAT (ESMO Scale for Clinical Actionability of molecular Targets) framework. It addresses the challenge of overtreatment in low- to intermediate-risk patients and undertreatment in high-risk patients by exploring genomic-guided strategies for targeted therapy or chemotherapy de-escalation.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Fondazione Policlinico Universitario Agostino Gemelli IRCCS, Rome, Italy</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Oncologists, molecular pathologists, clinical researchers, precision oncology practitioners, guideline developers.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative — prospective cohort study with targeted next-generation sequencing (NGS) and ESCAT classification.</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical study applying a conceptual framework (ESCAT) to clinical genomic data.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This prospective single-center study analyzed 180 patients with FIGO stage I–II EOC, using targeted NGS to identify oncogenic variants classified under ESCAT Tier I–III. Seventy percent of patients had at least one Tier I–III alteration; 26% had Tier I variants (primarily BRCA1/2, BRAF V600E). PIK3CA mutations (Tier IIIA) were most frequent, found in 59% overall, with distinct prevalence by recurrence-risk category. The authors discuss potential implications for chemotherapy de-escalation in low/intermediate-risk patients and targeted maintenance therapy in high-risk groups. Findings suggest that ESCAT-based genomic profiling can uncover clinically actionable targets in most early-stage EOC patients, enabling personalized treatment strategies.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<p>The paper explicitly applies the ESCAT actionability framework, providing a structured classification of mutations according to their clinical actionability level and discussing how this may guide treatment selection.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is framed through the ESCAT scale, which ranks molecular targets based on clinical evidence strength, prioritizing variants that inform therapeutic decisions.</p>

<blockquote>
  <p>“Oncogenic alterations were identified using OncoKB and classified according to the ESMO Scale for Clinical Actionability of molecular Targets (ESCAT) Tier I–III.” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“The ESCAT framework… prioritizes molecular targets based on the strength of evidence supporting their relevance as clinical targets.” (p. 2)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Evidence-supported relevance as a clinical target.</p></li>
<li><p>Classification in ESCAT Tier I–III (Tier I = highest clinical evidence; Tier III = emerging evidence).</p></li>
<li><p>Potential to inform therapeutic decisions (drug selection, de-escalation/escalation).</p></li>
<li><p>Relevance to tumor biology and prognosis.</p></li>
</ul>

<hr />

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> ESCAT (ESMO Scale for Clinical Actionability of molecular Targets).  </p></li>
<li><p><strong>Methods/Levers:</strong> Comprehensive genomic profiling via TSO500 high-throughput NGS panel; annotation via OncoKB; ESCAT classification.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Patient enrollment and staging.  </p>

<p> 2. NGS sequencing of tumor tissue.  </p>

<p> 3. Variant annotation and filtering for oncogenicity.  </p>

<p> 4. ESCAT tier assignment.  </p>

<p> 5. Risk stratification integration.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Mutation type, frequency, co-occurrence, MSI, TMB, recurrence-free survival.  </p></li>
<li><p><strong>Implementation Context:</strong> Applied in a clinical oncology setting for prospective patient profiling.  </p></li>
</ul>

<blockquote>
  <p>“Sequencing was carried out with a mean depth of &gt;500×… only mutations annotated as ‘Oncogenic’ or ‘Likely Oncogenic’… were considered for the analysis… ESCAT scores were applied to all genetic variants detected.” (p. 3)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — ESCAT provides clear ranking criteria.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Actionability tied to EOC stage, histotype, recurrence risk.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Technically feasible in a hospital NGS program.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No explicit mention.  </p></li>
<li><p><strong>EX (Explainability):</strong> No direct link made.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Actionability linked to patient outcome improvement and toxicity reduction.  </p></li>
<li><p><strong>Other Dimensions:</strong> Risk-stratified application, molecular co-alteration analysis.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>ESMO Precision Medicine Working Group ESCAT framework.</p></li>
<li><p>OncoKB oncogenicity annotation system.</p></li>
<li><p>Principles of tumor-agnostic targeting.</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>ESCAT Tier classification.</p></li>
<li><p>Mutation prevalence and co-occurrence.</p></li>
<li><p>MSI status and TMB values.</p></li>
<li><p>Risk group-specific mutation frequency.</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Short follow-up; unclear prognostic role of some variants; potential resistance to targeted therapy; rare histotypes with limited trial data.  </p></li>
<li><p><strong>Enablers:</strong> High prevalence of actionable variants; feasibility of NGS profiling; established ESCAT framework; integration with clinical risk stratification.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions findings within ESMO/ESGO consensus guidelines for EOC, contrasts with mutation prevalence in advanced-stage EOC and other cancers, and references prior multi-gene ESCAT studies to contextualize prevalence rates.</p>

<hr />

<h2>Summary</h2>

<p>This study demonstrates that genomic profiling of early-stage EOC using the ESCAT framework reveals clinically actionable alterations in the majority of patients. By integrating molecular data with recurrence-risk categories, the authors propose targeted therapy for high-risk patients and potential chemotherapy de-escalation for low/intermediate-risk groups. The operationalization is robust, employing a structured NGS-to-ESCAT workflow with clear criteria for actionability. Key actionable mutations include BRCA1/2 (Tier I) and PIK3CA (Tier IIIA), with notable co-alteration patterns. The approach aligns clinical decisions with molecular evidence, though further trials are needed to validate treatment changes.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 — Strong use of ESCAT for defining and ranking actionability; integrates clinical and genomic data.  </p></li>
<li><p><strong>Operationalization Score:</strong> 80 — Detailed NGS and classification workflow; some gaps in timeliness and patient-level intervention detail.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Oncogenic alterations were identified using OncoKB and classified according to the ESMO Scale for Clinical Actionability of molecular Targets (ESCAT) Tier I–III.” (p. 1)  </p></li>
<li><p>“ESCAT… prioritizing them based on the strength of evidence supporting their relevance as clinical targets.” (p. 2)  </p></li>
<li><p>“Sequencing was carried out with a mean depth of &gt;500×… only mutations annotated as ‘Oncogenic’ or ‘Likely Oncogenic’… were considered for the analysis.” (p. 3)  </p></li>
<li><p>“These findings highlight the potential for actionable alterations in most early-stage EOC patients and support… targeted maintenance therapy for high-risk individuals.” (p. 1)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Mosele MF et al., 2024 — ESMO Precision Medicine Working Group recommendations for NGS use.  </p></li>
<li><p>Fieuws C et al., 2024 — Identification of actionable variants in EOC.  </p></li>
<li><p>Multiple ESMO-ESGO consensus guidelines on EOC pathology and molecular biology.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Actionable Knowledge: Design Causality in the Service of Consequential Theory</p>

<p>Authors: Chris Argyris</p>

<p>DOI: n/a</p>

<p>Year: 1996</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Organizational Behavior / Management Science</p>

<p>Subdomain/Topic: Actionable Knowledge; Design Causality; Management Theory</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 92</p>

<p>Operationalization Score: 85</p>

<p>Contains Definition of Actionability: Yes</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual</p>

<p>Study Context: Theories of managing in organizations</p>

<p>Geographic/Institutional Context: Harvard University (USA)</p>

<p>Target Users/Stakeholders: Managers, management theorists, organizational researchers</p>

<p>Primary Contribution Type: Conceptual framework and theoretical proposition</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Partial</p>

<p>EX: Partial</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: n/a</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Actionable Knowledge: Design Causality in the Service of Consequential Theory  </p>

<p><strong>Authors:</strong>  </p>

<p>Chris Argyris  </p>

<p><strong>DOI:</strong>  </p>

<p>n/a  </p>

<p><strong>Year:</strong>  </p>

<p>1996  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Organizational Behavior / Management Science  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Actionable Knowledge; Design Causality; Management Theory  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the gap between externally valid empirical research and its practical use in managerial contexts. It argues for the design of knowledge that is directly usable (“actionable”) in everyday organizational decision-making, emphasizing the role of “design causality” in linking theory and practice.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Harvard University (USA)  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Managers, management theorists, organizational researchers  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework and theoretical proposition  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper by Chris Argyris examines how empirical research, while often externally valid, frequently fails to be actionable for managers. Argyris defines actionable knowledge as that which enables managers to implement relevant findings in real-world settings, integrating them into decision-making processes that produce desired consequences. The work critiques the dominant “concept of causality” in empirical research, which can impede learning and, in some cases, result in unethical consequences. Argyris proposes an alternative causal framework—design causality—that enhances actionability. The paper positions management as inherently normative, requiring alignment between theories, values, and organizational goals. Finally, Argyris stresses that managers must be treated as human agents whose effectiveness depends on addressing specific, recurring questions.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Argyris frames actionability as the property of knowledge that allows it to be directly applied to real-world problems with relevance and consequence.  </p>

<blockquote>
  <p>“Actionable knowledge is that knowledge required to implement the external validity (relevance) in that world.” (p. 390)  </p>
</blockquote>

<blockquote>
  <p>“The claim is made that the concept of causality that underlies much rigorous empirical research makes it difficult to transform knowledge with high external validity into actionable knowledge.” (p. 390)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>High external validity <strong>and</strong> the ability to be implemented in everyday decision-making.</p></li>
<li><p>A causal framework that supports adaptability and learning rather than constraining them.</p></li>
<li><p>Relevance to the lived realities and values of the decision-makers.</p></li>
<li><p>Alignment with normative goals of management.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Design Causality</p></li>
<li><p><strong>Methods/Levers:</strong> Shift from traditional causality models to ones that encourage learning, adaptability, and value alignment.</p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify intended consequences, define the activities to achieve them, ensure persistence of these consequences.</p></li>
<li><p><strong>Data &amp; Measures:</strong> Not quantitatively defined; emphasis on conceptual fit and practical testing.</p></li>
<li><p><strong>Implementation Context:</strong> Organizational management decision-making.</p></li>
</ul>

<blockquote>
  <p>“A different concept of causality is proposed that enhances actionability. Design causality is defined, and how it can be implemented is illustrated.” (p. 390)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — actionable knowledge must be clear enough to guide implementation.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — relevance to “everyday life” and managerial context is explicit.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — tied to ability to “implement” findings.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — implicit in application to “managers in everyday life” but not explicitly elaborated.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — implied in the ability to illustrate design causality but not a standalone criterion.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — theories must be consistent with values and intended consequences.  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Theories of managing as theories of effectiveness.</p></li>
<li><p>Normative theory of management rooted in values and goals.</p></li>
<li><p>Prior works: Argyris (1982); Argyris &amp; Schön (1996).</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>No quantitative indicators provided; assessment is conceptual, focusing on implementability, consequence persistence, and normative alignment.</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Traditional causality models that constrain learning.  </p>

<p> - Disconnect between external validity and applicability.  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Adoption of design causality.  </p>

<p> - Normative alignment of theory and practice.  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on Argyris’ prior work and critiques conventional empirical methods, adding a normative and practical dimension to discussions of external validity.</p>

<hr />

<h2>Summary</h2>

<p>Chris Argyris’ 1996 paper “Actionable Knowledge: Design Causality in the Service of Consequential Theory” is a conceptual exploration of how to make research knowledge truly usable in managerial contexts. Actionability here is the ability of knowledge to be implemented in real-world situations, producing intended and sustainable consequences. Argyris critiques conventional causality for its limits on learning and proposes “design causality” as an alternative that fosters adaptability, relevance, and goal alignment. The paper positions management theory as normative, rooted in values, and inseparable from practice. It offers a framework (design causality) to bridge the gap between external validity and practical application, emphasizing clarity, contextual relevance, feasibility, and goal alignment as critical dimensions of actionability.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Strong conceptual definition and detailed features directly tied to actionability; clear theoretical framing.  </p></li>
<li><p><strong>Operationalization Score:</strong> 85 — Offers a defined approach (design causality) and implementation illustration, though lacks quantitative or procedural precision.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Actionable knowledge is that knowledge required to implement the external validity (relevance) in that world.” (p. 390)  </p></li>
<li><p>“The claim is made that the concept of causality… makes it difficult to transform knowledge with high external validity into actionable knowledge.” (p. 390)  </p></li>
<li><p>“A different concept of causality is proposed that enhances actionability. Design causality is defined, and how it can be implemented is illustrated.” (p. 390)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Argyris, C. (1982)  </p></li>
<li><p>Argyris, C., &amp; Schön, D. (1996)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: A semiquantitative metric for evaluating clinical actionability of incidental or secondary findings from genome-scale sequencing  </p>

<p>Authors: Jonathan S. Berg, Ann Katherine M. Foreman, Julianne M. O’Daniel, Jessica K. Booker, Lacey Boshe, Timothy Carey, Kristy R. Crooks, Brian C. Jensen, Eric T. Juengst, Kristy Lee, Daniel K. Nelson, Bradford C. Powell, Cynthia M. Powell, Myra I. Roche, Cecile Skrzynia, Natasha T. Strande, Karen E. Weck, Kirk C. Wilhelmsen, James P. Evans  </p>

<p>DOI: 10.1038/gim.2015.104  </p>

<p>Year: 2016  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Genomic Medicine / Medical Genetics  </p>

<p>Subdomain/Topic: Clinical Actionability Assessment in Genomic Sequencing  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 100  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual Framework Development and Application  </p>

<p>Study Context: Evaluation of incidental/secondary findings in clinical genome-scale sequencing  </p>

<p>Geographic/Institutional Context: University of North Carolina at Chapel Hill, USA  </p>

<p>Target Users/Stakeholders: Clinical geneticists, genomic testing laboratories, healthcare providers, policy-makers  </p>

<p>Primary Contribution Type: Framework/method for assessing clinical actionability of gene–disease pairs  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>A semiquantitative metric for evaluating clinical actionability of incidental or secondary findings from genome-scale sequencing  </p>

<p><strong>Authors:</strong>  </p>

<p>Jonathan S. Berg et al.  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1038/gim.2015.104  </p>

<p><strong>Year:</strong>  </p>

<p>2016  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Genomic Medicine / Medical Genetics  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Clinical Actionability Assessment in Genomic Sequencing  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the challenge of systematically evaluating the clinical actionability of genomic variants identified incidentally or as secondary findings in genome-scale sequencing. It is situated within clinical genomic diagnostics, particularly in defining and standardizing which gene–disease pairs warrant routine reporting based on actionability.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of North Carolina at Chapel Hill, USA  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Clinical geneticists, genetic counselors, genomic laboratories, healthcare providers, professional organizations (e.g., ACMG), policy-makers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework and scoring metric development, applied analysis of multiple gene lists  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Development and validation of a semiquantitative scoring framework for clinical actionability  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper presents a semiquantitative metric for evaluating the clinical actionability of incidental or secondary findings in genome-scale sequencing. Developed by the Locus-Variant Binning Committee (LVBC) of the NCGENES project, the metric assesses five elements—severity, likelihood, efficacy of intervention, burden of intervention, and strength of the knowledge base—each scored from 0 to 3, producing a total score from 0 to 15. The framework was applied to 161 provisionally actionable genes, the 57 ACMG-recommended genes, and 1,000 randomly selected genes, demonstrating the metric’s ability to discriminate between highly actionable and less actionable conditions. The authors propose a score of ≥11 as a threshold for high actionability and highlight the framework’s flexibility, transparency, and potential for adaptation across contexts.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is conceptualized as a <strong>continuum</strong> rather than a binary state, integrating the potential severity and likelihood of adverse health outcomes, the effectiveness and acceptability of preventive or therapeutic interventions, and the strength of supporting evidence.  </p>

<blockquote>
  <p>“The LVBC developed a semiquantitative metric for determining the clinical actionability of gene–disease pairs. This metric explicitly recognizes that actionability is a continuum, not a binary state.” (p. 468)  </p>
</blockquote>

<blockquote>
  <p>“The subcategories… approximate the clinical utility of revealing incidental/secondary findings in a presymptomatic individual.” (p. 472)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>High severity of the potential health outcome  </p></li>
<li><p>Moderate to high likelihood of disease manifestation  </p></li>
<li><p>Availability of effective preventive or therapeutic interventions  </p></li>
<li><p>Low burden or acceptable risk of intervention  </p></li>
<li><p>Substantial and reliable knowledge base supporting decision-making  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Semiquantitative Metric for Clinical Actionability  </p></li>
<li><p><strong>Methods/Levers:</strong> Five criteria scored 0–3 (severity, likelihood, efficacy, burden, knowledge base)  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Evidence review → Assign scores for each criterion → Consensus scoring by multidisciplinary panel → Total score calculation → Apply threshold (≥11) for actionability  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Literature from OMIM, GeneReviews, PubMed, clinical guidelines  </p></li>
<li><p><strong>Implementation Context:</strong> NCGENES project and ACMG incidental findings recommendations  </p></li>
</ul>

<blockquote>
  <p>“All five criteria are scored on a scale of 0–3… The outcome and intervention are defined in advance… to balance clinical effects against benefits and harms.” (p. 469)  </p>
</blockquote>

<blockquote>
  <p>“The LVBC chose to consider genes with a score ≥11… as meeting the threshold of actionability.” (p. 472)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Clarity through structured scoring definitions (Table 1)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Explicit to presymptomatic, incidental/secondary findings context  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Evaluated through “burden of intervention” score  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Implied in presymptomatic intervention consideration  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Transparent, evidence-based scoring with defined criteria  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — Implicit alignment with clinical utility and patient benefit  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Knowledge base strength</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Clinical utility concepts from genomic medicine  </p></li>
<li><p>Evidence-based assessment models  </p></li>
<li><p>Prior ACMG deliberative consensus recommendations  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Total score (0–15)  </p></li>
<li><p>Threshold ≥11 for high actionability  </p></li>
<li><p>Subscores for severity, likelihood, efficacy, burden, and knowledge base  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Limited evidence base; subjective burden assessment; rare diseases with insufficient penetrance data  </p></li>
<li><p><strong>Enablers:</strong> Structured metric; multidisciplinary consensus; adaptability to different contexts  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper builds on and critiques earlier expert consensus models like the ACMG recommendations, adding a reproducible, transparent, and adaptable scoring framework for actionability.</p>

<hr />

<h2>Summary</h2>

<p>This paper delivers a rigorous, transparent framework for assessing the clinical actionability of incidental or secondary genomic findings, operationalizing actionability as a multidimensional continuum. Its five equally weighted dimensions—severity, likelihood, efficacy, burden, and knowledge base—are scored to produce a composite metric (0–15). A threshold score of ≥11 designates high actionability. The framework is validated through comparative analysis of ACMG-recommended genes, provisionally actionable genes, and random genes, demonstrating clear discriminatory capacity. It is adaptable to various clinical and policy contexts, supports reproducibility, and allows for updates as knowledge evolves, marking a significant advance in standardized genomic reporting.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Clear conceptualization of actionability as multidimensional, detailed definitions, and systematic feature set  </p></li>
<li><p><strong>Operationalization Score:</strong> 100 — Fully developed metric with applied examples and scoring workflow  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Actionability is a continuum, not a binary state.” (p. 468)  </p></li>
<li><p>“The LVBC established five core characteristics of clinical actionability…” (p. 469)  </p></li>
<li><p>“The LVBC chose to consider genes with a score ≥11… as meeting the threshold of actionability.” (p. 472)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>ACMG Recommendations for Reporting of Incidental Findings (Green et al., 2013)  </p></li>
<li><p>Evidence-based Genomic Applications in Practice and Prevention Working Group (Goddard et al., 2013)  </p></li>
<li><p>NCGENES project preliminary outputs (Berg et al., 2013)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: A look into travel motivation post-crisis: Insights from means-end chain theory</p>

<p>Authors: Swechchha Subedi, Lali Odosashvili, Marketa Kubickova</p>

<p>DOI: https://doi.org/10.1016/j.jhtm.2025.05.013</p>

<p>Year: 2025</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Hospitality and Tourism Management</p>

<p>Subdomain/Topic: Post-crisis travel motivation, Means-End Chain (MEC) theory</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 92</p>

<p>Operationalization Score: 88</p>

<p>Contains Definition of Actionability: Yes (implicit, through “actionable insights for tourism practitioners” and conditions for effective tourism offerings)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes (Crisis-Modified MEC Framework)</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Quantitative (hard laddering MEC survey)</p>

<p>Study Context: International leisure travel motivation post-COVID-19</p>

<p>Geographic/Institutional Context: U.S. residents (international travel context)</p>

<p>Target Users/Stakeholders: Destination Marketing Organizations (DMOs), tourism practitioners, policy makers</p>

<p>Primary Contribution Type: Theoretical and practical framework advancement</p>

<p>CL: Yes — clarity of destination attributes and value linkages is explicitly linked to actionability</p>

<p>CR: Yes — contextual relevance (post-crisis, safety, cultural connection)</p>

<p>FE: Yes — feasibility discussed in aligning offerings with traveler needs</p>

<p>TI: Yes — timeliness in responding to evolving post-crisis priorities</p>

<p>EX: Yes — explainability via hierarchical value maps</p>

<p>GA: Yes — goal alignment with traveler values and DMO strategies</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>A look into travel motivation post-crisis: Insights from means-end chain theory  </p>

<p><strong>Authors:</strong>  </p>

<p>Swechchha Subedi, Lali Odosashvili, Marketa Kubickova  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1016/j.jhtm.2025.05.013  </p>

<p><strong>Year:</strong>  </p>

<p>2025  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Hospitality and Tourism Management  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Post-crisis travel motivation, Means-End Chain (MEC) theory  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>Examines how major crises, specifically COVID-19, have reshaped leisure travel motivations, destination attribute prioritization, and cognitive linkages using the Means-End Chain (MEC) theory.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>U.S.-based survey with international travel focus.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Destination Marketing Organizations, tourism stakeholders, policy makers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative (hard laddering MEC survey, hierarchical value mapping).  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Theoretical expansion (Crisis-Modified MEC Framework) and practitioner guidance.  </p>

<h2>General Summary of the Paper</h2>

<p>This study explores how COVID-19 has altered the cognitive structures underlying international leisure travel decisions. Using MEC theory and hard laddering with 415 U.S. participants, it identifies three key post-crisis phenomena: <strong>motivation realignment</strong> (safety, natural scenery, and cultural attributes moving to central motivators), <strong>compression effect</strong> (shorter cognitive pathways between attributes, consequences, and values), and <strong>value resilience</strong> (core values like personal happiness remain stable despite structural changes). The authors develop a <strong>Crisis-Modified MEC Framework</strong> integrating macro-level disruptions (pandemic) with micro-level demographic influences. Findings offer actionable strategies for DMOs, such as emphasizing safety protocols, nature-based travel, wellness experiences, and cultural engagement in intimate settings.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as the tourism sector’s ability to <strong>align post-crisis offerings with restructured traveler motivations and stable core values</strong>, enabling targeted, effective interventions.  </p>

<blockquote>
  <p>“The study also provides actionable insights for tourism practitioners, emphasizing the need for tailored, post-crisis experiences that align with the evolving values of today’s travelers.” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“By addressing key motivators such as safety, relaxation, and cultural connection, DMOs can align their offerings with travelers’ expectations…” (p. 428)  </p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Direct alignment with travelers’ <strong>core values</strong> (e.g., personal happiness, self-reflection, enhanced enjoyment of life).</p></li>
<li><p>Incorporation of <strong>repositioned attributes</strong> (e.g., safety, natural scenery) into central offerings.</p></li>
<li><p>Ability to <strong>adapt frameworks</strong> to crisis conditions (flexibility, safety protocols, smaller-scale cultural experiences).</p></li>
<li><p>Evidence-based linkages between <strong>destination attributes → consequences → values</strong> via hierarchical mapping.</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Crisis-Modified MEC Framework.</p></li>
<li><p><strong>Methods/Levers:</strong> Hard laddering surveys; Hierarchical Value Mapping (HVM); demographic segmentation.</p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify priority attributes post-crisis; map A-C-V chains; detect motivation realignment, compression effect, value resilience; tailor marketing/offerings accordingly.</p></li>
<li><p><strong>Data &amp; Measures:</strong> 22 attributes, 9 consequences, 13 values (see Table 2); linkage frequencies from implication matrices.</p></li>
<li><p><strong>Implementation Context:</strong> DMOs redesigning tourism strategies for post-COVID conditions.</p></li>
</ul>

<blockquote>
  <p>“…health safety has become a critical driver of destination choice… creating new benchmarks for what constitutes a ‘safe’ destination.” (p. 426)  </p>
</blockquote>

<blockquote>
  <p>“Flexible booking options… address uncertainty while fostering trust and reducing perceived risks.” (p. 428)  </p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Clear mapping of attributes to values via HVM.</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Post-crisis travel shifts explicitly tied to safety, cultural relevance.</p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Practical recommendations like flexible bookings, wellness tourism.</p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — Responding to immediate post-crisis traveler shifts.</p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Visual and narrative explanation of cognitive linkages.</p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — DMOs aligning with enduring traveler values.</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Motivation realignment, compression effect, value resilience.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Borgardt’s extended MEC framework (macro-environmental influence).</p></li>
<li><p>Hill et al. (2022) on direct attribute-value linkages.</p></li>
<li><p>Classic MEC theory (Gutman, 1982; Reynolds &amp; Gutman, 1988).</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Frequency of A-C-V linkages.</p></li>
<li><p>Attribute prioritization frequencies.</p></li>
<li><p>Shift in pathway lengths (compression effect).</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Rigid traditional travel motivation models; oversimplified attribute categorizations; uncertainty in global travel.</p></li>
<li><p><strong>Enablers:</strong> Demographic-specific tailoring; visible safety protocols; integration of nature and culture; flexible travel policies.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Challenges push-pull and hierarchical motivation models for their static assumptions, proposing dynamic structural shifts in MEC hierarchies post-crisis.</p>

<h2>Summary</h2>

<p>This paper operationalizes actionability as the ability to adapt tourism offerings to post-crisis traveler motivations by re-mapping the attribute–consequence–value chains. It demonstrates that crises cause <strong>motivation realignment</strong> (peripheral attributes becoming central), <strong>compression effects</strong> (shorter cognitive linkages), and <strong>value resilience</strong> (core values persisting despite pathway changes). The Crisis-Modified MEC Framework merges macro-crisis effects with demographic segmentation, offering DMOs a tool to design contextually relevant, feasible, and value-aligned travel experiences. Actionability here depends on the clarity of A-C-V relationships, the timeliness of adjustments, and the alignment of offerings with enduring traveler values, all backed by systematic mapping and measurable linkage frequencies.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Strong conceptual clarity on actionability, rich with systematic features and definitions via MEC.</p></li>
<li><p><strong>Operationalization Score:</strong> 88 — Detailed process for achieving actionability through mapping and framework adaptation; could be enhanced by more cross-context validation.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“The study also provides actionable insights for tourism practitioners, emphasizing the need for tailored, post-crisis experiences that align with the evolving values of today’s travelers.” (p. 1)  </p></li>
<li><p>“Health safety has become a critical driver of destination choice… creating new benchmarks for what constitutes a ‘safe’ destination.” (p. 426)  </p></li>
<li><p>“The Crisis-Modified MEC Framework… incorporates both macro-level disruptions and micro-level demographic factors as active forces in reshaping decision hierarchies.” (p. 429)  </p></li>
<li><p>“Despite significant restructuring… certain fundamental values… maintain their importance… accessible through different pathways.” (p. 429)  </p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Borgardt (2018) — Extended MEC framework.</p></li>
<li><p>Hill et al. (2022) — Direct attribute-value linkages.</p></li>
<li><p>McIntosh &amp; Thyne (2005) — MEC in tourism.</p></li>
<li><p>Jiang et al. (2015) — Pre-crisis MEC structures in tourism.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: A framework to rank genomic alterations as targets for cancer precision medicine: the ESMO Scale for Clinical Actionability of molecular Targets (ESCAT)  </p>

<p>Authors: Mateo, J.; Chakravarty, D.; Dienstmann, R.; Jezdic, S.; Gonzalez-Perez, A.; Lopez-Bigas, N.; Ng, C.K.Y.; Bedard, P.L.; Tortora, G.; Douillard, J.-Y.; Van Allen, E.M.; Schultz, N.; Swanton, C.; Andre, F.; Pusztai, L.  </p>

<p>DOI: 10.1093/annonc/mdy263  </p>

<p>Year: 2018  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Oncology / Precision Medicine  </p>

<p>Subdomain/Topic: Genomic targets prioritization, cancer biomarkers, targeted therapy classification  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (ESCAT)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual framework development and consensus guidelines  </p>

<p>Study Context: Classification and prioritization of molecular targets for cancer treatment based on clinical evidence  </p>

<p>Geographic/Institutional Context: Multinational collaboration (Europe, USA, Canada) led by ESMO  </p>

<p>Target Users/Stakeholders: Oncologists, molecular tumor boards, clinical researchers, drug developers, regulatory agencies  </p>

<p>Primary Contribution Type: Conceptual framework and evidence-based classification system  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: No  </p>

<p>EX: Partial  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>A framework to rank genomic alterations as targets for cancer precision medicine: the ESMO Scale for Clinical Actionability of molecular Targets (ESCAT)  </p>

<p><strong>Authors:</strong>  </p>

<p>Mateo, J.; Chakravarty, D.; Dienstmann, R.; Jezdic, S.; Gonzalez-Perez, A.; Lopez-Bigas, N.; Ng, C.K.Y.; Bedard, P.L.; Tortora, G.; Douillard, J.-Y.; Van Allen, E.M.; Schultz, N.; Swanton, C.; Andre, F.; Pusztai, L.</p>

<p><strong>DOI:</strong>  </p>

<p>10.1093/annonc/mdy263  </p>

<p><strong>Year:</strong>  </p>

<p>2018  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Oncology / Precision Medicine  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Genomic targets prioritization, cancer biomarkers, targeted therapy classification  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the lack of harmonization in defining and prioritizing “actionable” genomic alterations in cancer, aiming to support precision medicine by establishing a globally applicable, evidence-based classification for clinical utility of molecular targets. Intended for oncologists, researchers, and policy-makers, the ESCAT framework provides a tiered system to guide treatment selection and drug development.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Led by the European Society for Medical Oncology (ESMO) with contributors from multiple global institutions.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Oncologists, clinical researchers, molecular tumor boards, drug developers, regulatory agencies.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework development via expert consensus and literature synthesis.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework / classification system.  </p>

<h2>General Summary of the Paper</h2>

<p>The authors present the ESMO Scale for Clinical Actionability of molecular Targets (ESCAT), a structured, six-tier classification system ranking genomic alterations by strength of evidence and clinical utility in guiding targeted cancer therapies. Drawing on existing but fragmented classification approaches, the framework differentiates between targets ready for routine clinical use, investigational targets, those with benefit in other tumor types, preclinical-only evidence, co-targeting opportunities, and non-actionable alterations. ESCAT emphasizes evidence-based prioritization, clear terminology, and adaptability as new data emerge, aiming to standardize reporting and decision-making in precision oncology.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionability is defined as the clinical utility of a genomic alteration for guiding targeted therapy, grounded in strength of evidence from clinical and preclinical studies. The ESCAT framework explicitly links actionability to demonstrated patient benefit in specific clinical contexts.  </p>

<blockquote>
  <p>“The ESCAT defines clinical evidence-based criteria to prioritise genomic alterations as markers to select patients for targeted therapies.” (p. 1895)  </p>
</blockquote>

<blockquote>
  <p>“We consider a target ‘tier I-A’, if… data… has demonstrated clinically meaningful improvement of a survival end point…” (p. 1896)  </p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Demonstrated clinical benefit in survival or relevant endpoints in appropriate trial designs.</p></li>
<li><p>Consistency of benefit across tumor types (for tier I-C) or specificity to certain tumor contexts.</p></li>
<li><p>Supporting evidence from retrospective, prospective, or preclinical studies depending on tier.</p></li>
<li><p>Predictive rather than merely prognostic value.</p></li>
<li><p>Feasibility of therapeutic intervention targeting the alteration.</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> ESMO Scale of Clinical Actionability for molecular Targets (ESCAT)  </p></li>
<li><p><strong>Methods/Levers:</strong> Evidence-tier system based on trial type, outcome measures, and tumor specificity.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Classify molecular targets into ESCAT tiers I–X; integrate into tumor boards and genomic reports; revise tiers as new evidence emerges.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Clinical trial endpoints (OS, PFS), response rates, biomarker presence, preclinical models, in silico predictions.  </p></li>
<li><p><strong>Implementation Context:</strong> Precision oncology decision-making, research prioritization, and reporting harmonization.  </p></li>
</ul>

<blockquote>
  <p>“This classification system aims to offer a common language… to place targets within their clinical context.” (p. 1895)  </p>
</blockquote>

<blockquote>
  <p>“The scale uses the strength of evidence from clinical studies as the basis to assign tiers…” (p. 1900)  </p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><strong>CL (Clarity):</strong> Yes — Clear definition and tier structure; standardized terminology.  </li>
</ul>

<blockquote>
  <p>“…offer a terminology that can be broadly applicable and help clinicians…” (p. 1901)  </p>
</blockquote>

<ul>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Tiers depend on tumor-type-specific evidence.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Only feasible therapeutic targets are considered for higher tiers.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No explicit mention as an actionability criterion.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — Mechanistic rationale described for examples but not formalized as a requirement.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Focus on improving patient outcomes and guiding therapy choice.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Magnitude of benefit; type and quality of evidence.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Builds on and harmonizes prior classification schemas (Andre et al. 2014; Van Allen et al. 2014; Meric-Bernstam et al. 2015; OncoKB 2017).</p></li>
<li><p>Incorporates ESMO Magnitude of Clinical Benefit Scale.</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Clinical trial endpoints: overall survival (OS), progression-free survival (PFS), objective response rate (ORR).</p></li>
<li><p>Magnitude of benefit per ESMO MCBS.</p></li>
<li><p>Level and type of supporting evidence.</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of harmonized terminology; variable evidence strength; tumor heterogeneity; rarity of alterations; limited trial feasibility.  </p></li>
<li><p><strong>Enablers:</strong> ESCAT tier system; existing genomic databases; collaborative curation; prospective registries.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions ESCAT as an integrative and globally applicable framework addressing gaps in prior systems, emphasizing consistent evidence grading and cross-tumor applicability when justified.</p>

<h2>Summary</h2>

<p>This paper presents ESCAT, a structured, evidence-based framework for ranking genomic alterations in cancer by clinical actionability. Actionability is defined by the strength of clinical evidence supporting a target–drug match, contextualized by tumor type and measured by meaningful clinical endpoints. The system includes six tiers (I–V, X) spanning from ready-for-routine use to non-actionable findings. ESCAT is both a conceptual and operational tool, offering explicit criteria for tier assignment, a shared terminology for reporting, and adaptability as evidence evolves. Its adoption aims to reduce overinterpretation of hypothetical targets, ensure high-value interventions are prioritized, and foster alignment among oncologists, researchers, and regulators.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Strong, explicit definition of actionability, detailed features tied to clinical utility, robust conceptual clarity.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Fully developed framework with concrete tiering system, explicit criteria, examples, and integration guidance.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“The ESCAT defines clinical evidence-based criteria to prioritise genomic alterations…” (p. 1895)  </p></li>
<li><p>“We consider a target ‘tier I-A’, if… data… has demonstrated clinically meaningful improvement…” (p. 1896)  </p></li>
<li><p>“The scale uses the strength of evidence from clinical studies as the basis to assign tiers to a target.” (p. 1900)  </p></li>
<li><p>“Clear terminology regarding clinical utility should decrease the chance for misinterpretation…” (p. 1901)  </p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Andre et al., Ann Oncol 2014  </p></li>
<li><p>Van Allen et al., Nat Med 2014  </p></li>
<li><p>Meric-Bernstam et al., J Natl Cancer Inst 2015  </p></li>
<li><p>Chakravarty et al., JCO Precis Oncol 2017 (OncoKB)  </p></li>
<li><p>ESMO Magnitude of Clinical Benefit Scale (Cherny et al., Ann Oncol 2017)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: A framework for genomic biomarker actionability and its use in clinical decision making</p>

<p>Authors: Smruti J. Vidwans, Michelle L. Turski, Filip Janku, Ignacio Garrido-Laguna, Javier Munoz, Richard Schwab, Vivek Subbiah, Jordi Rodon, Razelle Kurzrock</p>

<p>DOI: 10.18632/oncoscience.104</p>

<p>Year: 2014</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Oncology, Genomics</p>

<p>Subdomain/Topic: Biomarker actionability, targeted cancer therapy</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 95</p>

<p>Operationalization Score: 90</p>

<p>Contains Definition of Actionability: Yes</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual framework</p>

<p>Study Context: Genomic biomarkers in cancer diagnosis and treatment planning</p>

<p>Geographic/Institutional Context: USA, Spain (multi-institutional collaboration)</p>

<p>Target Users/Stakeholders: Oncologists, molecular pathologists, clinical researchers</p>

<p>Primary Contribution Type: Conceptual framework and practical categorization</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Partial</p>

<p>EX: Yes</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>A framework for genomic biomarker actionability and its use in clinical decision making</p>

<p><strong>Authors:</strong>  </p>

<p>Smruti J. Vidwans, Michelle L. Turski, Filip Janku, Ignacio Garrido-Laguna, Javier Munoz, Richard Schwab, Vivek Subbiah, Jordi Rodon, Razelle Kurzrock</p>

<p><strong>DOI:</strong>  </p>

<p>10.18632/oncoscience.104</p>

<p><strong>Year:</strong>  </p>

<p>2014</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Oncology, Genomics</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Biomarker actionability, targeted cancer therapy</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the growing use of molecular diagnostics in oncology, particularly genomic biomarkers, and the challenges of translating these findings into clinical decision-making. It proposes a structured actionability framework to categorize and assess biomarkers based on evidence, potential therapeutic targeting, and clinical relevance.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>USA and Spain, involving institutions like MD Anderson Cancer Center, University of California San Diego, Huntsman Cancer Institute, and Vall d’Hebron Institut d’Oncologia.</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Oncologists, molecular pathologists, clinical researchers, trial designers.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework development.</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Proposal of a structured framework for determining biomarker actionability in cancer.</p>

<h2>General Summary of the Paper</h2>

<p>The authors present a comprehensive framework for evaluating the actionability of genomic biomarkers in cancer treatment decision-making. They classify biomarkers into categories based on their functional role in malignancy, drug targetability (approved or investigational), pathway involvement, homology to actionable biomarkers, or use in targeted delivery. The framework incorporates both the "basis" of actionability and the "rationale"—ranging from companion diagnostics and treatment guidelines to pre-clinical evidence and genetic disease analogies. Practical considerations for applying the framework in clinical contexts are discussed, including complexities like multiple co-occurring aberrations, histology-agnostic relevance, and novel variants. The paper aims to bridge the gap between the proliferation of genomic data and its effective use in guiding targeted cancer therapy.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>Actionability refers to a biomarker being oncogenic and/or differentially expressed in tumor cells such that it can be therapeutically targeted to mitigate oncogenic potential or enable selective tumor destruction.</p>

<blockquote>
  <p>“A biomarker is actionable if it is oncogenic and/or differentially expressed on tumor cells, and a treatment approach can be crafted that mitigates its oncogenic potential…” (p. 614)  </p>
</blockquote>

<blockquote>
  <p>“A gene may be considered theoretically actionable if it has a basis of actionability….” (p. 614)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Functional role in driving malignancy.</p></li>
<li><p>Targetability by approved or investigational drugs.</p></li>
<li><p>Involvement in targetable pathways (directly or indirectly).</p></li>
<li><p>Homology to other actionable biomarkers.</p></li>
<li><p>Differential expression enabling targeted delivery.</p></li>
<li><p>Supportive evidence from clinical guidelines, clinical/pre-clinical studies, or analogous genetic diseases.</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Basis of Actionability &amp; Rationale for Actionability.</p></li>
<li><p><strong>Methods/Levers:</strong> Categorization based on functional role, drug targetability, pathway involvement, homology, or expression pattern.</p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify biomarker → Determine category (basis) → Map rationale (evidence type) → Match with therapeutic options or trials.</p></li>
<li><p><strong>Data &amp; Measures:</strong> Clinical trial data, pre-clinical evidence, treatment guidelines, registry data, genetic disease analogies.</p></li>
<li><p><strong>Implementation Context:</strong> Personalized oncology decision-making.</p></li>
</ul>

<blockquote>
  <p>“The framework also includes a rationale for actionability in which strength of evidence for a biomarker is mapped to <em>highest</em> strength of evidence for a given cancer.” (p. 615)  </p>
</blockquote>

<blockquote>
  <p>“A biomarker may be considered actionable if it is a direct target of one or more approved drugs…” (p. 616)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><strong>CL (Clarity):</strong> Yes — clearly defined biomarker-drug relationships are necessary for actionability.  </li>
</ul>

<blockquote>
  <p>“…standards exist that outline treatments for individuals harboring aberrations in the biomarker…” (p. 614)  </p>
</blockquote>

<ul>
<li><strong>CR (Contextual Relevance):</strong> Yes — considers histology-specific and histology-agnostic evidence.  </li>
</ul>

<blockquote>
  <p>“…extrapolating predictive data from the tumor site of origin with the highest strength of evidence to a different histology…” (p. 619)  </p>
</blockquote>

<ul>
<li><p><strong>FE (Feasibility):</strong> Yes — includes evidence-based categories to guide clinical applicability.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — recognizes rapid adoption of NGS and challenges in matching treatments to emerging data.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — detailed rationale for why a biomarker is actionable.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — aligns biomarker actionability with optimal patient outcomes.</p></li>
</ul>

<p><strong>Other Dimensions Named by Authors:</strong>  </p>

<ul>
<li><p>Strength of evidence level.</p></li>
<li><p>Functional role versus passenger status.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Companion diagnostics in oncology.</p></li>
<li><p>NCCN and FDA treatment guideline frameworks.</p></li>
<li><p>Molecular oncology concepts like oncogenic drivers, passengers, and pathway targeting.</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Approval status of drugs with companion diagnostics.</p></li>
<li><p>Inclusion in treatment guidelines.</p></li>
<li><p>Evidence from clinical trials, pre-clinical studies, or genetic disease contexts.</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Conflicting data across histologies, novel variants of unknown significance, tumor genomic complexity.  </p></li>
<li><p><strong>Enablers:</strong> Systems biology approaches, multi-omic profiling, histology-agnostic trial designs.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Builds on existing oncology guidelines and targeted therapy concepts but integrates them into a unified framework explicitly linking biomarker characteristics and evidence types to clinical actionability.</p>

<h2>Summary</h2>

<p>This paper offers a structured framework for assessing genomic biomarker actionability in cancer therapy, combining mechanistic insights with an evidence-based rationale. It identifies biomarker categories based on functional role, pathway involvement, drug targetability, and analogies to other biomarkers, and maps these to levels of supporting evidence from guidelines to pre-clinical data. The framework is intended to support personalized oncology by enabling clinicians and researchers to systematically evaluate which genomic findings are actionable, under what circumstances, and with what strength of evidence. It also acknowledges practical challenges such as histology-agnostic interpretations, multiple co-occurring aberrations, and emerging variants, proposing solutions like systems biology approaches.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Offers a direct, explicit definition of actionability, detailed categorization, and multiple linked attributes.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Provides a clear workflow and categories for applying actionability assessments in clinical practice.</p></li>
</ul>

<h2>Supporting Quotes from th</h2>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Transforming disease data into ‘actionable intelligence’</p>

<p>Authors: Arabella Gray</p>

<p>DOI: 10.1002/vetr.5447</p>

<p>Year: 2025</p>

<p>Publication Type: Journal News/Feature (Veterinary Record)</p>

<p>Discipline/Domain: Veterinary epidemiology / One Health</p>

<p>Subdomain/Topic: Animal disease surveillance dashboards; evidence-based risk management</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 62</p>

<p>Operationalization Score: 45</p>

<p>Actionable/Actionability Used in Paper: Yes — e.g., “transform complex [disease] outbreak data into clear, actionable intelligence, free of charge” (p. 297).</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — e.g., “Timely and reliable data is essential… to detect emerging threats and implement effective preventive measures” (p. 297).</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: Yes (implicit; timeliness, clarity, contextual relevance, feasibility, goal alignment)</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: No (describes a dashboard/platform rather than a theoretical framework)</p>

<p>Operationalization Present: Yes (platform features/workflows described; no formal methodology)</p>

<p>Primary Methodology: Review/Descriptive (news feature)</p>

<p>Study Context: Global animal disease outbreak surveillance platform (“Animal Disease Insights”)</p>

<p>Geographic/Institutional Context: World Organisation for Animal Health (WOAH) data; One Health Epi Consulting; global country coverage</p>

<p>Target Users/Stakeholders: Veterinarians, veterinary services, policymakers, public/animal health communities</p>

<p>Primary Contribution Type: Platform overview and implications for decision support</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Partial</p>

<p>TI: Yes</p>

<p>EX: Partial</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Transforming disease data into ‘actionable intelligence’</p>

<p><strong>Authors:</strong>  </p>

<p>Arabella Gray</p>

<p><strong>DOI:</strong>  </p>

<p>10.1002/vetr.5447</p>

<p><strong>Year:</strong>  </p>

<p>2025</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal News/Feature (Veterinary Record)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Veterinary epidemiology / One Health</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Animal disease surveillance dashboards; evidence-based risk management</p>

<p><strong>Contextual Background:</strong>  </p>

<p>This feature introduces “Animal Disease Insights,” a web-based dashboard that aggregates two decades of official global animal disease outbreak data and augments it with visualization and media analytics to support evidence-based decisions. Assumption: As a news/feature piece, it synthesizes platform functions rather than presenting original empirical research. :contentReference[oaicite:0]{index=0}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Uses official reports accessible via WOAH’s World Animal Health Information Service; global scope across ~200 countries. :contentReference[oaicite:1]{index=1}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Veterinarians, veterinary services, policymakers; broader One Health decision-makers. :contentReference[oaicite:2]{index=2}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Review/Descriptive (journal feature; no empirical study). :contentReference[oaicite:3]{index=3}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Platform overview and articulation of decision-support implications. :contentReference[oaicite:4]{index=4}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The article presents “Animal Disease Insights,” an interactive dashboard by One Health Epi Consulting. It integrates two decades of official outbreak data for 130+ diseases across ~200 countries and provides maps, trend charts, and country rankings, plus analysis of news/media coverage. Future additions include real-time social media monitoring and predictive modeling to issue proactive alerts; longer-term plans aim to include human outbreak data for zoonoses to support a One Health perspective. The piece argues that timely, reliable, and accessible data empowers veterinarians and policymakers to detect emerging threats and implement preventive measures. :contentReference[oaicite:5]{index=5}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>Yes.</strong> Verbatim mentions tied to decisions:</p>

<ul>
<li><p>“transform complex [disease] outbreak data into clear, actionable intelligence, free of charge.” (p. 297) :contentReference[oaicite:6]{index=6}  </p></li>
<li><p>“By opening up access to high‑quality disease data, we’re empowering veterinarians and veterinary services around the globe to make informed decisions that enhance both animal and public health.” (p. 297) :contentReference[oaicite:7]{index=7}  </p></li>
<li><p>“[Data] can support evidence-based risk management… [and] evidence-based decision-making.” (p. 297) :contentReference[oaicite:8]{index=8}</p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>Yes.</strong>  </p>

<ul>
<li><p>“Timely and reliable data is essential for veterinarians and policymakers to detect emerging threats and implement effective preventive measures.” (p. 297) :contentReference[oaicite:9]{index=9}  </p></li>
<li><p>Future features aim to “capture early signals of emerging threats” and use “predictive modelling to deliver proactive alerts.” (p. 297) :contentReference[oaicite:10]{index=10}</p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p><strong>Implicit conceptualization:</strong> Actionability is achieved when disease surveillance data is timely, reliable, accessible, and presented in clear, decision-oriented forms (maps, trends, rankings) that enable informed, preventive actions and risk management in a One Health context. (Synthesis from p. 297.) :contentReference[oaicite:11]{index=11}  </p>

<blockquote>
  <p>“transform… data into clear, actionable intelligence” (p. 297) :contentReference[oaicite:12]{index=12}</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Timeliness / Early signals</strong>  </p>

<p> &gt; “real-time social media monitoring to ‘capture early signals of emerging threats’… predictive modelling to deliver proactive alerts.” (p. 297) :contentReference[oaicite:13]{index=13}  </p></li>
<li><p><strong>Reliability / Data quality</strong>  </p>

<p> &gt; “Timely and reliable data is essential…” (p. 297) :contentReference[oaicite:14]{index=14}  </p></li>
<li><p><strong>Clarity of presentation</strong>  </p>

<p> &gt; “interactive maps, trend charts, country rankings” (p. 297) — to “transform complex outbreak data into clear… intelligence.” :contentReference[oaicite:15]{index=15}  </p></li>
<li><p><strong>Contextual relevance (local insights)</strong>  </p>

<p> &gt; “Country insights: individual disease events… interactive maps and local hotspots identified.” (p. 297) :contentReference[oaicite:16]{index=16}  </p></li>
<li><p><strong>Accessibility / Usability</strong>  </p>

<p> &gt; “free of charge” and designed to meet demand for “modern, user‑friendly tools.” (p. 297) :contentReference[oaicite:17]{index=17}  </p></li>
<li><p><strong>Goal alignment (One Health perspective)</strong>  </p>

<p> &gt; “incorporate human outbreak data… to ‘truly support a One Health perspective’.” (p. 297) :contentReference[oaicite:18]{index=18}</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> “Animal Disease Insights” dashboard. :contentReference[oaicite:19]{index=19}  </p></li>
<li><p><strong>Methods/Levers:</strong> Integration of official WOAH outbreak data (20 years, 130+ diseases, ~200 countries); visualization (maps, trends, rankings); media coverage analytics; planned real-time social monitoring; predictive modeling for alerts; eventual human-outbreak linkage. :contentReference[oaicite:20]{index=20}  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1) Aggregate official outbreak reports; 2) compute disease frequency and country rankings; 3) render global and country-level interactive visualizations; 4) augment with news/media analytics; 5) (planned) ingest real-time social signals; 6) (planned) run predictive models to issue proactive alerts. (Synthesized from p. 297.) :contentReference[oaicite:21]{index=21}  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Outbreak counts, cases, deaths; host–pathogen interactions; media coverage frequency; country-level rankings; (planned) social signal indicators; (planned) predictive alert thresholds. :contentReference[oaicite:22]{index=22}  </p></li>
<li><p><strong>Implementation Context:</strong> Global veterinary surveillance; evidence-based risk management for animal and public health. :contentReference[oaicite:23]{index=23}  </p></li>
</ul>

<blockquote>
  <p>“By making official animal health data publicly accessible, we support evidence-based decision‑making…” (p. 297) :contentReference[oaicite:24]{index=24}</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> <strong>Yes.</strong> “transform complex… data into clear… intelligence.” (p. 297) :contentReference[oaicite:25]{index=25}  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> <strong>Yes.</strong> “Country insights… local hotspots identified.” (p. 297) :contentReference[oaicite:26]{index=26}  </p></li>
<li><p><strong>FE (Feasibility):</strong> <strong>Partial.</strong> “free of charge”; “user‑friendly tools” (no explicit feasibility constraints discussed). (p. 297) :contentReference[oaicite:27]{index=27}  </p></li>
<li><p><strong>TI (Timeliness):</strong> <strong>Yes.</strong> “real-time… capture early signals… proactive alerts.” (p. 297) :contentReference[oaicite:28]{index=28}  </p></li>
<li><p><strong>EX (Explainability):</strong> <strong>Partial.</strong> Predictive modelling mentioned without detail; visualizations aid interpretation. (p. 297) :contentReference[oaicite:29]{index=29}  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> <strong>Yes.</strong> “truly support a One Health perspective”; “risk management,” “decision‑making.” (p. 297) :contentReference[oaicite:30]{index=30}  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Accessibility (“free of charge”), Data Quality (“high‑quality,” “reliable”). (p. 297) :contentReference[oaicite:31]{index=31}</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<p>No formal theory; the piece situates the dashboard within One Health and evidence-based risk management paradigms. :contentReference[oaicite:32]{index=32}</p>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>Implied indicators: outbreak frequency, cases, deaths, country rankings, detection of “early signals,” and issuance of proactive alerts; no explicit KPI framework. :contentReference[oaicite:33]{index=33}</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Not explicitly discussed; implicitly, complexity of data and lack of timely signals. (p. 297) :contentReference[oaicite:34]{index=34}  </p></li>
<li><p><strong>Enablers:</strong> Public accessibility of official data, user‑friendly interface, media analytics, real‑time social monitoring, predictive modelling, One Health integration. (p. 297) :contentReference[oaicite:35]{index=35}</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The article references WOAH’s official reporting system and positions the dashboard as complementary—adding visualization, rankings, and media analytics not available in other global platforms. It echoes broader One Health calls for integrated, cross‑species surveillance to inform evidence‑based action. :contentReference[oaicite:36]{index=36}</p>

<hr />

<h2>Summary</h2>

<p>This journal feature profiles a global surveillance dashboard that reframes official animal disease reports into decision‑oriented outputs. Actionability is construed as the combination of timely, reliable data with clear, contextualized visualization and access, enabling veterinarians and policymakers to detect threats and act preventively. The platform operationalizes this via global/country views, host–pathogen lenses, rankings, and media analytics, and plans to heighten timeliness with real‑time social monitoring and predictive alerts. While no formal definition or theory of “actionable intelligence” is provided, the article consistently links clarity, timeliness, accessibility, and One Health alignment to actionable decision‑support. The piece is descriptive rather than empirical, but it delineates concrete levers—data integration, visualization, and alerting—that practitioners can associate with producing actionable insights in veterinary epidemiology. :contentReference[oaicite:37]{index=37}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> <strong>62/100.</strong> Strong explicit use of “actionable intelligence” and multiple implied dimensions (timeliness, clarity, context, access). Lacks formal definition or deep conceptual framework, keeping the score moderate. :contentReference[oaicite:38]{index=38}  </p></li>
<li><p><strong>Operationalization Score:</strong> <strong>45/100.</strong> Provides practical platform features and describes future alerting, but without methodological detail (e.g., models, thresholds, evaluation), limiting actionable “how‑to” specificity. :contentReference[oaicite:39]{index=39}</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“transform complex [disease] outbreak data into clear, actionable intelligence, free of charge.” (p. 297) :contentReference[oaicite:40]{index=40}  </p></li>
<li><p>“Timely and reliable data is essential… to detect emerging threats and implement effective preventive measures.” (p. 297) :contentReference[oaicite:41]{index=41}  </p></li>
<li><p>“real-time social media monitoring to ‘capture early signals of emerging threats’, and… predictive modelling to deliver proactive alerts.” (p. 297) :contentReference[oaicite:42]{index=42}  </p></li>
<li><p>“By making official animal health data publicly accessible, we support evidence-based decision-making and contribute to a safer future for animals and people.” (p. 297) :contentReference[oaicite:43]{index=43}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A (news/feature article; no explicit academic citations beyond WOAH resources are discussed in the text). :contentReference[oaicite:44]{index=44}</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Actionable Knowledge Discovery and Delivery  </p>

<p>Authors: Longbing Cao  </p>

<p>DOI: 10.1002/widm.1044  </p>

<p>Year: 2012  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Data Mining / Knowledge Discovery  </p>

<p>Subdomain/Topic: Actionable Knowledge Discovery (AKD), Domain-Driven Data Mining  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 98  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual / Framework Development  </p>

<p>Study Context: Knowledge discovery in data mining, focusing on bridging the gap between academic outputs and business decision-making  </p>

<p>Geographic/Institutional Context: University of Technology, Sydney, Australia  </p>

<p>Target Users/Stakeholders: Data mining researchers, practitioners, business decision-makers  </p>

<p>Primary Contribution Type: Conceptual framework and methodological proposition (Domain-Driven Data Mining for AKD)  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Actionable Knowledge Discovery and Delivery  </p>

<p><strong>Authors:</strong>  </p>

<p>Longbing Cao  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1002/widm.1044  </p>

<p><strong>Year:</strong>  </p>

<p>2012  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Data Mining / Knowledge Discovery  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Actionable Knowledge Discovery (AKD), Domain-Driven Data Mining  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the persistent gap between data mining research outputs and the needs of business decision-makers. It proposes a paradigm shift from traditional Knowledge Discovery in Databases (KDD) to Actionable Knowledge Discovery (AKD), emphasizing integration of business context, environmental constraints, and human expertise into data mining processes.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of Technology, Sydney, Australia  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Data mining researchers, practitioners, and business decision-makers in domains such as retail, healthcare, intrusion detection, and social network analysis.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual / Framework Development  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Proposal of a structured AKD methodology (Domain-Driven Data Mining) and operational frameworks.  </p>

<h2>General Summary of the Paper</h2>

<p>This paper critiques the inadequacies of traditional KDD, highlighting its inability to produce knowledge directly usable for decision-making. Cao introduces Actionable Knowledge Discovery (AKD) as a multidimensional process integrating problem, data, environment, model, decision, and optimization to produce results that satisfy both technical and business needs. The Domain-Driven Data Mining (D3M) framework operationalizes AKD by embedding domain, human, organizational, and social intelligence into mining processes. The paper outlines systematic features of actionability, proposes mathematical formulations for actionability measurement, and discusses architectures, tools, and delivery mechanisms to make mined knowledge truly usable in operational environments. It also presents examples (e.g., retail basket analysis) to illustrate how additional context transforms technically interesting patterns into actionable business insights.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>Actionability is defined as “the power to work” — the quality of knowledge that enables direct, effective decision-making without further manipulation. It must satisfy both technical and business perspectives, combining objective and subjective measures, and be integrable into operational environments.  </p>

<blockquote>
  <p>“Actionable knowledge ‘is not only relevant to the world of practice, it is the knowledge that people use to create that world’.” (p. 149)  </p>
</blockquote>

<blockquote>
  <p>“Actionability means the power to work, which is an optimal outcome… through the best integration of six core dimensions.” (p. 154)  </p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Addresses the actual business problem, not just technical interest.  </p></li>
<li><p>Integrates environmental, organizational, and social factors.  </p></li>
<li><p>Is interpretable and explainable to end users.  </p></li>
<li><p>Is feasible and integrable into existing business processes.  </p></li>
<li><p>Produces measurable impact toward business goals.  </p></li>
<li><p>Satisfies both technical and business interestingness thresholds.  </p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Domain-Driven Data Mining (D3M), AKD Framework  </p></li>
<li><p><strong>Methods/Levers:</strong> Integration of domain, human, network, and social intelligence; postanalysis; unified and combined interestingness metrics; interactive and parallel mining; closed-loop refinement.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Problem definition → Data understanding → Environmental/context modeling → Model building → Decision mapping → Optimization → Deliverable transformation into business rules.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Technical and business actionability metrics (objective and subjective), thresholds for technical interestingness (ti) and business interestingness (bi).  </p></li>
<li><p><strong>Implementation Context:</strong> Retail, healthcare, intrusion detection, web analytics, organizational decision-making.  </p></li>
</ul>

<blockquote>
  <p>“AKD is a six-dimension-based optimization process: problem, data, environment, model, decision, optimization.” (p. 152)  </p>
</blockquote>

<blockquote>
  <p>“For a pattern p… Act(p) can be further measured in terms of technical actionability and business actionability.” (p. 153)  </p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — interpretability and understandability emphasized.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — explicit requirement to integrate environmental/business context.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — must be directly usable without major rework.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — addressed indirectly via adaptability to dynamic data and environments.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — must be interpretable in business language and logic.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — deliverables must meet business expectations and objectives.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Autonomy, deliverability, dependability, repeatability, trust, semantics.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li>System sciences, cybernetics, complex systems theory, metasynthesis, agent-based systems, ubiquitous intelligence integration.</li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Technical interestingness (ti) and business interestingness (bi) with defined thresholds.  </p></li>
<li><p>Objective/subjective measures from technical and business perspectives.  </p></li>
<li><p>Evaluation of business impact (e.g., revenue, efficiency).</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Academic–business goal misalignment; oversimplification of problems; lack of integration of context; passive knowledge formats.  </p></li>
<li><p><strong>Enablers:</strong> Involving domain experts; modeling environmental factors; unified interestingness measures; delivering in business-ready formats.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions itself as extending prior notions of actionable rules and interestingness by embedding them in a systemic, multi-intelligence framework (D3M). It draws on and critiques both technical-focused and business-focused prior work, aiming to balance the two.</p>

<h2>Summary</h2>

<p>Cao (2012) advances the concept of Actionable Knowledge Discovery (AKD) as a shift from conventional KDD to decision-ready insights. Actionability is framed as the “power to work,” requiring integration of problem, data, environment, model, decision, and optimization dimensions, and satisfaction of both technical and business needs. The Domain-Driven Data Mining framework operationalizes AKD through context-rich, human-involved, and adaptive processes. Systematic features include clarity, contextual relevance, feasibility, explainability, and goal alignment, supported by quantifiable actionability metrics. The paper offers architectures, process models, and illustrative cases to demonstrate how embedding domain, human, and social intelligence can transform technically interesting patterns into operationally valuable knowledge.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 98 — Provides a rich, explicit conceptualization of actionability, systematic features, and detailed framework.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Offers a complete methodology with measurable metrics, process models, and examples for achieving actionability.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Actionable knowledge ‘is not only relevant to the world of practice…’” (p. 149)  </p></li>
<li><p>“Actionability means the power to work… through the best integration of six core dimensions.” (p. 154)  </p></li>
<li><p>“AKD is a six-dimension-based optimization process: problem, data, environment, model, decision, optimization.” (p. 152)  </p></li>
<li><p>“Deliverables… must be easily interpretable, convertible into business rules, and linked to decision-making systems.” (p. 151)  </p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Argyris (1993, 1996) on actionable knowledge in organizational contexts.  </p></li>
<li><p>He et al. (2005) on actionable knowledge in data mining.  </p></li>
<li><p>Ras &amp; Wieczorkowska (2000) on action rules.  </p></li>
<li><p>Cao &amp; Zhang (2007, 2010) on knowledge actionability and domain-driven data mining.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Geopolitical Forecasting and Actionable Intelligence</p>

<p>Authors: Ian S. Lustick</p>

<p>DOI: 10.1080/00396338.2022.2032959</p>

<p>Year: 2022</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Political Science / International Relations</p>

<p>Subdomain/Topic: Geopolitical forecasting, intelligence analysis, decision support</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 88</p>

<p>Operationalization Score: 70</p>

<p>Contains Definition of Actionability: Yes (implicit, tied to “actionable intelligence”)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: No formal named framework, but conceptual approach</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual / Analytical Essay</p>

<p>Study Context: Intelligence analysis for U.S. foreign policy and national security</p>

<p>Geographic/Institutional Context: Primarily U.S. intelligence community</p>

<p>Target Users/Stakeholders: Policymakers, intelligence analysts, national security officials</p>

<p>Primary Contribution Type: Conceptual framework for linking forecasting validity/verification to actionability</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Partial</p>

<p>TI: No</p>

<p>EX: Yes</p>

<p>GA: Partial</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong> Geopolitical Forecasting and Actionable Intelligence  </p>

<p><strong>Authors:</strong> Ian S. Lustick  </p>

<p><strong>DOI:</strong> 10.1080/00396338.2022.2032959  </p>

<p><strong>Year:</strong> 2022  </p>

<p><strong>Publication Type:</strong> Journal  </p>

<p><strong>Discipline/Domain:</strong> Political Science / International Relations  </p>

<p><strong>Subdomain/Topic:</strong> Geopolitical forecasting, intelligence analysis, decision support  </p>

<p><strong>Contextual Background:</strong> Discusses the evolution of U.S. intelligence forecasting from WWII to the present, focusing on the challenges of making forecasts that are both valid and <em>actionable</em> for policy and decision-making.  </p>

<p><strong>Geographic/Institutional Context:</strong> U.S. intelligence community and policymaking environment  </p>

<p><strong>Target Users/Stakeholders:</strong> Policymakers, intelligence analysts, decision-support tool developers  </p>

<p><strong>Primary Methodology:</strong> Conceptual / Analytical Essay  </p>

<p><strong>Primary Contribution Type:</strong> Conceptual linkage between validation, verification, and actionable intelligence  </p>

<h2>General Summary of the Paper</h2>

<p>The paper examines why geopolitical forecasting, despite technological advances, often fails to produce actionable intelligence for policymakers. Lustick distinguishes between forecasts used for general discussion versus those directly informing policy decisions, arguing that the latter require rigorous <em>validation</em> (accuracy, precision, reliability) and <em>verification</em> (causal explanation). He critiques the dominance of engineers and brute-force empiricism in intelligence R&amp;D, advocating for greater integration of political science, sociology, economics, and cultural expertise. Actionable intelligence, he asserts, must answer not only “what, where, when” but also “why” and “how,” enabling policymakers to select effective interventions. Without this integration of substantive theory, even technically accurate forecasts will have limited practical utility.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>Actionability is implicitly defined as the capacity of intelligence forecasts to inform and guide concrete policy or operational decisions — requiring both empirical validity and causal explanation. Actionable intelligence is contrasted with forecasts that are merely interesting or discussion-enhancing.</p>

<blockquote>
  <p>“If forecasts are used as actual inputs into a policy- or decision-making process, they do need to be accurate, precise and reliable.” (p. 53)  </p>
</blockquote>

<blockquote>
  <p>“Only models capable of answering why and how questions, not just what, where and when questions, will fit the bill.” (p. 55)  </p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Empirical validity (accuracy, precision, reliability of forecasts)  </p></li>
<li><p>Verification (causal traceability and theoretical grounding)  </p></li>
<li><p>Ability to answer “why” and “how” questions to guide action  </p></li>
<li><p>Integration of domain-specific cultural, political, and economic knowledge  </p></li>
<li><p>Relevance to decision-makers’ context and needs</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Not formalized; dual requirement of validation + verification  </p></li>
<li><p><strong>Methods/Levers:</strong> Brier scoring for validation; causal modeling for verification; integration of substantive theory into computational forecasting tools  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Validate forecasts statistically (probability conformity to outcomes).  </p>

<p> 2. Verify causal soundness of models.  </p>

<p> 3. Integrate social science expertise with computational modeling.  </p>

<p> 4. Tailor models to specific geographic/cultural contexts.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Brier score; qualitative causal traceability  </p></li>
<li><p><strong>Implementation Context:</strong> U.S. intelligence community forecasting for policy use  </p></li>
</ul>

<blockquote>
  <p>“Only streams of outcomes that exhibit the forecasted probability can corroborate the validity of the forecast and the techniques used to produce it.” (p. 54)  </p>
</blockquote>

<blockquote>
  <p>“If outcomes cannot be traced to particular combinations of antecedent variables… decision-makers cannot know how to make use of the forecast.” (p. 54)  </p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — forecasts must be precise and interpretable to decision-makers.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — tied to specific geopolitical/cultural contexts.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — implies that forecasts should inform feasible actions, but not fully elaborated.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No explicit emphasis.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — forecasts must answer “why” and “how” to be useful.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — linked to enhancing desired outcomes and avoiding undesirable ones.  </p></li>
<li><p><strong>Other Dimensions:</strong> Validation, Verification.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Distinction between validation and verification from modeling literature.  </p></li>
<li><p>Critique of brute-force empiricism in forecasting (Lustick &amp; Tetlock 2021).  </p></li>
<li><p>Decision-support theory in intelligence studies.</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Brier scoring for forecast validity.  </p></li>
<li><p>Presence of causal explanations linking variables to outcomes.  </p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Dominance of engineers over social scientists in intelligence R&D; overreliance on machine learning without substantive theory; lack of integration of domain-specific knowledge.  </p></li>
<li><p><strong>Enablers:</strong> Combining social science expertise with computing power; rigorous validation and verification; tailoring models to cultural/geopolitical specifics.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions itself against purely technical, data-driven forecasting approaches, emphasizing the need for theory-informed, causally explainable models in line with social science insights.</p>

<h2>Summary</h2>

<p>Lustick’s article argues that for geopolitical forecasts to yield <em>actionable intelligence</em>, they must satisfy two conditions: <strong>validation</strong> (accuracy, precision, and reliability) and <strong>verification</strong> (causal explanation and theoretical grounding). Actionability here means enabling decision-makers to understand not just what might happen, but why and how, so they can act to shape outcomes. Current intelligence R&amp;D, dominated by engineering and brute-force empiricism, fails to integrate enough substantive expertise from social sciences and cultural studies. The author proposes combining computational power with deep domain knowledge, using tools like Brier scoring for statistical validation and theoretical modeling for causal verification. Without such integration, even technologically sophisticated forecasting will remain of limited practical utility.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 — Strong implicit definition and clear features linked to actionability; robust conceptual discussion of requirements.  </p></li>
<li><p><strong>Operationalization Score:</strong> 70 — Outlines a clear dual-process approach (validation + verification) and suggests methods, but lacks a detailed step-by-step implementation framework.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“If forecasts are used as actual inputs into a policy- or decision-making process, they do need to be accurate, precise and reliable.” (p. 53)  </p></li>
<li><p>“Only models capable of answering why and how questions, not just what, where and when questions, will fit the bill.” (p. 55)  </p></li>
<li><p>“Only streams of outcomes that exhibit the forecasted probability can corroborate the validity of the forecast and the techniques used to produce it.” (p. 54)  </p></li>
<li><p>“If outcomes cannot be traced to particular combinations of antecedent variables… decision-makers cannot know how to make use of the forecast.” (p. 54)  </p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Lustick &amp; Tetlock (2021), <em>The Simulation Manifesto</em>  </p></li>
<li><p>O’Brien (2010), <em>Crisis Early Warning and Decision Support</em>  </p></li>
<li><p>Johnston (2005), <em>Analytic Culture in the U.S. Intelligence Community</em>  </p></li>
<li><p>Halberstam (1972), <em>The Best and the Brightest</em></p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Knowledge and Policy: research – information – intervention  </p>

<p>Authors: Ingrid Gogolin, Edwin Keiner, Gita Steiner-Khamsi, Jenny Ozga, Lyn Yates  </p>

<p>DOI: n/a  </p>

<p>Year: 2007  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Educational Policy, Educational Research  </p>

<p>Subdomain/Topic: Policy Analysis, Research Governance, Knowledge Transfer  </p>

<p>Eligibility: Yes  </p>

<p>Overall Relevance Score: 85  </p>

<p>Operationalization Score: 70  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual and Review  </p>

<p>Study Context: Education Policy, International Comparisons  </p>

<p>Geographic/Institutional Context: International (Switzerland, UK, Germany, USA, Australia)  </p>

<p>Target Users/Stakeholders: Educational Policymakers, Researchers, Educators  </p>

<p>Primary Contribution Type: Conceptual Exploration, Policy Implications  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong> Knowledge and Policy: research – information – intervention  </p>

<p><strong>Authors:</strong> Ingrid Gogolin, Edwin Keiner, Gita Steiner-Khamsi, Jenny Ozga, Lyn Yates  </p>

<p><strong>DOI:</strong> n/a  </p>

<p><strong>Year:</strong> 2007  </p>

<p><strong>Publication Type:</strong> Journal  </p>

<p><strong>Discipline/Domain:</strong> Educational Policy, Educational Research  </p>

<p><strong>Subdomain/Topic:</strong> Policy Analysis, Research Governance, Knowledge Transfer  </p>

<p><strong>Contextual Background:</strong> The paper discusses the evolving relationships between research, information, and policy interventions in the context of educational research. The authors explore how educational research is influenced by political agendas, particularly focusing on the role of international knowledge banks, evidence-based policy, and research governance. They address the implications for the knowledge production process and the role of researchers in shaping educational reforms.  </p>

<p><strong>Geographic/Institutional Context:</strong> The paper draws on international perspectives, including the UK, Germany, Switzerland, the USA, and Australia.  </p>

<p><strong>Target Users/Stakeholders:</strong> Educational policymakers, researchers, practitioners in education  </p>

<p><strong>Primary Methodology:</strong> Conceptual analysis, review of educational policy trends  </p>

<p><strong>Primary Contribution Type:</strong> Conceptual exploration of policy-research interactions and implications for the educational field  </p>

<h2>General Summary of the Paper</h2>

<p>This paper explores the interplay between research, information, and policy interventions in educational systems, emphasizing how knowledge is shaped by political agendas. The authors critically examine international knowledge banks and their role in shaping policy through data-driven comparisons, such as PISA and TIMSS. The paper also discusses how research governance has evolved, with a shift toward evidence-based policy-making, and explores the tensions between academic autonomy and policy influence in the production of educational knowledge.  </p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<p>Reason if Not Eligible: n/a  </p>

<h2>How Actionability is Understood</h2>

<p>The authors define actionability in the context of research-policy relationships as the process by which research outputs are transformed into policy decisions. This involves translating research findings into actionable knowledge that policymakers can use to drive reforms, often shaped by political agendas and the externalization of policy needs.  </p>

<blockquote>
  <p>“Research knowledge is not just a tool for solving problems but becomes a resource for governance, facilitating policy actions” (p. 13).  </p>
</blockquote>

<blockquote>
  <p>“Policy-making increasingly relies on research that is ‘actionable,’ a process that is mediated by political needs and external pressures” (p. 14).</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<p>The authors argue that for research to be actionable, it must:</p>

<ul>
<li><p>Be clearly translated into policy-relevant knowledge  </p></li>
<li><p>Align with political and economic needs, particularly in the context of global benchmarking and educational reforms  </p></li>
<li><p>Be produced with a view toward achieving practical outcomes, often under the constraints of governance frameworks  </p></li>
</ul>

<blockquote>
  <p>“Actionable knowledge must be framed to meet both the practical needs of policymakers and the strategic goals of educational reform” (p. 16).  </p>
</blockquote>

<blockquote>
  <p>“The shift toward evidence-based policy-making demands that research be oriented toward measurable outcomes” (p. 17).</p>
</blockquote>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<p>The paper proposes that actionability is achieved through mechanisms like international knowledge banks and the growing reliance on data-driven policy interventions. The authors highlight the role of global benchmarking (e.g., OECD’s PISA) in creating externally validated measures of educational performance that become the basis for policy interventions.  </p>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Evidence-based Policy, Knowledge Transfer  </p></li>
<li><p><strong>Methods/Levers:</strong> International knowledge banks, benchmarking, cross-national comparisons  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Researchers produce data-driven reports that become policy tools; these tools are used by governments to justify or guide educational reforms  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Standardized assessments (PISA, TIMSS), national rankings, educational benchmarks  </p></li>
<li><p><strong>Implementation Context:</strong> Primarily in global educational reform initiatives, influenced by international organizations like the World Bank and OECD  </p></li>
</ul>

<blockquote>
  <p>“International comparisons, like those of PISA and TIMSS, provide the evidence that policymakers need to justify reform and secure funding” (p. 19).  </p>
</blockquote>

<blockquote>
  <p>“The creation of knowledge banks is a deliberate attempt to shape the policy landscape by providing evidence that fits political agendas” (p. 20).</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – Actionable knowledge must be clear and understandable to policymakers.  </p>

<p> &gt; “Actionable research must be accessible to those making policy decisions, as clarity is essential to ensure it is implemented effectively” (p. 15).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – Knowledge must be relevant to the specific political and educational contexts.  </p>

<p> &gt; “Research needs to be contextualized to fit the political, social, and economic conditions of the country” (p. 16).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – Research should be practical and feasible to implement in policy.  </p>

<p> &gt; “Feasibility is a key attribute for research to be considered actionable, particularly when framed within the realities of national governance” (p. 14).  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes – Actionability also depends on the timeliness of the research in relation to policy needs.  </p>

<p> &gt; “Timely interventions are necessary to ensure that research can be translated into action during critical policy windows” (p. 17).  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – The ability to explain research findings in a way that informs decision-making is vital for actionability.  </p>

<p> &gt; “The explanation of research results in an understandable way is critical for influencing policy decisions” (p. 14).  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – Research must align with the goals and agendas of policymakers.  </p>

<p> &gt; “Alignment with national or international educational goals is crucial for ensuring that research is actionable in policy” (p. 19).</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<p>The paper draws on the concept of Mode 1 and Mode 2 knowledge production (Gibbons et al., 1994), highlighting a shift from traditional, discipline-based research to a more collaborative, policy-oriented approach that involves multiple stakeholders, including government bodies and international organizations.  </p>

<blockquote>
  <p>“Mode 2 knowledge production is marked by its transdisciplinary approach, involving collaboration between researchers, policymakers, and practitioners” (p. 13).</p>
</blockquote>

<h2>Indicators or Metrics for Actionability</h2>

<p>The paper implies that actionable knowledge is measured through indicators such as educational rankings, standardized test results, and performance benchmarks. These metrics are used to guide policy decisions and justify educational reforms.  </p>

<blockquote>
  <p>“International rankings and benchmarks act as primary indicators of the quality and impact of educational systems” (p. 18).</p>
</blockquote>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><strong>Barriers:</strong> Political agendas that shape the research questions and the framing of evidence, resistance to non-quantitative research, lack of researcher engagement with policy needs.  </li>
</ul>

<blockquote>
  <p>“Political pressures can skew the research agenda, prioritizing data that aligns with predetermined policy goals” (p. 14).  </p>
</blockquote>

<ul>
<li><strong>Enablers:</strong> Collaboration between researchers and policymakers, the rise of evidence-based policy-making, international comparative studies.  </li>
</ul>

<blockquote>
  <p>“The growth of knowledge banks and international policy networks has enhanced the ability to translate research into action” (p. 16).</p>
</blockquote>

<h2>Relation to Existing Literature</h2>

<p>The paper critiques the linear model of research-to-policy transfer, which assumes a direct link from research to practical intervention. It aligns with literature on policy transfer and knowledge governance, emphasizing the complexity of how knowledge is adapted and used in policy contexts.  </p>

<blockquote>
  <p>“The relationship between research and policy is more complex than the simple transmission of knowledge to action; it is shaped by political and economic forces” (p. 17).</p>
</blockquote>

<h2>Summary</h2>

<p>This paper critically examines the relationship between research, information, and policy interventions in education, focusing on how research is framed and transformed into actionable knowledge that informs policy. The authors highlight the growing reliance on international knowledge banks and benchmarking systems as key tools for shaping educational reforms, arguing that actionability in education research is increasingly driven by political agendas and the need for quantifiable outcomes. They explore how this shift affects researchers' roles and the types of knowledge that are valued in policy-making contexts.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 – The paper offers valuable insights into the complexities of making research actionable in the context of educational policy and governance, providing both theoretical and practical perspectives.  </p></li>
<li><p><strong>Operationalization Score:</strong> 70 – While the paper discusses mechanisms for achieving actionability, it lacks detailed operational steps or frameworks that could be directly applied in practice.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li>“Research knowledge is not just a tool for solvin</li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Actionable Insights in Urban Multivariate Time-series  </p>

<p>Authors: Anika Tabassum, Supriya Chinthavali, Varisara Tansakul, B. Aditya Prakash  </p>

<p>DOI: https://doi.org/10.1145/3459637.3482410  </p>

<p>Year: 2021  </p>

<p>Publication Type: Conference (ACM CIKM ’21)  </p>

<p>Discipline/Domain: Computer Science / Urban Analytics  </p>

<p>Subdomain/Topic: Multivariate Time-series Segmentation, Explainability, Rationalization  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes (implicit, formalized in RaTSS problem)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (RaTSS, Find-RaTSS)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual + Quantitative Evaluation (Algorithm design, experiments)  </p>

<p>Study Context: Urban analytics applications in disasters, public health, epidemiology, and general high-dimensional datasets  </p>

<p>Geographic/Institutional Context: US (Oak Ridge National Laboratory, Virginia Tech, Georgia Tech)  </p>

<p>Target Users/Stakeholders: Urban domain experts (emergency management authorities, epidemiologists, planners)  </p>

<p>Primary Contribution Type: Novel problem formulation + algorithmic solution  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Actionable Insights in Urban Multivariate Time-series  </p>

<p><strong>Authors:</strong>  </p>

<p>Anika Tabassum, Supriya Chinthavali, Varisara Tansakul, B. Aditya Prakash  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1145/3459637.3482410  </p>

<p><strong>Year:</strong>  </p>

<p>2021  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference Paper (CIKM 2021)  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Data Mining  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Urban Analytics, Time-series Segmentation, Explainable AI  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the difficulty urban domain experts face in extracting <strong>actionable</strong> time-series of interest (TOIs) from complex multivariate time-series segmentation outputs. Contexts include hurricanes, pandemics, epidemiology, and web analytics, where quick identification of non-obvious but important series can direct interventions.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>US, collaboration between Virginia Tech, Oak Ridge National Laboratory, Georgia Tech.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Emergency management authorities, epidemiologists, public health planners, infrastructure operators.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework + Algorithm design (RaTSS &amp; Find-RaTSS) + Empirical evaluation on synthetic, real, and domain-specific datasets.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Novel problem definition + algorithm to produce actionable insights for any black-box segmentation algorithm.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors introduce <strong>RaTSS</strong> (Rationalization for Time-series Segmentation), a framework for identifying <em>actionable</em> Time-series of Interest (TOIs) from multivariate segmentation results in urban applications. They argue that existing segmentation methods produce accurate phase boundaries but lack human-friendly, decision-ready outputs. RaTSS treats segmentation as a black box and derives importance weights for each series at each cutpoint via a graph optimization problem over a <em>segment graph</em>. They implement <strong>Find-RaTSS</strong>, an algorithm to solve this problem efficiently for large datasets. Empirical evaluation on synthetic, real-world, and domain-specific urban datasets (hurricanes, COVID-19, epidemiology, Wikipedia traffic) shows Find-RaTSS consistently outperforms baselines in identifying ground-truth TOIs and generates non-obvious but operationally relevant insights for decision-making.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as identifying TOIs whose changes across segmentation cutpoints are <strong>most relevant to operational decisions</strong> in the target domain — for example, counties to prioritize for hurricane recovery or states likely affected by policy interventions.  </p>

<blockquote>
  <p>“… actionable insights, i.e., which time-series/counties are the most important with respect to an event, they can send personnel to fix damage and alert local authorities to reduce further loss” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“… human-friendly and actionable TOIs (rationalizations) for the urban experts across the associated events” (p. 2)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>High relative importance across a cutpoint (based on learned weights)  </p></li>
<li><p>Potential to influence direct interventions or decisions  </p></li>
<li><p>Inclusion of <em>non-obvious</em> series not apparent from visual inspection  </p></li>
<li><p>Contextual linkage to events (e.g., weather, policy changes, epidemiological outbreaks)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> RaTSS (problem), Find-RaTSS (algorithm)  </p></li>
<li><p><strong>Methods/Levers:</strong> Segment graph representation; optimization of global latent weights (α) to maximize separation of chosen segmentation path over all alternatives.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Build segment graph for multivariate time series.  </p>

<p> 2. Calculate edge weights using basic statistical features across segments.  </p>

<p> 3. Compute Δπ (difference in path lengths between chosen and alternative segmentations).  </p>

<p> 4. Optimize α under sparsity and norm constraints.  </p>

<p> 5. Derive r_j (importance weights) per cutpoint and select top TOIs.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Mean, variance, min, max features per segment; importance weights; F1-scores for evaluation.  </p></li>
<li><p><strong>Implementation Context:</strong> Works for any black-box segmentation algorithm, regardless of internal mechanics.  </p></li>
</ul>

<blockquote>
  <p>“We propose an algorithm Find-RaTSS to automatically capture the TOIs in a way that is flexible and works for any black-box segmentation that a DE may use” (p. 2)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — output is simplified, interpretable list of TOIs with weights.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — TOIs tied to specific events and domain context.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — outputs can be operationalized into concrete actions (e.g., send crews, investigate policy).  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — method processes historical data; potential for near real-time with optimization.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — weight-based rationalizations with clear link to cutpoints.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — TOIs are selected to match decision-makers’ objectives.  </p></li>
<li><p><strong>Other Dimensions:</strong> Non-obviousness (ability to surface hidden but important cases).  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Graph-based representation of segmentation paths (segment graph)  </p></li>
<li><p>Optimization under sparsity and norm constraints  </p></li>
<li><p>Basic statistical change detection (mean, variance, min, max features)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Importance weight (r_j) per series at each cutpoint  </p></li>
<li><p>F1-score comparing predicted TOIs to ground truth  </p></li>
<li><p>Fraction of total rationalization weight captured by top-k TOIs  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - If segmentation is meaningless (e.g., constant series), rationalizations may not be meaningful.  </p>

<p> - Some actionable groups may consist of combinations of series, not individual ones (not yet implemented).  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Algorithm’s independence from segmentation model details  </p>

<p> - Works with any multivariate time-series data  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions itself as the first method to identify actionable TOIs for any black-box segmentation. Builds on work in urban analytics, change point detection, and interpretable AI, but moves beyond model-internal explanations to produce human-friendly rationalizations.</p>

<hr />

<h2>Summary</h2>

<p>This paper presents RaTSS, a formal problem framing for deriving actionable Time-series of Interest (TOIs) from multivariate time-series segmentation, and Find-RaTSS, an algorithm that computes these TOIs without requiring access to the internal workings of the segmentation algorithm. By representing all possible segmentations in a segment graph and optimizing a global weight vector to distinguish the chosen segmentation from alternatives, the method outputs ranked TOIs per cutpoint. The approach is validated on synthetic, real-world, and domain-specific datasets, outperforming baselines and surfacing non-obvious but operationally relevant insights, such as unexpected counties affected during hurricanes or states with COVID-19 interventions. Actionability here is operationalized as relevance to decision-making, contextual interpretability, feasibility, and alignment with domain objectives.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 — Strong implicit and operational definition of actionability, clear identification of relevant features.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Detailed algorithm and workflow for achieving actionable outputs, tested in varied contexts.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“... actionable insights, i.e., which time-series/counties are the most important with respect to an event…” (p. 2)  </p></li>
<li><p>“We introduce and formalize a novel problem Rationalization for Time-series Segmentations (RaTSS)…” (p. 2)  </p></li>
<li><p>“r<em>j = |α ⊙ w</em>ijk|” (p. 4)  </p></li>
<li><p>“Remark 1: … when the time-series is constant, then rationalizations (TOIs) found by RaTSS may not be meaningful” (p. 4)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>[23] Cut-n-Reveal: Time Series Segmentations with Explanations — related explanation approach but model-dependent.  </p></li>
<li><p>[6] ORNL EARSS — situational awareness in disaster response.  </p></li>
<li><p>[19] Dynammo — handling missing values in time-series.  </p></li>
<li><p>[21] Autoplait — segmentation with HMMs.  </p></li>
<li><p>[12] TICC — segmentation with multilayer Markov Random Fields.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Communication of Actionable Information  </p>

<p>Authors: Giles W. Boland, Richard Duszak Jr, Paul A. Larson  </p>

<p>DOI: http://dx.doi.org/10.1016/j.jacr.2014.08.003  </p>

<p>Year: 2014  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Radiology / Medical Imaging  </p>

<p>Subdomain/Topic: Communication of actionable radiology findings  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 83  </p>

<p>Operationalization Score: 75  </p>

<p>Contains Definition of Actionability: Yes (implicit and partially explicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: No  </p>

<p>Contains Interpretability: No  </p>

<p>Contains Framework/Model: Yes (ACR categories)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual / Practice guidance  </p>

<p>Study Context: Communication of actionable radiology information in clinical workflows  </p>

<p>Geographic/Institutional Context: U.S. radiology practices, hospitals, and teleradiology services  </p>

<p>Target Users/Stakeholders: Radiologists, referring physicians, patients, hospital administrators  </p>

<p>Primary Contribution Type: Practice recommendations and framework adaptation  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: No  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Communication of Actionable Information  </p>

<p><strong>Authors:</strong>  </p>

<p>Giles W. Boland, Richard Duszak Jr, Paul A. Larson  </p>

<p><strong>DOI:</strong>  </p>

<p>http://dx.doi.org/10.1016/j.jacr.2014.08.003  </p>

<p><strong>Year:</strong>  </p>

<p>2014  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Radiology / Medical Imaging  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Communication of actionable radiology findings  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the challenge of ensuring that radiology reports—especially those containing actionable findings—are effectively and efficiently communicated to relevant stakeholders. It emphasizes operational workflows, integration of information systems, and policies for timely reporting.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>U.S. radiology practices, including academic centers, private groups, and teleradiology services.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Radiologists, referring physicians, patients, hospital administrators.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual / Practice guidance.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Practice recommendations and operational framework.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This article outlines the critical role radiologists play in not only producing timely, meaningful, and actionable reports, but also ensuring these reports are communicated effectively to the appropriate stakeholders. It frames this communication as the final link in the “imaging value chain,” which is often the weakest. The authors highlight barriers such as fragmented IT systems, lack of standardized critical findings policies, and challenges in teleradiology. They reference the American College of Radiology (ACR) framework that categorizes findings based on urgency, offering clear timelines for communication. Proposed solutions include integrated electronic systems, closed-loop communication protocols, embedding radiologists in clinical teams, and providing patients direct access to their reports. The paper stresses that radiologists operate in the information business, and actionable value is only realized when reports are both delivered and understood.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>The paper defines actionable information in radiology as findings that, once communicated, can influence patient management and outcomes, requiring delivery that is timely, clear, and directed to the correct stakeholders.</p>

<blockquote>
  <p>“A report creates little value until it is delivered, read, and correctly understood… Only then can information be used to have an impact on patient outcomes.” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“Effective communication of actionable information” is described as the final step in the imaging value chain, essential for delivering appropriateness, quality, safety, efficiency, and patient satisfaction. (p. 1)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Clear identification of findings with clinical significance.  </p></li>
<li><p>Timeliness in delivering the report relative to urgency.  </p></li>
<li><p>Delivery to the right recipient(s) with confirmation.  </p></li>
<li><p>Documentation of communication.  </p></li>
<li><p>Use of standardized categories (ACR Category 1–3) tied to urgency.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> ACR Actionable Reporting categories.  </p></li>
<li><p><strong>Methods/Levers:</strong> Standardized timelines for Category 1 (minutes), Category 2 (hours), Category 3 (days); integrated IT and EMR systems; closed-loop communication; embedding radiologists in clinical teams; direct patient portals.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Interpret findings → classify urgency → communicate via appropriate channel (verbal, electronic alert, direct message) → document delivery and recipient acknowledgment.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Time from report finalization to communication; confirmation logs; audit trails.  </p></li>
<li><p><strong>Implementation Context:</strong> Hospital radiology, teleradiology, academic centers, multidisciplinary clinics.  </p></li>
</ul>

<blockquote>
  <p>“Category-1 findings require communication within minutes, usually by direct verbal communication…” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“Electronic text and e-mail alerts… confirm whether referrers have reviewed such reports… close the communication loop…” (p. 2)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><strong>CL (Clarity):</strong> Yes — Reports must be concise and precisely structured to be understood by stakeholders.  </li>
</ul>

<blockquote>
  <p>“…synthesize all relevant clinical information into a concise and precisely structured document.” (p. 1)  </p>
</blockquote>

<ul>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Findings must be relevant to the patient’s condition and clinical management.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Communication processes must be operationally possible within institutional constraints.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — Strong emphasis on rapid delivery based on urgency category.  </p></li>
<li><p><strong>EX (Explainability):</strong> No — Paper does not explicitly frame explainability as part of actionability.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — Aligns communication with patient outcomes but not framed as explicit dimension.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Integration with IT systems; closed-loop communication; documentation.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Imaging Value Chain model.  </p></li>
<li><p>ACR Actionable Reporting framework.</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Time-to-communication metrics by urgency category.  </p></li>
<li><p>Audit logs of communication events.  </p></li>
<li><p>Confirmation of recipient acknowledgment.</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Fragmented IT systems; lack of integrated EMR; variability in preliminary/final report workflows; teleradiology delays; ad hoc communication methods.  </p></li>
<li><p><strong>Enablers:</strong> Integrated IT solutions; standardized critical findings policies; embedding radiologists in care teams; electronic alerts; patient portals.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds directly on ACR Actionable Reporting Work Group recommendations, situating them within broader workflow and technology integration strategies.</p>

<hr />

<h2>Summary</h2>

<p>Boland et al. (2014) conceptualize actionability in radiology as the combination of meaningful findings, timeliness, targeted delivery, and confirmation that recipients understand the information. They operationalize this via the ACR’s three-category urgency system, advocating for integrated IT solutions, closed-loop communication, and embedding radiologists within clinical teams to facilitate real-time exchange. The paper situates actionable reporting as the final and often weakest link in the imaging value chain, emphasizing that value is realized only when reports are delivered and understood by relevant stakeholders. It extends prior frameworks by addressing institutional barriers (e.g., fragmented systems, teleradiology inefficiencies) and proposing specific operational strategies for different clinical contexts, including patient-facing transparency initiatives.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 83 — Strong implicit definition, tied to explicit features and urgency framework, though not a formal theoretical model.  </p></li>
<li><p><strong>Operationalization Score:</strong> 75 — Provides concrete steps and workflow recommendations linked to actionability; primarily conceptual rather than empirical.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“A report creates little value until it is delivered, read, and correctly understood… Only then can information be used to have an impact on patient outcomes.” (p. 1)  </p></li>
<li><p>“Category-1 findings require communication within minutes, usually by direct verbal communication…” (p. 1)  </p></li>
<li><p>“Electronic text and e-mail alerts… close the communication loop…” (p. 2)  </p></li>
<li><p>“Radiologists need to remember that they serve primarily in an information business and recognize that value will be created only when actionable reports are delivered…” (p. 3)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li>Larson PA, Berland LL, Kahn CE, Liebscher LA. <em>Actionable findings and the role of IT support: report of the ACR Actionable Reporting Work Group</em>. J Am Coll Radiol. 2014;11:552–8.</li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Generating Actionable Insights from Patient Medical Records and Structured Clinical Knowledge  </p>

<p>Authors: Natasha Trajkovska, Michael Roiss, Sophie Bauernfeind, Mohammad Alnajdawi, Simone Sandler, Daniel Herzmanek, Matthias Winkler, Michael Haider, Oliver Krauss  </p>

<p>DOI: 10.3233/SHTI240015  </p>

<p>Year: 2024  </p>

<p>Publication Type: Conference  </p>

<p>Discipline/Domain: Health Informatics / Medical Data Science  </p>

<p>Subdomain/Topic: Clinical decision support, medical NLP, structured knowledge integration  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 85  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (implicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: Yes (implicitly through process mining and ontology mapping)  </p>

<p>Contains Framework/Model: Yes (Treetop treatment pathways &amp; disease models)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Mixed Methods (technical implementation with evaluation)  </p>

<p>Study Context: Extraction and structuring of unstructured patient records for clinical decision support  </p>

<p>Geographic/Institutional Context: Austria; University of Applied Sciences Upper Austria, Treetop Medical, Medical University of Vienna  </p>

<p>Target Users/Stakeholders: Clinicians, medical decision support developers, healthcare institutions  </p>

<p>Primary Contribution Type: Technical method and evaluation  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: Partial  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Generating Actionable Insights from Patient Medical Records and Structured Clinical Knowledge  </p>

<p><strong>Authors:</strong>  </p>

<p>Natasha Trajkovska, Michael Roiss, Sophie Bauernfeind, Mohammad Alnajdawi, Simone Sandler, Daniel Herzmanek, Matthias Winkler, Michael Haider, Oliver Krauss  </p>

<p><strong>DOI:</strong>  </p>

<p>10.3233/SHTI240015  </p>

<p><strong>Year:</strong>  </p>

<p>2024  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Health Informatics / Medical Data Science  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Clinical decision support, medical NLP, structured knowledge integration  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>This work addresses the challenge of converting unstructured medical text (e.g., patient letters, lab reports) into structured, encoded, and contextualized data to reconstruct a patient’s treatment course. The aim is to integrate this with predefined treatment pathways and disease models for improved clinical decision-making.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Austria; University of Applied Sciences Upper Austria, Treetop Medical, Medical University of Vienna.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Clinicians, health IT specialists, hospital administrators, AI developers in healthcare.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed methods—technical pipeline development, natural language processing, process mining, comparative evaluation.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Technical method and evaluation.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper proposes a method to transform unstructured patient medical records into structured, encoded, and contextually interpreted data, enabling the generation of actionable clinical insights. The approach uses LLM-based extraction (LLM and GuidedLLM variants), enriched by structured medical knowledge from treatment pathways and disease models, to improve accuracy. Extracted data are encoded with SNOMED CT, organized chronologically using process mining, and compared against standard treatment pathways to identify deviations or missing steps. Evaluation with four chronic myeloid leukemia patient cases shows that GuidedLLM outperforms a generic LLM in detecting relevant diagnoses and medications, achieving 100% detection in targeted evaluation and high Jaccard similarity for detail accuracy. The method supports better clinical decision-making and patient safety by highlighting deviations, resource bottlenecks, and required follow-ups.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is implicitly defined as the transformation of raw, unstructured medical data into structured, encoded, and contextually interpreted knowledge that can directly inform clinical decision-making and patient management.</p>

<blockquote>
  <p>“...transform unstructured data into a cascade of progressively refined stages: structured data, encoded data, interpreted data, and ultimately, actionable knowledge.” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“...identify relevant findings in the treatment course that might be relevant for upcoming treatments or procedures.” (p. 4)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Accurate extraction of relevant clinical events from unstructured data.  </p></li>
<li><p>Encoding with standardized clinical terminologies (e.g., SNOMED CT).  </p></li>
<li><p>Chronological reconstruction of treatment history.  </p></li>
<li><p>Contextual comparison with evidence-based treatment pathways.  </p></li>
<li><p>Identification of deviations, missing steps, or bottlenecks in care.  </p></li>
<li><p>Alignment with patient-specific disease models and upcoming care needs.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Treetop Medical treatment pathways and disease models; GuidedLLM extraction pipeline.  </p></li>
<li><p><strong>Methods/Levers:</strong> NLP with Llama-2-70b-orca-200k, medical knowledge-infused prompting, ontology mapping, process mining.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Convert unstructured PDFs to plain text.  </p>

<p> 2. Classify document type.  </p>

<p> 3. Section segmentation (diagnosis, medication, etc.).  </p>

<p> 4. Extract structured data using LLM or GuidedLLM.  </p>

<p> 5. Map extracted data to SNOMED CT codes via hybrid lexical-semantic matching.  </p>

<p> 6. Construct treatment timeline using process mining.  </p>

<p> 7. Compare with predefined treatment pathways and detect deviations/missing steps.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Sensitivity, Jaccard similarity coefficient.  </p></li>
<li><p><strong>Implementation Context:</strong> Chronic myeloid leukemia patient letters and lab reports.</p></li>
</ul>

<blockquote>
  <p>“...construct a chronological treatment timeline... can then be automatically compared to the treatment plan that should be followed...” (p. 3)  </p>
</blockquote>

<blockquote>
  <p>“...identify relevant findings... and deviations between predefined treatment pathways and actual treatment courses...” (p. 4)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Data is structured, encoded, and clearly organized in JSON for interpretability.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Aligned with disease models and treatment pathways.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Implemented with existing EHR data and ontology standards.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — Designed to highlight upcoming procedures and overdue checks.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — Process is interpretable, but LLM outputs may have limited transparency.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Directly aligned with clinical guidelines and personalized patient management.  </p></li>
<li><p><strong>Other Dimensions:</strong> Safety relevance, deviation detection.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Evidence-based clinical pathways and guidelines.  </p></li>
<li><p>Ontology-based data encoding (SNOMED CT).  </p></li>
<li><p>Process mining for event timeline reconstruction.</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Sensitivity (diagnosis and medication detection).  </p></li>
<li><p>Jaccard similarity coefficient for extraction detail accuracy.  </p></li>
<li><p>Deviation detection between actual and standard treatment timelines.</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Unstructured and heterogeneous medical data formats.  </p>

<p> - LLM hallucinations.  </p>

<p> - Limited initial dataset size.  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Integration of structured medical knowledge in LLM prompting.  </p>

<p> - Use of standard clinical ontologies.  </p>

<p> - Automated process mining.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions itself among LLM applications in medicine, highlighting mixed results without domain-specific knowledge, and shows improvement via expert knowledge integration. Builds on work in NLP for EHRs and structured data extraction.</p>

<hr />

<h2>Summary</h2>

<p>The paper presents a practical, technically grounded approach to making medical data actionable by systematically transforming unstructured patient records into structured, encoded, and clinically contextualized information. Through the GuidedLLM method, enriched by disease models and treatment pathways, the authors achieve high detection and detail accuracy in extracting relevant diagnoses and medications. Actionability here is tied to enabling precise clinical decision support: contextual relevance, adherence to treatment pathways, detection of deviations, and alignment with patient safety. Operationalization is robust, combining NLP, ontology mapping, and process mining to produce outputs directly comparable to clinical guidelines. While explainability of the LLM components remains partial, the methodology is well-aligned with goal-driven, evidence-based care.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 — Strong implicit conceptualization of actionability with explicit features tied to clinical decision-making.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Clear, multi-step pipeline from raw data to actionable knowledge, evaluated with concrete metrics.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“...transform unstructured data into a cascade of progressively refined stages: structured data, encoded data, interpreted data, and ultimately, actionable knowledge.” (p. 2)  </p></li>
<li><p>“...identify relevant findings in the treatment course that might be relevant for upcoming treatments or procedures.” (p. 4)  </p></li>
<li><p>“...construct a chronological treatment timeline... can then be automatically compared to the treatment plan that should be followed...” (p. 3)  </p></li>
<li><p>“...identify deviations between predefined treatment pathways and actual treatment courses...” (p. 4)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Cellina et al. (2023) on personalized medicine and digital twins.  </p></li>
<li><p>Sugandh et al. (2024) on personalized diabetes care.  </p></li>
<li><p>Packer &amp; Metra (2021) on guideline adherence in heart failure.  </p></li>
<li><p>Jarjour et al. (2020) on care gaps in guideline adherence.  </p></li>
<li><p>Vaismoradi et al. (2020) on patient safety principles.  </p></li>
<li><p>Koleck et al. (2019) and Sheikhalishahi et al. (2019) on NLP for clinical notes.  </p></li>
<li><p>Thirunavukarasu et al. (2023) on LLMs in medicine.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: The future of artificial intelligence in intensive care: moving from predictive to actionable AI</p>

<p>Authors: Jim M. Smit; Jesse H. Krijthe; Jasper van Bommel; on behalf of the Causal Inference for ICU Collaborators</p>

<p>DOI: 10.1007/s00134-023-07102-y</p>

<p>Year: 2023</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Critical Care Medicine; Artificial Intelligence</p>

<p>Subdomain/Topic: Causal inference; decision support; ICU sepsis treatment strategies</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 86</p>

<p>Operationalization Score: 61</p>

<p>Actionable/Actionability Used in Paper: Yes — “we propose to refer to any data‑driven model used for causal inference tasks as ‘actionable AI’, as opposed to ‘predictive AI’” (p. 1114).</p>

<p>Authors Argue for Need for Actionability Without Defining It: No — they explicitly define actionable AI as causal-inference‑based.</p>

<p>Contains Definition of Actionability: Yes — “Actionable AI should perform causal inference tasks… predict… outcomes… that would result from alternative treatment decisions.” (p. 1114–1115).</p>

<p>Contains Systematic Features/Dimensions: Partial</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Partial (summarizes methods and exemplars rather than proposing a new framework)</p>

<p>Operationalization Present: Yes (target trial emulation, marginal structural models, reinforcement learning; use of RCTs for individualized effects)</p>

<p>Primary Methodology: Conceptual (Perspective/Commentary)</p>

<p>Study Context: ICU treatment decision-making, especially sepsis fluids/vasopressors</p>

<p>Geographic/Institutional Context: General ICU context; authors from Erasmus MC (NL) and TU Delft (NL)</p>

<p>Target Users/Stakeholders: ICU physicians; clinical researchers developing AI for ICU</p>

<p>Primary Contribution Type: Conceptual clarification and research agenda</p>

<p>CL: Partial</p>

<p>CR: Yes</p>

<p>FE: Partial</p>

<p>TI: Partial</p>

<p>EX: No</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>The future of artificial intelligence in intensive care: moving from predictive to actionable AI</p>

<p><strong>Authors:</strong>  </p>

<p>Jim M. Smit; Jesse H. Krijthe; Jasper van Bommel; on behalf of the Causal Inference for ICU Collaborators</p>

<p><strong>DOI:</strong>  </p>

<p>10.1007/s00134-023-07102-y</p>

<p><strong>Year:</strong>  </p>

<p>2023</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal (What’s New in Intensive Care)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Critical Care Medicine; Artificial Intelligence</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Causal inference for treatment decisions; sepsis fluid/vasopressor strategies</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The piece distinguishes “predictive AI” (risk/early‑warning) from “actionable AI” (causal decision support) and argues ICU care requires sequential, policy‑level decision‑making with time‑varying confounding. Assumption: readers are familiar with ICU sepsis management and basic causal inference.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>General ICU; examples and authorship from Netherlands‑based institutions.</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>ICU clinicians; methodologists developing clinical AI; trialists.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual perspective synthesizing methods and exemplars.</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Definition/clarification plus methodological guidance and future directions.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The article argues that most ICU AI focuses on predicting outcomes (e.g., mortality, sepsis) but cannot advise which treatment to choose. It defines “actionable AI” as AI performing causal inference tasks—predicting patient outcomes under alternative actions to recommend optimal treatment. The paper explains why ICU care involves sequential decisions with time‑varying confounding and highlights suitable methods such as target trial emulation, marginal structural models, and reinforcement learning. It reviews challenges of observational data (bias, limited effective sample size) and suggests RCT data, when available, can support individualized treatment‑effect modeling. A figure contrasts predictive versus actionable AI and illustrates decision‑policy pathways over time.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>Yes.</strong>  </p>

<ul>
<li><p>“we propose to refer to any data‑driven model used for causal inference tasks as ‘actionable AI’, as opposed to ‘predictive AI’” (p. 1114).  </p></li>
<li><p>“For an AI to advise ICU physicians in treatment decisions, i.e., ‘actionable AI’, cause and effect need to be taken into account.” (p. 1114).  </p></li>
<li><p>“Actionable AI should perform causal inference tasks… predict… outcomes… that would result from alternative treatment decisions.” (p. 1114–1115).</p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>No.</strong> They both argue for and define “actionable AI” explicitly as causal‑inference‑based decision support.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability = the capacity of AI to perform causal inference by predicting outcomes under alternative treatment choices to recommend optimal actions.  </p>

<blockquote>
  <p>“Actionable AI should perform causal inference tasks… [to] predict (future) patient outcomes or events that would result from alternative treatment decisions.” (p. 1114–1115).</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Counterfactual/causal orientation (predict outcomes under alternative actions):</strong>  </p>

<p> &gt; “…predicts (future) patient outcomes or events that would result from alternative treatment decisions.” (p. 1115).</p></li>
<li><p><strong>Ability to compare treatments to recommend an optimal option:</strong>  </p>

<p> &gt; “…advise on treatment options that lead to the best predicted outcome (i.e., the optimal treatment).” (p. 1114).</p></li>
<li><p><strong>Bias management appropriate to treatment setting (incl. time‑varying confounding):</strong>  </p>

<p> &gt; “…more sophisticated methods are required [for] ‘time‑varying confounding’.” (p. 1115).</p></li>
<li><p><strong>Sequential decision‑policy modeling (regimes/strategies over time):</strong>  </p>

<p> &gt; “ICU patients are typically treated according to a certain regime—or policy… which represents a set of rules informing treatment decisions during follow‑up…” (p. 1115).</p></li>
<li><p><strong>Sufficient effective sample size and appropriate data source (observational vs. RCT):</strong>  </p>

<p> &gt; “…limited ‘effective sample size’… a prerequisite for successfully implementing actionable AI…” (p. 1116).  </p>

<p> &gt; “towards actionable AI at the bedside, usage of RCT data may currently be the safest route.” (p. 1116).</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Target trial emulation; marginal structural models; reinforcement learning; individualized treatment‑effect modeling from RCTs.  </p></li>
<li><p><strong>Methods/Levers:</strong> Adjustment for confounding (including time‑varying); causal diagrams (DAGs) to identify bias; policy learning for dosing strategies.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> (Implied) Define treatment regimes → map sequential decisions → model counterfactual outcomes under each regime (e.g., MSMs/RL) → adjust for confounders (incl. time‑varying) using appropriate methods → compare predicted outcomes to recommend optimal action → validate, ideally with RCT or emulated target trials.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Observational ICU data (e.g., sepsis fluids/vasopressors) with attention to effective sample size; RCT data for average and heterogeneous treatment effects.  </p></li>
<li><p><strong>Implementation Context:</strong> ICU bedside decision support for sepsis management (fluids and vasopressors).  </p></li>
</ul>

<blockquote>
  <p>“Shahn… performed a ‘target trial emulation’ to develop a marginal structural model…”; “Komorowski… a reinforcement learning model that predicts the optimal dosing of fluids and vasopressors in sepsis.” (p. 1115).</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<p><em>(Marked “Yes/Partial” only if tied to actionability as defined by the authors.)</em></p>

<ul>
<li><p><strong>CL (Clarity):</strong> Partial — clear distinction of predictive vs actionable AI; no explicit clarity criterion. Quote: “Predictive AI… cannot guide ICU clinicians in what to do…” (p. 1114).</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — anchored in ICU sequential decisions/policies. Quote: “Intensive care medicine is about sequential decision‑making.” (p. 1115).</p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — feasibility constraints emphasized (bias, effective sample size). Quote: “Causal inference using observational data is challenging… limited ‘effective sample size’…” (p. 1116).</p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — implied need for bedside decision support; not explicitly operationalized. Quote: “towards actionable AI at the bedside…” (p. 1116).</p></li>
<li><p><strong>EX (Explainability):</strong> No — not addressed.</p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — explicit “optimal treatment” framing. Quote: “…advise on treatment options that lead to the best predicted outcome (i.e., the optimal treatment).” (p. 1114).</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Management of time‑varying confounding; sequential policies; causal validity (bias control).</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Causal inference (counterfactual outcomes; DAGs; time‑varying confounding; marginal structural models).  </p></li>
<li><p>Reinforcement learning for policy optimization in clinical settings.  </p></li>
<li><p>RCTs for causal identification and individualized treatment‑effect modeling.</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><strong>Implicit</strong>: ability to recommend an optimal action based on predicted counterfactual outcomes; adequacy of bias adjustment; sufficient effective sample size for regime comparisons. No explicit numeric KPI provided.</li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Confounding and selection biases in observational data.  </p>

<p> - Time‑varying confounding in sequential decisions.  </p>

<p> - Limited effective sample size for agreement between observed and modeled regimes.</p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Use of causal diagrams to plan adjustment.  </p>

<p> - Target trial emulation and marginal structural models.  </p>

<p> - RCT data enabling causal identification and individualized effects.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper situates “actionable AI” within the broader shift in data science from association to causation, referencing reviews on AI in ICU and sepsis prediction (predictive focus) and methodological work on causal inference tasks and target trial emulation. It highlights exemplar ICU studies using MSMs and RL to illustrate actionable approaches and cites guidance on RL in healthcare, DAG use, and treatment‑effect heterogeneity for precision medicine.</p>

<hr />

<h2>Summary</h2>

<p>This perspective reframes ICU AI from predominantly predictive tasks (risk forecasts and early warnings) toward “actionable AI,” defined as causal‑inference‑driven decision support that predicts outcomes under alternative treatment choices to recommend optimal actions. The ICU is characterized by sequential policies with time‑varying confounding; thus, actionability requires appropriate adjustment methods (e.g., marginal structural models), study designs (target trial emulation), and, where possible, RCT data to personalize treatment effects. The article underscores challenges (bias, effective sample size) and points to exemplars in sepsis management using RL and MSMs. A central diagram contrasts predictive vs actionable AI and depicts counterfactual outcomes across treatment regimes, reinforcing the need to model decisions over time. Overall, the contribution is a clear conceptual definition, a mapping of suitable methods, and guidance on data sources and pitfalls for moving ICU AI toward genuinely decision‑guiding systems.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 86 — Strong, explicit definition of “actionable AI” as causal inference with clear linkage to decision‑making and necessary conditions (sequential decisions, confounding control). Limited granular dimensions beyond causal validity lowers the score slightly.  </p></li>
<li><p><strong>Operationalization Score:</strong> 61 — Provides concrete methodological avenues (MSMs, target trial emulation, RL; RCT‑based ITE modeling) and identifies practical constraints, but lacks a full step‑by‑step operational framework or metrics for bedside deployment.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“we propose to refer to any data‑driven model used for causal inference tasks as ‘actionable AI’, as opposed to ‘predictive AI’” (p. 1114).  </p></li>
<li><p>“Actionable AI should perform causal inference tasks… predict… outcomes… that would result from alternative treatment decisions.” (p. 1114–1115).  </p></li>
<li><p>“ICU patients are typically treated according to a certain regime—or policy… informing treatment decisions during follow‑up… [with] ‘time‑varying confounding’.” (p. 1115).  </p></li>
<li><p>“a significant challenge is the typically limited ‘effective sample size’…” (p. 1116).  </p></li>
<li><p>“towards actionable AI at the bedside, usage of RCT data may currently be the safest route.” (p. 1116).</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Hernán, Hsu, Healy (2019): classification of data science tasks (prediction vs causal).  </p></li>
<li><p>Hernán &amp; Robins (2016): target trial emulation.  </p></li>
<li><p>Daniel et al. (2013); Mansournia et al. (2017): time‑dependent confounding methods.  </p></li>
<li><p>Komorowski et al. (2018): RL for optimal sepsis treatment strategies in ICU.  </p></li>
<li><p>Shahn et al. (2020): MSMs for fluid‑limiting strategies in sepsis.  </p></li>
<li><p>Tennant et al. (2021): DAGs for confounder identification.  </p></li>
<li><p>Kent et al. (2020): PATH statement on treatment‑effect heterogeneity.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Actionable Intelligence  </p>

<p>Authors: Eugene McMahon  </p>

<p>DOI: n/a  </p>

<p>Year: 2010  </p>

<p>Publication Type: Journal Commentary  </p>

<p>Discipline/Domain: Education / Special Education  </p>

<p>Subdomain/Topic: Education of students with blindness and visual impairments; data-driven program improvement  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 72  </p>

<p>Operationalization Score: 65  </p>

<p>Contains Definition of Actionability: Yes (explicit and contextualized to field)  </p>

<p>Contains Systematic Features/Dimensions: Yes (sample size, comparability, relevance to program change)  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (COSB outcome data collection infrastructure)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual with applied data infrastructure design  </p>

<p>Study Context: Council of Schools for the Blind (COSB) initiative to collect and use longitudinal student data for program improvement  </p>

<p>Geographic/Institutional Context: United States; COSB member schools  </p>

<p>Target Users/Stakeholders: Superintendents, educators, administrators in schools for the blind  </p>

<p>Primary Contribution Type: Conceptual framework with applied data collection process  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Partial  </p>

<p>TI: No  </p>

<p>EX: Partial  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Actionable Intelligence  </p>

<p><strong>Authors:</strong>  </p>

<p>Eugene McMahon  </p>

<p><strong>DOI:</strong>  </p>

<p>n/a  </p>

<p><strong>Year:</strong>  </p>

<p>2010  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Commentary  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Education / Special Education  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Education of students with blindness and visual impairments; data-driven program improvement  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The piece addresses the lack of “actionable intelligence” in the education of students with visual impairments, defined as information that drives meaningful changes in instructional strategies, program design, funding priorities, and professional development. It introduces the COSB initiative to systematically collect and analyze longitudinal outcome data to overcome barriers like low incidence and high diversity of the student population.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>United States; Council of Schools for the Blind (COSB)  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Superintendents, school administrators, educators of students with blindness/visual impairment  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework with applied data infrastructure and descriptive reporting  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual and practical model for collecting and using outcome data to enable actionable decision-making in a low-incidence educational field  </p>

<h2>General Summary of the Paper</h2>

<p>This commentary introduces the COSB’s long-term project to collect outcome data on graduates of schools for the blind, aiming to generate “actionable intelligence” that can inform program improvements. McMahon defines actionable intelligence as information sufficient to prompt changes in practice. The project uses a structured Base Data Set (school years) and Post-Graduation Data Set (post-school life) to allow for disaggregated, comparable analysis by student characteristics. The commentary highlights two main barriers to actionable intelligence in this field: low incidence of visual impairment and diversity of learning characteristics. While the data collection has limitations, the design allows superintendents to compare inputs and outcomes across schools with similar student profiles, supporting informed program adjustments.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionable intelligence is explicitly defined as <em>“information sufficient to allow the government to take some action for the protection of the American people”</em>, adapted here as <em>information that will cause those of us in the blindness field to change instructional strategies, program offerings, funding priorities, professional development, and the like</em> (p. 1).  </p>

<blockquote>
  <p>“Given the dearth of actionable intelligence, professionals are often left relying only on their past experiences and clinical judgments.” (p. 1)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Sufficient to prompt meaningful changes in educational practice  </p></li>
<li><p>Comparable across similar populations (“apple to apple” comparisons)  </p></li>
<li><p>Based on adequate sample sizes to justify practice changes  </p></li>
<li><p>Sensitive to diversity of learning characteristics in the target population  </p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> COSB Outcome Data Collection Infrastructure  </p></li>
<li><p><strong>Methods/Levers:</strong> Longitudinal data on student demographics, program activities, exit outcomes/satisfaction, and post-graduation outcomes  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Annual data submission from member schools; categorization into Base and Post-Graduation Data Sets; disaggregation by variables for meaningful comparison  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Demographics, reading level, disability status, employment, education, independence, satisfaction  </p></li>
<li><p><strong>Implementation Context:</strong> COSB schools in the U.S.  </p></li>
</ul>

<blockquote>
  <p>“Outcome data can be disaggregated… to arrive at meaningful ‘apple to apple’ comparisons.” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“Such comparisons might then result in professionals making meaningful, generalizeable changes to interventions.” (p. 2)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Actionability depends on clear, comparable data for interpreting results.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Data must be relevant to specific program improvement contexts.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — Acknowledges sample size and diversity constraints affecting practical application.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No — Timeliness not explicitly discussed.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — Comparisons aim to explain variations in outcomes.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Data collection designed to support COSB’s goal of improving programs.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Comparability, generalizability, meaningfulness.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Adaptation of “actionable intelligence” from national security discourse to education  </p></li>
<li><p>Emphasis on data-driven decision-making in special education contexts  </p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Ability to disaggregate and compare outcomes by relevant student characteristics  </p></li>
<li><p>Sufficient sample size to justify generalizable changes  </p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Low incidence of visual impairment; diversity of student characteristics; small research sample sizes.  </p></li>
<li><p><strong>Enablers:</strong> Systematic, longitudinal data collection; commitment of COSB superintendents; structured datasets enabling comparability.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions itself against a backdrop of limited empirical data in the field of visual impairment education, reframing the term “actionable intelligence” to fit the sector’s needs, and proposing structured outcome measurement as a remedy.</p>

<h2>Summary</h2>

<p>McMahon’s commentary redefines “actionable intelligence” from national security to the education of visually impaired students, emphasizing the need for information that directly prompts changes in practice. The COSB’s longitudinal data collection framework, split into Base and Post-Graduation Data Sets, is designed to overcome challenges of low incidence and population diversity by enabling meaningful comparisons across similar student groups. While limitations remain—particularly small sample sizes and potential overinterpretation—the approach provides a structured, replicable means for superintendents to align program changes with measured outcomes. Actionability here is tied to clarity, contextual relevance, comparability, and goal alignment, with feasibility partially addressed. This framework offers a practical path toward evidence-informed program improvement in a field historically lacking robust outcome data.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 72 — Clear, adapted definition of actionability with identified features (comparability, sufficient evidence, contextual relevance); less emphasis on certain dimensions like timeliness.  </p></li>
<li><p><strong>Operationalization Score:</strong> 65 — Provides a concrete data collection and comparison infrastructure linked to actionability, but lacks detailed procedural guidelines for converting data insights into implemented changes.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Information that will cause those of us in the blindness field to change instructional strategies, program offerings, funding priorities, professional development, and the like.” (p. 1)  </p></li>
<li><p>“Outcome data can be disaggregated… to arrive at meaningful ‘apple to apple’ comparisons.” (p. 2)  </p></li>
<li><p>“Such comparisons might then result in professionals making meaningful, generalizeable changes to interventions.” (p. 2)  </p></li>
<li><p>“The first purpose of the project is to give superintendents the ability to compare inputs and outcomes of their students to students with similar learning characteristics across the other COSB schools.” (p. 2)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li>None explicitly cited for defining/operationalizing actionability.</li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Explainability: Actionable Information Extraction</p>

<p>Authors: Catarina Silva, Jorge Henriques, Bernardete Ribeiro</p>

<p>DOI: https://doi.org/10.1007/978-3-031-59216-4_11</p>

<p>Year: 2024</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Artificial Intelligence / Machine Learning</p>

<p>Subdomain/Topic: Explainability, Actionable Information Extraction, Knowledge Distillation</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 78</p>

<p>Operationalization Score: 85</p>

<p>Contains Definition of Actionability: Implicit</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual with empirical demonstration</p>

<p>Study Context: Credit scoring (German credit dataset), adaptable to other domains</p>

<p>Geographic/Institutional Context: University of Coimbra, Portugal</p>

<p>Target Users/Stakeholders: AI practitioners, decision-makers in finance/healthcare, researchers in interpretability/actionability</p>

<p>Primary Contribution Type: Methodological approach for explainable and actionable AI</p>

<p>CL: Yes — “visualization of decision-trees is also human-friendly making them better for explanation and interpretation” (p. 108)</p>

<p>CR: Partial — implied via “adaptable to different setup… health prognosis… predictive maintenance” (p. 110)</p>

<p>FE: Yes — “training a model with the support of a neural net’s dark knowledge might be beneficial to get better performance on less complex models” (p. 111)</p>

<p>TI: No — timeliness not explicitly linked to actionability</p>

<p>EX: Yes — “importance of each feature… example of the set of rules extracted… for actionability” (p. 111–112)</p>

<p>GA: Partial — goal alignment implied via problem-specific feature importance</p>

<p>Reason if Not Eligible: n/a</p>

<!--META_END-->

<p><strong>Title:</strong> Explainability: Actionable Information Extraction  </p>

<p><strong>Authors:</strong> Catarina Silva, Jorge Henriques, Bernardete Ribeiro  </p>

<p><strong>DOI:</strong> https://doi.org/10.1007/978-3-031-59216-4_11  </p>

<p><strong>Year:</strong> 2024  </p>

<p><strong>Publication Type:</strong> Conference  </p>

<p><strong>Discipline/Domain:</strong> Artificial Intelligence / Machine Learning  </p>

<p><strong>Subdomain/Topic:</strong> Explainability, Actionable Information Extraction, Knowledge Distillation  </p>

<p><strong>Contextual Background:</strong> The paper addresses the challenge of making black-box AI models interpretable and actionable by transferring knowledge to interpretable decision-tree models. Demonstrated in credit scoring, the approach is intended for broader decision-support applications where explanation and actionable rules are critical.  </p>

<p><strong>Geographic/Institutional Context:</strong> University of Coimbra, Portugal  </p>

<p><strong>Target Users/Stakeholders:</strong> AI/ML practitioners, data scientists, domain experts in finance/healthcare, policy-makers needing interpretable decision rationale.  </p>

<p><strong>Primary Methodology:</strong> Conceptual proposal with empirical validation  </p>

<p><strong>Primary Contribution Type:</strong> Methodological — interpretable surrogate modeling for actionable insights  </p>

<h2>General Summary of the Paper</h2>

<p>This work proposes a method for extracting actionable information from black-box machine learning models by distilling their decision patterns into interpretable decision-tree surrogates. The approach uses logits from a trained deep neural network (“Teacher”) as soft targets to train a decision-tree model (“Student”), thereby mimicking the black-box model’s decision process while maintaining interpretability. Experiments on the German credit dataset show that the student model closely matches the teacher’s performance, especially in recall, which is important for credit risk contexts. Feature importance visualizations and explicit decision rules are extracted from the surrogate, enabling actionable insights for decision support. The authors argue that this approach can generalize to other domains and outline future work towards a general-purpose framework.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>Actionability is implicitly defined as providing interpretable decision patterns from AI models that can support human decision-making through explicit rules and feature importance that guide interventions.</p>

<blockquote>
  <p>“provide actionable information that can be used to support decisions” (p. 105)  </p>
</blockquote>

<blockquote>
  <p>“Rules extracted for actionability” (p. 112)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Interpretability through human-friendly visualization (decision trees)</p></li>
<li><p>Ability to reveal feature interactions and their role in decision-making</p></li>
<li><p>Extraction of explicit rules that map conditions to outcomes</p></li>
<li><p>Alignment of model logic with domain-specific decision needs</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Decision-tree surrogate via knowledge distillation  </p></li>
<li><p><strong>Methods/Levers:</strong> Transfer logits from a deep neural net to a gradient-boosted decision-tree  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Train a black-box deep neural network (Teacher)  </p>

<p> 2. Extract logits (soft targets) from its final layer  </p>

<p> 3. Train a decision-tree model (Student) on these soft targets  </p>

<p> 4. Compare Student’s performance with Teacher’s to validate fidelity  </p>

<p> 5. Extract interpretable rules and feature importance from the Student  </p></li>
<li><p><strong>Data &amp; Measures:</strong> German credit dataset; metrics include accuracy, precision, recall, F1-score; special focus on recall due to domain priorities  </p></li>
<li><p><strong>Implementation Context:</strong> Credit risk classification, adaptable to health prognosis and predictive maintenance  </p></li>
</ul>

<blockquote>
  <p>“visualization of decision-trees is… human-friendly making them better for explanation and interpretation” (p. 108)  </p>
</blockquote>

<blockquote>
  <p>“Rules extracted for actionability” (p. 112)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — decision-tree visualization explicitly linked to explanation (p. 108)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Partial — adaptation to multiple domains suggested (p. 110)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — method improves performance of less complex models (p. 111)  </p></li>
<li><p><strong>TI (Timeliness):</strong> No — timeliness not discussed  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — feature importance and rule extraction for decision understanding (p. 111–112)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — alignment implied via feature targeting and decision context  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Fidelity to original model’s decision-making</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Knowledge distillation (Hinton et al., 2015)  </p></li>
<li><p>Surrogate model interpretability (Ribeiro et al., 2016 — LIME)  </p></li>
<li><p>Model compression (Bucila et al., 2006)</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Fidelity between surrogate and original model’s predictions  </p></li>
<li><p>Recall and F1-score improvements in decision-critical contexts  </p></li>
<li><p>Feature importance scores  </p></li>
<li><p>Explicit decision rules</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Black-box nature of high-performance models; complexity trade-offs with interpretability  </p></li>
<li><p><strong>Enablers:</strong> Surrogate modeling; human-friendly rule extraction; high fidelity between models</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions itself within interpretability research, particularly model-agnostic surrogate modeling and knowledge distillation, extending these techniques to emphasize rule extraction for actionable decision-making.</p>

<h2>Summary</h2>

<p>The paper contributes a method for making AI models both interpretable and actionable by distilling a black-box neural network into a decision-tree surrogate. This enables extraction of explicit, human-readable rules that preserve the predictive behavior of the original model while providing actionable insights for practitioners. The method is validated in credit scoring, showing that surrogate models can achieve comparable or better performance than the original black-box while revealing feature importance and decision logic. Actionability is achieved through clarity, explainability, and feasibility, though timeliness and explicit goal alignment are less developed. The approach is positioned as domain-agnostic and adaptable to various decision-support scenarios.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 78 — Strong implicit definition of actionability and clear identification of actionable features; could be improved with an explicit, formal definition and broader coverage of contextual relevance and goal alignment.  </p></li>
<li><p><strong>Operationalization Score:</strong> 85 — Detailed, replicable workflow with specific implementation steps; directly tied to producing actionable outputs from black-box models.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“provide actionable information that can be used to support decisions” (p. 105)  </p></li>
<li><p>“visualization of decision-trees is… human-friendly making them better for explanation and interpretation” (p. 108)  </p></li>
<li><p>“training a model with the support of a neural net’s dark knowledge might be beneficial to get better performance on less complex models” (p. 111)  </p></li>
<li><p>“Rules extracted for actionability” (p. 112)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Hinton et al., 2015 — Knowledge distillation  </p></li>
<li><p>Ribeiro et al., 2016 — LIME  </p></li>
<li><p>Bucila et al., 2006 — Model compression  </p></li>
<li><p>Che et al., 2015 — Interpretable mimic learning  </p></li>
<li><p>Xu et al., 2018 — DarkSight visualization</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Domain-Driven, Actionable Knowledge Discovery  </p>

<p>Authors: Longbing Cao, Chengqi Zhang  </p>

<p>DOI: 10.1109/MIS.2007.75  </p>

<p>Year: 2007  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Computer Science / Data Mining  </p>

<p>Subdomain/Topic: Domain-Driven Data Mining (D3M), Actionable Knowledge Discovery  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 92  </p>

<p>Operationalization Score: 88  </p>

<p>Contains Definition of Actionability: Yes (explicit and implicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (Domain-Driven Data Mining framework)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual with applied case studies  </p>

<p>Study Context: Complex domain problems in business and government (e.g., trade support, social security debt detection)  </p>

<p>Geographic/Institutional Context: University of Technology Sydney; case studies in Australian government and business domains  </p>

<p>Target Users/Stakeholders: Business decision-makers, data scientists, government analysts  </p>

<p>Primary Contribution Type: Conceptual framework with operational guidance  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong> Domain-Driven, Actionable Knowledge Discovery  </p>

<p><strong>Authors:</strong> Longbing Cao, Chengqi Zhang  </p>

<p><strong>DOI:</strong> 10.1109/MIS.2007.75  </p>

<p><strong>Year:</strong> 2007  </p>

<p><strong>Publication Type:</strong> Journal Article  </p>

<p><strong>Discipline/Domain:</strong> Computer Science / Data Mining  </p>

<p><strong>Subdomain/Topic:</strong> Domain-Driven Data Mining (D3M), Actionable Knowledge Discovery  </p>

<p><strong>Contextual Background:</strong> Focuses on bridging the gap between data-mining research outputs and actionable results that meet real-world business and government decision-making needs. Argues for integrating domain knowledge, human intelligence, and context constraints into all stages of the KDD process.  </p>

<p><strong>Geographic/Institutional Context:</strong> University of Technology Sydney; case applications in Australia.  </p>

<p><strong>Target Users/Stakeholders:</strong> Business managers, policy-makers, domain experts, data analysts.  </p>

<p><strong>Primary Methodology:</strong> Conceptual with applied case examples.  </p>

<p><strong>Primary Contribution Type:</strong> Framework and methodology proposal with operational examples.</p>

<h2>General Summary of the Paper</h2>

<p>The paper introduces the Domain-Driven Data Mining (D3M) paradigm as a shift from traditional, purely data-driven KDD toward a methodology that explicitly incorporates domain knowledge, human expertise, and business context to produce actionable knowledge. The authors define actionable knowledge as patterns that hold both technical and business interestingness from objective and subjective perspectives. They present a formal framework, key differentiators between traditional and domain-driven approaches, and case studies in trade support and government debt analysis. The methodology emphasizes integrating multiple intelligence sources, balancing technical performance with business impact, and embedding human decision-making in the mining process.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as knowledge that is not only technically valid but also meaningful and implementable in a business or operational context.</p>

<blockquote>
  <p>“Domain-driven data mining generally targets actionable knowledge discovery in complex domain problems.” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“Actionable knowledge discovery should fit the following framework… from not only technological and business viewpoints but also objective and subjective perspectives.” (p. 1)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Meets both technical and business interestingness criteria.  </p></li>
<li><p>Balances objective (quantitative) and subjective (expert judgment) measures.  </p></li>
<li><p>Fits within business rules, policies, and operational constraints.  </p></li>
<li><p>Supports decision-making by delivering trustworthy, relevant, and context-sensitive results.  </p></li>
<li><p>Is derived through integration of multiple intelligence sources (data, domain, human, social, environmental).  </p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Domain-Driven Data Mining (D3M)  </p></li>
<li><p><strong>Methods/Levers:</strong> Integration of domain expertise, metasynthesis of multiple intelligence sources, business-oriented interestingness measures, runtime model customization.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify business and technical objectives → integrate domain knowledge and human input → apply adaptive mining processes → evaluate patterns by both technical and business measures → deliver decision-support-ready insights.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Technical metrics (support, confidence, lift); business metrics (impact on debt amount/duration).  </p></li>
<li><p><strong>Implementation Context:</strong> Applied in Australian government social security debt detection; trade support systems.  </p></li>
</ul>

<blockquote>
  <p>“We developed both technical and business measures for patterns relevant to these issues in real, unbalanced social security data.” (p. 2)  </p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – patterns must be understandable to decision-makers.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – must reflect complex, real-world context.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – must be implementable under operational constraints.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial – timeliness is implied via runtime/adaptive processes but not a major focus.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – human involvement in interpretation is key.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – explicitly aligned with business goals and problem-solving.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Reliability, trustworthiness, cost-effectiveness.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Pattern interestingness theory (Silberschatz &amp; Tuzhilin, 1996)  </p></li>
<li><p>Metasynthesis approach in complex systems  </p></li>
<li><p>Evolution of KDD toward domain-driven paradigms  </p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Technical: support, confidence, lift.  </p></li>
<li><p>Business: average debt amount, debt duration, business impact scores.  </p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Data constraints (heterogeneity, imbalance), evolving scenarios, technical–business conflicts.  </p></li>
<li><p><strong>Enablers:</strong> Human–machine collaboration, domain expert involvement, integration of contextual knowledge.  </p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions itself as an evolution of KDD beyond method-centric research to a business-impact-oriented practice. Builds on pattern interestingness and decision-support literature, extending with domain-specific operational frameworks.</p>

<h2>Summary</h2>

<p>Cao and Zhang (2007) present Domain-Driven Data Mining as a framework to make knowledge discovery truly actionable by integrating domain knowledge, human input, and contextual constraints into all stages of the process. Actionability is defined as knowledge that is both technically valid and business-relevant, balancing objective measures (e.g., statistical significance) with subjective expert judgment. The framework operationalizes actionability via metasynthesis of intelligence sources, runtime customization, and dual evaluation metrics. Case studies in government debt prevention illustrate how technical and business measures jointly determine a pattern’s value. This approach reframes KDD as a decision-support tool rather than a purely academic exercise, with clear methodological and evaluative criteria.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 – Strong, explicit definition of actionability; detailed conceptualization and criteria.  </p></li>
<li><p><strong>Operationalization Score:</strong> 88 – Clear framework and concrete operational examples, though some implementation details remain high-level.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Domain-driven data mining generally targets actionable knowledge discovery in complex domain problems.” (p. 1)  </p></li>
<li><p>“Actionable knowledge discovery should fit the following framework… from not only technological and business viewpoints but also objective and subjective perspectives.” (p. 1)  </p></li>
<li><p>“We developed both technical and business measures for patterns relevant to these issues in real, unbalanced social security data.” (p. 2)  </p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Silberschatz, A., &amp; Tuzhilin, A. (1996). <em>What Makes Patterns Interesting in Knowledge Discovery Systems?</em> IEEE TKDE.  </p></li>
<li><p>Cao, L., &amp; Zhang, C. (2006). <em>Domain-Driven Data Mining: A Practical Methodology</em>. IJ Data Warehousing and Mining.  </p></li>
<li><p>Fayyad, U., Shapiro, G., &amp; Uthurusamy, R. (2003). <em>Data Mining: The Next 10 Years</em>. ACM SIGKDD Explorations.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Delivering actionable information  </p>

<p>Authors: Nathalie Colineau, Cécile Paris, Mingfang Wu  </p>

<p>DOI: 10.3166/ria.18.549-576  </p>

<p>Year: 2004  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Information Retrieval, Natural Language Generation  </p>

<p>Subdomain/Topic: Information Delivery, Document Generation, User Models  </p>

<p>Eligibility: Yes  </p>

<p>Overall Relevance Score: 85  </p>

<p>Operationalization Score: 80  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual and Empirical Analysis  </p>

<p>Study Context: Tailored Information Delivery in Knowledge Management  </p>

<p>Geographic/Institutional Context: CSIRO, Monash University  </p>

<p>Target Users/Stakeholders: Information Retrieval Practitioners, Knowledge Management Professionals  </p>

<p>Primary Contribution Type: Conceptual framework, platform development  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong> Delivering actionable information  </p>

<p><strong>Authors:</strong> Nathalie Colineau, Cécile Paris, Mingfang Wu  </p>

<p><strong>DOI:</strong> 10.3166/ria.18.549-576  </p>

<p><strong>Year:</strong> 2004  </p>

<p><strong>Publication Type:</strong> Journal  </p>

<p><strong>Discipline/Domain:</strong> Information Retrieval, Natural Language Generation  </p>

<p><strong>Subdomain/Topic:</strong> Information Delivery, Document Generation, User Models  </p>

<p><strong>Contextual Background:</strong> The paper discusses the need for delivering information in a way that answers users' information needs and is presented in a way that facilitates understanding and use. The authors propose the Virtual Document Planner (VDP), a platform designed to support tailored information delivery. The platform integrates user models, information retrieval, and natural language generation to create coherent and useful documents for users. The paper focuses on improving the traditional search-and-browse mechanisms and investigates how delivering coherent, tailored documents can enhance user comprehension and engagement with the information.  </p>

<p><strong>Geographic/Institutional Context:</strong> CSIRO - ICT Centre, Monash University, Australia  </p>

<p><strong>Target Users/Stakeholders:</strong> Researchers, practitioners in information retrieval, knowledge management  </p>

<p><strong>Primary Methodology:</strong> Conceptual framework, empirical evaluation  </p>

<p><strong>Primary Contribution Type:</strong> Platform development, case study, evaluation  </p>

<h2>General Summary of the Paper</h2>

<p>The paper presents the Virtual Document Planner (VDP), a platform designed to generate tailored information delivery for users based on their specific needs. The VDP integrates techniques from user modeling, information retrieval, and natural language generation. The platform is aimed at producing coherent and useful documents that help users easily make sense of complex information, such as scientific or business-related content. The paper also describes a case study, PERCY, which generates customized corporate brochures for users, demonstrating the effectiveness of the VDP. A preliminary study shows that the tailored and coherent delivery of information is more useful than conventional search-and-browse systems.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<p>Reason if Not Eligible: n/a  </p>

<h2>How Actionability is Understood</h2>

<p>Actionability in this context is understood as the delivery of information in a form that is not only relevant to the user's needs but also structured in a way that allows users to easily understand and apply the information. The VDP aims to provide actionable information by delivering tailored content that addresses the specific tasks or questions of the user, facilitating decision-making and understanding.  </p>

<blockquote>
  <p>“Actionable information is delivered when it addresses the user’s needs in a coherent and structured manner, enabling effective use and decision-making” (p. 3).  </p>
</blockquote>

<blockquote>
  <p>“Tailored information delivery ensures that the content is relevant, structured, and easy to use for the specific user context” (p. 5).</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<p>The paper identifies several key factors that make information actionable:</p>

<ul>
<li><p><strong>Relevance:</strong> The content must be specifically relevant to the user's needs and goals.  </p></li>
<li><p><strong>Clarity:</strong> The information should be presented in a clear and organized manner to enhance comprehension.  </p></li>
<li><p><strong>Tailoring:</strong> The information must be customized to the user's context, such as their role or task.  </p></li>
<li><p><strong>Coherence:</strong> The content must be logically structured to ensure that the relationships between information elements are clear.  </p></li>
</ul>

<blockquote>
  <p>“Tailored and coherent presentation of information makes it actionable by aligning the content with the user’s task and preferences” (p. 7).  </p>
</blockquote>

<blockquote>
  <p>“Actionability is achieved when the information is not only relevant but also easy to understand and apply” (p. 6).</p>
</blockquote>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<p>Actionability is operationalized through the use of the VDP platform, which applies discourse planning and user modeling to generate coherent documents. The VDP platform uses three main steps:</p>

<ol>
<li><p><strong>Content Planning:</strong> Determines the relevant information based on the user's query and profile.  </p></li>
<li><p><strong>Presentation Planning:</strong> Organizes the content and formats it according to the user’s delivery medium (e.g., web or paper).  </p></li>
<li><p><strong>Surface Realization:</strong> Generates the final document by assembling the content and formatting it for the specified medium.  </p></li>
</ol>

<blockquote>
  <p>“The VDP generates actionable information by selecting and organizing content based on the user’s needs and preferences, and presenting it in an appropriate format” (p. 7).  </p>
</blockquote>

<blockquote>
  <p>“By using discourse planning, the VDP ensures that the content is logically organized and relevant to the user’s context, which facilitates actionability” (p. 8).</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – Clear, coherent presentation of information is essential for actionability.  </p>

<p> &gt; “Coherent presentation is key to ensuring the information is easily understood and actionable” (p. 6).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – The information must be relevant to the user’s specific task or role.  </p>

<p> &gt; “Contextual relevance ensures that the information meets the user’s needs, making it actionable” (p. 5).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – The information should be easy to access and apply.  </p>

<p> &gt; “Feasibility is a key factor in actionability, as the information should be easily applied to the user’s task” (p. 7).  </p></li>
<li><p><strong>TI (Timeliness):</strong> No – The paper does not directly address timeliness, but it is implied through the relevance and organization of content.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – The clarity and structure of the information enable explainability and make it actionable.  </p>

<p> &gt; “Explainability is crucial for actionability, as the user must understand how to apply the information” (p. 7).  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – The information should align with the user’s goals to ensure that it is actionable.  </p>

<p> &gt; “Aligning the content with the user’s goals ensures that the information is actionable and leads to meaningful outcomes” (p. 6).</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<p>The authors base their approach on established theories in natural language generation and discourse planning, particularly Rhetorical Structure Theory (RST). They also draw from research in user modeling and information retrieval to create a system that tailors information delivery to users’ needs.  </p>

<blockquote>
  <p>“The VDP platform is built on discourse planning, using Rhetorical Structure Theory to ensure coherence and facilitate the delivery of actionable information” (p. 7).</p>
</blockquote>

<h2>Indicators or Metrics for Actionability</h2>

<p>The paper suggests that actionability can be evaluated by the relevance, clarity, and coherence of the delivered information. These factors determine how well the user can understand and use the information.  </p>

<blockquote>
  <p>“Actionability is measured by how well the information supports the user’s task and how easily it can be applied” (p. 7).</p>
</blockquote>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of coherence, irrelevant information, and poor organization of content can hinder actionability.  </p></li>
<li><p><strong>Enablers:</strong> Tailoring the information to the user’s needs, ensuring clarity, and maintaining a coherent structure are key enablers of actionability.  </p></li>
</ul>

<blockquote>
  <p>“Barriers to actionability arise when information is not tailored to the user’s needs or when it is presented in a disorganized manner” (p. 6).  </p>
</blockquote>

<blockquote>
  <p>“Tailoring and structuring the information according to the user’s context are key enablers of actionability” (p. 7).</p>
</blockquote>

<h2>Relation to Existing Literature</h2>

<p>The paper builds on existing work in information retrieval, natural language generation, and discourse theory, particularly Rhetorical Structure Theory (RST). It extends these ideas by applying them to the problem of tailored information delivery for users, specifically in a corporate context.  </p>

<blockquote>
  <p>“This work extends previous research on information retrieval and discourse planning by focusing on delivering tailored, coherent information that is actionable for users” (p. 8).</p>
</blockquote>

<h2>Summary</h2>

<p>This paper introduces the Virtual Document Planner (VDP), a platform designed to deliver actionable, tailored information to users. The VDP uses discourse planning, user modeling, and natural language generation techniques to organize and present information in a coherent and contextually relevant manner. The authors demonstrate the effectiveness of this approach through a case study involving the generation of customized corporate brochures, showing that users prefer this tailored delivery method over traditional search-and-browse systems.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 – The paper provides valuable insights into tailored information delivery and its impact on actionable information.  </p></li>
<li><p><strong>Operationalization Score:</strong> 80 – The VDP platform is well-described, though practical implementation details for wider applications could be expanded.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Coherent presentation is key to ensuring the information is easily understood and actionable” (p. 6).  </p></li>
<li><p>“Tailoring and structuring the information according to the user’s context are key enablers of actionability” (p. 7).  </p></li>
<li><p>“Actionability is measured by how well the information supports the user’s task and how easily it can be applied” (p. 7).  </p></li>
<li><p>“This work extends previous research on information retrieval and discourse planning by focusing on delivering tailored, coherent information that is actionable for users” (p. 8).</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Moore, J.D., &amp; Paris, C.L. (1993). Planning Text for Advisory Dialogues: Capturing Intentional and Rhetorical Information. Computational Linguistics.  </p></li>
<li><p>André, E., &amp; Rist, T. (1995). Generating Coherent Presentations Employing Textual and Visual Material. Artificial Intelligence Review.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: A Process‐Oriented Approach to Analyze Analysts' Use of Visualizations: Revealing Insights into the What, When, and How  </p>

<p>Authors: L. Zimmermann, F. Zerbato, K. Vrotsou, B. Weber  </p>

<p>DOI: 10.1111/cgf.70104  </p>

<p>Year: 2025  </p>

<p>Publication Type: Conference Paper (EuroVis / Computer Graphics Forum)  </p>

<p>Discipline/Domain: Visualization / Visual Analytics  </p>

<p>Subdomain/Topic: Process Mining, Visualization Evaluation, User Interaction Analysis  </p>

<p>Eligibility: Not Eligible  </p>

<p>Overall Relevance Score: 20  </p>

<p>Operationalization Score: 10  </p>

<p>Actionable/Actionability Used in Paper: No  </p>

<p>Authors Argue for Need for Actionability Without Defining It: No  </p>

<p>Contains Definition of Actionability: No  </p>

<p>Contains Systematic Features/Dimensions: No  </p>

<p>Contains Explainability: Partial (as part of visualization interpretation)  </p>

<p>Contains Interpretability: Partial (through focus on misinterpretation and accuracy)  </p>

<p>Contains Framework/Model: Yes (multi-perspective, multi-granular event sequence analysis)  </p>

<p>Operationalization Present: Yes (operationalizes visualization-use analysis method)  </p>

<p>Primary Methodology: Qualitative (observational study with think-aloud + video analysis)  </p>

<p>Study Context: Evaluation of visualization usage patterns in process mining analysis tasks  </p>

<p>Geographic/Institutional Context: Participants from multiple institutions, mainly Europe (Swiss, Dutch, Swedish institutions)  </p>

<p>Target Users/Stakeholders: Visualization researchers, process mining tool developers, process analysts  </p>

<p>Primary Contribution Type: Methodological framework for multi-perspective visualization-use analysis  </p>

<p>CL: N/A  </p>

<p>CR: N/A  </p>

<p>FE: N/A  </p>

<p>TI: N/A  </p>

<p>EX: Partial – e.g., identifying misinterpretation causes in visualizations  </p>

<p>GA: N/A  </p>

<p>Reason if Not Eligible: Paper does not address “actionability” or the state of being actionable in terms of deriving concrete actions or decisions; focus is solely on evaluating visualization use in analytic processes.  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>A Process‐Oriented Approach to Analyze Analysts' Use of Visualizations: Revealing Insights into the What, When, and How  </p>

<p><strong>Authors:</strong>  </p>

<p>L. Zimmermann, F. Zerbato, K. Vrotsou, B. Weber  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1111/cgf.70104  </p>

<p><strong>Year:</strong>  </p>

<p>2025  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference Paper (EuroVis / Computer Graphics Forum)  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Visualization / Visual Analytics  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Process Mining, Visualization Evaluation, User Interaction Analysis  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the challenge of evaluating how analysts actually use visualizations in complex, real-world analytical processes. Traditional evaluation methods often miss nuanced usage patterns, particularly when multiple tools and visualization types are employed. The authors propose a process-oriented approach that combines video recordings, think-aloud protocols, and multi-perspective coding to generate analyzable event sequences.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Collaborating institutions: University of St. Gallen (Switzerland), Eindhoven University of Technology (Netherlands), Linköping University (Sweden). Participants were recruited internationally, mainly from Europe.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Visualization researchers, process mining tool developers, process analysts.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Qualitative (observational study with think-aloud protocols, video coding, and sequence analysis).  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Methodological framework for multi-perspective visualization-use analysis.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper presents a qualitative, process-oriented method to study how analysts use visualizations across different tools and contexts, focusing on process mining as the application domain. The method starts from synchronized video and audio recordings of analysts performing analytical tasks. Using qualitative coding, events are identified across multiple perspectives—such as visualization type (HOW), analysis focus (WHAT), and analytical intent (WHY)—and at various granularity levels. These events are transformed into event sequences, enabling analysis of visualization usage patterns over time, including efficiency, accuracy, and context of use. The authors demonstrate the approach on 33 process analysts analyzing the Road Traffic Fine Management event log, revealing patterns in visualization adoption, sequence of use, and effectiveness. They conclude that certain visualizations (e.g., Directly-Follows Graphs) are heavily used but prone to misinterpretation, while others (e.g., Sequence Charts, Causal Nets) support more efficient observation derivation.  </p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No — The paper does not reference “actionability,” “actionable insight,” “actionable recommendation,” or “actionable knowledge.”  </p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No — There is no discussion of the need for actionable outputs in the decision-making sense.  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A  </p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A  </p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A — While the paper operationalizes the evaluation of visualization use, it does not operationalize the concept of actionability.  </p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> N/A  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> N/A  </p></li>
<li><p><strong>FE (Feasibility):</strong> N/A  </p></li>
<li><p><strong>TI (Timeliness):</strong> N/A  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial – Authors note interpretation errors, misinterpretation causes, and need for clarifying the origin/meaning of certain visualizations.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> N/A  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Visualization evaluation methods (e.g., GOMS, heuristic evaluation, insight-based evaluation)  </p></li>
<li><p>Process mining visualization literature  </p></li>
<li><p>Multi-perspective coding inspired by Brehmer &amp; Munzner’s typology (WHY/HOW/WHAT)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A  </p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p>N/A  </p>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The authors position their method as extending prior visualization evaluation frameworks by adding a process-oriented, multi-perspective temporal analysis from qualitative video data, bridging the gap between rich contextual insights and quantitative evaluation metrics.  </p>

<hr />

<h2>Summary</h2>

<p>This paper introduces a structured method to evaluate visualization use in analytical workflows using multi-perspective, multi-granular event sequence analysis derived from video and think-aloud recordings. Applied to process mining analysts, the approach reveals usage frequencies, temporal patterns, and efficiency/accuracy indicators for different visualization types. Findings include the dominance of Directly-Follows Graphs (DFGs) in use despite higher misinterpretation rates, and the comparative effectiveness of Sequence Charts and Causal Nets for deriving observations. While the method offers a transferable framework for studying visualization use across domains, it requires substantial manual coding effort. The contribution is methodological rather than conceptual with respect to actionability; the paper does not address actionable insights or recommendations in the decision-making sense, making it <strong>not eligible</strong> for the actionability-focused literature review.  </p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 20 — The study is unrelated to actionability; relevance is only tangential via general support for effective decision-support visualization design.  </p></li>
<li><p><strong>Operationalization Score:</strong> 10 — The paper operationalizes a visualization-use analysis method but not actionability.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We propose a structured process-oriented analysis method to convert video recordings… into event sequences that capture analytic processes from multiple perspectives and levels of granularity.” (p. 2)  </p></li>
<li><p>“Our method is particularly useful for capturing realistic analysis patterns, making it a valuable resource for researchers and tool developers.” (p. 10)  </p></li>
<li><p>“Our study… revealed that the DFG is the most frequently used visualization type but causes a substantial amount of interpretation errors.” (p. 10)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Relational Calculus for Actionable Knowledge</p>

<p>Authors: Michel Barès; Éloi Bossé</p>

<p>DOI: 10.1007/978-3-030-92430-0</p>

<p>Year: 2022</p>

<p>Publication Type: Book (Monograph)</p>

<p>Discipline/Domain: Data Science; Information Fusion; Knowledge Engineering</p>

<p>Subdomain/Topic: Relational calculus; Analytics &amp; Information Fusion (AIF); Situation Awareness; Decision–Action systems</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 86</p>

<p>Operationalization Score: 72</p>

<p>Actionable/Actionability Used in Paper: Yes — “Actionable knowledge is explicit symbolic knowledge that allows the decision‑maker to perform an action…” (Ch. 7). :contentReference[oaicite:0]{index=0}</p>

<p>Authors Argue for Need for Actionability Without Defining It: No — definition and positioning are provided (Ch. 1 &amp; 7). </p>

<p>Contains Definition of Actionability: Yes — see quote in “How Actionability is Understood.” :contentReference[oaicite:2]{index=2}</p>

<p>Contains Systematic Features/Dimensions: Yes (dimensions of knowledge; decision–action efficiency factors; context awareness; cooperability/interoperability). </p>

<p>Contains Explainability: Partial (emphasis on representation of mental models; knowledge representation for interpretation). :contentReference[oaicite:4]{index=4}</p>

<p>Contains Interpretability: Partial (situation awareness framing; AIF integrating framework for sense‑making). :contentReference[oaicite:5]{index=5}</p>

<p>Contains Framework/Model: Yes — AIF integrating framework (“Archetypal Dynamics”) and end‑to‑end data→information→knowledge→decision‑action chain. :contentReference[oaicite:6]{index=6}</p>

<p>Operationalization Present: Yes — mapping AIF core processes to relational calculus operations; workflow to “transform data into actionable knowledge.” </p>

<p>Primary Methodology: Conceptual (theoretical synthesis with formal methods)</p>

<p>Study Context: Cyber‑Physical &amp; Social Systems; multi‑agent decision and information fusion environments. :contentReference[oaicite:8]{index=8}</p>

<p>Geographic/Institutional Context: N/A (general technical context; examples reference business/defense analytics literature)</p>

<p>Target Users/Stakeholders: Decision‑makers; engineers; data scientists; AIF system designers; in some cases “machines/systems” as users of actionable knowledge. :contentReference[oaicite:9]{index=9}</p>

<p>Primary Contribution Type: Conceptual framework and formalization (relational calculus) to generate actionable knowledge via AIF</p>

<p>CL: Partial</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Yes</p>

<p>EX: Partial</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Relational Calculus for Actionable Knowledge</p>

<p><strong>Authors:</strong>  </p>

<p>Michel Barès; Éloi Bossé</p>

<p><strong>DOI:</strong>  </p>

<p>10.1007/978-3-030-92430-0</p>

<p><strong>Year:</strong>  </p>

<p>2022</p>

<p><strong>Publication Type:</strong>  </p>

<p>Book (Monograph)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Data Science; Information Fusion; Knowledge Engineering</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Relational calculus; Analytics &amp; Information Fusion (AIF); Situation Awareness; Decision–Action systems</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The book positions “actionable knowledge” within analytics and information fusion for complex, data‑rich decision environments, arguing that relations and their calculus provide the formal machinery to turn data into knowledge suitable for action. (Assumption: written primarily for AIF practitioners bridging management notions of actionability with computational formalisms.) </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>General/unspecified; cross‑domain (business, defense, CPS/IoT). :contentReference[oaicite:11]{index=11}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Decision‑makers and engineers designing AIF systems; also “machines/systems” consuming actionable knowledge. :contentReference[oaicite:12]{index=12}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual/theoretical synthesis with formal methods (crisp &amp; fuzzy relational calculus). :contentReference[oaicite:13]{index=13}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework + formalization linking relational calculus to AIF processes for producing actionable knowledge. :contentReference[oaicite:14]{index=14}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>Barès and Bossé develop an end‑to‑end perspective on producing actionable knowledge in complex environments by integrating analytics and information fusion (AIF) with relational calculus. After introducing actionability and related notions (situation awareness, decision models), they survey knowledge types and dimensions, quality of information, and imperfections across the data→information→knowledge chain. The core chapters formalize crisp and fuzzy relations and show how fundamental operations (composition, transitivity, closure) underpin AIF tasks. The authors then discuss the “knowledge–action” couple, context awareness, cooperability, and efficiency of actions, culminating in an integrating AIF framework (incl. Archetypal Dynamics) that structures processing pipelines to “transform data into actionable knowledge.” </p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>Yes.</strong>  </p>

<ul>
<li><p>“Actionable knowledge is explicit symbolic knowledge that allows the decision‑maker to perform an action…” (Ch. 7).   </p></li>
<li><p>AIF “allows to coherently and semantically frame a complex processing chain that ‘transform data into actionable knowledge.’” (Ch. 6).   </p></li>
<li><p>“The aim of this book is to present… formalization to support the [AIF] processes that aim at delivering actionable knowledge.” (Ch. 1). </p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>No.</strong> They provide an explicit characterization and repeatedly tie actionability to AIF workflows and decision‑action outcomes. </p>

<hr />

<h2>How Actionability is Understood</h2>

<blockquote>
  <p>“Actionable knowledge is explicit symbolic knowledge that allows the decision‑maker to perform an action…” (Ch. 7). </p>
</blockquote>

<p>They further position actionability as the desired end‑state of a situation‑awareness process enabled by AIF: a chain that “transform[s] data into actionable knowledge.” (Ch. 6). </p>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Explicit, symbolic form enabling decision and action.</strong>  </p>

<p> &gt; “Actionable knowledge is explicit symbolic knowledge that allows the decision‑maker to perform an action…” (Ch. 7). </p></li>
<li><p><strong>Situated within situation awareness and context.</strong>  </p>

<p> &gt; AIF “support[s] actionable knowledge” as output of “a situation awareness process.” (Ch. 6). </p></li>
<li><p><strong>Represented and organized to user goals via integrating framework.</strong>  </p>

<p> &gt; Framework should “represent knowledge through well‑defined notions of situation and awareness” and “achieve a specific objective.” (Ch. 6). </p></li>
<li><p><strong>Quality and efficiency considerations for action.</strong>  </p>

<p> &gt; “Examine the impact that the ‘quality’ of information can have on the conduct of an action…” (Ch. 5). </p></li>
<li><p><strong>Timeliness/speed of decision loops.</strong>  </p>

<p> &gt; The OODA loop emphasizes that “the speed at which the OODA Loop is executed becomes the largest factor…” (Ch. 1). </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong>  </p>

<p> Archetypal Dynamics as an AIF integrating framework; AIF core processes mapped to relational calculus operations within a data→information→knowledge→decision‑action chain. </p></li>
<li><p><strong>Methods/Levers:</strong>  </p>

<p> Crisp &amp; fuzzy relational calculus (composition, transitivity, closure), knowledge quality (QoI), context awareness, cooperability/interoperability. </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> Measure/organize/understand/reason over data using relations → fuse &amp; analyze (AIF) → obtain situation awareness → produce explicit, symbolic knowledge aligned to actions. (Fig. 1.16; Ch. 6). </p></li>
<li><p><strong>Data &amp; Measures:</strong>  </p>

<p> Transactional/unstructured inputs modeled into computational models; QoI considerations; uncertainty/belief modeling. </p></li>
<li><p><strong>Implementation Context:</strong>  </p>

<p> Cyber‑Physical &amp; Social systems, multi‑agent decision environments; defense/business analytics examples.   </p></li>
</ul>

<blockquote>
  <p>“Relations and its calculus make AIF processes more capable… to support situation awareness.” (Ch. 6). </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> <em>Partial</em> — emphasis on explicit symbolic representation and coherent frameworks guiding processing.  </p>

<p> &gt; “Explicit symbolic knowledge…”; “coherently and semantically frame a complex processing chain.” </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> <em>Yes</em> — knowledge must be “most useful… in the context of the action”; situation awareness central.  </p>

<p> &gt; “Represent the most useful knowledge in the context of the action…” (Ch. 5). </p></li>
<li><p><strong>FE (Feasibility):</strong> <em>Yes</em> — focus on QoI and imperfect knowledge to enable efficient action.  </p>

<p> &gt; “Examine the impact that the ‘quality’ of information can have on the conduct of an action…” (Ch. 5). </p></li>
<li><p><strong>TI (Timeliness):</strong> <em>Yes</em> — OODA loop speed as a decisive factor in action effectiveness.  </p>

<p> &gt; “The speed at which the OODA Loop is executed becomes the largest factor…” (Ch. 1). </p></li>
<li><p><strong>EX (Explainability):</strong> <em>Partial</em> — representation of mental models with expressive constructs to support interpretation.  </p>

<p> &gt; “Represent… the internal mental models… by expressive graphical constructs…” (Ch. 1). </p></li>
<li><p><strong>GA (Goal Alignment):</strong> <em>Yes</em> — frameworks designed to “achieve a specific objective.”  </p>

<p> &gt; “Represented, organized, structured… to achieve a specific objective or multiple objectives.” (Ch. 6). </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong>  </p>

<p> Knowledge dimensions (ontological, semantic, temporal, reference) affecting processing toward action. </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Relational calculus (crisp &amp; fuzzy) as computational substrate.   </p></li>
<li><p>Situation awareness and AIF as technological pathway.   </p></li>
<li><p>Archetypal Dynamics integrating framework for meaning‑laden information flows. </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>Limited explicit metrics; emphasis on <strong>Quality of Information (QoI)</strong>, uncertainty/belief modeling, and closure/transitivity properties in relational operations that support reliable, efficient action selection. </p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Information overload and complexity; imperfect/uncertain knowledge; interoperability challenges across cooperative contexts.   </p></li>
<li><p><strong>Enablers:</strong> AIF integrating frameworks; explicit symbolic representations; relational operations (composition, closure); context awareness; cooperability matrices. </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The authors note actionability’s roots in management/social sciences and in “actionable knowledge discovery” in data mining, reframing these for data science and engineering through formal methods and AIF. They cite work on FAIR digital objects and domain‑driven actionable mining as adjacent streams. </p>

<hr />

<h2>Summary</h2>

<p>This monograph makes a strong, explicit connection between <strong>actionability</strong> and a <strong>formal, computational pathway</strong>: relations and their calculus embedded into <strong>AIF</strong> workflows. The authors define actionable knowledge as <em>explicit symbolic knowledge enabling an action</em>, then build the machinery to produce it: crisp/fuzzy relations, algebraic properties (composition, transitivity, closure), and their role in information fusion. The book broadens beyond algebra to the <em>knowledge–action</em> couple, arguing that context awareness, quality of information, and cooperability/interoperability shape whether knowledge becomes actionable in practice. An integrating AIF framework (with Archetypal Dynamics) structures end‑to‑end processing to transform data into decision‑ready knowledge. While concrete KPIs of “actionability” are sparse, the work supplies a rich conceptual and formal foundation showing how to operationalize actionability through representation, reasoning, and system design choices in complex CPS/IoT and multi‑agent settings. </p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 86 — Strong explicit definition; sustained, book‑length treatment of how knowledge becomes actionable via formal AIF framing and relational methods. Limited empirical validation reduces maximal score.  </p></li>
<li><p><strong>Operationalization Score:</strong> 72 — Clear workflow (data→SA→actionable knowledge), concrete formal tools (relational operations) and a system framework; however, few quantitative <em>metrics</em> of actionability or domain‑specific implementation case studies.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“<strong>Actionable knowledge is explicit symbolic knowledge that allows the decision‑maker to perform an action</strong>…” (Ch. 7).   </p></li>
<li><p>“This integrating framework allows to <em>coherently and semantically frame</em> a complex processing chain that ‘<strong>transform data into actionable knowledge</strong>.’” (Ch. 6).   </p></li>
<li><p>“Represent the most useful knowledge <strong>in the context of the action</strong>…” (Ch. 5).   </p></li>
<li><p>“Examine the impact that the <strong>quality of information</strong> can have on the conduct of an action…” (Ch. 5).   </p></li>
<li><p>“The <strong>speed</strong> at which the OODA Loop is executed becomes the largest factor…” (Ch. 1). </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Batra &amp; Rehman (2019) — <em>Actionable Knowledge Discovery for Increasing Enterprise Profit</em> (domain‑driven data mining).   </p></li>
<li><p>De Smedt, Koureas &amp; Wittenburg (2020) — <em>FAIR digital objects… actionable knowledge units</em>.   </p></li>
<li><p>Barnaghi, Sheth &amp; Henson (2013) — <em>From data to actionable knowledge: Big data challenges in the web of things</em>.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Grand Challenges in Visual Analytics Applications  </p>

<p>Authors: Aoyu Wu, Dazhen Deng, Min Chen, Shixia Liu, Daniel Keim, Ross Maciejewski, Silvia Miksch, Hendrik Strobelt, Fernanda Viegas, Martin Wattenberg  </p>

<p>DOI: 10.1109/MCG.2023.3284620  </p>

<p>Year: 2023  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Visualization / Visual Analytics  </p>

<p>Subdomain/Topic: Research rigor and value in VA application research  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 80  </p>

<p>Operationalization Score: 70  </p>

<p>Contains Definition of Actionability: Yes (implicit, framed through "rigor" and "value" in VA applications)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (VA application research ecosystem)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual / Review with expert interviews and panel synthesis  </p>

<p>Study Context: Visual analytics research ecosystem and practice  </p>

<p>Geographic/Institutional Context: International (authors from USA, China, UK, Germany, Austria)  </p>

<p>Target Users/Stakeholders: Visual analytics researchers, practitioners, tool developers, interdisciplinary collaborators  </p>

<p>Primary Contribution Type: Conceptual framework and agenda-setting  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Grand Challenges in Visual Analytics Applications</p>

<p><strong>Authors:</strong>  </p>

<p>Aoyu Wu, Dazhen Deng, Min Chen, Shixia Liu, Daniel Keim, Ross Maciejewski, Silvia Miksch, Hendrik Strobelt, Fernanda Viegas, Martin Wattenberg</p>

<p><strong>DOI:</strong>  </p>

<p>10.1109/MCG.2023.3284620</p>

<p><strong>Year:</strong>  </p>

<p>2023</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Visualization / Visual Analytics</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Research rigor and value in VA application research</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses long-standing concerns about the rigor, value, and generalizability of visual analytics (VA) application research, synthesizing insights from interviews and a panel discussion to produce a conceptual research ecosystem and a set of 12 grand challenges.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>International (authors affiliated with Harvard University, Zhejiang University, University of Oxford, Tsinghua University, University of Konstanz, Arizona State University, TU Wien, MIT-IBM Watson AI Lab, Google)</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>VA researchers, application developers, interdisciplinary research collaborators, practitioners in domains like bioinformatics, urban analytics, explainable AI.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual/review, based on synthesis of expert interviews and conference panel discussion.</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework and strategic research agenda.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This article identifies and analyzes fundamental dilemmas in VA application research, particularly the tension between domain-specific solutions and the drive for generalizable knowledge, the subjectivity of design study methodologies, lack of documentation standards, and limited open science practices. The authors propose a conceptual ecosystem connecting academia, VA research, and practice through cycles of "rigor" and "value," and map 12 grand challenges across four thematic areas: foundation, methodology, application, and community. They call for better theoretical grounding, integration of AI and VA, improved evaluation frameworks, explainable VA, open-source contributions, deployment strategies, documentation standards, and expanded educational materials.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>The paper conceptualizes "actionability" in VA research implicitly through two linked constructs: <em>rigor</em> (scientific validity, methodological soundness, generalizability) and <em>value</em> (practical relevance, societal impact, adoption). Actionability emerges from research that both advances academic knowledge and is practically deployable.</p>

<blockquote>
  <p>“VA application research is driven by real-world application problems, and successful solutions… generate socio-technical impact and value.” (p. 85)  </p>
</blockquote>

<blockquote>
  <p>“We advocate for an inclusive perspective to derive combined benefits from promoting the research value and rigor of VA applications.” (p. 85)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Connection between domain-specific problems and generalizable knowledge.</p></li>
<li><p>Use of both qualitative and quantitative methodologies to enhance validity.</p></li>
<li><p>Comprehensive documentation enabling reuse.</p></li>
<li><p>Openness (data, code) for replication and extension.</p></li>
<li><p>Integration with broader data science workflows.</p></li>
<li><p>Deployment and sustained community engagement.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> VA Application Research Ecosystem (rigor and value cycles).</p></li>
<li><p><strong>Methods/Levers:</strong> Construction of knowledge bases, shared vocabularies, integration of VA and AI, guidance mechanisms, modular system design, open-source release.</p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify domain-specific problem → Design/build VA system → Justify/validate with mixed evaluation → Deploy and document for reuse.</p></li>
<li><p><strong>Data &amp; Measures:</strong> Real-world case collections, evaluation metrics tailored to complex analytical tasks, provenance data for explainability.</p></li>
<li><p><strong>Implementation Context:</strong> Academic-industry collaborations, interdisciplinary research projects.</p></li>
</ul>

<blockquote>
  <p>“We propose a research ecosystem that connects VA application research with academia and practice through the rigor circle and the value circle…” (p. 85)  </p>
</blockquote>

<blockquote>
  <p>“Open software is key to facilitating comparison and improvement…” (p. 88)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — through shared vocabularies, documentation standards.</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — driven by domain-specific application needs.</p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — focus on deployable, sustainable open-source tools.</p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — mentions guidance that is “timely” but not a core recurring theme.</p></li>
<li><p><strong>EX (Explainability):</strong> Yes — goal of constructing explainable VA and capturing analytical processes.</p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — aligning academic rigor with real-world value.</p></li>
</ul>

<p><strong>Other Dimensions Named by Authors:</strong> Sustainability, modularity, interdisciplinarity, openness.</p>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Chen &amp; Ebert’s ontological framework for VA workflows.</p></li>
<li><p>Thomas &amp; Cook’s early VA theory work.</p></li>
<li><p>Design study methodology (Sedlmair et al.).</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Extent of code/data openness.</p></li>
<li><p>Adoption beyond original domain.</p></li>
<li><p>Evaluation metrics linked to cognitive functions and decision outcomes.</p></li>
<li><p>Reuse/modularization success.</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of shared vocabularies; subjective evaluations; limited deployment; closed systems.</p></li>
<li><p><strong>Enablers:</strong> Open-source release; shared knowledge bases; deployment tracks; guidance tools.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions itself in line with foundational VA definitions (Keim et al., 2008) and theoretical calls (Thomas &amp; Cook, 2006), extending them to emphasize the balance between scientific rigor and practical value.</p>

<hr />

<h2>Summary</h2>

<p>This paper reframes actionability in VA application research as the dual pursuit of <em>rigor</em> and <em>value</em>. The authors identify four persistent dilemmas — domain specificity vs. generalizability, subjective design study methods vs. quantitative rigor, documentation gaps, and limited open science — as barriers to actionability. They propose an ecosystem model linking academia, VA research, and practice, and outline 12 grand challenges spanning foundational theory, methodological innovation, deployment, community building, and education. Actionable VA research, in their view, produces reusable, explainable, well-documented systems that address real-world problems while advancing general knowledge. Operationalization strategies include constructing VA knowledge bases, integrating VA with AI, refining evaluation frameworks, and fostering open-source contributions.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 80 — Strong conceptual linkage between actionability, rigor, and value; explicit identification of features; lacks a formal definition of “actionability.”</p></li>
<li><p><strong>Operationalization Score:</strong> 70 — Provides a conceptual model and concrete levers for achieving actionability, but operational detail remains high-level.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[VA research]… driven by real-world application problems, and successful solutions… generate socio-technical impact and value.” (p. 85)  </p></li>
<li><p>“We advocate for an inclusive perspective to derive combined benefits from promoting the research value and rigor…” (p. 85)  </p></li>
<li><p>“Open software is key to facilitating comparison and improvement…” (p. 88)  </p></li>
<li><p>“Another larger goal is to build explainable VA—how can we capture one’s analytical process and explain it to someone else?” (p. 87)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Chen &amp; Ebert (2019) — Ontological framework for VA.</p></li>
<li><p>Thomas &amp; Cook (2006) — Theory of VA.</p></li>
<li><p>Sedlmair et al. (2012) — Design study methodology.</p></li>
<li><p>Ceneda et al. (2017) — Guidance in VA.</p></li>
<li><p>Khayat et al. (2020) — Evaluation methods in VA.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Towards Visual Analytics for Explainable AI in Industrial Applications</p>

<p>Authors: Kostiantyn Kucher; Elmira Zohrevandi; Carl A. L. Westin</p>

<p>DOI: https://doi.org/10.3390/analytics4010007</p>

<p>Year: 2025</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Visual Analytics; Human–AI Interaction; Explainable AI</p>

<p>Subdomain/Topic: Conceptual framework for VA-supported XAI in industrial settings; design &amp; evaluation workflow; exemplars</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 52</p>

<p>Operationalization Score: 47</p>

<p>Actionable/Actionability Used in Paper: Yes — “ensuring that the interpreted results are communicated to stakeholders and are actionable” (p. 6). :contentReference[oaicite:0]{index=0}</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — see above quote; no explicit definition provided (p. 6). :contentReference[oaicite:1]{index=1}</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: Partial (features for XAI evaluation; stakeholder involvement; TRL perspective)</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Partial (conceptual workflow, actors, stages; matrix template)</p>

<p>Primary Methodology: Conceptual + Review</p>

<p>Study Context: Industrial AI/XAI projects supported by visual analytics; synthesis of prior VIS/XAI/industrial case work</p>

<p>Geographic/Institutional Context: Linköping University (Sweden) with funding from Sweden, Germany (BMBF), Netherlands (RVO) via EXPLAIN project</p>

<p>Target Users/Stakeholders: Industrial stakeholders, end users/operators, data professionals, visualization/HCI designers, model designers</p>

<p>Primary Contribution Type: Conceptual framework + roadmap + exemplar instantiations</p>

<p>CL: Partial</p>

<p>CR: Yes</p>

<p>FE: Partial</p>

<p>TI: Partial</p>

<p>EX: Yes</p>

<p>GA: Partial</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Towards Visual Analytics for Explainable AI in Industrial Applications</p>

<p><strong>Authors:</strong>  </p>

<p>Kostiantyn Kucher; Elmira Zohrevandi; Carl A. L. Westin</p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.3390/analytics4010007</p>

<p><strong>Year:</strong>  </p>

<p>2025</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal (Analytics)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Visual Analytics; Human–AI Interaction; Explainable AI</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Framework for integrating VA with XAI for industrial applications; design &amp; evaluation workflow; exemplar case mappings.</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper motivates VA as a bridge between black-box AI models and industrial stakeholders, focusing on trust, transparency, and human–automation collaboration; proposes a conceptual matrix-based framework aligning actors, stages, and activities across TRLs. </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Department of Science and Technology, Linköping University (Sweden); funding from VINNOVA (SE), BMBF (DE), and RVO (NL) under EXPLAIN. :contentReference[oaicite:3]{index=3}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Industrial stakeholders, end users/operators, data scientists/engineers, visualization/HCI designers, model designers. :contentReference[oaicite:4]{index=4}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual (framework/roadmap) + narrative review + exemplar instantiations of prior systems. :contentReference[oaicite:5]{index=5}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework/model + synthesis + design/evaluation guidance for VA-enabled XAI in industry. :contentReference[oaicite:6]{index=6}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors examine how visual analytics (VA) can support explainable AI (XAI) in industrial applications where trust, transparency, and human factors are critical. They synthesize prior VIS/XAI work and propose a conceptual, matrix-based framework that aligns project <strong>actors</strong> (e.g., stakeholders, operators, data pros, designers) with <strong>stages/activities</strong> spanning requirements, QA/SE/IT, VA &amp; GUI, analytics &amp; dissemination, lab studies, and real‑world deployment. The framework is positioned along technology readiness levels (TRLs) and stresses iterative feedback loops and multi-actor involvement. They then retroactively instantiate the framework with several published systems to illustrate design trade-offs and gaps (e.g., long-term deployment, evaluation), concluding with a roadmap and call to action for academia–industry collaboration. </p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>Yes.</strong>  </p>

<ul>
<li>“<strong>…ensuring that the interpreted results are communicated to stakeholders and are actionable</strong> [72].” (p. 6) :contentReference[oaicite:8]{index=8}</li>
</ul>

<p><em>Note:</em> The paper uses “actionable” to emphasize outcome-oriented communication but <strong>does not</strong> define the term or provide metrics specific to actionability.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>Yes.</strong>  </p>

<ul>
<li>“<strong>…ensuring that the interpreted results are communicated to stakeholders and are actionable</strong>” (p. 6). No definition of “actionable” is provided. :contentReference[oaicite:9]{index=9}</li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p><strong>Implicit.</strong> Actionability is implied as the end state where interpreted (X)AI results are communicated in ways that support stakeholders’ decisions within industrial constraints; tied to decision‑making support and dissemination.  </p>

<blockquote>
  <p>“Designs of visualization mechanisms for explanations are essential… where operators’ decision-making can have significant consequences…” (p. 7) :contentReference[oaicite:10]{index=10}</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Decision-making orientation (industrial consequences).</strong>  </p>

<p> &gt; “Designs of visualization mechanisms for explanations are essential… where <strong>operators’ decision-making</strong> can have significant consequences…” (p. 7) :contentReference[oaicite:11]{index=11}  </p></li>
<li><p><strong>Context-sensitive, stakeholder-tailored explanations.</strong>  </p>

<p> &gt; “…<strong>one-size-fits-all XAI solution is not sufficient</strong> considering the particular constraints and experiences of various users…” (p. 7) :contentReference[oaicite:12]{index=12}  </p></li>
<li><p><strong>Effective communication/translation of interpreted results.</strong>  </p>

<p> &gt; “…interpreted results are communicated to stakeholders <strong>and are actionable</strong>.” (p. 6) :contentReference[oaicite:13]{index=13}  </p></li>
<li><p><strong>Integration across lifecycle and roles (TRL-oriented, iterative).</strong>  </p>

<p> &gt; “The overall workflow direction is from left to right; however, <strong>multiple implicit feedback loops are expected</strong>… to ensure agile development and proper project risk management.” (p. 8) :contentReference[oaicite:14]{index=14}</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Conceptual framework for VA design &amp; evaluation for XAI in industrial applications (matrix of actors × stages/activities; TRL perspective). :contentReference[oaicite:15]{index=15}  </p></li>
<li><p><strong>Methods/Levers:</strong> Human-centered evaluation; stakeholder &amp; end‑user involvement; VA encodings for explanations; iterative feedback loops; analytics &amp; dissemination planning; pilot studies; long-term deployment and monitoring.   </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Data &amp; requirements → QA/SE/IT → VA &amp; GUI → Analytics &amp; dissemination → Lab studies → Real‑world application; with continuous feedback loops. :contentReference[oaicite:17]{index=17}  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Suggests XAI evaluation dimensions (e.g., explanation transparency/usability/simulatability; causability; modality-specific metrics) and industrial KPIs for validation. :contentReference[oaicite:18]{index=18}  </p></li>
<li><p><strong>Implementation Context:</strong> Industrial collaborations emphasizing deployment, maintenance, and long-term case studies to gather adoption/usage evidence. :contentReference[oaicite:19]{index=19}  </p></li>
</ul>

<blockquote>
  <p>“<strong>Real-World Application</strong>… test the proposed solutions in more realistic scenarios… followed by eventual deployment and adoption.” (p. 13) :contentReference[oaicite:20]{index=20}</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<p><em>(Marked “Yes/Partial” only where tied to making outcomes actionable.)</em></p>

<ul>
<li><p><strong>CL (Clarity):</strong> <strong>Partial.</strong> Clarity implied via “communicated to stakeholders” and user‑friendly, tailored explanations. (pp. 6–7) :contentReference[oaicite:21]{index=21}  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> <strong>Yes.</strong> Emphasizes user constraints, roles, and domain‑specific explanations; rejects one‑size‑fits‑all. (p. 7) :contentReference[oaicite:22]{index=22}  </p></li>
<li><p><strong>FE (Feasibility):</strong> <strong>Partial.</strong> TRL framing and QA/SE/IT stages tie feasibility to deployable systems under industrial constraints. (pp. 8, 13)   </p></li>
<li><p><strong>TI (Timeliness):</strong> <strong>Partial.</strong> Implied by operational decision‑making and real‑time/monitoring interfaces discussed in exemplars. (pp. 7, 24)   </p></li>
<li><p><strong>EX (Explainability):</strong> <strong>Yes.</strong> Central focus; multiple evaluation dimensions and VA mechanisms to support explanation quality. (pp. 2, 13)   </p></li>
<li><p><strong>GA (Goal Alignment):</strong> <strong>Partial.</strong> Stress on stakeholders’ KPIs and adoption as validation criteria. (p. 22) :contentReference[oaicite:26]{index=26}  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Trust calibration; human factors; generalizability (deployment/long‑term evidence). (pp. 2, 13, 24) </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<p>Nested model (Munzner); design study methodology (Sedlmair et al.); data–users–tasks triangle (Miksch &amp; Aigner); knowledge generation model (Sacha et al.); VA‑for‑trust workflow; human‑centered design and human–automation collaboration; TRL perspective. </p>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p><strong>None specific to “actionability.”</strong> The paper lists XAI/UX metrics (explanation transparency/usability/simulatability; causability; modality‑specific XAI metrics) and industrial KPIs for validation, but no dedicated actionability KPI. </p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Confidentiality vs. replicability tensions in industry collaborations (proprietary data/methods). (p. 22) :contentReference[oaicite:30]{index=30}  </p>

<p> - Gaps in long‑term deployment and rigorous real‑world evaluation. (p. 24) :contentReference[oaicite:31]{index=31}  </p>

<p> - Risk of linear/waterfall design; need for iterative feedback loops. (p. 22) :contentReference[oaicite:32]{index=32}</p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Early involvement of end users and data scientists to tailor explanations. (p. 9) :contentReference[oaicite:33]{index=33}  </p>

<p> - TRL‑aware planning from prototype to deployment/maintenance. (pp. 8, 13)   </p>

<p> - Use of VA encodings (what‑if, counterfactuals, multi‑view dashboards) to support decisions. (pp. 7, 24) </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper situates itself among surveys and frameworks on VA for XAI and human‑centered ML, noting limited coverage of industrial‑specific constraints and end‑to‑end (TRL‑spanning) workflows. It draws on prior VIS methodologies and evaluation guidance, human‑factors research, and industry‑focused reflections, arguing for integrated VA‑XAI design from requirements through deployment and long‑term studies. </p>

<hr />

<h2>Summary</h2>

<p>This paper contributes a <strong>matrix‑based conceptual framework</strong> for designing and evaluating <strong>VA‑supported XAI</strong> in industrial contexts. While “actionable” outcomes are explicitly named, the authors do not define “actionability”; instead, they frame it implicitly as <strong>stakeholder‑oriented, decision‑supportive communication</strong> of interpreted results. The framework operationalizes progress toward such outcomes via <strong>roles</strong> (stakeholders, operators, data pros, designers) and <strong>stages</strong> (requirements → QA/SE/IT → VA &amp; GUI → analytics &amp; dissemination → lab studies → real‑world deployment), emphasizing <strong>iterative feedback loops</strong> and <strong>TRL‑aware planning</strong>. The paper inventories evaluation levers (e.g., transparency, simulatability, causability) and stresses <strong>real‑world validation</strong>, acknowledging barriers like <strong>confidentiality vs. replicability</strong> and gaps in <strong>long‑term deployment evidence</strong>. Exemplar mappings illustrate how VA mechanisms (e.g., what‑if analysis, counterfactual views, ecological dashboards) can <strong>support operators’ decision‑making</strong>, pointing to opportunities for more comprehensive, user‑tailored solutions that bridge model explanations with industrial KPIs and adoption. </p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 52 — The paper <strong>explicitly</strong> mentions making results “actionable” and strongly orients XAI toward decision support, but <strong>does not define</strong> actionability nor articulate dimensions/metrics specifically for it. :contentReference[oaicite:38]{index=38}</p></li>
<li><p><strong>Operationalization Score:</strong> 47 — Provides a <strong>clear conceptual workflow</strong> (actors × stages, TRL framing) and evaluation levers; however, <strong>no concrete procedures or KPIs</strong> are offered to <strong>assess or guarantee actionability</strong> per se. </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[XAI] serves as a critical mechanism for <strong>calibrating user trust</strong> in AI by providing insights into AI/ML system decision‑making processes.” (p. 2) :contentReference[oaicite:40]{index=40}  </p></li>
<li><p>“<strong>…interpreted results are communicated to stakeholders and are actionable</strong>.” (p. 6) :contentReference[oaicite:41]{index=41}  </p></li>
<li><p>“Figure 2 presents the <strong>conceptual framework</strong>… to design and evaluate (visual) analytic workflows and solutions for (X)AI in industrial applications.” (p. 8) :contentReference[oaicite:42]{index=42}  </p></li>
<li><p>“<strong>Real‑World Application</strong> … test … in realistic scenarios… followed by <strong>deployment and adoption</strong>.” (p. 13) :contentReference[oaicite:43]{index=43}  </p></li>
<li><p>“<strong>One‑size‑fits‑all XAI</strong> solution is not sufficient considering the particular constraints and experiences of various users.” (p. 7) :contentReference[oaicite:44]{index=44}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>The paper does not cite a dedicated “actionability” definition. It references evaluation dimensions for explanations (e.g., <strong>transparency, usability, simulatability</strong>, <strong>causability</strong>) and human‑centered evaluation templates that could indirectly relate to assessing actionable outcomes in practice. :contentReference[oaicite:45]{index=45}</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: The Value of Information Visualization</p>

<p>Authors: Jean-Daniel Fekete; Jarke J. van Wijk; John T. Stasko; Chris North</p>

<p>DOI: 10.1007/978-3-540-70956-5_1</p>

<p>Year: 2008</p>

<p>Publication Type: Book Chapter (LNCS 4950)</p>

<p>Discipline/Domain: Human-Computer Interaction; Information Visualization</p>

<p>Subdomain/Topic: Value of InfoVis; evaluation; cognition; economics of visualization</p>

<p>Eligibility: Eligible (implicit treatment of actionability via decisions/actions and criteria)</p>

<p>Overall Relevance Score: 70</p>

<p>Operationalization Score: 35</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — “consider if the new knowledge influences decisions, leads to actions”:contentReference[oaicite:0]{index=0}</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: Partial (conditions when browsing/InfoVis is valuable; benefits that “amplify cognition”)</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes (economic model of value)</p>

<p>Operationalization Present: No</p>

<p>Primary Methodology: Conceptual</p>

<p>Study Context: Conceptual synthesis with illustrative cases and prior literature</p>

<p>Geographic/Institutional Context: N/A</p>

<p>Target Users/Stakeholders: Researchers, practitioners, tool builders, sponsors, decision-makers who rely on insights from visualization</p>

<p>Primary Contribution Type: Conceptual argument and modeling (economic model of value)</p>

<p>CL: No</p>

<p>CR: Partial</p>

<p>FE: Partial</p>

<p>TI: No</p>

<p>EX: No</p>

<p>GA: Partial</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>The Value of Information Visualization</p>

<p><strong>Authors:</strong>  </p>

<p>Jean-Daniel Fekete; Jarke J. van Wijk; John T. Stasko; Chris North</p>

<p><strong>DOI:</strong>  </p>

<p>10.1007/978-3-540-70956-5_1</p>

<p><strong>Year:</strong>  </p>

<p>2008</p>

<p><strong>Publication Type:</strong>  </p>

<p>Book Chapter (LNCS 4950)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Human-Computer Interaction; Information Visualization</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Value of InfoVis; evaluation; cognition; economics of visualization</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The chapter addresses why InfoVis is valuable yet hard to evaluate, emphasizing exploratory analysis, cognitive/perceptual mechanisms, and an economic model for value. (Assumption: treated as a field-level position paper synthesizing evidence and arguments.)</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>N/A</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Visualization researchers and practitioners; funders; analysts; decision-makers in domains using exploratory analysis.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual (argumentation, literature synthesis, illustrative examples)</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework and economic model of visualization value</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors argue that demonstrating the value of Information Visualization (InfoVis) is difficult because its core promise—“to amplify cognition”—lacks a simple ground truth for measurement:contentReference[oaicite:1]{index=1}. They position InfoVis as particularly suited to exploratory tasks where users browse data, learn, and gain insight, especially when specific questions are not yet formed:contentReference[oaicite:2]{index=2}. Cognitive and perceptual arguments are presented (e.g., preattentive processing and Gestalt principles) to explain why visuals help users recognize patterns and reduce search:contentReference[oaicite:3]{index=3}. The chapter contrasts InfoVis with statistics and data mining, emphasizing complementary roles and showcasing classic examples (Minard, John Snow, dynamic queries):contentReference[oaicite:4]{index=4}. A centerpiece is van Wijk’s economic model, framing visualization’s profit as the value of increased knowledge (impacting decisions and actions) minus costs across research, use, and sessions:contentReference[oaicite:5]{index=5}. The paper concludes that, given ubiquitous data and needs, InfoVis’ value will continue to grow:contentReference[oaicite:6]{index=6}.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No.  </p>

<p>(“Actionable/actionability” terms do not appear. However, the chapter explicitly links insight to <strong>decisions and actions</strong>, which is central to actionability.)</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes.  </p>

<ul>
<li>“A more pragmatic and operational point of view is to consider <strong>if the new knowledge influences decisions, leads to actions</strong>, and, hopefully, improves the quality of these.”:contentReference[oaicite:7]{index=7}</li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p><strong>Implicit conceptualization:</strong> InfoVis is valuable insofar as it generates insights that <strong>influence decisions and lead to actions</strong>; usefulness is greatest in exploratory contexts where users need to “ask better questions,” recognize patterns, and narrow focus:contentReference[oaicite:8]{index=8}.  </p>

<blockquote>
  <p>“Visualization… to <strong>amplify cognition</strong>.”:contentReference[oaicite:9]{index=9}  </p>
</blockquote>

<blockquote>
  <p>“InfoVis systems are best applied for <strong>exploratory tasks</strong>… to learn more… make new discoveries, or <strong>gain insight</strong>.”:contentReference[oaicite:10]{index=10}</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Linked to decisions and actions:</strong>  </p>

<p> &gt; “Consider if the new knowledge <strong>influences decisions, leads to actions</strong>, and, hopefully, improves the quality of these.”:contentReference[oaicite:11]{index=11}</p></li>
<li><p><strong>Exploratory relevance / when browsing is useful (context fit):</strong>  </p>

<p> &gt; Useful when users are unfamiliar with contents; have difficulty verbalizing needs; or when information is easier to <strong>recognize than describe</strong>:contentReference[oaicite:12]{index=12}.</p></li>
<li><p><strong>Cognitive leverage (pattern recognition &amp; reduced search):</strong>  </p>

<p> &gt; Visuals can <strong>reduce search</strong>, <strong>enhance recognition of patterns</strong>, and enable <strong>perceptual inference</strong>:contentReference[oaicite:13]{index=13}.</p></li>
<li><p><strong>Perceptual effectiveness (preattentive &amp; Gestalt):</strong>  </p>

<p> &gt; Certain visual features are processed <strong>preattentively</strong>; Gestalt principles guide grouping and structure perception:contentReference[oaicite:14]{index=14}.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p><em>(No explicit procedural operationalization for “making outputs actionable.” The chapter instead specifies conditions and mechanisms that increase the likelihood insights will inform decisions.)</em>  </p>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Economic model of visualization value:contentReference[oaicite:15]{index=15}.  </p></li>
<li><p><strong>Methods/Levers:</strong> Choose tasks with browsing value; employ visual encodings that support preattentive processing and Gestalt grouping; integrate tools to reduce per-session/user costs; combine with statistics/data mining as needed:contentReference[oaicite:16]{index=16}.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> N/A (conceptual guidance rather than a stepwise method).  </p></li>
<li><p><strong>Data &amp; Measures:</strong> N/A (no KPIs specified; model posits value W(ΔK) and cost terms).  </p></li>
<li><p><strong>Implementation Context:</strong> General InfoVis applications and examples (e.g., dynamic queries, treemaps):contentReference[oaicite:17]{index=17}.  </p></li>
</ul>

<blockquote>
  <p>“The overall profit… <strong>F = nm(W(ΔK) − Cs − kCe) − Ci − nCu</strong>.”:contentReference[oaicite:18]{index=18}</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<p><em>(Marked “Yes/Partial” only where explicitly tied to making insights lead to decisions/actions.)</em></p>

<ul>
<li><p><strong>CL (Clarity):</strong> No.</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Partial — conditions when browsing is useful (e.g., unfamiliarity, recognition &gt; description) define contextual fit:contentReference[oaicite:19]{index=19}.</p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — feasibility framed economically via costs (Ci, Cu, Cs, Ce) affecting practical use:contentReference[oaicite:20]{index=20}.</p></li>
<li><p><strong>TI (Timeliness):</strong> No.</p></li>
<li><p><strong>EX (Explainability):</strong> No.</p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — value judged by whether increased knowledge <strong>influences decisions</strong> and actions (alignment with decision goals):contentReference[oaicite:21]{index=21}.</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Cognitive amplification (pattern recognition, reduced search) as enabling qualities:contentReference[oaicite:22]{index=22}.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Cognition amplification via visualization (Card, Mackinlay, Shneiderman):contentReference[oaicite:23]{index=23}  </p></li>
<li><p>Preattentive processing &amp; Gestalt principles:contentReference[oaicite:24]{index=24}  </p></li>
<li><p>Popper’s epistemology and insight generation as part of scientific process:contentReference[oaicite:25]{index=25}  </p></li>
<li><p>Economic model of value (van Wijk):contentReference[oaicite:26]{index=26}</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>No explicit metrics. The economic model suggests <strong>W(ΔK)</strong> (value of knowledge increase insofar as it affects decisions/actions) as a conceptual indicator, minus costs:contentReference[oaicite:27]{index=27}.</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Lack of ground truth for insight; difficulty measuring cognition amplification:contentReference[oaicite:28]{index=28}.  </p>

<p> - User visual literacy limits (e.g., scatterplots for lay audiences):contentReference[oaicite:29]{index=29}.  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Visual encodings exploiting preattentive features and Gestalt grouping:contentReference[oaicite:30]{index=30}.  </p>

<p> - Tasks with strong browsing utility (recognition &gt; description, unfamiliar collections):contentReference[oaicite:31]{index=31}.  </p>

<p> - Integration with user workflows to reduce Cs and Cu; routine usage (high n, m):contentReference[oaicite:32]{index=32}.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The chapter situates InfoVis among exploratory data analysis, statistics, and data mining, arguing complementarity rather than competition:contentReference[oaicite:33]{index=33}. It leverages canonical examples (Minard, Snow) and prior cognitive science literature to legitimize visualization’s role in generating insights and improving decision quality. The economic model reframes evaluation from internal mechanisms to <strong>external value and cost</strong> accounting:contentReference[oaicite:34]{index=34}.</p>

<hr />

<h2>Summary</h2>

<p>This chapter makes a sustained case that InfoVis creates value by enabling people to generate insights during exploratory analysis—especially when questions are ill-formed and recognition outperforms description. The authors ground this claim in cognitive and perceptual theory, explaining how visuals reduce search and enhance pattern recognition through preattentive processing and Gestalt grouping. They contrast InfoVis with statistics and data mining, emphasizing complementary roles: models and automation when hypotheses are clear or data is too large; visualization for discovery and sensemaking. A notable contribution is van Wijk’s economic model, which defines visualization’s profit as the decision-impacting value of knowledge gains minus costs at research, adoption, session, and interaction levels. While the chapter does not define “actionability” per se, it explicitly links insight to <strong>decisions and actions</strong>, offering conditions and mechanisms that increase the likelihood that insights will translate into action. Overall, it provides conceptual criteria for recognizing when visualization will be most valuable—and why.:contentReference[oaicite:35]{index=35}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 70 — Strong implicit link from insight to decisions/actions and a clear set of contributing mechanisms (cognitive benefits, conditions). Lacks explicit definition of “actionability.”</p></li>
<li><p><strong>Operationalization Score:</strong> 35 — Offers an economic model and conditions that support action but no concrete, stepwise operational method to produce “actionable” outputs.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“They describe visualization as… <strong>‘interactive visual representations of data to amplify cognition.’</strong>”:contentReference[oaicite:36]{index=36}  </p></li>
<li><p>“InfoVis systems are best applied for <strong>exploratory tasks</strong>… to <strong>gain insight</strong>.”:contentReference[oaicite:37]{index=37}  </p></li>
<li><p>“<strong>When information is easier to recognize than describe</strong>.”:contentReference[oaicite:38]{index=38}  </p></li>
<li><p>“Visuals can <strong>reduce search</strong>… <strong>enhance the recognition of patterns</strong>… <strong>enable perceptual inference</strong> operations.”:contentReference[oaicite:39]{index=39}  </p></li>
<li><p>“Consider if the new knowledge <strong>influences decisions, leads to actions</strong>…”:contentReference[oaicite:40]{index=40}  </p></li>
<li><p>“The overall profit… <strong>F = nm(W(ΔK) − Cs − kCe) − Ci − nCu</strong>.”:contentReference[oaicite:41]{index=41}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Card, Mackinlay, Shneiderman — cognition amplification and benefits (as grounds for linking insight to action):contentReference[oaicite:42]{index=42}  </p></li>
<li><p>Ware — preattentive processing and Gestalt principles enabling rapid recognition (preconditions for actionable recognition):contentReference[oaicite:43]{index=43}  </p></li>
<li><p>van Wijk (2005) — economic model aligning insight with decision/action value:contentReference[oaicite:44]{index=44}</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: The Value of Visualization</p>

<p>Authors: Jarke J. van Wijk</p>

<p>DOI: N/A</p>

<p>Year: 2005</p>

<p>Publication Type: Conference (IEEE Visualization 2005)</p>

<p>Discipline/Domain: Computer Science / Visualization</p>

<p>Subdomain/Topic: Value and evaluation of visualization; economic/decision model for visualization</p>

<p>Eligibility: Eligible (implicit and substantive treatment of what makes outputs actionable through decision-oriented value model)</p>

<p>Overall Relevance Score: 78</p>

<p>Operationalization Score: 52</p>

<p>Actionable/Actionability Used in Paper: Yes — implicit; e.g., visualization value tied to decisions and “possible actions of users”:contentReference[oaicite:0]{index=0}</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — recommends enumerating user actions and tying value to decisions:contentReference[oaicite:1]{index=1}</p>

<p>Contains Definition of Actionability: No (implicit conceptualization via decision/action support and economic model)</p>

<p>Contains Systematic Features/Dimensions: Yes (benefit W(ΔK), costs Ci, Cu, Cs, Ce, exploration steps k; subjectiveness; alternatives; interaction)</p>

<p>Contains Explainability: Partial (discusses perception/cognition P and knowledge K, but not “explainability” per se):contentReference[oaicite:2]{index=2}</p>

<p>Contains Interpretability: Partial (focus on user perception/knowledge and context; not formalized as “interpretability”):contentReference[oaicite:3]{index=3}</p>

<p>Contains Framework/Model: Yes (economic model of visualization; profit function; process diagram):contentReference[oaicite:4]{index=4}:contentReference[oaicite:5]{index=5}</p>

<p>Operationalization Present: Partial (advice to enumerate user actions, minimize interaction costs, set good defaults, integrate automation):contentReference[oaicite:6]{index=6}:contentReference[oaicite:7]{index=7}</p>

<p>Primary Methodology: Conceptual / Theoretical (with illustrative cases)</p>

<p>Study Context: Conceptual model applied to visualization practice; examples from flow visualization and treemaps</p>

<p>Geographic/Institutional Context: Eindhoven University of Technology (Netherlands):contentReference[oaicite:8]{index=8}</p>

<p>Target Users/Stakeholders: Visualization researchers, tool builders, and practitioners; end-users who make decisions from visualized data</p>

<p>Primary Contribution Type: Conceptual framework/model with practical implications</p>

<p>CL: Partial</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Partial</p>

<p>EX: Partial</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>The Value of Visualization</p>

<p><strong>Authors:</strong>  </p>

<p>Jarke J. van Wijk</p>

<p><strong>DOI:</strong>  </p>

<p>N/A</p>

<p><strong>Year:</strong>  </p>

<p>2005</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference (IEEE Visualization 2005)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Visualization</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Value and evaluation of visualization; economic/decision model for visualization</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper argues the field is maturing and needs principled ways to judge visualization’s effectiveness and efficiency. It proposes an economic model where visualization’s value derives from improved decisions (actions) relative to costs. (Assumption: “actionability” is operationalized as leading to identifiable user actions.)</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Technische Universiteit Eindhoven (Netherlands):contentReference[oaicite:9]{index=9}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Visualization researchers, developers, and end-user analysts/decision-makers.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual / Theoretical (with illustrative examples and critiques)</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework/model and evaluative argumentation</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper proposes a simple but comprehensive model to assess the value of visualization by linking it to effectiveness (knowledge gained) and efficiency (costs incurred). A process diagram formalizes how data (D) are transformed via a specification (S) into images (I) that, through perception/cognition (P), change user knowledge (K) over time, with interaction (E) feeding back to S:contentReference[oaicite:10]{index=10}. An economic model then defines costs at development, per-user, per-session, and exploration levels, and a benefit term W(ΔK), yielding a profit function to judge methods:contentReference[oaicite:11]{index=11}. The author discusses implications: need to tie value to decisions/actions, consider alternative non-visual methods, acknowledge subjectivity and risks (misleading visuals), and manage interaction costs:contentReference[oaicite:12]{index=12}:contentReference[oaicite:13]{index=13}. Examples (e.g., treemaps, texture-based flow visualization) illustrate why some techniques gain adoption and others do not:contentReference[oaicite:14]{index=14}:contentReference[oaicite:15]{index=15}. The paper concludes with three complementary views of visualization—as technology, art, and science—and calls for evaluation, taxonomies, and theory:contentReference[oaicite:16]{index=16}.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>Yes. While the term “actionable” is not used verbatim, the paper explicitly ties visualization value to <strong>actions/decisions</strong>:</p>

<ul>
<li><p>“The user has a problem, he must decide which action to take… The visualization should enable him to extract the relevant information from the data.”:contentReference[oaicite:17]{index=17}  </p></li>
<li><p>“I recommend my students to search for and enumerate possible actions of users after using their prospective tools. If such actions cannot be found or defined, the value of visualization is doubtful.”:contentReference[oaicite:18]{index=18}</p></li>
</ul>

<p><em>(Both quotes link visualization outputs to concrete actions/decisions, i.e., actionability.)</em></p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes.</p>

<ul>
<li>“Decisions are typically about actions to be taken or not… enumerate possible actions of users… If such actions cannot be found or defined, the value of visualization is doubtful.”:contentReference[oaicite:19]{index=19}</li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p><strong>Implicit conceptualization:</strong> A visualization is valuable if it increases knowledge <strong>that directly supports a user’s decision about an action</strong>, in a way that the expected value W(ΔK) outweighs costs.  </p>

<blockquote>
  <p>“The user has a problem, he must decide which action to take… The visualization should enable him to extract the relevant information from the data.” (p. 4):contentReference[oaicite:20]{index=20}</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Leads to identifiable user actions/decisions:</strong>  </p>

<p> &gt; “Enumerate possible actions of users… If such actions cannot be found or defined, the value of visualization is doubtful.” (p. 4):contentReference[oaicite:21]{index=21}</p></li>
<li><p><strong>Delivers knowledge with positive decision value (W(ΔK)) relative to costs:</strong>  </p>

<p> &gt; “The return… consists of the value W(ΔK)… hence… F = nm(W(ΔK)−Cs−kCe)−Ci−nCu.” (p. 3):contentReference[oaicite:22]{index=22}</p></li>
<li><p><strong>Preferable to alternative (possibly automated) methods:</strong>  </p>

<p> &gt; “When an automatic method exists to extract the relevant information, visualization is useless.” (p. 4):contentReference[oaicite:23]{index=23}</p></li>
<li><p><strong>Minimizes interaction and exploration overhead (effort/time):</strong>  </p>

<p> &gt; “Interaction is costly, and leads to a high Ce… developers… should think carefully about good defaults… so that as much knowledge is transferred as possible.” (p. 5):contentReference[oaicite:24]{index=24}</p></li>
<li><p><strong>Avoids misleading/negative knowledge:</strong>  </p>

<p> &gt; “Visualizations can be wrong and misleading… negative knowledge… can be produced.” (p. 5):contentReference[oaicite:25]{index=25}</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Economic model of visualization (benefit W(ΔK) vs. costs Ci, Cu, Cs, Ce; with exploration steps k and usage parameters n, m):contentReference[oaicite:26]{index=26}.</p></li>
<li><p><strong>Methods/Levers:</strong> Enumerate user actions; compare to alternative (including automated) methods; reduce interaction cost via good defaults/presets; integrate automated analytics when robust:contentReference[oaicite:27]{index=27}:contentReference[oaicite:28]{index=28}.</p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1) Define target decisions/actions and required information. 2) Estimate W(ΔK) for those decisions. 3) Quantify/estimate costs (Ci, Cu, Cs, Ce, k) and usage (n, m). 4) Prefer solutions with higher F; adopt automation when feasible. 5) Design for low Ce via presets and minimal tuning. 6) Validate to avoid misleading artifacts:contentReference[oaicite:29]{index=29}:contentReference[oaicite:30]{index=30}:contentReference[oaicite:31]{index=31}.</p></li>
<li><p><strong>Data &amp; Measures:</strong> ΔK as knowledge gain per session; W(ΔK) as decision value proxy; time/effort as cost components; usage frequency/scale (n, m):contentReference[oaicite:32]{index=32}.</p></li>
<li><p><strong>Implementation Context:</strong> Visualization tool development and selection; examples include treemaps adoption and flow-visualization non-adoption:contentReference[oaicite:33]{index=33}:contentReference[oaicite:34]{index=34}.  </p></li>
</ul>

<blockquote>
  <p>The <strong>diagram on page 2</strong> depicts the V-model: data D and spec S → images I(t) → perception P → knowledge K, with interaction E adjusting S (feedback loop).:contentReference[oaicite:35]{index=35}</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<p><em>(Marked “Yes/Partial” when authors explicitly tie it to their value model of being actionable.)</em></p>

<ul>
<li><p><strong>CL (Clarity):</strong> Partial — argues for defaults/presets to quickly yield good images; clarity implied via reduced tuning:contentReference[oaicite:36]{index=36}.</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — value must be judged “in the context in which it is used” and relative to the user’s problem:contentReference[oaicite:37]{index=37}.</p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — feasibility framed as <strong>cost-efficiency</strong> (Ci, Cu, Cs, Ce, k) vs. benefits; competing methods considered:contentReference[oaicite:38]{index=38}:contentReference[oaicite:39]{index=39}.</p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — interaction time and rerendering delays increase Ce, reducing practical timeliness:contentReference[oaicite:40]{index=40}.</p></li>
<li><p><strong>EX (Explainability):</strong> Partial — perception/cognition P and knowledge K are discussed, but not formal explainability constructs:contentReference[oaicite:41]{index=41}.</p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — makes value conditional on supporting target actions/decisions (user’s goals) via W(ΔK):contentReference[oaicite:42]{index=42}.</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Subjectiveness and risk of misleading outputs (truthfulness/validity):contentReference[oaicite:43]{index=43}:contentReference[oaicite:44]{index=44}.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Economic/utility framing with benefit–cost analysis (profit F):contentReference[oaicite:45]{index=45}.  </p></li>
<li><p>Process model grounding in human perception/cognition and interaction (P, E):contentReference[oaicite:46]{index=46}.  </p></li>
<li><p>Literature drawing on visualization evaluation, perception (Ware), and communication (Tufte):contentReference[oaicite:47]{index=47}.</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p><strong>W(ΔK):</strong> Value of knowledge gain for the decision problem:contentReference[oaicite:48]{index=48}.  </p></li>
<li><p><strong>Cost components:</strong> Ci, Cu, Cs, Ce; interaction steps k; usage scale n, m:contentReference[oaicite:49]{index=49}.  </p></li>
<li><p><strong>Decision linkage:</strong> Presence of identifiable user actions (qualitative indicator):contentReference[oaicite:50]{index=50}.</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - High initial per-user costs (Cu) and learning/integration burdens:contentReference[oaicite:51]{index=51}.  </p>

<p> - Subjectiveness and parameter sensitivity (S) leading to doubtful claims:contentReference[oaicite:52]{index=52}.  </p>

<p> - Misleading visuals/negative knowledge (artifacts, aliasing):contentReference[oaicite:53]{index=53}.  </p>

<p> - High interaction cost (Ce) and tuning overhead:contentReference[oaicite:54]{index=54}.  </p>

<p> - Strong alternatives (including automation) diminishing n/m:contentReference[oaicite:55]{index=55}.</p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Clear mapping to user actions/decisions and measurable W(ΔK):contentReference[oaicite:56]{index=56}.  </p>

<p> - Good defaults/presets to minimize Ce and ensure quick, quality views:contentReference[oaicite:57]{index=57}.  </p>

<p> - Integration with automated/statistical methods (visual analytics):contentReference[oaicite:58]{index=58}.  </p>

<p> - Demonstrable practical need and low costs (e.g., SequoiaView case):contentReference[oaicite:59]{index=59}.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper references community calls for validation, uncertainty handling, and integration with user processes, aligning with NSF/NIH challenges. It situates its model alongside perception-informed design (Ware) and communication principles (Tufte), yet stresses the need for quantification and practical criteria enabling automated, cost-aware design and selection:contentReference[oaicite:60]{index=60}:contentReference[oaicite:61]{index=61}.</p>

<hr />

<h2>Summary</h2>

<p>Van Wijk reframes visualization’s value through a decision-centric economic model: visualization is worthwhile when the <strong>expected decision value</strong> of knowledge gained (W(ΔK)) outweighs development, adoption, session, and exploration costs (Ci, Cu, Cs, Ce) across actual usage (n, m). The process diagram clarifies how data and specification yield images that, via perception and interaction, update user knowledge; the model then exposes implications often glossed over—subjectivity from parameter choices, the potential for <strong>negative knowledge</strong>, and the real burden of interaction. Crucially, the paper operationalizes “value” by insisting on <strong>enumerable user actions</strong> and by benchmarking visualization against <strong>alternative (even automated) methods</strong>. Case discussions (texture-based flow visualization vs. cushion treemaps/SequoiaView) illustrate why some techniques fail to spread while others succeed: adoption hinges less on novelty and more on <strong>clear actions, high benefit, and low costs</strong>. The closing argument positions visualization simultaneously as technology, art, and science, calling for empirical evaluation, taxonomies, and predictive models to guide design toward impactful, decision-relevant results:contentReference[oaicite:62]{index=62}:contentReference[oaicite:63]{index=63}:contentReference[oaicite:64]{index=64}:contentReference[oaicite:65]{index=65}:contentReference[oaicite:66]{index=66}:contentReference[oaicite:67]{index=67}.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 78 — Strong, explicit linkage of visualization to actions/decisions and an evaluative model; no formal “actionability” definition but a robust implicit account.  </p></li>
<li><p><strong>Operationalization Score:</strong> 52 — Provides concrete levers (enumerate actions, compare to automation, reduce Ce via presets) and a cost–benefit framework; less prescriptive about measurement of W(ΔK) and lacks a full metricization protocol.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[W]e cannot judge visualization on its own, but have to take into account the context in which it is used.” (p. 1):contentReference[oaicite:68]{index=68}  </p></li>
<li><p>“F = nm(W(ΔK) − Cs − kCe) − Ci − nCu.” (p. 3):contentReference[oaicite:69]{index=69}  </p></li>
<li><p>“The user has a problem, he must decide which action to take… The visualization should enable him to extract the relevant information from the data.” (p. 4):contentReference[oaicite:70]{index=70}  </p></li>
<li><p>“Enumerate possible actions of users… If such actions cannot be found or defined, the value of visualization is doubtful.” (p. 4):contentReference[oaicite:71]{index=71}  </p></li>
<li><p>“When an automatic method exists to extract the relevant information, visualization is useless.” (p. 4):contentReference[oaicite:72]{index=72}  </p></li>
<li><p>“Interaction is costly… developers… should think carefully about good defaults… so that as much knowledge is transferred as possible.” (p. 5):contentReference[oaicite:73]{index=73}  </p></li>
<li><p>“Visualizations can be wrong and misleading… negative knowledge… can be produced.” (p. 5):contentReference[oaicite:74]{index=74}  </p></li>
<li><p>“One view is to consider visualization purely from a technological point of view, aiming for effectiveness and efficiency… Another view is… art… and finally… an empiric science.” (p. 8):contentReference[oaicite:75]{index=75}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Visual analytics agenda emphasizing integration with automated analysis: Thomas &amp; Cook, <em>Illuminating the Path</em>:contentReference[oaicite:76]{index=76}.  </p></li>
<li><p>Communication and validity concerns: Tufte’s works on honest, effective displays:contentReference[oaicite:77]{index=77}.  </p></li>
<li><p>Perceptual grounding: Ware’s <em>Information Visualization: Perception for Design</em>:contentReference[oaicite:78]{index=78}.  </p></li>
<li><p>Example adoption case (treemaps/cushion treemaps) via SequoiaView:contentReference[oaicite:79]{index=79}.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: White-Box Prediction of Process Performance Indicators via Flow Analysis</p>

<p>Authors: Ilya Verenich; Hoang Nguyen; Marcello La Rosa; Marlon Dumas</p>

<p>DOI: 10.1145/3084100.3084110</p>

<p>Year: 2017</p>

<p>Publication Type: Conference (ICSSP’17)</p>

<p>Discipline/Domain: Process Mining / Business Process Management</p>

<p>Subdomain/Topic: Predictive process monitoring; remaining cycle time prediction; flow analysis; white-box/explainable prediction</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 15</p>

<p>Operationalization Score: 35</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes (white-box decomposition via flow formulas)</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Mixed Methods (conceptual framework + empirical evaluation on real logs)</p>

<p>Study Context: Predicting remaining cycle time of ongoing cases using activity-level predictions aggregated by process-tree flow analysis</p>

<p>Geographic/Institutional Context: Event logs from BPIC’12 (large financial institution) and an Italian software company’s helpdesk</p>

<p>Target Users/Stakeholders: Process analysts; operations managers; data scientists working on predictive monitoring</p>

<p>Primary Contribution Type: Method/Algorithm (white-box prediction via flow analysis) + empirical comparison</p>

<p>CL: N/A</p>

<p>CR: N/A</p>

<p>FE: N/A</p>

<p>TI: N/A</p>

<p>EX: Yes — Explainability via decomposition of predictions into activity-level components</p>

<p>GA: N/A</p>

<p>Reason if Not Eligible: The paper focuses on explainability/white-box prediction of performance indicators (remaining time) and does not define or discuss “actionable” insights/recommendations or properties/criteria of actionability. It aims to make predictions traceable to activities, not to specify conditions that make outputs actionable. :contentReference[oaicite:0]{index=0}</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>White-Box Prediction of Process Performance Indicators via Flow Analysis</p>

<p><strong>Authors:</strong>  </p>

<p>Ilya Verenich; Hoang Nguyen; Marcello La Rosa; Marlon Dumas</p>

<p><strong>DOI:</strong>  </p>

<p>10.1145/3084100.3084110</p>

<p><strong>Year:</strong>  </p>

<p>2017</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference (ICSSP’17)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Process Mining / Business Process Management</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Predictive process monitoring; remaining cycle time prediction; flow analysis; white-box interpretability</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper proposes predicting instance-level performance by first predicting activity-level performance (e.g., cycle times) and then aggregating via control-flow–aware formulas (flow analysis), enabling “white-box” explanations of predictions. (Abstract &amp; Introduction, p.2–3.) </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Empirical evaluation uses BPIC’12 logs from a large financial institution and a helpdesk process from an Italian software company. (Evaluation setup, p.9.) :contentReference[oaicite:2]{index=2}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process analysts, operations managers, and data scientists seeking interpretable remaining-time predictions.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual method + empirical evaluation (four real-life event logs; MAE as main metric; multiple baselines). (Sec. 5, p.8–10.) </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>A white-box predictive approach based on process-tree flow analysis, plus comparative experiments vs. baselines. (Sec. 4–5, p.5–10.) :contentReference[oaicite:4]{index=4}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors address the prediction of remaining cycle time for running process cases. Instead of a single black-box estimate, they predict activity-level times and combine them with control-flow–specific formulas (sequences, XOR, AND, rework) derived from a discovered structured process model (“flow analysis”). This yields predictions that can be traced to specific activities. They implement two variants—predictive flow analysis (learned regressors/classifiers per activity/gateway) and mean flow analysis (historical averages)—and compare them to several baselines (e.g., transition systems, SPN, encodings) on BPIC’12 and a helpdesk log, using MAE. Results show flow-analysis methods are competitive and often better, with mean flow analysis strongest in most datasets. (Sec. 3–6, p.4–11.) </p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No. The paper does not use the terms “actionable”, “actionability”, or similar, nor does it define criteria for making outputs actionable. It focuses on explainability/interpretability of predictions. (Throughout.) :contentReference[oaicite:6]{index=6}</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No. The closest notion is explainability/traceability of predictions, not actionability. (Conclusion mentions “better recommendations” as an implication, but no actionability concept.) (Conclusion, p.10–11.) :contentReference[oaicite:7]{index=7}</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A.</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A.</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A.</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> N/A  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> N/A  </p></li>
<li><p><strong>FE (Feasibility):</strong> N/A  </p></li>
<li><p><strong>TI (Timeliness):</strong> N/A  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — the paper emphasizes that aggregate predictions are decomposed into activity-level components via flow analysis, enabling traceability. &gt; “the predicted indicators become more explainable, as they are decomposed into elementary components.” (Conclusion, p.10–11.) :contentReference[oaicite:8]{index=8}  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> N/A  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> None.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Flow analysis over process trees; handling of sequence/XOR/AND/rework using formal equations to aggregate activity measures. (Sec. 3.2, p.4; Eq. (1)–(4).) :contentReference[oaicite:9]{index=9}  </p></li>
<li><p>Structured model discovery (“discover and structure”) to obtain block-structured models suitable for flow analysis. (Sec. 4.2, p.5.) :contentReference[oaicite:10]{index=10}</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A.</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> N/A  </p></li>
<li><p><strong>Enablers:</strong> N/A</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions “white-box” flow analysis against black-box remaining-time predictors (transition systems, SPNs, encodings), arguing for interpretability by decomposing aggregate predictions into activity-level contributions. (Related Work &amp; Intro, p.3–4.) :contentReference[oaicite:11]{index=11}</p>

<hr />

<h2>Summary</h2>

<p>This paper introduces a white-box approach to predict remaining cycle time by first estimating activity-level cycle times and XOR branch probabilities, then aggregating them via control-flow–aware formulas (flow analysis) over a structured process tree. The method yields interpretable predictions tied to specific activities and patterns (sequence, AND, XOR, rework), enabling analysts to see where time is likely to be spent. Two variants are evaluated: (1) predictive flow analysis, training regressors/classifiers using index-based trace encodings, and (2) mean flow analysis, using historical averages. On BPIC’12 (three subprocess logs) and a helpdesk log, the flow-analysis methods match or outperform baselines in MAE; mean flow analysis is typically strongest, while predictive models can underperform when attributes inadequately explain activity-time variance or when rework probabilities are hard to estimate. The authors discuss runtime feasibility and limitations (e.g., overlapping loops; sensitivity to rework dynamics), and suggest extensions to other performance indicators (cost, error rate). (Sec. 3–6, p.4–11.) </p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 15 — The paper advances explainability in predictive monitoring but does not define or analyze “actionability” or its properties; therefore limited relevance to actionability as defined in the screening criteria. :contentReference[oaicite:13]{index=13}  </p></li>
<li><p><strong>Operationalization Score:</strong> 35 — It offers a concrete workflow (model discovery, alignment, formula derivation, prediction and aggregation) for explainable remaining-time prediction, but this operationalization is not tied to achieving actionability per se. </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[R]ather than predicting single scalar indicators, we demonstrated how these indicators can be estimated as aggregations of corresponding performance indicators of the activities composing the process… the predicted indicators become more explainable.” (Conclusion, p.10–11.) :contentReference[oaicite:15]{index=15}  </p></li>
<li><p>“The idea of flow analysis is to estimate a quantitative performance indicator at the level of a process by aggregating the estimated values … at the level of the activities … taking into account the control‑flow relations.” (Introduction, p.3.) :contentReference[oaicite:16]{index=16}  </p></li>
<li><p>“Applying the flow analysis formulas… CT = TA + max(TB + TC, TD) + TF + p2 [TG + TH/(1−r)].” (Approach example, p.6.) :contentReference[oaicite:17]{index=17}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A — the paper does not cite or discuss actionability literature.</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Process Mining Practices: Evidence from Interviews</p>

<p>Authors: Francesca Zerbato; Pnina Soffer; Barbara Weber</p>

<p>DOI: https://doi.org/10.1007/978-3-031-16103-2_19</p>

<p>Year: 2022</p>

<p>Publication Type: Conference (BPM 2022, LNCS 13420)</p>

<p>Discipline/Domain: Information Systems / Process Mining</p>

<p>Subdomain/Topic: Analyst work practices during the mining &amp; analysis stage; strategies, challenges, and influencing factors</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 15</p>

<p>Operationalization Score: 10</p>

<p>Actionable/Actionability Used in Paper: Yes — “we hope that the strategies we identified in this paper will inspire research on developing actionable support for process mining practitioners.” (p. 283). </p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — see above quote; no definition or criteria are provided. </p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: No (conceptual grouping into four phases, but not a formal framework for “actionability”)</p>

<p>Operationalization Present: No (operationalizes analysis strategies, not “actionability”)</p>

<p>Primary Methodology: Qualitative</p>

<p>Study Context: Semi-structured interviews with 37 practitioners and academics focusing on the mining &amp; analysis stage of process mining projects; interviews anchored in a hands-on task using the Road Traffic Fine Management event log. </p>

<p>Geographic/Institutional Context: Data collected May–July 2021; participants from 29 organizations; authors affiliated with University of St. Gallen and University of Haifa; sectors include healthcare, food processing, insurance. </p>

<p>Target Users/Stakeholders: Process analysts, consultants, managers; business stakeholders involved in analysis validation. </p>

<p>Primary Contribution Type: Empirical characterization of 16 analysis strategies across four phases (understand, plan, analyze, evaluate) and factors affecting their use. </p>

<p>CL: No</p>

<p>CR: No</p>

<p>FE: No</p>

<p>TI: No</p>

<p>EX: No</p>

<p>GA: No</p>

<p>Reason if Not Eligible: The paper does not define “actionability” or provide criteria/features for what makes findings actionable; “actionable” appears only once in a generic future-work remark.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Process Mining Practices: Evidence from Interviews</p>

<p><strong>Authors:</strong>  </p>

<p>Francesca Zerbato; Pnina Soffer; Barbara Weber</p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1007/978-3-031-16103-2_19</p>

<p><strong>Year:</strong>  </p>

<p>2022</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference (BPM 2022, LNCS 13420)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Information Systems / Process Mining</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Analyst strategies and challenges during the mining &amp; analysis stage</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper responds to limited understanding of how analysts actually conduct process mining analyses in practice and aims to characterize common strategies, challenges, and influencing factors. </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Interviews (May–July 2021) with 37 participants from 29 organizations; authors at University of St. Gallen and University of Haifa. </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process analysts and business stakeholders who validate findings. </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Qualitative (semi-structured interviews; inductive coding). </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical synthesis of 16 strategies across four phases; identification of four influencing factors (questions, role, stakeholder availability, tools). </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors investigate how process mining is used in practice during the mining &amp; analysis stage by interviewing 37 practitioners and academics, anchored to a realistic analysis task. Using inductive qualitative coding, they derive 16 strategies grouped into four phases: understand, plan, analyze, and evaluate. They report recurring challenges (e.g., limited domain knowledge, difficulty formulating questions, lack of causal analysis support) and four factors that influence strategy use: analysis questions, analyst’s role, stakeholder availability, and tools. The paper provides an empirically grounded overview of analyst work practices and suggests directions for tool and methodology development. </p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>Yes — used once in a future-work sense, not as a defined concept tied to findings:  </p>

<blockquote>
  <p>“we hope that the strategies we identified in this paper will inspire research on <strong>developing actionable support</strong> for process mining practitioners.” (p. 283). </p>
</blockquote>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes — the above line implies the need for actionable support but provides no definition or criteria. </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A — no explicit or implicit conceptualization of “actionability” beyond a generic aspiration for support tools.</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A — the paper does not enumerate properties/conditions for actionability.</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A — no methods/workflows are provided specifically to produce “actionable” outputs (the operationalization pertains to analysis strategies, not actionability). </p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> No  </p></li>
<li><p><strong>FE (Feasibility):</strong> No  </p></li>
<li><p><strong>TI (Timeliness):</strong> No  </p></li>
<li><p><strong>EX (Explainability):</strong> No  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> No  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> None</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<p>General references include process mining methodologies (e.g., PM²), problem-solving cycles, and literature on adoption/challenges; none used to define “actionability.” </p>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> N/A (paper discusses barriers to analysis (e.g., lack of causality support, stakeholder access) rather than to “actionability”).   </p></li>
<li><p><strong>Enablers:</strong> N/A</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper situates itself among empirical studies of process mining practice, noting prior work on adoption, transparency, and evaluation; it extends this by focusing on individual analyst strategies during analysis. </p>

<hr />

<h2>Summary</h2>

<p>This conference paper empirically maps how analysts conduct the mining &amp; analysis stage of process mining projects. Through 37 semi-structured interviews, it identifies 16 recurring strategies grouped into four phases—understand (problem, domain, data), plan (formulate/prioritize questions, choose approach, map questions to data, hypothesize), analyze (understand process, discover patterns, classify/compare, search correlations, focus scopes, test hypotheses), and evaluate (verify, validate with stakeholders). Table 1 (page 275) visually consolidates these strategies and their prevalence across participants, illustrating an iterative, flexible analysis process. The authors highlight persistent challenges such as limited domain knowledge, difficulty in eliciting precise questions with stakeholders, and insufficient support for causal inference that would enable recommendations. They also identify four factors shaping strategy use: question specificity, analyst role (generalist vs. specialist), stakeholder availability, and tool capabilities. While the paper mentions the aspiration for “actionable support,” it does not define actionability or specify criteria for actionable insights, placing it outside the eligibility scope for actionability-focused synthesis. </p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 15 — Mentions “actionable support” once without defining the term or tying it to features/criteria; the contribution is about analysis practices, not actionability.</p></li>
<li><p><strong>Operationalization Score:</strong> 10 — Details strategies for analysis work but not how to achieve “actionability” per se; no workflow or metrics dedicated to making outputs actionable.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“we conducted semi-structured interviews with <strong>37</strong> practitioners and academics” (Abstract / p. 268).   </p></li>
<li><p>“we organized the strategies into four main phases representing intermediate analysis goals: <strong>understand, plan, analyze, and evaluate</strong>.” (p. 274).   </p></li>
<li><p>“a <strong>characterization of analysis strategies</strong>, organized into four main phases…[and] recurring challenges” (Abstract).   </p></li>
<li><p>“lack of techniques for <strong>identifying causality</strong> … makes it difficult to recommend solutions” (p. 279).   </p></li>
<li><p>“developing <strong>actionable support</strong> for process mining practitioners” (p. 283). </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>None — the paper does not cite works that define/operationalize “actionability”.</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Process Mining Manifesto</p>

<p>Authors: Wil van der Aalst et al.</p>

<p>DOI: N/A</p>

<p>Year: 2012</p>

<p>Publication Type: Book Chapter</p>

<p>Discipline/Domain: Business Process Management / Information Systems / Data Mining</p>

<p>Subdomain/Topic: Process mining principles, lifecycle, challenges, and use as actionable Business Intelligence</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 72</p>

<p>Operationalization Score: 60</p>

<p>Actionable/Actionability Used in Paper: Yes — “All technologies and methods that aim at providing actionable information that can be used to support decision making can be positioned under the umbrella of Business Intelligence (BI).” (p. 192) :contentReference[oaicite:0]{index=0}</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — e.g., “process mining should be viewed as a continuous process providing actionable information according to various time scales (minutes, hours, days, weeks, and months).” (p. 186) :contentReference[oaicite:1]{index=1}</p>

<p>Contains Definition of Actionability: No — No formal definition; actionability is framed via BI and operational support outcomes (detect/predict/recommend). :contentReference[oaicite:2]{index=2}</p>

<p>Contains Systematic Features/Dimensions: Partial</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual</p>

<p>Study Context: IEEE Task Force manifesto consolidating principles and challenges; no single empirical dataset</p>

<p>Geographic/Institutional Context: Global, multi-institution IEEE Task Force (academia, vendors, end-users)</p>

<p>Target Users/Stakeholders: Software developers, scientists, consultants, business managers, and end-users</p>

<p>Primary Contribution Type: Guiding principles, lifecycle framework (L*), challenge agenda</p>

<p>CL: Partial</p>

<p>CR: Yes</p>

<p>FE: Partial</p>

<p>TI: Yes</p>

<p>EX: Partial</p>

<p>GA: Partial</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Process Mining Manifesto</p>

<p><strong>Authors:</strong>  </p>

<p>Wil van der Aalst et al.</p>

<p><strong>DOI:</strong>  </p>

<p>N/A</p>

<p><strong>Year:</strong>  </p>

<p>2012</p>

<p><strong>Publication Type:</strong>  </p>

<p>Book Chapter (BPM 2011 Workshops, LNBIP 99) :contentReference[oaicite:3]{index=3}</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Business Process Management / Information Systems / Data Mining :contentReference[oaicite:4]{index=4}</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Process mining principles, lifecycle (L*), discovery/conformance/enhancement, operational support, and challenges :contentReference[oaicite:5]{index=5}</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The manifesto promotes process mining as techniques to discover, monitor, and improve real processes from event logs, positioning it between data mining and process modeling and linking it to BI/CPM/TQM and compliance. (pp. 170–176) :contentReference[oaicite:6]{index=6}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>IEEE Task Force with authors from universities, vendors, and users worldwide. (pp. 170–175) :contentReference[oaicite:7]{index=7}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>“software developers, scientists, consultants, business managers, and end-users.” (Abstract, p. 170) :contentReference[oaicite:8]{index=8}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual (principles + framework + agenda) :contentReference[oaicite:9]{index=9}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Guiding principles (GP1–GP6), project lifecycle (L*), and research challenges (C1–C11). (pp. 178–186, 179–186) :contentReference[oaicite:10]{index=10}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The manifesto introduces process mining as a bridge between event data and process models, outlining three core types: discovery, conformance checking, and enhancement. It situates process mining within the BPM lifecycle and provides a five-stage “L<em>” project lifecycle from planning and data extraction to operational support. Six guiding principles highlight data quality, question-driven extraction, proper control-flow constructs, linking events to model elements, purposeful abstraction (“maps”), and continuous usage. Eleven challenges are proposed, including log quality, scalability, benchmarks, concept drift, representational bias, and operationalization for online support (detect/predict/recommend). Figures illustrate event-log–to-model workflows and roles (e.g., Fig. 1 on p. 171; L</em> lifecycle in Fig. 5 on p. 178). :contentReference[oaicite:11]{index=11}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>Yes.</strong>  </p>

<ul>
<li><p>“process mining should be viewed as a continuous process <strong>providing actionable information</strong> according to various time scales (minutes, hours, days, weeks, and months).” (p. 186) :contentReference[oaicite:12]{index=12}  </p></li>
<li><p>“All technologies and methods that aim at providing <strong>actionable information</strong> that can be used to support decision making can be positioned under the umbrella of Business Intelligence (BI).” (p. 192) :contentReference[oaicite:13]{index=13}</p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>Yes.</strong>  </p>

<ul>
<li>Actionability is positioned as the <strong>goal</strong> (supporting decision-making via BI and ongoing operational support) but not formally defined. (pp. 184–186, 192) :contentReference[oaicite:14]{index=14}</li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly: Actionability arises when event-log–driven models enable <strong>operational support</strong> (detect deviations, predict outcomes, recommend actions) and provide timely, user-relevant maps for decisions.  </p>

<blockquote>
  <p>“Three operational support activities can be identified: <strong>detect, predict, and recommend</strong>.” (p. 190) :contentReference[oaicite:15]{index=15}</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Timeliness/Continuity:</strong> Provides information “according to various time scales (minutes…months).”  </p>

<p> &gt; “process mining should be viewed as a continuous process providing actionable information according to various time scales…” (p. 186) :contentReference[oaicite:16]{index=16}  </p></li>
<li><p><strong>Operational Levers (Detect–Predict–Recommend):</strong> Information tied to concrete interventions.  </p>

<p> &gt; “Three operational support activities can be identified: detect, predict, and recommend.” (p. 190) :contentReference[oaicite:17]{index=17}  </p></li>
<li><p><strong>Model–Data Linkage for Diagnostics:</strong> Replay to reveal discrepancies and bottlenecks for action.  </p>

<p> &gt; “Replay may be used to reveal discrepancies between an event log and a model… [and] add expected waiting times to the model.” (p. 183) :contentReference[oaicite:18]{index=18}  </p></li>
<li><p><strong>Audience-Oriented Abstraction (“Maps”):</strong> Fit representation to stakeholder needs.  </p>

<p> &gt; “Models… should be seen as ‘maps’… emphasize the things relevant for a particular type of user.” (p. 183) :contentReference[oaicite:19]{index=19}</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> L* Life-cycle (Stages 0–4); Three Types of Process Mining (discovery, conformance, enhancement). (pp. 175–178) :contentReference[oaicite:20]{index=20}  </p></li>
<li><p><strong>Methods/Levers:</strong> Event-log extraction guided by questions (GP2), model discovery with concurrency support (GP3), event–model replay for diagnostics/enhancement (GP4), ongoing monitoring/prediction/recommendation (C8). (pp. 180–186, 188–191) :contentReference[oaicite:21]{index=21}  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Plan &amp; justify → extract data/models/objectives → discover control-flow &amp; connect log → build integrated model (add time/resources/data) → provide operational support (interpret current data to redesign/adjust/intervene/support). (Fig. 5, p. 178) :contentReference[oaicite:22]{index=22}  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Event logs with trustworthy/comprehensive semantics (maturity levels, Table 1); quality metrics for models (fitness, simplicity, precision, generalization). (pp. 180–182, 188–189) :contentReference[oaicite:23]{index=23}  </p></li>
<li><p><strong>Implementation Context:</strong> BPM lifecycle phases; continuous usage akin to real-time “maps” with projections of traffic/bottlenecks. (pp. 177–186) :contentReference[oaicite:24]{index=24}  </p></li>
</ul>

<blockquote>
  <p>The <strong>diagram on page 178 (Fig. 5)</strong> visualizes the L* lifecycle from planning to operational support, including feedback loops to redesign/adjust. :contentReference[oaicite:25]{index=25}</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<p><em>(Marked when explicitly linked to making outputs actionable.)</em></p>

<ul>
<li><p><strong>CL (Clarity):</strong> Partial — Emphasis on understandable “maps” and cartographic principles.  </p>

<p> &gt; “select the right representation and fine-tune it for the intended audience.” (p. 184) :contentReference[oaicite:26]{index=26}</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Views should match stakeholder roles, levels (strategic/tactical/operational), and perspectives (costs, deviations).  </p>

<p> &gt; “different stakeholders may want to view a process at different levels…” (p. 183) :contentReference[oaicite:27]{index=27}</p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — Recommendations aim to reduce costs/flow time; challenges note data/log feasibility constraints.  </p>

<p> &gt; “propose particular actions to reduce costs or shorten the flow time.” (p. 190) :contentReference[oaicite:28]{index=28}</p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — Continuous, multi-timescale operational support.  </p>

<p> &gt; “providing actionable information according to various time scales…” (p. 186) :contentReference[oaicite:29]{index=29}</p></li>
<li><p><strong>EX (Explainability):</strong> Partial — Replay-based diagnostics and bottleneck annotation; conformance insights.  </p>

<p> &gt; “Replay may be used to reveal discrepancies… and add expected waiting times to the model.” (p. 183) :contentReference[oaicite:30]{index=30}</p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — Question-driven extraction and KPI-oriented objectives in Stage 1.  </p>

<p> &gt; Stage 1 collects “objectives (KPIs) [and] questions.” (p. 178) :contentReference[oaicite:31]{index=31}</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Model quality trade-offs (fitness, simplicity, precision, generalization) as criteria that affect useful, actionable modeling. (pp. 188–189) :contentReference[oaicite:32]{index=32}</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>BPM lifecycle positioning and L* lifecycle for projects. (pp. 176–178) :contentReference[oaicite:33]{index=33}  </p></li>
<li><p>Process mining triad: discovery, conformance, enhancement. (pp. 175–176) :contentReference[oaicite:34]{index=34}  </p></li>
<li><p>Model quality dimensions: fitness, simplicity (Occam’s Razor), precision, generalization. (pp. 188–189) :contentReference[oaicite:35]{index=35}</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li>No explicit KPI set for “actionability” itself; instead, prerequisites: event-log maturity (Table 1), model quality (fitness/precision/etc.), and operational support outcomes (e.g., predicted remaining time). (pp. 180–182, 190) :contentReference[oaicite:36]{index=36}</li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Data quality and integration (C1), scalability/diversity of logs (C2), concept drift (C4), representational bias (C5), balancing model criteria (C6), usability/understandability for non-experts (C10–C11). (pp. 185–191) :contentReference[oaicite:37]{index=37}  </p></li>
<li><p><strong>Enablers:</strong> Question-driven extraction (GP2), concurrency-aware discovery (GP3), event–model linkage and replay (GP4), purposeful “map” abstractions (GP5), continuous monitoring and operational support (GP6/C8). (pp. 180–186, 190) :contentReference[oaicite:38]{index=38}</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The manifesto consolidates state-of-the-art practice and refers to van der Aalst’s 2011 monograph for foundational techniques and to XES standardization efforts, positioning process mining within BI and BPM rather than introducing new empirical studies. (pp. 173–175, 193–194) :contentReference[oaicite:39]{index=39}</p>

<hr />

<h2>Summary</h2>

<p>This manifesto frames process mining as a discipline that extracts knowledge from event logs to discover, check, and enhance process models, thereby enabling practical decision support. Actionability is not formally defined, but is operationally construed as delivering timely, stakeholder-relevant insights that can detect deviations, predict outcomes, and recommend interventions. The L* lifecycle (planning → extraction → discovery/linkage → integrated modeling → operational support) offers a structured path to make outputs actionable, with event–model replay and model quality metrics supporting explanation and improvement. The paper advances six guiding principles—emphasizing event-data quality, question-driven design, concurrency-aware modeling, event–model mapping, meaningful abstraction (“maps”), and continuous use—and eleven challenges spanning data engineering, scalability, drift, representation, evaluation trade-offs, and usability. In sum, it supplies a pragmatic conceptual toolkit for turning raw event data into operationally useful, BI-aligned insights, even if it stops short of a formal definition of “actionability.” :contentReference[oaicite:40]{index=40}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 72 — Strong, repeated use of “actionable information” tied to BI and operational support; lacks a formal definition but offers clear mechanisms and contexts that imply actionability. :contentReference[oaicite:41]{index=41}  </p></li>
<li><p><strong>Operationalization Score:</strong> 60 — Provides concrete lifecycle (L*), replay-based diagnostics, and detect/predict/recommend levers; however, no explicit actionability metric or checklist beyond model/data quality proxies. :contentReference[oaicite:42]{index=42}</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[P]rocess mining should be viewed as a continuous process <strong>providing actionable information</strong> according to various time scales…” (p. 186) :contentReference[oaicite:43]{index=43}  </p></li>
<li><p>“All technologies and methods that aim at providing <strong>actionable information</strong> that can be used to support decision making…” (p. 192) :contentReference[oaicite:44]{index=44}  </p></li>
<li><p>“Three operational support activities can be identified: <strong>detect, predict, and recommend</strong>.” (p. 190) :contentReference[oaicite:45]{index=45}  </p></li>
<li><p>“Replay may be used to reveal discrepancies between an event log and a model… [and] add expected waiting times to the model.” (p. 183) :contentReference[oaicite:46]{index=46}  </p></li>
<li><p>“Models… should be seen as ‘maps’… emphasize the things relevant for a particular type of user.” (p. 183) :contentReference[oaicite:47]{index=47}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li>van der Aalst, W.M.P. (2011). <em>Process Mining: Discovery, Conformance and Enhancement of Business Processes</em>. Springer. (Referenced as foundational background.) :contentReference[oaicite:48]{index=48}</li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Process Mining Challenges Perceived by Analysts: An Interview Study</p>

<p>Authors: Lisa Zimmermann, Francesca Zerbato, Barbara Weber</p>

<p>DOI: 10.1007/978-3-031-07475-2_1</p>

<p>Year: 2022</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Information Systems / Process Mining</p>

<p>Subdomain/Topic: Analyst work practices; challenges across process mining project phases</p>

<p>Eligibility: Eligible (implicit treatment of how to derive concrete recommendations/next steps and what hinders them)</p>

<p>Overall Relevance Score: 55</p>

<p>Operationalization Score: 20</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — e.g., “I think it’s challenging to answer this question with recommendation of what to do afterwards” and that process mining shows “where your issues are, but it’s not helping you to solve them.” (participant quotes):contentReference[oaicite:0]{index=0}</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: No</p>

<p>Operationalization Present: No</p>

<p>Primary Methodology: Qualitative</p>

<p>Study Context: Semi-structured interviews (n=41) with process mining analysts after a realistic analysis task on the Road Traffic Fine Management event log:contentReference[oaicite:1]{index=1}</p>

<p>Geographic/Institutional Context: Participants from 27 organizations; conducted via virtual meetings; authors at University of St. Gallen:contentReference[oaicite:2]{index=2}</p>

<p>Target Users/Stakeholders: Process mining analysts (practitioners &amp; academics) and project stakeholders:contentReference[oaicite:3]{index=3}</p>

<p>Primary Contribution Type: Empirical catalog of 23 analyst-perceived challenges organized by project phase; discussion of gaps and research needs:contentReference[oaicite:4]{index=4}</p>

<p>CL: Partial</p>

<p>CR: Yes</p>

<p>FE: No</p>

<p>TI: No</p>

<p>EX: No</p>

<p>GA: Partial</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Process Mining Challenges Perceived by Analysts: An Interview Study</p>

<p><strong>Authors:</strong>  </p>

<p>Lisa Zimmermann, Francesca Zerbato, Barbara Weber</p>

<p><strong>DOI:</strong>  </p>

<p>10.1007/978-3-031-07475-2_1</p>

<p><strong>Year:</strong>  </p>

<p>2022</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference (BPMDS/EMMSAD 2022, LNBIP 450):contentReference[oaicite:5]{index=5}</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Information Systems / Process Mining</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Analyst work practices; perceived challenges across process mining project phases</p>

<p><strong>Contextual Background:</strong>  </p>

<p>Process mining adoption is rising, yet little is known about analysts’ individual needs and obstacles. The study uncovers analyst-perceived challenges to inform better support for practice:contentReference[oaicite:6]{index=6}.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Interviews conducted virtually in 2021 with participants from 27 organizations; authors from University of St. Gallen:contentReference[oaicite:7]{index=7}.</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process mining analysts (practitioners and academics) and collaborating business/IT stakeholders:contentReference[oaicite:8]{index=8}.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Qualitative (semi-structured interviews; grounded-theory coding):contentReference[oaicite:9]{index=9}.</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical catalog and analysis of 23 challenges (summarized in Figure 1):contentReference[oaicite:10]{index=10}.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper investigates what individual process mining analysts perceive as challenges during projects. Through an interview study with 41 analysts (21 practitioners, 20 academics) following a realistic analysis task, the authors identify 23 challenges distributed across phases: defining research questions, data collection, data pre-processing, mining &amp; analysis, and stakeholder evaluation, plus four cross-cutting issues:contentReference[oaicite:11]{index=11}. Figure 1 (page 8) overviews all challenges with counts per challenge and phase:contentReference[oaicite:12]{index=12}. The study discusses how some challenges resemble known data/organizational problems, but many are distinctly individual-level (e.g., maintaining analysis focus, tool knowledge, deriving concrete recommendations). The authors conclude that existing solutions are weakly integrated into practice and call for methods that specifically support individuals’ work practices:contentReference[oaicite:13]{index=13}.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No. The paper does not use the terms “actionable/actionability.” However, it explicitly treats the need to produce <em>recommendations and next steps</em> and the difficulty of doing so (see below).:contentReference[oaicite:14]{index=14}</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes. Verbatim evidence tying analyses to <em>recommendations/next steps</em>:</p>

<ul>
<li><p>“I think it’s challenging to answer this question with recommendation of what to do afterwards” (participant p4).:contentReference[oaicite:15]{index=15}  </p></li>
<li><p>Process mining shows “where your issues are, but it’s not helping you to solve them” (participant p17).:contentReference[oaicite:16]{index=16}  </p></li>
<li><p>It is difficult to “come to … hard conclusions” or to decide “what we should change now” (participant p20).:contentReference[oaicite:17]{index=17}</p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicit: Actionability is equated with being able to move from descriptive findings to <em>hard conclusions</em> and <em>concrete recommendations/next steps</em> for process change.  </p>

<blockquote>
  <p>“It’s challenging … with recommendation of what to do afterwards” and tools show issues but “not helping you to solve them.” (participants):contentReference[oaicite:18]{index=18}</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Support for deriving concrete recommendations:</strong>  </p>

<p> &gt; “It’s challenging … with recommendation of what to do afterwards.” (p4):contentReference[oaicite:19]{index=19}  </p></li>
<li><p><strong>Causal/justified conclusions (to inform change):</strong>  </p>

<p> &gt; Danger of “jump[ing] to incorrect conclusions” and difficulty to reach “hard conclusions.” (p11, p20):contentReference[oaicite:20]{index=20}  </p></li>
<li><p><strong>Adequate domain knowledge to target relevant changes:</strong>  </p>

<p> &gt; “Without domain knowledge, you won’t achieve much or nothing at all.” (p38):contentReference[oaicite:21]{index=21}  </p></li>
<li><p><strong>Access to additional contextual information/stakeholders:</strong>  </p>

<p> &gt; Need “additional knowledge to really get into an event log,” but lack of access to documentation/stakeholders. (p8, p34, p17):contentReference[oaicite:22]{index=22}  </p></li>
<li><p><strong>Maintaining analysis focus aligned to the goal:</strong>  </p>

<p> &gt; Risk of “losing the big picture” and deviating from the original aim. (p24, p26):contentReference[oaicite:23]{index=23}</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>(Not directly provided as a prescriptive method.) The paper catalogs impediments and implies enablers (domain knowledge, stakeholder access, analysis focus) but does not offer a concrete workflow to <em>produce</em> actionable recommendations.  </p>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> N/A  </p></li>
<li><p><strong>Methods/Levers:</strong> Implied need for domain knowledge, stakeholder collaboration, stronger techniques for causality/root-cause, and better tool support:contentReference[oaicite:24]{index=24}.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> N/A  </p></li>
<li><p><strong>Data &amp; Measures:</strong> N/A  </p></li>
<li><p><strong>Implementation Context:</strong> General process mining projects across sectors.  </p></li>
</ul>

<blockquote>
  <p>“Process mining cannot answer all the questions … you need to combine it with other approaches … to answer the whys.” (p3):contentReference[oaicite:25]{index=25}</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Partial — difficulty reaching “hard conclusions” suggests clarity is necessary for action. Quote: “jump to incorrect conclusions … [hard] to find … what we should change now.”:contentReference[oaicite:26]{index=26}  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — domain knowledge is crucial: “Without domain knowledge, you won’t achieve much.”:contentReference[oaicite:27]{index=27}  </p></li>
<li><p><strong>FE (Feasibility):</strong> No — feasibility of recommended actions is not discussed.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No — timeliness not addressed.  </p></li>
<li><p><strong>EX (Explainability):</strong> No — not framed as explainability.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — challenges in question formulation and maintaining focus imply goal alignment matters: “hard to identify the correct question” (C1); risk of “losing the big picture” (C17):contentReference[oaicite:28]{index=28}  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<p>Organizing frame by project phases (after Emamjome et al. 2019) to place challenges; grounded-theory coding for analysis:contentReference[oaicite:29]{index=29}.</p>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A (no metrics/KPIs proposed).</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Difficulty producing <em>recommendations &amp; next steps</em> (C19):contentReference[oaicite:30]{index=30}  </p>

<p> - Weak causal inference / risk of incorrect conclusions (C18):contentReference[oaicite:31]{index=31}  </p>

<p> - Limited domain knowledge (C20):contentReference[oaicite:32]{index=32}  </p>

<p> - Restricted access to contextual information/stakeholders (C14, C21):contentReference[oaicite:33]{index=33}  </p>

<p> - Loss of analysis focus (C17):contentReference[oaicite:34]{index=34}  </p>

<p> - Technique/tool limitations for root-cause (C13):contentReference[oaicite:35]{index=35}</p></li>
<li><p><strong>Enablers (Implied):</strong>  </p>

<p> - Stronger stakeholder collaboration and documentation access:contentReference[oaicite:36]{index=36}  </p>

<p> - Building domain knowledge:contentReference[oaicite:37]{index=37}  </p>

<p> - Guidance to maintain focus and align with questions:contentReference[oaicite:38]{index=38}  </p>

<p> - Integrating complementary methods for “the whys” (beyond descriptive PM):contentReference[oaicite:39]{index=39}</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper relates analyst-level challenges to organizational and technical ones identified in prior work (e.g., Manifesto challenges; Delphi study) and argues many remain unresolved or insufficiently integrated into tools/practice. It notes a mismatch between technical solutions and individual analysts’ needs and calls for methods explicitly supporting individual work practices:contentReference[oaicite:40]{index=40}.</p>

<hr />

<h2>Summary</h2>

<p>This interview study (n=41) surfaces 23 analyst-perceived challenges across all phases of process mining projects. Although the paper does not use “actionability,” it repeatedly emphasizes the <em>difficulty of translating analyses into justified conclusions and concrete recommendations</em>. Key impediments include weak causal support, limited domain knowledge and stakeholder access, loss of analysis focus, and tool/technique constraints for root-cause reasoning. Data-related hurdles (extraction, availability, quality, transformation, validation) remain pervasive and undermine downstream interpretability and recommendation-making. The figure on page 8 consolidates challenges by phase and frequency, underscoring that most analysts experience issues during mining/analysis and stakeholder evaluation. The discussion highlights that while partial solutions exist (e.g., data quality frameworks, extraction/abstraction techniques), they are poorly integrated into mainstream tools and seldom address the <em>individual</em> analyst’s workflow. The authors advocate for methods, training, and integrations that help analysts connect findings to decisions, maintain goal alignment, access contextual knowledge, and responsibly infer the “whys” that underpin prescriptive recommendations.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 55 — Actionability is implicitly central (recommendations/next steps, hard conclusions), with multiple barriers identified, but there is no explicit definition or structured conceptualization of “actionability.”  </p></li>
<li><p><strong>Operationalization Score:</strong> 20 — The paper catalogs obstacles and hints at enablers but provides no concrete framework, workflow, or metrics to <em>produce</em> actionable outputs.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“It’s challenging … with recommendation of what to do afterwards.” (participant p4):contentReference[oaicite:41]{index=41}  </p></li>
<li><p>“Process mining … shows where your issues are, but it’s not helping you to solve them.” (participant p17):contentReference[oaicite:42]{index=42}  </p></li>
<li><p>“A major pitfall is that you jump to incorrect conclusions … [it is] difficult to … find … what we should change now.” (participants p11, p20):contentReference[oaicite:43]{index=43}  </p></li>
<li><p>“Without domain knowledge, you won’t achieve much or nothing at all.” (participant p38):contentReference[oaicite:44]{index=44}  </p></li>
<li><p>Need for “additional knowledge” and lack of access to stakeholders/documentation (participants p8, p34, p17):contentReference[oaicite:45]{index=45}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>The paper mainly references broader PM challenges and adoption (e.g., van der Aalst et al., 2012 “Process Mining Manifesto”; Martin et al., 2021 Delphi study; data quality/extraction/abstraction works) as context for gaps, not as direct actionability frameworks:contentReference[oaicite:46]{index=46}.</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Process Mining and Verification of Properties: An Approach based on Temporal Logic</p>

<p>Authors: W.M.P. van der Aalst; H.T. de Beer; B.F. van Dongen</p>

<p>DOI: 10.1007/11575771_11</p>

<p>Year: 2005</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Computer Science / Business Process Management</p>

<p>Subdomain/Topic: Process mining; temporal logic; conformance/verification; ProM; LTL Checker</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 15</p>

<p>Operationalization Score: 20</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual + Tool demonstration</p>

<p>Study Context: Event-log–based verification on an academic paper review process (Petri net running example)</p>

<p>Geographic/Institutional Context: Eindhoven University of Technology; Netherlands</p>

<p>Target Users/Stakeholders: Process analysts; auditors; BPM/WFM practitioners; researchers</p>

<p>Primary Contribution Type: Language + software tool (LTL Checker in ProM) for log-based property verification</p>

<p>CL: No</p>

<p>CR: No</p>

<p>FE: No</p>

<p>TI: No</p>

<p>EX: No</p>

<p>GA: No</p>

<p>Reason if Not Eligible: The paper does not use or define “actionable/actionability” nor provide criteria for the state of being actionable; it focuses on verifying temporal properties in event logs (e.g., 4‑eyes principle) rather than conceptualizing or operationalizing actionability as such.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Process Mining and Verification of Properties: An Approach based on Temporal Logic</p>

<p><strong>Authors:</strong>  </p>

<p>W.M.P. van der Aalst; H.T. de Beer; B.F. van Dongen</p>

<p><strong>DOI:</strong>  </p>

<p>10.1007/11575771_11</p>

<p><strong>Year:</strong>  </p>

<p>2005</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference (Lecture Notes in Computer Science)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Business Process Management</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Process mining; temporal logic (LTL); verification of properties from event logs; ProM framework; conformance-style analysis</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the tension between flexibility/adaptivity of information systems and auditability/compliance pressures (e.g., SOX) and proposes LTL-based verification over event logs integrated into ProM. :contentReference[oaicite:0]{index=0}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Department of Technology Management, Eindhoven University of Technology, Netherlands. :contentReference[oaicite:1]{index=1}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process miners, BPM/WFM analysts, auditors/compliance teams, researchers using ProM. :contentReference[oaicite:2]{index=2}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual language design + implementation + illustrative case (journal review process) using event logs. :contentReference[oaicite:3]{index=3}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>A domain-tailored temporal logic (extensions of LTL) and an LTL Checker tool (ProM plugin) with ~60 predefined properties. :contentReference[oaicite:4]{index=4}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors propose a verification approach that checks whether observed behavior in event logs satisfies desired or undesired properties expressed in a Linear Temporal Logic (LTL) variant tailored for process mining. Integrated into the ProM framework, their “LTL Checker” evaluates properties directly on logs without first discovering a model. They illustrate the approach using a journal paper review process modeled as a Petri net and provide example formulas (e.g., 4‑eyes principle, ordering constraints, timestamp constraints). The checker partitions cases into satisfying and violating sets, supporting further analysis such as discovering models or social networks for each subset. :contentReference[oaicite:5]{index=5}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No; the paper does not use the terms “actionable,” “actionability,” “actionable insight/recommendation/knowledge,” nor does it frame results in those terms. It focuses on verification of temporal properties in event logs.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No; while the paper motivates auditing/monitoring needs under legislation and governance, it does not invoke or imply “actionability” as a concept requiring definition. It frames needs as verification of (un)desired behavior and compliance. :contentReference[oaicite:6]{index=6}</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> No  </p></li>
<li><p><strong>FE (Feasibility):</strong> No  </p></li>
<li><p><strong>TI (Timeliness):</strong> No  </p></li>
<li><p><strong>EX (Explainability):</strong> No  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> No  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<p>Temporal logic (LTL) for specifying behavioral properties over linear traces; event-log centric verification; Petri nets as illustrative process model (workflow nets). :contentReference[oaicite:7]{index=7}  </p>

<ul>
<li>Pnueli’s temporal logic of programs; automata/dynamic programming perspectives referenced. :contentReference[oaicite:8]{index=8}</li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> N/A  </p></li>
<li><p><strong>Enablers:</strong> N/A</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The work contrasts with process discovery methods (e.g., α-algorithm) by emphasizing verification directly on logs, and relates to conformance testing and requirements monitoring using LTL. It situates ProM’s LTL Checker among process mining, BPI/BAM tools, and software engineering monitoring research. :contentReference[oaicite:9]{index=9}</p>

<hr />

<h2>Summary</h2>

<p>This paper contributes a specialized LTL-based language and companion ProM plugin (“LTL Checker”) that verify properties directly from event logs, addressing organizational needs for monitoring and audit amid increasing process flexibility. The approach avoids pre-building models, working at the trace level to evaluate property satisfaction using temporal and logical operators, quantification over activities/persons, data attributes, and timestamps. A running example—the journal paper review process—demonstrates property templates such as exclusive acceptance/rejection, immediate follow-up after decisions, 4‑eyes principle, majority-based acceptance, and timing constraints. The checker partitions cases into satisfying/violating sets to surface counterexamples and support subsequent mining or social-network analysis. While highly relevant for compliance and conformance verification, the paper does not engage with the notion of “actionability” as defined in decision support or insight-to-action research; it neither defines actionability nor specifies dimensions that make insights actionable. Its contribution is thus methodological for verification, not conceptual for actionability. :contentReference[oaicite:10]{index=10}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 15 — The paper is adjacent to decision support via compliance verification but does not mention, define, or theorize “actionability,” nor tie properties to action-taking criteria.  </p></li>
<li><p><strong>Operationalization Score:</strong> 20 — Strong operationalization for LTL-based verification (language, tool, examples), but none for achieving “actionability” as a state; operational steps target property checking rather than translating insights into actions.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Given an event log and a property, our LTL Checker verifies whether the observed behavior matches the (un)expected/(un)desirable behavior.” (Abstract) :contentReference[oaicite:11]{index=11}  </p></li>
<li><p>“Instead we focus on verification, i.e., given an event log we want to verify certain properties.” :contentReference[oaicite:12]{index=12}  </p></li>
<li><p>“Therefore, we propose an approach based on temporal logic… an extension of Linear Temporal Logic (LTL) tailored towards event logs…” :contentReference[oaicite:13]{index=13}  </p></li>
<li><p>Example property schema (Table 2): <code>accept_or_reject_but_not_both()</code> and <code>four_eyes_principle(a1,a2)</code> with universal quantification over persons. :contentReference[oaicite:14]{index=14}  </p></li>
<li><p>“There are about 60 application-independent properties…” :contentReference[oaicite:15]{index=15}  </p></li>
<li><p>“The LTL Checker partitions the set of cases into two sets: L^OK … and L^NOK … Both sets can be saved and analyzed further.” :contentReference[oaicite:16]{index=16}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A (the cited works relate to process mining, conformance, LTL monitoring, and BPM/BAM tools rather than actionability.)</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Process mining and lean six sigma: a novel approach to analyze the supply chain quality of a hospital</p>

<p>Authors: Francisco Ramires; Paulo Sampaio</p>

<p>DOI: 10.1108/IJLSS-12-2020-0226</p>

<p>Year: 2021 (journal record); manuscript uploaded 2022</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Operations Management / Health Services Management</p>

<p>Subdomain/Topic: Lean Six Sigma (LSS); Process Mining (PM); Hospital supply chain; DMAIC</p>

<p>Eligibility: Eligible (implicit treatment of what makes outputs usable for decisions through PM+DMAIC mechanisms and metrics)</p>

<p>Overall Relevance Score: 56</p>

<p>Operationalization Score: 72</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — “This paper provides insights for six sigma and process mining practitioners … Implementing this blended approach can bring visibility to operations and accelerate process improvement initiatives.” (Abstract) :contentReference[oaicite:0]{index=0}</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: Partial (visibility, speed, efficiency, end‑to‑end view discussed but not framed as “actionability”)</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: Partial (dashboards and KPIs to interpret process performance)</p>

<p>Contains Framework/Model: Yes (PM integrated into DMAIC; follows Graafmans et al. 2020 structure)</p>

<p>Operationalization Present: Yes (event-log construction, KPIs, regression analyses, improvement levers, control plan)</p>

<p>Primary Methodology: Mixed Methods (descriptive case study + quantitative analyses; action research stance)</p>

<p>Study Context: Purchasing of consigned medical products in a public hospital</p>

<p>Geographic/Institutional Context: Portuguese National Health Service hospital; global supplier (“Company X”)</p>

<p>Target Users/Stakeholders: Purchasing Department distributor/buyers/head; supplier staff; hospital management</p>

<p>Primary Contribution Type: Practice-oriented case study demonstrating PM+LSS integration with concrete improvement recommendations</p>

<p>CL: Partial</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Partial</p>

<p>EX: No</p>

<p>GA: Partial</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Process mining and lean six sigma: a novel approach to analyze the supply chain quality of a hospital</p>

<p><strong>Authors:</strong>  </p>

<p>Francisco Ramires; Paulo Sampaio</p>

<p><strong>DOI:</strong>  </p>

<p>10.1108/IJLSS-12-2020-0226</p>

<p><strong>Year:</strong>  </p>

<p>2021 (journal publication; manuscript posted 2022) :contentReference[oaicite:1]{index=1}</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Operations Management / Health Services Management</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Lean Six Sigma; Process Mining; DMAIC; Hospital supply chains</p>

<p><strong>Contextual Background:</strong>  </p>

<p>Hospitals face inefficiencies and rising costs; LSS and PM are proposed together to create data-driven improvements in purchasing processes for consigned products. (pp. 3–5) :contentReference[oaicite:2]{index=2}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Portuguese NHS hospital collaborating with a global medical technology supplier (“Company X”). (pp. 10–11) :contentReference[oaicite:3]{index=3}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Hospital Purchasing Department (distributor, buyers, head), supplier teams, hospital management. (pp. 16–17) :contentReference[oaicite:4]{index=4}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed methods descriptive case study within an action research frame; PM dashboards + OLS and logistic regression; DMAIC stages. (pp. 9–10, 22–24) :contentReference[oaicite:5]{index=5}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Applied demonstration and guidance on integrating PM into DMAIC for supply chain quality, with quantified results and improvement plan. (pp. 18–26) :contentReference[oaicite:6]{index=6}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper reports a hospital–supplier collaboration to improve the consignment purchasing process using Lean Six Sigma’s DMAIC structure enhanced with process mining. After building event logs from SAP-derived extracts, the authors used PM dashboards to establish a baseline, then applied OLS and logistic regression to identify drivers of long ordering times and redundant purchase orders. They found 202 redundant POs (29%) and only 66% of requisitions processed within a two‑day target. Improvement measures include redistributing requisitions by supplier, converting direct adjudications to annual tenders, streamlining documentation, and sharing consumption data. A control plan reuses the same PM dashboards for monthly monitoring. (pp. 2, 16–26) :contentReference[oaicite:7]{index=7}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No. The exact terms “actionable,” “actionability,” or “actionable insight/recommendation/knowledge” are not used.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes.  </p>

<ul>
<li><p>“This paper provides insights… Implementing this blended approach can bring visibility to operations and accelerate process improvement initiatives.” (Abstract, p. 2) :contentReference[oaicite:8]{index=8}  </p></li>
<li><p>PM “can add great value to quality initiatives by considering a greater breadth of data… [and] help teams draw process quality‑related conclusions.” (pp. 27–28) :contentReference[oaicite:9]{index=9}</p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicit: Actionable outputs are those that directly inform and justify concrete process changes via end‑to‑end visibility, quantified baselines, and evidence linking drivers to outcomes within DMAIC.  </p>

<blockquote>
  <p>“Combining PM’s process intelligence capabilities with… DMAIC… can support organizations… to build more agile and efficient improvement initiatives.” (p. 27) :contentReference[oaicite:10]{index=10}</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>End‑to‑end operational visibility enabling targeted changes</strong>  </p>

<p> &gt; “The link between event data and process models allows… users to act on updated information promptly and interact with the results.” (p. 7) :contentReference[oaicite:11]{index=11}  </p></li>
<li><p><strong>Quantified performance baselines and KPIs</strong>  </p>

<p> &gt; “To analyze the process, three supply chain quality‑related metrics were designed: Process Quality Level, Working Days Lost, Operational Cost.” (p. 18) :contentReference[oaicite:12]{index=12}  </p></li>
<li><p><strong>Causal/driver analysis connecting factors to outcomes</strong>  </p>

<p> &gt; “Annual agreements lead to 25% faster purchasing, and… decrease the odds of producing repeated POs by 70%.” (pp. 23–24) :contentReference[oaicite:13]{index=13}  </p></li>
<li><p><strong>Operational levers mapped to expected impact</strong>  </p>

<p> &gt; “Five change directions are proposed… [with] expected impact on redundant orders, costs, and days lost.” (pp. 23–25) :contentReference[oaicite:14]{index=14}  </p></li>
<li><p><strong>Ongoing monitoring/control to close the loop</strong>  </p>

<p> &gt; “Using the SQL code and the excel structure created, the same dashboards can be used again to monitor the process… recommended to monitor and compare the results monthly.” (p. 26) :contentReference[oaicite:15]{index=15}</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> DMAIC augmented with Process Mining (per Graafmans et al. 2020). (pp. 8–10) :contentReference[oaicite:16]{index=16}  </p></li>
<li><p><strong>Methods/Levers:</strong> Event‑log construction from SAP extracts; PM dashboards; definition of KPIs; OLS and logistic regression; redesign of distribution policy; shift to annual tenders; documentation streamlining; data‑sharing cadence with supplier. (pp. 14–26) :contentReference[oaicite:17]{index=17}  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Define (charter, CTQ, event‑log build) → Measure (PM baseline, KPIs) → Analyze (driver prioritization, regressions) → Improve (5 interventions with quantified impacts) → Control (dashboard‑based monthly monitoring). (pp. 9–10, 12–26) :contentReference[oaicite:18]{index=18}  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Case ID, activity, timestamps; KPIs: Process Quality Level, Working Days Lost, Operational Cost; ordering time distributions; six sigma level. (pp. 6–7, 18–19) :contentReference[oaicite:19]{index=19}  </p></li>
<li><p><strong>Implementation Context:</strong> Portuguese public hospital consignment purchasing process; Celonis used for PM; SAP as source. (pp. 11, 16) :contentReference[oaicite:20]{index=20}  </p></li>
</ul>

<blockquote>
  <p>“There were 202 redundant purchase orders… only 66% processed below the target of 2 days.” (pp. 18–19) :contentReference[oaicite:21]{index=21}</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<p><em>(Marked when explicitly tied to making changes in this case; authors do not frame them as “actionability” per se.)</em></p>

<ul>
<li><p><strong>CL (Clarity):</strong> Partial — PM dashboards and process maps “discover the process performance” and present “high‑level view” for stakeholders. Quote: “Different dashboards were created to discover the process performance.” (p. 18) :contentReference[oaicite:22]{index=22}  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Metrics and levers are tailored to consignment purchasing in the specific hospital context. Quote: “Three supply chain quality‑related metrics were designed…” (p. 18) :contentReference[oaicite:23]{index=23}  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Interventions include quantified cost/time savings and specific responsibility &amp; dates (Table XIII). Quote: “Altering the distribution method… 336 euros/year… early 2021.” (p. 26) :contentReference[oaicite:24]{index=24}  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Target of ≤2 business days; monthly monitoring recommended. Quotes: “Ordering time target of 2 days.” (p. 18–19); “recommended to monitor… monthly.” (p. 26) :contentReference[oaicite:25]{index=25}  </p></li>
<li><p><strong>EX (Explainability):</strong> No — Paper does not discuss model transparency beyond descriptive dashboards.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — Goals set in project charter/CTQ (reduce redundant POs; reduce ordering time). Quote: “Two key critical indicators… time &gt;2 business days; redundant POs.” (p. 13) :contentReference[oaicite:26]{index=26}  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> End‑to‑end visibility; evidence‑based improvement. Quotes: “End‑to‑end visibility is key to optimize… anticipate disruptions.” (p. 27) :contentReference[oaicite:27]{index=27}</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Lean Six Sigma (DMAIC).  </p></li>
<li><p>Process Mining as data‑driven process analysis; follows Graafmans et al. (2020) for PM‑into‑DMAIC scaffolding. (pp. 4–9) :contentReference[oaicite:28]{index=28}</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p><strong>Process Quality Level</strong> = Redundant POs / Total POs (%).  </p></li>
<li><p><strong>Working Days Lost</strong> from redundant POs (conversion from minutes).  </p></li>
<li><p><strong>Operational Cost</strong> = Redundant POs × €8 per PO.  </p></li>
<li><p><strong>Ordering Time</strong> distribution; <strong>Six Sigma level</strong> for POs. (pp. 18–19) :contentReference[oaicite:29]{index=29}</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Fragmented/“materialized” process with paper approvals (adds ~3 minutes per requisition). (pp. 20–21) :contentReference[oaicite:30]{index=30}  </p>

<p> - Frequent legal/quotation requests despite fixed annual prices (adds up to 2 workdays). (p. 21) :contentReference[oaicite:31]{index=31}  </p>

<p> - Requisition distribution method impedes aggregation, causing redundant POs. (p. 20) :contentReference[oaicite:32]{index=32}  </p>

<p> - Contract modality constraints (direct adjudication) increase delay and fragmentation. (pp. 20, 23–24) :contentReference[oaicite:33]{index=33}</p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - PM dashboards for baseline and monitoring; end‑to‑end visibility. (pp. 16, 26–28) :contentReference[oaicite:34]{index=34}  </p>

<p> - Annual tender agreements reducing ordering time by ~25% and redundant PO odds by ~70%. (pp. 23–24, 28) :contentReference[oaicite:35]{index=35}  </p>

<p> - Centralized digital documentation hub and improved supplier communication. (p. 25) :contentReference[oaicite:36]{index=36}  </p>

<p> - Data‑sharing cadence for batching POs (e.g., weekly issuance). (p. 25) :contentReference[oaicite:37]{index=37}</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The study positions itself as operationalizing Graafmans et al. (2020)’s guideline for integrating PM within DMAIC, responding to calls for descriptive case studies that show “where and how” PM adds value in LSS projects. It echoes prior arguments about the need for end‑to‑end views and leveraging IT system data for improvement (Aalst; Davenport &amp; Spanyi) and contributes empirical evidence in a healthcare supply chain context. (pp. 4–9, 27–28) :contentReference[oaicite:38]{index=38}</p>

<hr />

<h2>Summary</h2>

<p>This paper is a practice‑driven case study showing how to combine PM with LSS’s DMAIC to improve a hospital’s consignment purchasing. The authors build an event log (consumption → PO issue → delivery) from SAP extracts and load it into Celonis to visualize the as‑is process. They define CTQs (ordering time ≤2 days; avoid redundant POs), derive KPIs (Process Quality Level, Working Days Lost, Operational Cost), and quantify the baseline: 202 redundant POs (29%), 120 redundant deliveries, and only 66% under the 2‑day target. Regression analyses reveal contract modality as a major driver: annual tenders shorten ordering time ~25% and reduce redundant PO odds ~70%. Five interventions are proposed (redistribute by supplier, shift to annual tenders, streamline documentation, share consumption data, strengthen communication), each with estimated impacts and responsibilities, plus a control plan reusing the PM dashboards for monthly monitoring. While the article does not define “actionability,” it implicitly delivers it through traceable metrics, causal analyses, and concrete, scheduled levers that close the loop from insight to sustained change. (pp. 12–26) :contentReference[oaicite:39]{index=39}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 56 — The paper substantively enables decision‑oriented change via PM+DMAIC, KPIs, and quantified drivers, but lacks explicit definition/theory of “actionability” and does not frame features as dimensions of actionability. :contentReference[oaicite:40]{index=40}  </p></li>
<li><p><strong>Operationalization Score:</strong> 72 — Strong on “how to”: event‑log construction, KPIs, dashboards, regression for driver identification, defined levers with expected impacts and control plan; still context‑specific with limited generalizable metrics for “actionability” per se. :contentReference[oaicite:41]{index=41}</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[PM] can support organizations that already adopt LSS methods… to build more agile and efficient improvement initiatives.” (p. 27) :contentReference[oaicite:42]{index=42}  </p></li>
<li><p>“Three supply chain quality‑related metrics were designed: Process Quality Level, Working Days Lost, Operational Cost.” (p. 18) :contentReference[oaicite:43]{index=43}  </p></li>
<li><p>“Annual agreements lead to 25% faster purchasing, and… decrease the odds of producing repeated POs by 70%.” (pp. 23–24) :contentReference[oaicite:44]{index=44}  </p></li>
<li><p>“Recommended to monitor and compare the results monthly.” (p. 26) :contentReference[oaicite:45]{index=45}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Graafmans, T. et al. (2020) — PM for Six Sigma guideline integrated into DMAIC (foundation for the blended approach).  </p></li>
<li><p>van der Aalst (2011, 2016) — PM fundamentals enabling end‑to‑end, event‑log‑based analysis.  </p></li>
<li><p>Davenport &amp; Spanyi (2019) — Emphasis on leveraging information systems for process improvement. (pp. 4–9, 27–29) :contentReference[oaicite:46]{index=46}</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Prescriptive process monitoring: Quo vadis?</p>

<p>Authors: Kateryna Kubrak; Fredrik Milani; Alexander Nolte; Marlon Dumas</p>

<p>DOI: 10.7717/peerj-cs.1097</p>

<p>Year: 2022</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Process Mining / Business Process Management / Data Science</p>

<p>Subdomain/Topic: Prescriptive process monitoring; interventions; policies; causality; SLR and framework</p>

<p>Eligibility: Eligible (Implicit treatment of what makes recommendations usable and effective; emphasis on effective, timely, feasible interventions and explainability)</p>

<p>Overall Relevance Score: 72</p>

<p>Operationalization Score: 64</p>

<p>Actionable/Actionability Used in Paper: No (term not used explicitly); implicit throughout via “prescriptions/interventions” and their effectiveness:contentReference[oaicite:0]{index=0}</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — e.g., “Predictions… only become useful to users when they are combined with recommendations” (p. 2):contentReference[oaicite:1]{index=1}; “benefits… realized if these methods prescribe effective interventions that are followed” (p. 3):contentReference[oaicite:2]{index=2}</p>

<p>Contains Definition of Actionability: No (no explicit definition; provides conditions/mechanisms instead)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Review (Systematic Literature Review)</p>

<p>Study Context: Multiple domains via surveyed papers; not a single empirical field study</p>

<p>Geographic/Institutional Context: Literature-centered; authors from University of Tartu &amp; CMU</p>

<p>Target Users/Stakeholders: Researchers; BPM tool developers; process workers/end‑users; decision-makers</p>

<p>Primary Contribution Type: Conceptual framework + systematic review</p>

<p>CL: Partial</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Yes</p>

<p>EX: Yes</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Prescriptive process monitoring: Quo vadis?</p>

<p><strong>Authors:</strong>  </p>

<p>Kateryna Kubrak; Fredrik Milani; Alexander Nolte; Marlon Dumas</p>

<p><strong>DOI:</strong>  </p>

<p>10.7717/peerj-cs.1097</p>

<p><strong>Year:</strong>  </p>

<p>2022</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal (PeerJ Computer Science):contentReference[oaicite:3]{index=3}</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Process Mining / Business Process Management / Data Science</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Prescriptive process monitoring; runtime interventions; policy design; causality; SLR &amp; framework.</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper reviews prescriptive process monitoring (PPM) methods that recommend runtime interventions to optimize outcomes or efficiency. It proposes a multi‑dimensional framework (objective, metrics, intervention types, inputs, techniques, policies) and highlights research gaps including causality, explainability, and real‑world validation (pp. 2–4, 14–22).:contentReference[oaicite:4]{index=4}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Not tied to a single field site; cross‑domain literature. Authors affiliated with University of Tartu (Estonia) and CMU (USA) (p. 2).:contentReference[oaicite:5]{index=5}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Researchers and tool developers; also process workers and end‑users who receive prescriptions (pp. 3, 4, 11).:contentReference[oaicite:6]{index=6}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Systematic Literature Review following Kitchenham &amp; Charters; search strings, inclusion/exclusion, data extraction (pp. 5–7; Table 1–3 p. 7–8 image).:contentReference[oaicite:7]{index=7}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework + synthesis of 37 papers (pp. 4, 14–18; Figs. 2–3 pp. 16–17).:contentReference[oaicite:8]{index=8}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The article studies prescriptive process monitoring methods that recommend runtime interventions to prevent negative outcomes or improve performance. Using a systematic literature review of 37 papers, it categorizes methods by objectives (outcome vs. efficiency), intervention perspectives (control‑flow vs. resource), data inputs, modeling techniques, and policies to trigger interventions. It provides a framework (with figures) mapping these characteristics and illustrates common policies such as similarity thresholds, probability‑based alarms with cost/benefit trade‑offs, and user‑defined rules. The paper identifies major gaps: lack of in‑vivo validation, limited exploration of causal policies and second‑order effects, scant explainability (especially of policies), narrow focus on temporal KPIs, and inconsistent terminology (pp. 2–4, 11–18, 20–22).:contentReference[oaicite:9]{index=9}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No (term not used explicitly). However, the paper repeatedly treats the <em>usability and effectiveness</em> of recommendations as necessary for value:</p>

<ul>
<li><p>“Predictions… only become useful to users when they are combined with recommendations.” (p. 2):contentReference[oaicite:10]{index=10}  </p></li>
<li><p>“The benefits of prescriptive process monitoring can only be fully realized if these methods prescribe effective interventions that are followed.” (p. 3):contentReference[oaicite:11]{index=11}  </p></li>
<li><p>Policies weigh “cost model… and mitigation effectiveness before triggering interventions.” (p. 4):contentReference[oaicite:12]{index=12}</p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes.  </p>

<ul>
<li><p>“Only become useful to users when… combined with recommendations.” (p. 2):contentReference[oaicite:13]{index=13}  </p></li>
<li><p>Effectiveness depends on “interventions that are followed” and user acceptance (p. 3).:contentReference[oaicite:14]{index=14}  </p></li>
<li><p>Calls for explainability of predictions and policies to support decision-makers (pp. 19–20).:contentReference[oaicite:15]{index=15}</p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly: information (predictions) must be paired with <em>effective, feasible, timely</em> interventions and a <em>policy</em> that decides <em>when</em> and <em>what</em> to prescribe, ideally considering <em>causal impact</em>, <em>costs</em>, <em>resource availability</em>, and <em>second‑order effects</em>, and being <em>explainable</em> to end‑users (pp. 3–4, 13–20).:contentReference[oaicite:16]{index=16}  </p>

<blockquote>
  <p>“An alarm is raised that can lead to an intervention… evaluate the cost model and mitigation effectiveness before triggering interventions.” (p. 4):contentReference[oaicite:17]{index=17}  </p>
</blockquote>

<blockquote>
  <p>“Only a few existing methods take causality into account… need to explain why… recommends a given intervention… prediction explanation and policy explanation.” (pp. 19–20):contentReference[oaicite:18]{index=18}</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Effectiveness of intervention:</strong>  </p>

<p> &gt; “Benefits… realized if… prescribe effective interventions that are followed.” (p. 3):contentReference[oaicite:19]{index=19}</p></li>
<li><p><strong>Causal impact (not mere correlation):</strong>  </p>

<p> &gt; “Developing policy design techniques that take causality into account.” (p. 20):contentReference[oaicite:20]{index=20}</p></li>
<li><p><strong>Feasibility &amp; cost trade‑off:</strong>  </p>

<p> &gt; “Evaluates… cost model… intervention, undesired outcome, compensation… and the mitigation effectiveness.” (p. 4; also pp. 13–15):contentReference[oaicite:21]{index=21}</p></li>
<li><p><strong>Resource availability / capacity constraints:</strong>  </p>

<p> &gt; Policies consider “resource availability” when prescribing interventions (pp. 13, 15).:contentReference[oaicite:22]{index=22}</p></li>
<li><p><strong>Timeliness (when to trigger):</strong>  </p>

<p> &gt; “Intervention frequency… continuous or discrete… triggered only when… probability… exceeds a defined threshold.” (pp. 11–13, 15):contentReference[oaicite:23]{index=23}</p></li>
<li><p><strong>Explainability to end‑users:</strong>  </p>

<p> &gt; “Ability to explain… prediction… and… policy… is unexplored.” (pp. 19–20):contentReference[oaicite:24]{index=24}</p></li>
<li><p><strong>Consideration of second‑order effects &amp; user acceptance:</strong>  </p>

<p> &gt; Interventions can be “ineffective or counter‑productive… second‑order effects… need… human judgment and iterative policy validation (e.g., A/B testing).” (p. 19):contentReference[oaicite:25]{index=25}</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong>  </p>

<p> Multi‑dimensional <em>Prescriptive Process Monitoring Framework</em> (Figs. 2–3) mapping objectives, targets, intervention perspective, inputs, feature encoding, modeling technique, policy, intervention frequency, purpose (pp. 14–17).:contentReference[oaicite:26]{index=26}</p></li>
<li><p><strong>Methods/Levers:</strong>  </p>

<p> Prediction models (e.g., DT, RF, LSTM), similarity/kNN, causal estimation (e.g., CATE), cost models, user‑defined policies (pp. 11–15).:contentReference[oaicite:27]{index=27}</p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> (i) Detect risk/goal; (ii) estimate outcome probability; (iii) evaluate intervention effectiveness &amp; costs; (iv) check constraints/resources; (v) trigger prescription via policy (thresholds/rules/similarity); (vi) possibly iterate/validate (pp. 4, 13–15, 19).:contentReference[oaicite:28]{index=28}</p></li>
<li><p><strong>Data &amp; Measures:</strong>  </p>

<p> Control‑flow, resource, temporal, domain‑specific features; targets include outcome violation, cycle/processing time, cost, revenue, defect rate (pp. 9–13, 15–17).:contentReference[oaicite:29]{index=29}</p></li>
<li><p><strong>Implementation Context:</strong>  </p>

<p> Cross‑domain exemplars; often evaluated on real or synthetic logs; limited in‑vivo trials (pp. 9–12, 17–19).:contentReference[oaicite:30]{index=30}  </p></li>
</ul>

<blockquote>
  <p>“An alarm… probability of a negative outcome… cost model… mitigation effectiveness before triggering interventions.” (p. 4):contentReference[oaicite:31]{index=31}</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<p><em>(Marked only where the paper ties the attribute to prescriptions and their usefulness.)</em></p>

<ul>
<li><p><strong>CL (Clarity):</strong> Partial — need for common terminology suggests clarity matters to apply prescriptions.  </p>

<p> &gt; “Lack of common terminology… need for common terminology.” (p. 20):contentReference[oaicite:32]{index=32}</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — policies/methods depend on domain data and case context.  </p>

<p> &gt; Inputs include domain‑specific features and case attributes; prescriptions vary by context (pp. 11–13, 15–17).:contentReference[oaicite:33]{index=33}</p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — cost models, resource availability, constraints.  </p>

<p> &gt; “Cost model… intervention… compensation” and “resource availability” before prescribing (pp. 4, 13, 15).:contentReference[oaicite:34]{index=34}</p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — continuous vs. discrete triggering; thresholds.  </p>

<p> &gt; “Intervention frequency… continuous or discrete… probability above threshold” (pp. 11–13, 15).:contentReference[oaicite:35]{index=35}</p></li>
<li><p><strong>EX (Explainability):</strong> Yes — explicit call for prediction &amp; policy explanation.  </p>

<p> &gt; “Ability to explain… prediction… and… policy… unexplored.” (pp. 19–20):contentReference[oaicite:36]{index=36}</p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — objectives/targets (KPI) drive prescriptions.  </p>

<p> &gt; Objectives: optimize outcome or efficiency; targets like cycle time, deadlines, revenue (pp. 9–10, 14–17).:contentReference[oaicite:37]{index=37}</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong>  </p>

<p> <strong>Causality</strong> — as a design principle for policies (pp. 19–20).:contentReference[oaicite:38]{index=38}</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li>Value of recommendations paired with predictions; alarm‑based and policy‑based control; causal inference notions (CATE) introduced in cited works; Kitchenham SLR methodology; A/B testing for policy validation (pp. 4–5, 12–15, 19–20).:contentReference[oaicite:39]{index=39}</li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li>No explicit “actionability metric,” but operational proxies: probability thresholds of negative outcomes, mitigation effectiveness, cost models (intervention vs. penalty/compensation), resource availability/utilization, KPI improvement (cycle/processing time, deadlines, revenue, defect rate) (pp. 4, 9–15).:contentReference[oaicite:40]{index=40}</li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Lack of in‑vivo validation; prescriptions may not change outcomes (pp. 17–19).:contentReference[oaicite:41]{index=41}  </p>

<p> - Correlation‑based policies may miss true causes (pp. 18–20).:contentReference[oaicite:42]{index=42}  </p>

<p> - Second‑order effects; user acceptance (p. 19).:contentReference[oaicite:43]{index=43}  </p>

<p> - Limited explainability, especially of policies (pp. 19–20).:contentReference[oaicite:44]{index=44}</p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Cost‑aware, resource‑aware, causality‑aware policies (pp. 4, 13–15, 19–20).:contentReference[oaicite:45]{index=45}  </p>

<p> - Rich multi‑perspective data (control‑flow, resource, temporal, domain) (pp. 11–13).:contentReference[oaicite:46]{index=46}  </p>

<p> - Clear objectives/targets and policy rules/thresholds (pp. 13–16).:contentReference[oaicite:47]{index=47}</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The review situates PPM relative to predictive monitoring, resource allocation, and prescriptive analytics, noting prior taxonomies for predictive tasks and gaps around prescriptive interventions and policy design. It synthesizes methods from similarity‑based guidance to prediction‑ and causality‑based optimization, highlighting emerging causal approaches and alarm systems (pp. 3–4, 12–15).:contentReference[oaicite:48]{index=48}</p>

<hr />

<h2>Summary</h2>

<p>This SLR frames prescriptive process monitoring as the pairing of predictions with <em>effective, feasible, timely</em> runtime interventions governed by explicit policies. Across 37 studies, objectives cluster into optimizing outcomes (e.g., deadline compliance) and optimizing efficiency (e.g., cycle/processing time, cost, revenue). Prescriptions commonly act on control‑flow (next task/path) or resources (assignment/reallocation), using multi‑perspective inputs (control‑flow, resource, temporal, domain). Policies include similarity thresholds, rule sets, and probability‑and‑cost‑based alarms; a minority incorporate causal estimation to avoid spurious correlations. The proposed framework (Figs. 2–3) catalogs characteristics: objective/target, intervention perspective, input and feature encoding, modeling technique, policy, intervention frequency, and purpose (guiding vs. optimizing). Key gaps limit “actionability”: scarce in‑vivo validation, minimal policy explainability, limited attention to second‑order effects and human factors, and a focus on temporal KPIs. The authors call for causality‑aware, explainable, validated policies and broader performance objectives to make prescriptions reliably useful in practice (pp. 14–22).:contentReference[oaicite:49]{index=49}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 72 — Strong implicit treatment of what makes prescriptions <em>usable</em> (effectiveness, feasibility, timeliness, explainability), plus a concrete framework. Lacks an explicit “actionability” definition.</p></li>
<li><p><strong>Operationalization Score:</strong> 64 — Provides concrete policy patterns (thresholds, cost models), intervention perspectives, and a framework with examples, but no unified metric of “actionability” and limited procedural guidance for implementing explanations or causal validation.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[P]redictions… only become useful to users when they are combined with recommendations.” (p. 2):contentReference[oaicite:50]{index=50}  </p></li>
<li><p>“Benefits… fully realized if… prescribe effective interventions that are followed.” (p. 3):contentReference[oaicite:51]{index=51}  </p></li>
<li><p>“Evaluates the probability of a negative outcome together with a cost model… and the mitigation effectiveness [to]… trigger interventions.” (p. 4):contentReference[oaicite:52]{index=52}  </p></li>
<li><p>“Developing policy design techniques that take causality into account.” (p. 20):contentReference[oaicite:53]{index=53}  </p></li>
<li><p>“Ability to explain… prediction… and… policy… unexplored.” (pp. 19–20):contentReference[oaicite:54]{index=54}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Teinemaa et al. (2018) — Alarm‑based prescriptive monitoring with thresholds, cost, mitigation effectiveness (cited pp. 4, 13–15).:contentReference[oaicite:55]{index=55}  </p></li>
<li><p>Fahrenkrog‑Petersen et al. (2022) — Alarm‑based systems, cost/benefit &amp; mitigation effectiveness (pp. 4, 13–15).:contentReference[oaicite:56]{index=56}  </p></li>
<li><p>Shoush &amp; Dumas (2021) — Causal inference under resource constraints; CATE for prescriptions (pp. 12–15, 20).:contentReference[oaicite:57]{index=57}  </p></li>
<li><p>Bozorgi et al. (2021) — Cost‑aware cycle time reduction with causal estimation/policies (pp. 12–15, 17).:contentReference[oaicite:58]{index=58}  </p></li>
<li><p>Dees et al. (2019) — Field evidence that accurate predictions do not guarantee effective recommendations (p. 17).:contentReference[oaicite:59]{index=59}  </p></li>
<li><p>Márquez‑Chamorro et al. (2018) — Predictive monitoring survey; motivation for pairing predictions with prescriptions (pp. 2–4).:contentReference[oaicite:60]{index=60}</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Predicting process performance: A white‐box approach based on process models</p>

<p>Authors: Ilya Verenich, Marlon Dumas, Marcello La Rosa, Hoang Nguyen</p>

<p>DOI: https://doi.org/10.1002/smr.2170</p>

<p>Year: 2019</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Business Process Management / Process Mining</p>

<p>Subdomain/Topic: Predictive Process Monitoring, White-box Prediction, Flow Analysis</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 75</p>

<p>Operationalization Score: 85</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — “...business analysts can pinpoint the bottlenecks in the process execution and provide better recommendations to keep the process compliant with the performance standards.” (p. 24)</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes — White-box predictive framework using flow analysis</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Quantitative / Experimental</p>

<p>Study Context: Predicting remaining cycle time of ongoing process instances from event logs</p>

<p>Geographic/Institutional Context: Multiple — data from public process mining datasets (BPIC, Hospital, Helpdesk, Invoice, etc.)</p>

<p>Target Users/Stakeholders: Process analysts, business managers, operational decision-makers</p>

<p>Primary Contribution Type: Methodological / Framework Development</p>

<p>CL: Partial — explains decomposition but not labeled as “clarity” dimension</p>

<p>CR: Yes — model contextualized to specific process models and datasets</p>

<p>FE: Partial — considers feasibility of runtime application</p>

<p>TI: Yes — supports early prediction during case execution</p>

<p>EX: Yes — white-box decomposition into activity-level components</p>

<p>GA: Partial — aligns prediction explanation with operational improvement goals</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Predicting process performance: A white‐box approach based on process models</p>

<p><strong>Authors:</strong>  </p>

<p>Ilya Verenich, Marlon Dumas, Marcello La Rosa, Hoang Nguyen</p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1002/smr.2170</p>

<p><strong>Year:</strong>  </p>

<p>2019</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Business Process Management / Process Mining</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Predictive Process Monitoring, White-box Prediction, Flow Analysis</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses limitations of black-box predictive process monitoring methods by proposing a white-box approach. Instead of producing a single scalar prediction for process performance indicators, the approach predicts performance at the activity level and aggregates results using flow analysis to improve interpretability and explanatory power.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Multiple domains and organizations; datasets from public benchmarks and industry logs (BPIC, Hospital, Helpdesk, Invoice, RTFMP, Credit Requirement).</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process analysts, business managers, operational decision-makers.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative / Experimental</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Methodological / Framework Development</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper proposes a white-box predictive process monitoring framework that predicts quantitative process performance indicators—specifically, remaining cycle time—by decomposing predictions into activity-level estimates and aggregating them via flow analysis. The approach begins by discovering a structured process model from historical event logs, then trains regression models for activity cycle times and classification models for branching probabilities at decision points. At runtime, partial traces of ongoing cases are aligned with the process model, and remaining time formulas are generated and evaluated. Three variants are presented: predictive flow analysis, mean flow analysis, and adaptive flow analysis. The method is evaluated on nine real-life event logs against black-box and other baseline methods. Results show the white-box approach often achieves comparable or better accuracy while enhancing interpretability, allowing analysts to identify bottlenecks and target interventions.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>No</strong> — The paper does not use the terms <em>actionable</em> or <em>actionability</em>.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>Yes</strong> —  </p>

<blockquote>
  <p>“...business analysts can pinpoint the bottlenecks in the process execution and provide better recommendations to keep the process compliant with the performance standards.” (p. 24)  </p>
</blockquote>

<p>This implies a need for actionable insights derived from interpretable predictions.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p><strong>Implicit</strong> — Actionability is implied as the ability to understand <em>where</em> in the process predicted performance issues will occur, enabling targeted managerial interventions.</p>

<blockquote>
  <p>The white-box decomposition “...allows users not only to make predictions but also to explain them” (p. 23), facilitating operational adjustments.</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Traceable to specific activities:</strong>  </p>

<p> &gt; “...determine to what extent each activity contributes to the prediction” (p. 3)</p></li>
<li><p><strong>Pinpoint bottlenecks:</strong>  </p>

<p> &gt; “...business analysts can pinpoint the bottlenecks... and provide better recommendations” (p. 24)</p></li>
<li><p><strong>Operationally relevant granularity:</strong>  </p>

<p> &gt; “...explain in which parts of the process the remaining time will be spent” (p. 3)</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> White-box predictive process monitoring via flow analysis</p></li>
<li><p><strong>Methods/Levers:</strong> Discover process models, decompose performance indicators into activity-level components, train regression/classification models, align partial traces, aggregate via flow formulas.</p></li>
<li><p><strong>Operational Steps / Workflow:</strong> (1) Discover process model; (2) Train regressors and classifiers; (3) Align ongoing case traces; (4) Generate flow formulas; (5) Predict and aggregate activity-level values.</p></li>
<li><p><strong>Data &amp; Measures:</strong> Event logs (case and event attributes), cycle times, branching probabilities.</p></li>
<li><p><strong>Implementation Context:</strong> Applicable to structured process models discovered from logs.</p></li>
</ul>

<blockquote>
  <p>“...first predict the performance indicator at the level of activities and then aggregate these predictions... by means of flow analysis techniques.” (p. 1)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Partial — Predictions decomposed for interpretability but no formal clarity definition.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Predictions are process-specific, linked to actual activity flows.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — Runtime performance tested; feasible for online applications.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — Supports early predictions during execution.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — White-box decomposition provides direct explanation of results.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — Predictions framed to support performance compliance goals.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Flow analysis in process models</p></li>
<li><p>Machine learning regression/classification for predictive process monitoring</p></li>
<li><p>Process model discovery from event logs</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A — Metrics focus on MAE for prediction accuracy, not explicit actionability measures.</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Data sparsity for rare activities, rework loops complicating predictions, lack of relevant attributes in logs.</p></li>
<li><p><strong>Enablers:</strong> Structured process models, interpretable prediction formulas, activity-level granularity.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions itself against black-box remaining time predictors, drawing on literature on process mining, predictive monitoring, and explainable models. Claims novelty in applying flow analysis for interpretable quantitative predictions.</p>

<hr />

<h2>Summary</h2>

<p>This study introduces a white-box predictive framework for process performance monitoring that predicts remaining cycle time by aggregating activity-level predictions using flow analysis. Unlike black-box methods, it decomposes predictions, making them interpretable and enabling process analysts to identify specific bottlenecks. Three variants—predictive, mean, and adaptive—are tested on nine real-life event logs, with the adaptive variant often achieving the best accuracy. The approach improves transparency without sacrificing performance and supports early intervention by revealing which process segments are likely to cause delays. While the term “actionability” is not used, the framework implicitly targets actionable outcomes by aligning predictive explanations with operational decision-making needs.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 75 — Strong alignment with implicit actionability via interpretability; lacks explicit definition or conceptualization of actionability.</p></li>
<li><p><strong>Operationalization Score:</strong> 85 — Detailed, replicable methodology with concrete steps for implementation; operationalizes interpretability into workflow.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“...first predict the performance indicator at the level of activities and then aggregate these predictions... by means of flow analysis techniques.” (p. 1)  </p></li>
<li><p>“...determine to what extent each activity contributes to the prediction.” (p. 3)  </p></li>
<li><p>“...business analysts can pinpoint the bottlenecks in the process execution and provide better recommendations...” (p. 24)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A — No explicit citations defining or operationalizing "actionability".</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: PEM4PPM: A Cognitive Perspective on the Process of Process Mining  </p>

<p>Authors: Elizaveta Sorokina, Pnina Soffer, Irit Hadar, Uri Leron, Francesca Zerbato, Barbara Weber  </p>

<p>DOI: https://doi.org/10.1007/978-3-031-41620-0_27  </p>

<p>Year: 2023  </p>

<p>Publication Type: Conference  </p>

<p>Discipline/Domain: Information Systems / Process Mining  </p>

<p>Subdomain/Topic: Cognitive perspectives in process mining, Prediction Error Minimization (PEM) theory application  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 85  </p>

<p>Operationalization Score: 78  </p>

<p>Actionable/Actionability Used in Paper: No  </p>

<p>Authors Argue for Need for Actionability Without Defining It: No  </p>

<p>Contains Definition of Actionability: No  </p>

<p>Contains Systematic Features/Dimensions: Yes – cognitive steps mapped to operational process mining tasks  </p>

<p>Contains Explainability: Yes – via cognitive process modeling  </p>

<p>Contains Interpretability: Yes – mapping of thought processes to PM actions  </p>

<p>Contains Framework/Model: Yes – PEM4PPM model (v1 and v2)  </p>

<p>Operationalization Present: Yes – analysis protocol, coding scheme, strategies  </p>

<p>Primary Methodology: Mixed Methods (qualitative &amp; quantitative)  </p>

<p>Study Context: Cognitive strategies in process mining analysis  </p>

<p>Geographic/Institutional Context: University of Haifa, Technion (Israel), University of St. Gallen (Switzerland)  </p>

<p>Target Users/Stakeholders: Process mining analysts (students &amp; professionals), tool developers, educators  </p>

<p>Primary Contribution Type: Theoretical framework and empirical validation of analyst strategies  </p>

<p>CL: Partial – clarity embedded in goal setting and task understanding steps  </p>

<p>CR: Yes – grounded in PM context and task-related goals  </p>

<p>FE: Partial – feasibility implied in operational PM steps  </p>

<p>TI: No explicit timeliness focus  </p>

<p>EX: Yes – explicit explanation of steps and reasoning processes  </p>

<p>GA: Yes – goal-driven analysis is a core element of the model  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>PEM4PPM: A Cognitive Perspective on the Process of Process Mining  </p>

<p><strong>Authors:</strong>  </p>

<p>Elizaveta Sorokina, Pnina Soffer, Irit Hadar, Uri Leron, Francesca Zerbato, Barbara Weber  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1007/978-3-031-41620-0_27  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Information Systems / Process Mining  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Cognitive perspectives in process mining, Prediction Error Minimization (PEM) theory application  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses a gap in understanding the “process of process mining” (PPM) from a cognitive science perspective, adapting the Prediction Error Minimization (PEM) theory to explain and analyze analysts’ sense-making processes when interacting with process mining tools.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of Haifa, Technion (Israel), University of St. Gallen (Switzerland)  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process mining analysts (students &amp; professionals), process mining tool designers, educators  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed Methods (qualitative for theory adaptation &amp; strategy identification; quantitative for validation &amp; performance impact)  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Theoretical framework (PEM4PPM model) and empirical strategy validation  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper develops and validates the PEM4PPM model, a cognitive framework for understanding how process mining analysts approach analysis tasks. Drawing on Prediction Error Minimization (PEM) theory from cognitive science, the authors map cognitive steps—such as goal setting, attention focusing, hypothesis generation, and testing—onto concrete process mining operations. The research involved two participant groups: students and experienced analysts, whose think-aloud protocols, screen interactions, and tool logs were analyzed. The study identified four analyst strategies (NNN, WNN, WWN, WWW), showing that those following the full cognitive process (WWW) achieved significantly higher performance. The work provides both a conceptual model and an operational analysis protocol, with implications for training analysts and improving PM tools.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No – the paper focuses on cognitive processes and performance but does not explicitly use “actionable” in relation to outputs or decisions.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No – the focus is on cognitive completeness and performance, not explicitly on producing actionable outputs.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A – actionability is not addressed.</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A – not discussed.</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>While actionability per se is not targeted, the paper operationalizes cognitive process modeling:</p>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> PEM4PPM model  </p></li>
<li><p><strong>Methods/Levers:</strong> Mapping PEM cognitive steps to process mining tasks; think-aloud protocols; coding of analyst behavior  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Task understanding → Goal setting/refinement → Focusing attention → Exploration → Data interpretation → Hypothesis generation/testing → Results assessment → Conclusion  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Multimodal datasets (verbal utterances, screen recordings, Disco logs), performance grading, statistical testing  </p></li>
<li><p><strong>Implementation Context:</strong> Process mining analysis tasks in research settings with students and professionals  </p></li>
</ul>

<blockquote>
  <p>“We validated the PEM4PPM v2 model… describing the cognitive steps… their explanation, example statements, and detection method.” (p. 474–475)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Partial – clarity implied in explicit task understanding and goal formulation  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – goals and steps are grounded in the PM task context  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial – feasible operational steps mapped to PM techniques  </p></li>
<li><p><strong>TI (Timeliness):</strong> No – timeliness is not addressed  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – each cognitive step is explicitly defined and exemplified  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – goal setting/refinement is central to the process  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li>Prediction Error Minimization (PEM) theory within Predictive Processing framework</li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p>N/A – focus is on barriers/enablers to cognitive completeness:</p>

<ul>
<li><p><strong>Barriers:</strong> Insufficient tool knowledge; reluctance to perform trial-and-error in observation settings; incomplete hypothesis testing  </p></li>
<li><p><strong>Enablers:</strong> Complete cognitive cycle (WWW strategy); structured goal setting; familiarity with tools</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Extends prior process mining individual perspective research by applying a theory-guided cognitive framework, contrasting with prior purely data-driven or interview-based approaches.</p>

<hr />

<h2>Summary</h2>

<p>This study introduces PEM4PPM, a cognitive framework adapted from Prediction Error Minimization theory, to explain and analyze the strategies process mining analysts use. Through a mixed-methods approach involving both students and professionals, the authors map cognitive steps to concrete PM tasks, validate the model, and identify four analyst strategies differing in cognitive completeness. The WWW strategy, which includes data interpretation, hypothesis generation, and testing, yields the highest performance, regardless of expertise level. The work operationalizes the model via a detailed analysis protocol, enabling structured study of analysts’ cognitive processes. While not explicitly targeting actionability, the framework has implications for improving analyst training, guiding tool design, and potentially informing process guidance systems. The findings highlight that cognitive completeness, rather than experience alone, drives better analytical outcomes in PM contexts.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 – Strong conceptual framework linked to operational process analysis; not directly about actionability but methodologically rich for adaptation.  </p></li>
<li><p><strong>Operationalization Score:</strong> 78 – Clear steps, coding schemes, and protocols for mapping cognitive processes to PM actions.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We validated the PEM4PPM v2 model… describing the cognitive steps… their explanation, example statements, and detection method.” (p. 474–475)  </p></li>
<li><p>“The WWW strategy reflects the PEM4PPM v2 model by containing all its steps.” (p. 477)  </p></li>
<li><p>“The grades of analysts… using the WWW strategy are significantly higher than… other strategies.” (p. 478)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A – No cited works directly addressing actionability.</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Process Science: The Interdisciplinary Study of Continuous Change</p>

<p>Authors: Jan vom Brocke; Wil M.P. van der Aalst; Thomas Grisold; Waldemar Kremser; Jan Mendling; Brian Pentland; Jan Recker; Maximilian Roeglinger; Michael Rosemann; Barbara Weber</p>

<p>DOI: N/A</p>

<p>Year: 2021</p>

<p>Publication Type: Working Paper (SSRN preprint)</p>

<p>Discipline/Domain: Information Systems / Interdisciplinary (process studies)</p>

<p>Subdomain/Topic: Process science; discovery–explanation–intervention; digital trace data; interdisciplinarity</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 20</p>

<p>Operationalization Score: 25</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — stresses “impact,” “interventions,” and “instrumental value” but does not define actionability. Quotes below.</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes — Process Science framework (focus, objectives, perspectives)</p>

<p>Operationalization Present: Partial — outlines discovery, explanation, intervention phases</p>

<p>Primary Methodology: Conceptual</p>

<p>Study Context: Conceptual positioning of a new field (“process science”)</p>

<p>Geographic/Institutional Context: Multi-institutional international authorship</p>

<p>Target Users/Stakeholders: Researchers across disciplines; policy and practice communities aiming to influence processes</p>

<p>Primary Contribution Type: Conceptual positioning + high-level framework</p>

<p>CL: No</p>

<p>CR: Partial — discusses “impact” and societal challenges</p>

<p>FE: No</p>

<p>TI: No</p>

<p>EX: Partial — “Explanation” phase aims at understanding why/how processes unfold</p>

<p>GA: Partial — interventions are “based on an envisioned goal”</p>

<p>Reason if Not Eligible: The paper does not use or define “actionable/actionability” nor specify criteria of what makes knowledge “actionable”; it focuses on processes, impact, and interventions at a conceptual level.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Process Science: The Interdisciplinary Study of Continuous Change</p>

<p><strong>Authors:</strong>  </p>

<p>Jan vom Brocke; Wil M.P. van der Aalst; Thomas Grisold; Waldemar Kremser; Jan Mendling; Brian Pentland; Jan Recker; Maximilian Roeglinger; Michael Rosemann; Barbara Weber</p>

<p><strong>DOI:</strong>  </p>

<p>N/A</p>

<p><strong>Year:</strong>  </p>

<p>2021</p>

<p><strong>Publication Type:</strong>  </p>

<p>Working Paper (SSRN preprint)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Information Systems / Interdisciplinary (process studies)</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Process science; discovery–explanation–intervention; digital trace data; interdisciplinarity</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper proposes “process science” as a new interdisciplinary field centered on continuous change, leveraging digital trace data and cross-disciplinary methods to understand and influence processes. :contentReference[oaicite:0]{index=0}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>International, multi-institutional author team (Liechtenstein, Germany, Netherlands, USA, Australia). :contentReference[oaicite:1]{index=1}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Researchers across social, technical, environmental, political, economic, and human perspectives; practitioners seeking to shape unfolding processes. :contentReference[oaicite:2]{index=2}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual (field framing and framework articulation). :contentReference[oaicite:3]{index=3}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework and agenda for a new field (“process science”). :contentReference[oaicite:4]{index=4}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper introduces “process science” as an interdisciplinary field dedicated to studying coherent series of changes that unfold over time at multiple levels. The authors position processes—rather than objects—as the primary unit of analysis and argue for a process‑first perspective to understand contemporary phenomena. They outline three core activities of process science: discovery (capturing and describing processes via event/trace data), explanation (understanding how and why processes unfold), and intervention (shaping processes toward desired directions). A framework figure (page 4) summarizes the field’s focus, objectives, and perspectives, and tables describe activities, methods, and contributing disciplines. Process mining is highlighted as an exemplar that bridges data, theory, and practice. :contentReference[oaicite:5]{index=5}:contentReference[oaicite:6]{index=6}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes. The paper repeatedly emphasizes <em>impact</em> and <em>interventions</em> without defining “actionability.”  </p>

<ul>
<li><p>“Process science strives to make an impact… aims to produce knowledge that has instrumental value in solving real‑word problems.” :contentReference[oaicite:7]{index=7}  </p></li>
<li><p>“Intervention aims at changing processes as they unfold… design‑oriented research can generate prescriptions…” :contentReference[oaicite:8]{index=8}</p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicit: usefulness is equated with the ability to <strong>intervene</strong> in and <strong>influence</strong> processes based on causal–temporal understanding.  </p>

<blockquote>
  <p>“When we know why and how a specific process unfolds, we are better prepared to re‑direct and change it.” (p. 5) :contentReference[oaicite:9]{index=9}</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<p><em>(Implicitly inferred; the paper does not use “actionable.”)</em>  </p>

<ul>
<li><p>Property/Condition: <strong>Causal–temporal understanding enabling intervention</strong>  </p>

<p> &gt; “Explanation aims at understanding… how and why processes unfold… [which] enables predictions… and… interventions.” (p. 5) :contentReference[oaicite:10]{index=10}  </p></li>
<li><p>Property/Condition: <strong>Goal‑directed design of measures</strong>  </p>

<p> &gt; “Interventions are based on an envisioned goal… and can include one or many measures to interfere with how the process seems likely to unfold.” (p. 5) :contentReference[oaicite:11]{index=11}</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p><em>(Partial, via the process science activity model; not framed as “actionability.”)</em>  </p>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Process Science Activities (Discovery, Explanation, Intervention) — see Table 2 and the framework diagram (p. 4). :contentReference[oaicite:12]{index=12}  </p></li>
<li><p><strong>Methods/Levers:</strong> Event/trace data capture; process mining; qualitative sense‑making; design‑oriented research to develop and evaluate interventions. :contentReference[oaicite:13]{index=13}  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Capture processes (discovery) → explain cause‑effect relations and context (explanation) → design/evaluate interventions against goals (intervention). :contentReference[oaicite:14]{index=14}  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Time‑stamped “event data” from digital traces; complementary contextual data. :contentReference[oaicite:15]{index=15}  </p></li>
<li><p><strong>Implementation Context:</strong> Socio‑technical processes across human, social, environmental, political, economic, technological perspectives. :contentReference[oaicite:16]{index=16}  </p></li>
</ul>

<blockquote>
  <p>“Process science progresses by systematically making use of various and novel data sources… ‘event data’… to infer when they took place.” (p. 6) :contentReference[oaicite:17]{index=17}</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Partial — impact framed relative to societal challenges and goals.  </p>

<p> &gt; “In light of… grand challenges… process science should enable the development of effective solutions.” (p. 7) :contentReference[oaicite:18]{index=18}  </p></li>
<li><p><strong>FE (Feasibility):</strong> No  </p></li>
<li><p><strong>TI (Timeliness):</strong> No  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — “Explanation aims at understanding the dynamics of processes… identify cause–effect relations.” (p. 5) :contentReference[oaicite:19]{index=19}  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — “Interventions are based on an envisioned goal…” (p. 5) :contentReference[oaicite:20]{index=20}  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<p>Process‑first ontology; interdisciplinary synthesis; design science for intervention; routine and organizational process studies; computational social science; process mining. :contentReference[oaicite:21]{index=21}</p>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A.</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Fragmentation across disciplines; differing assumptions and methods. :contentReference[oaicite:22]{index=22}  </p></li>
<li><p><strong>Enablers:</strong> Ubiquity of digital trace data; event‑data infrastructures; cross‑disciplinary integration; process mining exemplars. :contentReference[oaicite:23]{index=23}</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper extends prior calls (e.g., van der Aalst &amp; Damiani; process organization studies) by elevating <em>process</em> as the central analytic lens, integrating methods from multiple disciplines, and emphasizing intervention for impact. It situates process mining as a mature exemplar for discovery/explanation and as a bridge from data to theory and practice. :contentReference[oaicite:24]{index=24}</p>

<hr />

<h2>Summary</h2>

<p>This conceptual paper inaugurates “process science,” advocating a shift from object‑first to process‑first thinking to understand and shape continuous change. The authors define a process as a coherent series of changes unfolding over time and argue that digital trace data enable unprecedented discovery of process dynamics. A triadic activity model—discovery, explanation, intervention—structures the field: capture processes via event data; explain causal–temporal mechanisms in context; and design interventions to steer processes toward goals. The framework is explicitly interdisciplinary, spanning human, social, environmental, political, economic, and technological perspectives, and positions process mining as an illustrative domain where data, methods, and theory converge. While the paper emphasizes impact and prescriptions through interventions, it does not define “actionability” or provide criteria for judging the actionability of knowledge; usefulness is implied through goal‑aligned interventions grounded in explained mechanisms. Consequently, its relevance to <em>actionability</em> rests on indirect alignment rather than explicit definition or metrics. :contentReference[oaicite:25]{index=25}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 20 — The paper does not mention or define “actionability” and offers no explicit criteria; relevance is indirect via intervention/impact framing.  </p></li>
<li><p><strong>Operationalization Score:</strong> 25 — Provides a high‑level workflow (discovery–explanation–intervention) and method exemplars (e.g., process mining, design science) but no concrete procedures or metrics tied to <em>actionability</em> per se.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Process science is the interdisciplinary study of continuous change.” (p. 3) :contentReference[oaicite:26]{index=26}  </p></li>
<li><p>“When we know why and how a specific process unfolds, we are better prepared to re‑direct and change it.” (p. 5) :contentReference[oaicite:27]{index=27}  </p></li>
<li><p>“Intervention aims at changing processes as they unfold… design‑oriented research can generate prescriptions…” (p. 5) :contentReference[oaicite:28]{index=28}  </p></li>
<li><p>“Process science strives to make an impact… instrumental value in solving real‑word problems.” (p. 7) :contentReference[oaicite:29]{index=29}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>The paper cites design science (Hevner et al., 2004; Van Aken, 2005) and process mining (van der Aalst, 2016; Augusto et al., 2018) as vehicles for intervention and discovery/explanation, but does not cite sources defining <em>actionability</em>. :contentReference[oaicite:30]{index=30}</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Improving Process Mining Maturity – From Intentions to Actions  </p>

<p>Authors: Jonathan Brock, Katharina Brennig, Bernd Löhr, Christian Bartelheimer, Sebastian von Enzberg, Roman Dumitrescu  </p>

<p>DOI: 10.1007/s12599-024-00882-7  </p>

<p>Year: 2024  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Business Process Management, Process Mining  </p>

<p>Subdomain/Topic: Maturity Models, Process Mining Adoption  </p>

<p>Eligibility: Yes  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 85  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Mixed Methods (Interviews and Model Development)  </p>

<p>Study Context: Business Process Management, Process Mining in Organizations  </p>

<p>Geographic/Institutional Context: International (Multiple Organizations)  </p>

<p>Target Users/Stakeholders: Process Mining Practitioners, Business Process Managers, BPM Consultants  </p>

<p>Primary Contribution Type: Conceptual Model Development, Practical Guidelines  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong> Improving Process Mining Maturity – From Intentions to Actions  </p>

<p><strong>Authors:</strong> Jonathan Brock, Katharina Brennig, Bernd Löhr, Christian Bartelheimer, Sebastian von Enzberg, Roman Dumitrescu  </p>

<p><strong>DOI:</strong> 10.1007/s12599-024-00882-7  </p>

<p><strong>Year:</strong> 2024  </p>

<p><strong>Publication Type:</strong> Journal  </p>

<p><strong>Discipline/Domain:</strong> Business Process Management, Process Mining  </p>

<p><strong>Subdomain/Topic:</strong> Maturity Models, Process Mining Adoption  </p>

<p><strong>Contextual Background:</strong> The paper addresses the growing need for a comprehensive framework to bridge the intention-action gap in process mining adoption within organizations. It develops a Process Mining Maturity Model (P3M) to assess and improve process mining readiness, based on factors like data foundation, organizational embedding, and people's knowledge. The model aims to guide organizations in optimizing their process mining activities by providing actionable insights for improvement.  </p>

<p><strong>Geographic/Institutional Context:</strong> The paper involves multiple organizations across various industries, with practical insights derived from eleven interviews.  </p>

<p><strong>Target Users/Stakeholders:</strong> Process mining practitioners, BPM consultants, business process managers  </p>

<p><strong>Primary Methodology:</strong> Mixed Methods (Interviews and Model Development)  </p>

<p><strong>Primary Contribution Type:</strong> Conceptual Model Development, Practical Guidelines  </p>

<h2>General Summary of the Paper</h2>

<p>The paper develops a multi-factor maturity model for process mining (P3M) to assist organizations in increasing their process mining readiness. The model consists of five factors and 23 elements, with five maturity stages. The authors conducted interviews with practitioners to identify actions that organizations can take to improve their process mining maturity. The research highlights how organizations can overcome common implementation challenges, such as lack of management support, poor data quality, and ineffective integration of process mining tools into existing processes. It provides both a theoretical framework and practical steps for organizations to enhance their process mining maturity and effectively manage process dynamics.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<p>Reason if Not Eligible: n/a  </p>

<h2>How Actionability is Understood</h2>

<p>Actionability is understood as the ability of organizations to successfully implement process mining through structured readiness assessments and the adoption of actionable improvement steps derived from the maturity model. The paper emphasizes that closing the gap between the intention to adopt process mining and the actual implementation requires practical guidance on how to enhance organizational capabilities and resources.  </p>

<blockquote>
  <p>“The process mining maturity model provides a roadmap for organizations to turn their intentions into actionable steps, ensuring that process mining can be implemented sustainably” (p. 3).  </p>
</blockquote>

<blockquote>
  <p>“Organizations need concrete actions that they can take to improve their readiness for process mining across the different maturity factors” (p. 11).</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<p>For process mining to be actionable, the authors identify several key factors that organizations must address:</p>

<ul>
<li><p>Organizational embedding of process mining initiatives  </p></li>
<li><p>Access to high-quality process and event data  </p></li>
<li><p>Knowledge and training for individuals involved in process mining  </p></li>
<li><p>Governance structures that support process mining implementation and scaling  </p></li>
</ul>

<blockquote>
  <p>“The organizational embedding of process mining is a key success factor that enables actionability within organizations” (p. 11).  </p>
</blockquote>

<blockquote>
  <p>“Data accessibility, quality, and governance are fundamental prerequisites for actionable process mining” (p. 14).</p>
</blockquote>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<p>The actionability of process mining is achieved by:</p>

<ul>
<li><p>Developing a maturity model (P3M) that organizations can use to assess and improve their process mining readiness  </p></li>
<li><p>Providing a structured process to guide organizations through various stages of process mining adoption  </p></li>
<li><p>Conducting workshops and surveys to help organizations identify gaps and improvement areas in their process mining activities  </p></li>
<li><p>Offering practical actions, based on real-world interviews, that organizations can implement to increase their process mining maturity  </p></li>
</ul>

<blockquote>
  <p>“The maturity model is applied through an online survey and workshop, which helps organizations identify their current maturity and set a roadmap for improvement” (p. 12).  </p>
</blockquote>

<blockquote>
  <p>“The maturity model helps organizations understand where they are in their process mining journey and provides tailored actions for advancing their maturity” (p. 12).</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – Actionable knowledge must be clearly communicated, especially in terms of the steps needed to improve process mining maturity.  </p>

<p> &gt; “Clarity in the purpose and scope of the process mining initiative is essential for ensuring that actions are understandable and actionable” (p. 9).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – Actions must be relevant to the specific organizational context and tailored to the challenges each organization faces.  </p>

<p> &gt; “Actions should be customized based on the organization’s specific needs and readiness” (p. 14).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – The actions identified must be feasible given the resources and capabilities of the organization.  </p>

<p> &gt; “Organizations should prioritize actions that are both feasible and have the potential to create significant improvements in process mining maturity” (p. 11).  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes – Timely action is necessary to ensure that process mining initiatives can evolve as needed to address dynamic business process changes.  </p>

<p> &gt; “Organizations should not wait for perfect data or conditions but should take pragmatic steps to begin improving their process mining maturity” (p. 13).  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – Actionable steps must be easily understandable and justifiable for stakeholders across the organization.  </p>

<p> &gt; “Providing clear documentation and communication about process mining initiatives ensures that they are understood by all stakeholders” (p. 12).  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – Actions must be aligned with organizational goals and strategies, ensuring that process mining efforts contribute to broader business objectives.  </p>

<p> &gt; “Process mining initiatives must align with organizational goals, such as improving efficiency and flexibility, to be truly actionable” (p. 10).</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<p>The development of the P3M is based on existing BPM maturity models, particularly those focused on capability maturity in business process management (Rosemann and De Bruin, 2005b; Kerpedzhiev et al., 2021). The authors also draw on insights from process mining and data science to create a comprehensive model that includes both technical and organizational factors.  </p>

<blockquote>
  <p>“The P3M model synthesizes best practices from BPM maturity models, adapting them to the context of process mining and addressing both technical and organizational aspects” (p. 9).</p>
</blockquote>

<h2>Indicators or Metrics for Actionability</h2>

<p>The P3M model provides five maturity stages (Initial, Rudimentary, Standalone, Systematic, Optimizing) for each of the 23 elements across the five factors, enabling organizations to assess their current state and identify specific actions to improve their process mining readiness.  </p>

<blockquote>
  <p>“The maturity stages offer clear indicators of progress, allowing organizations to track their improvements and identify areas where action is needed” (p. 10).</p>
</blockquote>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of management support, poor data quality, insufficient organizational embedding of process mining initiatives  </p></li>
<li><p><strong>Enablers:</strong> Dedicated process mining teams, collaboration across business units, management support, structured maturity assessments  </p></li>
</ul>

<blockquote>
  <p>“Organizational embedding is a key enabler for process mining success, but without management buy-in, the initiative may struggle to gain traction” (p. 12).  </p>
</blockquote>

<blockquote>
  <p>“Data quality and accessibility are frequent barriers that need to be addressed early in the process mining implementation” (p. 13).</p>
</blockquote>

<h2>Relation to Existing Literature</h2>

<p>The paper builds on prior work in process mining and BPM maturity models, extending these frameworks by incorporating elements specific to the challenges of process mining adoption. It positions the P3M model as a solution to the intention-action gap identified in previous research, offering actionable steps for organizations to improve their process mining maturity.  </p>

<blockquote>
  <p>“This paper extends the concept of BPM maturity by integrating process mining-specific factors and providing actionable insights for organizations” (p. 14).</p>
</blockquote>

<h2>Summary</h2>

<p>The paper introduces a Process Mining Maturity Model (P3M), a framework that helps organizations assess and improve their process mining readiness. Through a detailed analysis of 23 elements across five factors, the model provides a structured approach for organizations to close the intention-action gap in process mining adoption. The authors also identify 30 actions, derived from real-world interviews, that organizations can take to improve their maturity and effectively manage process dynamics. The model and actions presented provide valuable guidance for organizations looking to enhance their process mining capabilities.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 – The paper provides a comprehensive, actionable framework for improving process mining maturity, addressing a significant gap in the current literature.  </p></li>
<li><p><strong>Operationalization Score:</strong> 85 – The maturity model is clearly operationalized through real-world actions and assessment tools, offering practitioners tangible steps for improvement.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“The process mining maturity model provides a roadmap for organizations to turn their intentions into actionable steps” (p. 3).  </p></li>
<li><p>“Organizations should prioritize actions that are both feasible and have the potential to create significant improvements in process mining maturity” (p. 11).  </p></li>
<li><p>“Actions should be customized based on the organization’s specific needs and readiness” (p. 14).  </p></li>
<li><p>“Clarity in the purpose and scope of the process mining initiative is essential for ensuring that actions are understandable and actionable” (p. 9).</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Reinkemeyer L, Grindemann P, Egli V, et al. (2022). Accelerating business transformation with a process mining center of excellence.  </p></li>
<li><p>Rosemann M, De Bruin T (2005b). Towards a business process management maturity model.  </p></li>
<li><p>Kerpedzhiev GD, Ko¨nig UM, Ro¨glinger M, Rosemann M (2021). An exploration into future business process management capabilities in view of digitalization.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Identifying Process Improvement Opportunities through Process Execution Benchmarking</p>

<p>Authors: Luka Abb, Majid Rafiei, Timotheus Kampik, Jana-Rebecca Rehse</p>

<p>DOI: arXiv:2504.16215v1</p>

<p>Year: 2025</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Process Mining / Business Process Management</p>

<p>Subdomain/Topic: Process Execution Benchmarking; Process Improvement; Activity Replacement</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 88</p>

<p>Operationalization Score: 90</p>

<p>Actionable/Actionability Used in Paper: Yes – “identifies actionable [23, 30] process changes expected to improve process performance” (p. 2)</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes – “provide concrete improvement suggestions… serve as evidence-based decision support” (p. 2)</p>

<p>Contains Definition of Actionability: Partial – framed as “concrete process modifications… expected to improve performance” (p. 14)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual + Evaluation (synthetic data + case study)</p>

<p>Study Context: Process execution benchmarking using event logs for process improvement</p>

<p>Geographic/Institutional Context: University of Mannheim; SAP Signavio</p>

<p>Target Users/Stakeholders: Process managers; business process analysts</p>

<p>Primary Contribution Type: Technique/method development with evaluation</p>

<p>CL: Yes – “list… can be presented to a process manager, who can… select the most promising changes” (p. 10)</p>

<p>CR: Yes – “same process type… comparable event logs” (p. 5)</p>

<p>FE: Yes – feasibility score computation (p. 9)</p>

<p>TI: No</p>

<p>EX: Partial – uses behavioral footprints to justify replacement plausibility</p>

<p>GA: Yes – align process changes to performance improvement goals (p. 2)</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Identifying Process Improvement Opportunities through Process Execution Benchmarking  </p>

<p><strong>Authors:</strong>  </p>

<p>Luka Abb, Majid Rafiei, Timotheus Kampik, Jana-Rebecca Rehse  </p>

<p><strong>DOI:</strong>  </p>

<p>arXiv:2504.16215v1  </p>

<p><strong>Year:</strong>  </p>

<p>2025  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Process Mining / Business Process Management  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Process Execution Benchmarking; Process Improvement; Activity Replacement  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses a gap in commercial process mining tools, which allow benchmarking via high-level performance indicators but do not recommend concrete improvement actions. It proposes a prescriptive technique that compares “own” and “benchmark” event logs to identify plausible activity replacements, assess feasibility, and estimate performance impact.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of Mannheim; SAP Signavio, Berlin, Germany  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process managers, business process analysts, BPM practitioners  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework development with evaluation using synthetic data and a real-life case study  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Prescriptive technique for automated process improvement recommendations  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper introduces a prescriptive process execution benchmarking technique that identifies specific, plausible process modifications to improve performance by comparing event logs from an organization’s own process and a benchmark process. Unlike descriptive approaches that visualize differences, this method produces a ranked list of activity replacements, each evaluated for feasibility and performance impact. The technique involves computing behavioral footprints, matching activities across logs, combining compatible replacements, and quantifying feasibility and performance improvements. An evaluation using synthetic data shows high precision and recall in identifying true replacements, with higher feasibility scores than random baselines. A case study with SAP Signavio purchasing process data demonstrates practical applicability, revealing both beneficial and detrimental modifications.  </p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>Yes.  </p>

<ul>
<li><p>“Identifies actionable [23, 30] process changes expected to improve process performance.” (p. 2)  </p></li>
<li><p>“Concrete improvement suggestions… provided to a process manager.” (p. 2)  </p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes.  </p>

<ul>
<li>“Provide concrete improvement suggestions… serve as evidence-based decision support for process improvement initiatives.” (p. 2)  </li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicit definition: Actionable changes are “concrete process modifications… expected to improve performance” and “behaviorally plausible… with feasibility and performance measures” (pp. 2, 14).  </p>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Concrete and implementable:</strong>  </p>

<p> &gt; “Behaviorally plausible process modifications… associated with a feasibility and performance assessment” (p. 5)  </p></li>
<li><p><strong>Evidence-based:</strong>  </p>

<p> &gt; “Empirical evidence from the benchmark log” (p. 9)  </p></li>
<li><p><strong>Performance-oriented:</strong>  </p>

<p> &gt; “Indicating the potential benefits of the change” (p. 10)  </p></li>
<li><p><strong>Contextually relevant:</strong>  </p>

<p> &gt; “Same process type… standardized activity names” (p. 5)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Process Execution Benchmarking Technique  </p></li>
<li><p><strong>Methods/Levers:</strong> Behavioral footprint analysis, activity matching, compatibility graph, feasibility and performance impact scoring  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Compute behavioral footprints  </p>

<p> 2. Match activities between logs  </p>

<p> 3. Combine compatible matches  </p>

<p> 4. Assess feasibility (alignment-based similarity)  </p>

<p> 5. Assess performance impact (performance metric differences)  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Event logs with standardized activity names and performance metrics; edit similarity; throughput time differences  </p></li>
<li><p><strong>Implementation Context:</strong> Demonstrated in synthetic experiments and a case study with SAP purchasing process logs  </p>

<p> &gt; “Outputs a list of process changes… can be filtered, prioritized, and selected” (p. 10)  </p></li>
</ul>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – list output is explicit and manager-ready (p. 10)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – limited to same process type with comparable logs (p. 5)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – feasibility score methodology (p. 9)  </p></li>
<li><p><strong>TI (Timeliness):</strong> No – no explicit reference to recency or urgency  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial – uses behavioral footprints as justifications (p. 6)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – aligned to performance improvement (p. 2)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> None explicitly  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Behavioral relations in process mining  </p></li>
<li><p>Benchmarking theory  </p></li>
<li><p>Action-oriented process mining ([23], [30])  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Feasibility score (0–1 scale)  </p></li>
<li><p>Expected performance impact (e.g., hours gained/lost per case)  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Regulatory constraints may prevent implementing certain changes (p. 11)  </p>

<p> - Noise and incompleteness in event logs (p. 12)  </p>

<p> - Dissimilarity between compared processes (p. 11)  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Standardized activity names and process types (p. 5)  </p>

<p> - Availability of comparable performance metrics (p. 5)  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on process mining literature by moving from descriptive variant comparison to prescriptive, performance-linked recommendations. Related to action-oriented process mining (Park &amp; van der Aalst) and process model matching but focused on event log–based execution data rather than reference models.  </p>

<hr />

<h2>Summary</h2>

<p>This paper proposes a prescriptive method for process execution benchmarking, extending traditional performance indicator benchmarking to concrete process improvement recommendations. By comparing “own” and “benchmark” event logs of the same process type, the technique identifies activity replacements that are both behaviorally plausible and empirically supported. Each recommendation is assessed for feasibility (based on trace alignment similarity) and potential performance gain (based on performance metric differences). The approach is operationalized through a structured five-step workflow and validated via synthetic log experiments and a case study using SAP Signavio purchasing process data. This work contributes to making process mining results more actionable by providing evidence-based, context-relevant, and performance-oriented change suggestions, moving from “all talk” insights to concrete implementation opportunities.  </p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 – Strong alignment with actionability in process improvement, explicit operationalization, partial conceptual definition  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 – Clear, stepwise method to generate actionable recommendations from data  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Identifies actionable [23, 30] process changes expected to improve process performance.” (p. 2)  </p></li>
<li><p>“Outputs a list of process changes… can be filtered, prioritized, and selected.” (p. 10)  </p></li>
<li><p>“Behaviorally plausible process modifications… associated with a feasibility and performance assessment.” (p. 5)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>[23] Park, G., van der Aalst, W.M.P. (2022). Action-oriented process mining: bridging the gap between insights and actions.  </p></li>
<li><p>[30] Stein Dani, V., Leopold, H., van der Werf, J.M.E.M., Beerepoot, I., Reijers, H.A. (2024). From process mining insights to process improvement: All talk and no action?</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: From Process Mining Insights to Process Improvement: All Talk and No Action?</p>

<p>Authors: Vinicius Stein Dani, Henrik Leopold, Jan Martijn E. M. van der Werf, Iris Beerepoot, Hajo A. Reijers</p>

<p>DOI: https://doi.org/10.1007/978-3-031-46846-9_15</p>

<p>Year: 2024</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Business Process Management / Process Mining</p>

<p>Subdomain/Topic: Process improvement; Insights-to-action translation; Systematic literature review</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 85</p>

<p>Operationalization Score: 70</p>

<p>Actionable/Actionability Used in Paper: Yes – implicit notion of actionability throughout; focus on “translating process mining insights into process improvement” and identifying “realm of actions” that organizations can take.</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes – “understanding this realm of actions is a valuable aspect to complement existing process mining methodologies… organizations can more easily identify the best path toward process improvement.” (p. 276)</p>

<p>Contains Definition of Actionability: No – implicit understanding as the ability to trigger specific, feasible improvement actions from insights.</p>

<p>Contains Systematic Features/Dimensions: Yes – implicitly through intervention spaces and action categories.</p>

<p>Contains Explainability: Partial – discussed in terms of clarifying/justifying conduct, root-cause analysis.</p>

<p>Contains Interpretability: Partial – linked to understanding process models and insights for improvement.</p>

<p>Contains Framework/Model: Yes – taxonomy of actions, intervention spaces, themes.</p>

<p>Operationalization Present: Yes – action categories linked to specific process mining insights and contexts.</p>

<p>Primary Methodology: Systematic Literature Review</p>

<p>Study Context: 57 process mining application case studies from multiple domains.</p>

<p>Geographic/Institutional Context: Global; cases from various industries and countries.</p>

<p>Target Users/Stakeholders: Process mining practitioners, consultants, managers, researchers.</p>

<p>Primary Contribution Type: Taxonomy of actions linked to process mining insights; intervention space model.</p>

<p>CL: Yes – clarity of actions and intervention spaces (e.g., “update documentation”, “create alert”).</p>

<p>CR: Yes – actions tied to process mining contexts and real-life case studies.</p>

<p>FE: Partial – feasibility implied through real-world recommendations but not systematically assessed.</p>

<p>TI: No – timeliness not explicitly discussed.</p>

<p>EX: Partial – explainability through root-cause analysis and justifications.</p>

<p>GA: Yes – goal alignment implied in linking insights to improvement goals.</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>From Process Mining Insights to Process Improvement: All Talk and No Action?  </p>

<p><strong>Authors:</strong>  </p>

<p>Vinicius Stein Dani, Henrik Leopold, Jan Martijn E. M. van der Werf, Iris Beerepoot, Hajo A. Reijers  </p>

<p><strong>DOI:</strong>  </p>

<p><a href="https://doi.org/10.1007/978-3-031-46846-9_15">https://doi.org/10.1007/978-3-031-46846-9_15</a>  </p>

<p><strong>Year:</strong>  </p>

<p>2024  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Business Process Management / Process Mining  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Process improvement; Insights-to-action translation; Systematic literature review  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>Process mining produces rich process insights, but the link between those insights and actual process improvements is poorly understood. This paper systematically examines case studies to map the range of actions organizations take (or recommend) based on process mining results.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Global scope – case studies from various industries and regions.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process mining practitioners, consultants, managers, and academic researchers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Systematic Literature Review (57 case studies).  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Taxonomy of actions and intervention spaces, linking process mining insights to improvement strategies.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper addresses the gap between process mining insights and their translation into actual process improvements. Through a systematic literature review of 57 case studies, the authors categorize 156 quotes into 226 action codes, producing a taxonomy of actions organized into three main themes: (i) supporting process understanding and documentation, (ii) improving the involved information system, and (iii) improving the investigated process. Actions span multiple intervention spaces, from updating documentation and training staff to automating system features and redesigning processes. The study highlights a many-to-many relationship between insights and actions, as well as a gap between recommended and performed actions. The contribution is a structured “realm of actions” that can complement existing process mining methodologies and guide practitioners in planning post-insight interventions.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>Yes – The notion of actionability is central, though not explicitly defined. Examples:  </p>

<ul>
<li><p>“Understanding the diversity of the actions triggered by process mining insights is important to instigate future research on… translating process mining insights into process improvement.” (p. 275)  </p></li>
<li><p>“Organizations can more easily identify the best path toward process improvement.” (p. 276)  </p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes –  </p>

<blockquote>
  <p>“Understanding this realm of actions is a valuable aspect to complement existing process mining methodologies.” (p. 276)  </p>
</blockquote>

<blockquote>
  <p>“By understanding which actions… organizations can more easily identify the best path toward process improvement.” (p. 276)  </p>
</blockquote>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly understood as the <strong>ability to convert process mining insights into concrete, feasible improvement actions</strong> targeting processes, systems, documentation, communication, or training.</p>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Clear linkage to an insight</strong>:  </p>

<p> &gt; “We investigate which types of actions… and to which insights these actions are linked.” (p. 275)  </p></li>
<li><p><strong>Feasibility</strong>:  </p>

<p> &gt; “The recommendations are made by experienced professionals in the field and… can be considered as feasible.” (p. 281)  </p></li>
<li><p><strong>Targeted intervention</strong>:  </p>

<p> &gt; “The aspects of the organization that are affected by the actions… may not only concern the process itself.” (p. 276)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Not named as a formal framework, but delivers a taxonomy of actions.</p></li>
<li><p><strong>Methods/Levers:</strong> Inductive content analysis, open coding of case study reports.</p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify insights → extract related quotes → code into verb-object pairs → categorize into intervention spaces and themes.</p></li>
<li><p><strong>Data &amp; Measures:</strong> 156 quotes from 57 papers; coded into 226 actions.</p></li>
<li><p><strong>Implementation Context:</strong> Process mining application case studies across industries.</p></li>
</ul>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – Action descriptions are precise (e.g., “update documentation”, “create alert”).</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – Actions tied to specific insights in real-world contexts.</p></li>
<li><p><strong>FE (Feasibility):</strong> Partial – Feasibility implied from professional recommendations.</p></li>
<li><p><strong>TI (Timeliness):</strong> No – Timeliness not addressed.</p></li>
<li><p><strong>EX (Explainability):</strong> Partial – Root-cause and justification actions.</p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – Actions linked to improvement goals.</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Process mining methodologies (e.g., PM2, L*, Process Diagnostics Methodology) as baseline references.</p></li>
<li><p>Intervention space taxonomy.</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>None explicitly stated; implied through linkage between insights and feasible actions.</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Gap between recommended and taken actions (p. 287), possible effort constraints.</p></li>
<li><p><strong>Enablers:</strong> Experienced practitioner recommendations; multi-faceted intervention spaces.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds upon process mining methodologies and prior studies linking insights to process awareness and improvement. Extends these by cataloging concrete actions from real-world applications.</p>

<hr />

<h2>Summary</h2>

<p>This paper examines the critical yet underexplored link between process mining insights and tangible process improvements. Through a systematic review of 57 case studies, the authors identify and classify a diverse set of actions into three overarching themes and multiple intervention spaces, spanning from technical system changes to process redesign, documentation updates, and staff training. The study highlights the complexity of the insight-action relationship, with many-to-many mappings and frequent gaps between recommended and executed actions. The resulting taxonomy serves as a practical guide for practitioners to plan improvement initiatives and complements existing methodologies by explicitly addressing the post-insight phase. While no formal definition of “actionability” is given, the paper implicitly frames it as the capacity to derive feasible, targeted actions from insights.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 – Strong alignment with actionability as the translation of insights into actions, supported by systematic evidence; lacks explicit definition.</p></li>
<li><p><strong>Operationalization Score:</strong> 70 – Provides detailed taxonomy and examples but not formalized into a replicable framework for other contexts.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Understanding this realm of actions is a valuable aspect to complement existing process mining methodologies.” (p. 276)  </p></li>
<li><p>“We investigate which types of actions… and to which insights these actions are linked.” (p. 275)  </p></li>
<li><p>“The recommendations are made by experienced professionals in the field and… can be considered as feasible.” (p. 281)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>PM2 methodology (van Eck et al., 2015)  </p></li>
<li><p>Process Diagnostics Methodology (Bozkaya et al., 2009)  </p></li>
<li><p>L* lifecycle model (van der Aalst, 2011)  </p></li>
<li><p>Lashkevich et al. (2023) – analysis template for improvement opportunities  </p></li>
<li><p>Eggers et al. (2021) – process awareness mechanisms</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: From Loss of Interest to Denial: A Study on the Terminators of Process Mining Initiatives  </p>

<p>Authors: Vinicius Stein Dani, Henrik Leopold, Jan Martijn E. M. van der Werf, Iris Beerepoot, Hajo A. Reijers  </p>

<p>DOI: https://doi.org/10.1007/978-3-031-61057-8_22  </p>

<p>Year: 2024  </p>

<p>Publication Type: Conference  </p>

<p>Discipline/Domain: Information Systems / Business Process Management  </p>

<p>Subdomain/Topic: Process Mining, Process Improvement, Implementation Barriers  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 80  </p>

<p>Operationalization Score: 70  </p>

<p>Actionable/Actionability Used in Paper: Yes – “organizations actually need to take action based on the insights process mining tools and techniques provide” (p. 371); “recommended actions… need to be performed and implemented” (p. 371)  </p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes – “If… recommended actions are not performed, the insights will not help organizations to progress into process improvement” (p. 371)  </p>

<p>Contains Definition of Actionability: No  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial – explanation of causes for non-action  </p>

<p>Contains Interpretability: No  </p>

<p>Contains Framework/Model: Yes – categorization of terminators into three dimensions (Data, Project, Insights)  </p>

<p>Operationalization Present: Yes – systematic literature review and interview-based identification of causes blocking actionable follow-up  </p>

<p>Primary Methodology: Mixed Methods (Systematic Literature Review + Semi-structured Interviews)  </p>

<p>Study Context: Process mining initiatives in various industries  </p>

<p>Geographic/Institutional Context: Global – experts from four continents, majority from large organizations  </p>

<p>Target Users/Stakeholders: Process mining experts, business analysts, managers, transformation consultants, product owners  </p>

<p>Primary Contribution Type: Empirical study of barriers to translating insights into actions  </p>

<p>CL: Yes – Implicit in recommendations that clarity of actionable steps is required  </p>

<p>CR: Yes – Insights tied to specific organizational contexts  </p>

<p>FE: Yes – Feasibility hindered by data, incentive, and expertise issues  </p>

<p>TI: No – Timeliness not explicitly discussed as a dimension  </p>

<p>EX: Partial – Explanation of why actions fail is central, but not formalized as an attribute of actionability  </p>

<p>GA: Yes – Goal alignment issues present where stakeholders lack incentive or deny insights  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>From Loss of Interest to Denial: A Study on the Terminators of Process Mining Initiatives  </p>

<p><strong>Authors:</strong>  </p>

<p>Vinicius Stein Dani, Henrik Leopold, Jan Martijn E. M. van der Werf, Iris Beerepoot, Hajo A. Reijers  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1007/978-3-031-61057-8_22  </p>

<p><strong>Year:</strong>  </p>

<p>2024  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Information Systems / Business Process Management  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Process Mining, Process Improvement, Implementation Barriers  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the gap between generating process mining insights and implementing actions based on them. It identifies why organizations fail to progress from recommended to performed actions, categorizing these “terminators” into data, project, and insight-related causes.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Global – interviewees from four continents, mostly large organizations (&gt;1,000 employees).  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process mining experts, business analysts, managers, transformation consultants, product owners.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed Methods – Systematic Literature Review (57 papers) + 17 Semi-structured Interviews.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical analysis of causes blocking actionable follow-up on process mining recommendations.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This study explores why recommended actions derived from process mining insights often fail to be implemented. Using a systematic literature review of 57 case-based papers and 17 expert interviews, the authors quantify the extent of performed actions and uncover reasons for inaction. They identify five main “terminators” – laborious data preparation, loss of interest, lack of expertise, lack of incentive, and denial of insights – and classify them into three overarching dimensions: data-related, project-related, and insight-related. The findings highlight how technical, organizational, and psychological factors interact to stall process improvement efforts. Recommendations include streamlining data preparation, ensuring the involvement of decision-makers with end-to-end process authority, and creating stakeholder incentives for action.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>Yes</strong>  </p>

<ul>
<li><p>“Organizations actually need to take action based on the insights process mining tools and techniques provide.” (p. 371)  </p></li>
<li><p>“Analysts typically use process mining insights to recommend actions, which then need to be performed and implemented.” (p. 371)  </p></li>
<li><p>“If… recommended actions are not performed, the insights will not help organizations to progress into process improvement.” (p. 371)  </p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>Yes</strong>  </p>

<ul>
<li><p>“If… recommended actions are not performed, the insights will not help organizations to progress into process improvement either.” (p. 371)  </p></li>
<li><p>“We need to develop a better understanding of… the causes hampering the progress from recommended to performed actions.” (p. 372)  </p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly framed as the transition from <strong>recommended actions</strong> (derived from process mining insights) to <strong>performed actions</strong> that lead to process improvement.</p>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Requires clear recommendations linked to insights</strong>  </p>

<p> &gt; “Analysts typically use the insights to recommend actions, which then need to be performed… by process owners or management.” (p. 371)  </p></li>
<li><p><strong>Feasibility in terms of data accessibility and preparation</strong>  </p>

<p> &gt; “Laborious data preparation… making data preparation… too long [and] the project was eventually stopped.” (p. 377)  </p></li>
<li><p><strong>Stakeholder interest and priority</strong>  </p>

<p> &gt; “There were more important projects to deal with… stakeholders ended up losing interest.” (p. 378)  </p></li>
<li><p><strong>Availability of expertise to implement changes</strong>  </p>

<p> &gt; “The organization did not have the expertise to make the required changes… and did not want to invest in a consultant.” (p. 380)  </p></li>
<li><p><strong>Alignment with stakeholder incentives</strong>  </p>

<p> &gt; “No action was taken… there was no financial incentive… implementing the action would result in decreased income.” (p. 378)  </p></li>
<li><p><strong>Acceptance of insights</strong>  </p>

<p> &gt; “Preferred to say they do not believe process mining results rather than to admit they were wrong.” (p. 379)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> None named specifically; operationalization via combined SLR and interviews.  </p></li>
<li><p><strong>Methods/Levers:</strong> Identification of recommended vs performed actions, categorization by type of insight (data quality, wait time, rework, discovered process, compliance).  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Data collection → open coding → categorization → synthesis of causes.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> 57 peer-reviewed papers; 17 interview transcripts; coding of recommended/performed actions.  </p></li>
<li><p><strong>Implementation Context:</strong> Multiple industries and geographies.  </p></li>
</ul>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – Recommendations need to be clearly defined for execution (implied).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – Actions linked to specific organizational process contexts.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – Often hindered by data, resource, and complexity barriers.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No – Not explicitly covered.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial – Paper explains reasons for inaction but does not frame explainability as an attribute.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – Misaligned incentives and denial hinder action.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li>Categorization of causes into three dimensions: Data, Project, Insights (proposed model in Fig. 2).  </li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>None explicitly proposed; indirectly assessed through ratio of recommended to performed actions.</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Laborious data preparation (p. 377–378)  </p>

<p> - Loss of interest (p. 378–379)  </p>

<p> - Lack of expertise (p. 378–380)  </p>

<p> - Lack of incentive (p. 378–380)  </p>

<p> - Denial of insights (p. 379)  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Involvement of decision-makers with end-to-end authority (p. 382)  </p>

<p> - Financial incentives aligned with proposed changes (p. 382)  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on prior studies that linked process mining insights to actions but did not differentiate recommended vs performed actions (e.g., Stein Dani et al., 2023; Emamjome et al., 2019). Extends literature by systematically identifying and categorizing causes of non-action.</p>

<hr />

<h2>Summary</h2>

<p>This paper examines why process mining recommendations often fail to result in implemented actions. Through a systematic review of 57 papers and 17 expert interviews, the authors find that many case studies focus on recommended actions without tracking whether they were carried out. They classify five “terminators” into three categories: data issues (laborious preparation), project factors (loss of interest, lack of expertise), and insight-related issues (lack of incentive, denial). The findings show that feasibility, incentives, and organizational buy-in are critical to turning insights into tangible improvements. The study offers both diagnostic and prescriptive value—diagnosing why process mining initiatives stall, and recommending improved data handling, higher-level managerial involvement, and incentive alignment to ensure follow-through. While the paper stops short of formalizing an actionability definition, it implicitly frames it as the capacity to move from recommended to performed actions that yield process improvement.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 80 – Strong conceptual link to actionability through focus on converting insights into actions; lacks explicit definition.  </p></li>
<li><p><strong>Operationalization Score:</strong> 70 – Provides structured methodology to identify barriers but no detailed prescriptive framework for ensuring actionability.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Organizations actually need to take action based on the insights process mining tools and techniques provide.” (p. 371)  </p></li>
<li><p>“If… recommended actions are not performed, the insights will not help organizations to progress into process improvement.” (p. 371)  </p></li>
<li><p>“Laborious data preparation… and the project was eventually stopped.” (p. 377)  </p></li>
<li><p>“No financial incentive… implementing the action would result in decreased income.” (p. 378)  </p></li>
<li><p>“Preferred to say they do not believe process mining results rather than to admit they were wrong.” (p. 379)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Emamjome et al. (2019) – Lack of practical implementation of insights hindering results.  </p></li>
<li><p>Stein Dani et al. (2023) – Link between process mining insights and types of actions.  </p></li>
<li><p>PM2 and Process Diagnostics methodologies – Recognize but exclude implementation from scope.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Explaining Change with Digital Trace Data: A Framework for Temporal Bracketing</p>

<p>Authors: Sophie Hartl, Sandro Franzoi, Thomas Grisold, Jan vom Brocke</p>

<p>DOI: 10.24251/HICSS.2023.689</p>

<p>Year: 2023</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Information Systems / Process Mining</p>

<p>Subdomain/Topic: Temporal bracketing, digital trace data, organizational change, computationally intensive theorizing</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 30</p>

<p>Operationalization Score: 40</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual with illustrative case study</p>

<p>Study Context: Customer onboarding process in a financial institution in Central Europe</p>

<p>Geographic/Institutional Context: Central Europe; financial institution</p>

<p>Target Users/Stakeholders: Researchers in process mining, computationally intensive theorizing, and organizational change; business process analysts</p>

<p>Primary Contribution Type: Conceptual framework + applied case illustration</p>

<p>CL: No</p>

<p>CR: No</p>

<p>FE: No</p>

<p>TI: No</p>

<p>EX: No</p>

<p>GA: No</p>

<p>Reason if Not Eligible: The paper does not address actionability, actionable insights, recommendations, or knowledge. Its framework focuses on integrating context into digital trace data analysis through temporal bracketing to explain change, without conceptualizing or defining actionability.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Explaining Change with Digital Trace Data: A Framework for Temporal Bracketing  </p>

<p><strong>Authors:</strong>  </p>

<p>Sophie Hartl, Sandro Franzoi, Thomas Grisold, Jan vom Brocke  </p>

<p><strong>DOI:</strong>  </p>

<p>10.24251/HICSS.2023.689  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Information Systems / Process Mining  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Temporal bracketing, digital trace data, organizational change, computationally intensive theorizing  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the challenge of explaining why and how organizational change occurs when studying digital trace data, which often lack contextual information. The authors propose a four-step framework for applying temporal bracketing in computationally intensive theorizing, combining human and computational sensemaking. An onboarding process at a financial institution in Central Europe serves as the illustrative case.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Central Europe; financial institution  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Researchers in process mining, computational theory development, and organizational change; business process improvement practitioners  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework + illustrative case study  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework for integrating context into digital trace data analysis to explain change  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper introduces a framework for applying temporal bracketing to digital trace data to explain organizational change by integrating contextual information. Temporal bracketing divides a process into discrete, connected stages (brackets) to examine changes over time. The proposed framework comprises four steps: data preparation, identification of brackets, analysis and sensemaking, and validation and evaluation—each using human and computational sensemaking in a recursive, iterative manner. An illustrative case analyzes the onboarding process of a financial institution, identifying change periods, measuring impacts on process performance, and demonstrating the value of integrating context with computational analysis. The paper concludes with theoretical and practical implications, limitations, and avenues for future research.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> No</p></li>
<li><p><strong>FE (Feasibility):</strong> No</p></li>
<li><p><strong>TI (Timeliness):</strong> No</p></li>
<li><p><strong>EX (Explainability):</strong> No</p></li>
<li><p><strong>GA (Goal Alignment):</strong> No</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Temporal bracketing (Langley, 1999)</p></li>
<li><p>Computationally intensive theorizing (Berente et al., 2019; Miranda et al., 2022)</p></li>
<li><p>Sensemaking (Weick, 1995; Sandberg &amp; Tsoukas, 2020)</p></li>
<li><p>Process mining (van der Aalst, 2016)</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p>N/A</p>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper situates temporal bracketing within the broader movement of computationally intensive theorizing, integrating insights from qualitative process research and computational analysis. It references works in process mining, sensemaking, and digital trace data research, aiming to bridge methodological gaps in integrating context with large-scale digital process data.</p>

<hr />

<h2>Summary</h2>

<p>This paper addresses the gap in integrating contextual understanding into digital trace data research when explaining organizational change. It proposes a four-step temporal bracketing framework—data preparation, identification of brackets, analysis and sensemaking, and validation/evaluation—emphasizing recursive use of human and computational sensemaking. Illustrated through a financial institution’s onboarding process, the framework identifies key change periods, analyzes process metrics, and validates findings through qualitative insights. While it provides a systematic method for incorporating context into computational analyses, it does not address or conceptualize "actionability" as understood in actionable insights or recommendations research. The contribution lies in methodological guidance for temporal bracketing in digital trace data studies, offering value to researchers and practitioners aiming to understand process changes over time.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 30 — The paper offers a clear framework for integrating context into data analysis, but it does not define or engage with the concept of actionability.</p></li>
<li><p><strong>Operationalization Score:</strong> 40 — Presents a detailed, step-by-step operational framework for temporal bracketing in digital trace data analysis, but unrelated to actionability.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We conceptualize a framework to apply temporal bracketing in the analysis of digital trace data.” (p. 2)  </p></li>
<li><p>“At the center of our framework are four recursively related steps – (1) data preparation, (2) identification of brackets, (3) analysis and sensemaking, and (4) evaluation and validation.” (p. 2)  </p></li>
<li><p>“Temporal bracketing provides a means to combine human and computationally-driven sensemaking to contextualize digital trace data to understand and explain change.” (p. 4)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: An assisted approach to business process redesign</p>

<p>Authors: Tobias Fehrer, Dominik A. Fischer, Sander J.J. Leemans, Maximilian Rögliner, Moe T. Wynn</p>

<p>DOI: https://doi.org/10.1016/j.dss.2022.113749</p>

<p>Year: 2022</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Business Process Management / Decision Support Systems</p>

<p>Subdomain/Topic: Assisted business process redesign, reference architecture, redesign patterns, process improvement tools</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 82 – The paper directly addresses making redesign recommendations actionable through structured guidance, automation levels, and integration of domain knowledge, but does not provide a formal definition of “actionability” as a concept beyond the redesign context.</p>

<p>Operationalization Score: 85 – Provides clear operational workflow for achieving actionable redesign options through ABPR steps, automation levels, and tool-supported evaluation.</p>

<p>Actionable/Actionability Used in Paper: Yes – “make actionable suggestions for redesigning business processes” (p. 1)</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes – “it is questionable to what extent such tool-based approaches can…make actionable suggestions” (p. 1)</p>

<p>Contains Definition of Actionability: No – No formal definition, but implicitly conceptualized through ability to generate feasible, guided, evaluable redesign options.</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Partial – Recommendations are described and linked to patterns, but transparency in ranking and some evaluation measures is questioned.</p>

<p>Contains Interpretability: Yes – Recommendations linked to specific redesign patterns and process parts are interpretable to users.</p>

<p>Contains Framework/Model: Yes – ABPR concept and ABPR Reference Architecture.</p>

<p>Operationalization Present: Yes – Four-step ABPR process with automation levels AL1–AL4, integrated into a reference architecture and prototype.</p>

<p>Primary Methodology: Design Science Research with expert interviews, artificial and naturalistic evaluation.</p>

<p>Study Context: Business process redesign in organizations, tool-supported decision-making.</p>

<p>Geographic/Institutional Context: Germany (University of Bayreuth, Fraunhofer FIT) and Australia (Queensland University of Technology); case study at KUKA (Germany).</p>

<p>Target Users/Stakeholders: Process designers, BPM managers, consultants, domain experts.</p>

<p>Primary Contribution Type: Conceptual framework + operational prototype for guided process redesign.</p>

<p>CL: Yes – “structured guidance along the phases of process redesign” (p. 4)</p>

<p>CR: Yes – “integration of user’s domain knowledge” (p. 4)</p>

<p>FE: Yes – Recommendations filtered for feasibility via data, simulation, and expert validation.</p>

<p>TI: Partial – Supports iterative improvement but not explicitly focused on timeliness of delivery.</p>

<p>EX: Partial – Recommendations linked to patterns, but some ranking transparency concerns noted by experts.</p>

<p>GA: Yes – Patterns selected to align with predefined performance objectives.</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>An assisted approach to business process redesign</p>

<p><strong>Authors:</strong>  </p>

<p>Tobias Fehrer, Dominik A. Fischer, Sander J.J. Leemans, Maximilian Rögliner, Moe T. Wynn</p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1016/j.dss.2022.113749</p>

<p><strong>Year:</strong>  </p>

<p>2022</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Business Process Management / Decision Support Systems</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Assisted business process redesign, reference architecture, redesign patterns, process improvement tools</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses limitations in existing business process redesign (BPR) methods and tools, particularly their inability to combine structured guidance, automation, and domain expertise to produce usable, context-relevant redesign suggestions. It introduces the Assisted Business Process Redesign (ABPR) concept, operationalized through a reference architecture and prototype that guide users in applying redesign patterns at varying automation levels.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Germany (University of Bayreuth, Fraunhofer FIT) and Australia (Queensland University of Technology); case study at KUKA (Germany).  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process designers, BPM managers, consultants, domain experts.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Design Science Research with expert interviews and evaluations in artificial and real-world contexts.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework + operational prototype for guided process redesign.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper presents the ABPR concept and reference architecture, designed to improve business processes by guiding users through redesign patterns in a structured, tool-supported way. The approach classifies recommendations into four automation levels, from basic pattern suggestions to fully automated redesign options, integrating simulation, data analysis, and domain knowledge. A prototype based on the Camunda Modeler demonstrates the concept, and its applicability is validated through expert interviews, controlled studies, and a real-world case at KUKA. The results show ABPR’s ability to generate feasible, performance-objective-aligned redesign options, highlighting strengths in structured guidance, integration of expert knowledge, and flexible data use, though challenges remain in data preparation and pattern coverage.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>Yes  </p>

<blockquote>
  <p>“…make actionable suggestions for redesigning business processes” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“…provide the user with a basis for decision-making” (p. 4)  </p>
</blockquote>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes  </p>

<blockquote>
  <p>“…it is questionable to what extent such tool-based approaches can…make actionable suggestions for redesigning business processes” (p. 1)  </p>
</blockquote>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly: An actionable recommendation in this context is a redesign suggestion that is feasible, context-aware, aligned with performance objectives, and supported by guidance or automation to move from idea to implementable option.  </p>

<blockquote>
  <p>“…assist the redesign process: low, moderate, elevated, and high [automation levels]…resulting in redesign options that may improve the process…depending on the evaluation outcome.” (p. 4)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Feasibility &amp; Data Fit</strong>  </p>

<p> &gt; “…patterns are recommended that have proven useful for achieving the performance objective…while no instructions…can be given at this high abstraction level, this recommendation type encourages the user to think about possible applications” (p. 4)</p></li>
<li><p><strong>Alignment with Performance Objectives</strong>  </p>

<p> &gt; “…support determining the anticipated effect of process redesign options on…performance objectives to compare alternative process designs” (p. 4)</p></li>
<li><p><strong>Integration of Domain Knowledge</strong>  </p>

<p> &gt; “…interactive customization of process improvement opportunities to address specific use cases and incorporate the user’s domain knowledge” (p. 4)</p></li>
<li><p><strong>Guided Application Process</strong>  </p>

<p> &gt; “…support structured guidance along the phases of process redesign” (p. 4)</p></li>
<li><p><strong>Evaluability via Simulation and Expert Judgment</strong>  </p>

<p> &gt; “…evaluate the performance of these alternative models” (p. 4)</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Assisted Business Process Redesign (ABPR)</p></li>
<li><p><strong>Methods/Levers:</strong> Structured four-step process (select patterns, identify process parts, create alternatives, evaluate performance); four automation levels (AL1–AL4).</p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify patterns → Match to process parts → Generate alternative models → Simulate &amp; evaluate.</p></li>
<li><p><strong>Data &amp; Measures:</strong> Process models, event logs, simulation data, performance objectives (time, cost, quality, flexibility).</p></li>
<li><p><strong>Implementation Context:</strong> BPM tool (Camunda Modeler) with GUI, recommendation provider, simulation manager, and redesign handlers.</p></li>
</ul>

<blockquote>
  <p>“…present their results as redesign recommendations…highlight a few top recommendations…estimate each recommendation’s impact according to the selected performance objective.” (p. 5)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – “…structured guidance along the phases of process redesign” (p. 4)</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – “…integration of…domain knowledge” (p. 4)</p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – “…compare alternative process designs…evaluate the effect…on the process” (p. 4)</p></li>
<li><p><strong>TI (Timeliness):</strong> Partial – Iterative improvement implied but not explicitly tied to timeliness.</p></li>
<li><p><strong>EX (Explainability):</strong> Partial – Pattern and process part links are clear, but ranking transparency questioned (Table 2).</p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – “…patterns…align with the performance objective” (p. 4)</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Design Science Research (Hevner et al., Peffers et al.)</p></li>
<li><p>Reference Architecture design principles (Galster &amp; Avgeriou)</p></li>
<li><p>Redesign patterns (Reijers &amp; Limam Mansar)</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Estimated performance improvement (time, cost, quality, flexibility)</p></li>
<li><p>Simulation-based impact scores</p></li>
<li><p>Similarity metrics for recommendation diversity</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> &gt; “Process models in practice are often outdated and therefore not usable” (Table 1)  </p>

<p> &gt; “The data collection effort could exceed the value of the solution” (Table 1)</p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> &gt; “The incorporation of domain knowledge is useful for improving recommendations” (Table 1)  </p>

<p> &gt; “The extensibility of the RA is helpful for the concrete application” (Table 1)</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>ABPR extends prior BPR approaches by combining structured redesign pattern application with varying automation levels and explicit integration of domain knowledge, addressing gaps where past methods either focused solely on automation or manual expertise without combining both.</p>

<hr />

<h2>Summary</h2>

<p>The paper proposes the Assisted Business Process Redesign (ABPR) concept and a supporting reference architecture to address the challenge of generating actionable business process redesign suggestions. Actionability is understood as the ability to produce context-aware, feasible, goal-aligned redesign options that can be operationalized through structured guidance, integration of domain knowledge, and evaluation against performance objectives. ABPR operationalizes actionability via a four-step process—select patterns, identify process parts, create alternative models, and evaluate—delivered at four automation levels from basic suggestion to full automation. The approach is instantiated in a prototype integrating process modeling, simulation, and recommendation components, and evaluated in expert interviews, artificial settings, and a real-world case at KUKA. Strengths include clarity, contextual relevance, feasibility, and goal alignment; limitations include data preparation effort, limited pattern coverage, and partial transparency in recommendation ranking. The work advances BPR by bridging automated tools and human expertise, offering a scalable and extensible method for delivering actionable process redesigns.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 82 – Strong fit with actionable recommendations in process redesign; lacks a standalone formal definition of “actionability” beyond operational context.</p></li>
<li><p><strong>Operationalization Score:</strong> 85 – Clear, structured, tool-supported operationalization with automation levels and evaluation procedures.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“…make actionable suggestions for redesigning business processes” (p. 1)</p></li>
<li><p>“…support structured guidance along the phases of process redesign” (p. 4)</p></li>
<li><p>“…support determining the anticipated effect…to compare alternative process designs” (p. 4)</p></li>
<li><p>“…integration of…domain knowledge” (p. 4)</p></li>
<li><p>“…highlight a few top recommendations…estimate each recommendation’s impact” (p. 5)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Reijers &amp; Limam Mansar (2005) – Best practices in business process redesign.</p></li>
<li><p>Netjes et al. (2010, 2009) – Tool support and algorithms for redesign pattern application.</p></li>
<li><p>Essam &amp; Limam Mansar (2012) – Automated BPR framework.</p></li>
<li><p>Fellmann et al. (2019) – Process model patterns.</p></li>
<li><p>Lopez-Pintado et al. (2021) – Multi-objective process performance optimization.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: A Framework to Support the Validation of Process Mining Inquiries</p>

<p>Authors: Francesca Zerbato, Marco Franceschetti, Barbara Weber</p>

<p>DOI: 10.1007/978-3-031-70418-5_15</p>

<p>Year: 2024</p>

<p>Publication Type: Book Chapter</p>

<p>Discipline/Domain: Process Mining / Business Process Management</p>

<p>Subdomain/Topic: Result Validation, Exploratory Analysis, Meta-analysis Support</p>

<p>Eligibility: Eligible (implicit conceptualization only; no explicit use of “actionability”)</p>

<p>Overall Relevance Score: 45</p>

<p>Operationalization Score: 80</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — e.g., “Analysts need to understand the result and ensure it aligns with their expectations… helping them decide on subsequent analysis.” (p. 5); “Our framework aims to support process analysts in reflecting on their queries and results…” (p. 3)</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: Yes (traceability, contextual comparison, clarity, relevance)</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual framework design, implemented in Python, demonstrated on real log</p>

<p>Study Context: Exploratory process mining, query result validation, meta-analysis</p>

<p>Geographic/Institutional Context: University of St. Gallen (Switzerland), Eindhoven University of Technology (Netherlands), Technical University of Denmark</p>

<p>Target Users/Stakeholders: Process analysts</p>

<p>Primary Contribution Type: Framework + software</p>

<p>CL: Partial (linked to interpretability but not explicitly to actionability)</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Partial</p>

<p>EX: Partial</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper proposes LogView, a modular Python framework for validating, comparing, and tracing query results in exploratory process mining. It addresses limitations of existing tools, which typically display only one filtered view of a log at a time and require manual tracking. LogView stores queries, complements, and results in a registry; supports set-level and element-level characterization; and allows intersection-based comparison between result sets. The framework is demonstrated on the Road Traffic Fine Management log, showing how it can reveal overlaps, dependencies, and unexplored subsets in payment outcomes.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>No.</strong> The terms “actionable” or “actionability” are never used.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>Yes.</strong>  </p>

<ul>
<li><p>“Analysts need to understand the result and ensure it aligns with their expectations… helping them decide on subsequent analysis.” (p. 5)  </p></li>
<li><p>“Our framework aims to support process analysts in reflecting on their queries and results…” (p. 3)  </p></li>
<li><p>“Understanding overlaps… can reveal situations where multiple queries occur simultaneously or where no query has been made, providing clues for further analysis…” (p. 6)</p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly: A result is “actionable” if it is well-characterized, compared against relevant baselines, and traceable to its source, enabling informed refinement of analysis.</p>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Clear identification of result set properties</p></li>
<li><p>Contextual comparison to a reference log</p></li>
<li><p>Traceability of queries and results</p></li>
<li><p>Identification of overlaps and dependencies</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name:</strong> LogView  </p></li>
<li><p><strong>Methods/Levers:</strong> Query execution with complement sets; registry for traceability; characterization and comparison components  </p></li>
<li><p><strong>Operational Steps:</strong>  </p>

<p> 1. Execute query → store result + complement  </p>

<p> 2. Characterize against reference log  </p>

<p> 3. Compare to other sets via intersection matrices  </p>

<p> 4. Visualize overlaps  </p></li>
<li><p><strong>Implementation Context:</strong> Python library, extensible via plug-ins</p></li>
</ul>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Partial — results are characterized for interpretability, but not explicitly tied to actionability  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — comparisons anchored to relevant baselines  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — modular, extensible design  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — supports iterative analysis but not real-time constraints  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — overlaps and dependencies explained through intersections  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — results linked to analyst goals</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Event log theory  </p></li>
<li><p>Set theory for result comparison  </p></li>
<li><p>Provenance tracking and meta-analysis</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Overlap percentages  </p></li>
<li><p>Attribute distribution changes  </p></li>
<li><p>Query dependency probabilities</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of baseline knowledge; manual tracking burdens; partial data views in tools  </p></li>
<li><p><strong>Enablers:</strong> Automated recording; structured comparison; visualization support</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Compared to ProcessExplorer and provenance systems, LogView focuses on meta-analysis of query results, not automated recommendations.</p>

<hr />

<h2>Summary</h2>

<p>LogView supports process analysts in validating and comparing query results, enabling better refinement and transparency in exploratory process mining. While the term “actionability” is absent, the framework addresses many qualities associated with actionable insights — clarity, contextual relevance, traceability, and alignment with goals — but never formally defines them. The operationalization is strong (detailed workflow, implemented system, demonstrative case study), but the conceptual definition of actionability is absent, leading to a moderate relevance score under stricter criteria.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 45 — Moderate relevance due to implicit alignment with actionability dimensions but no explicit definition or term usage.  </p></li>
<li><p><strong>Operationalization Score:</strong> 80 — Strong, concrete methods for achieving qualities akin to actionability.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Analysts need to understand the result and ensure it aligns with their expectations…” (p. 5)  </p></li>
<li><p>“Our framework aims to support process analysts in reflecting on their queries and results…” (p. 3)  </p></li>
<li><p>“Understanding overlaps… can reveal situations… providing clues for further analysis…” (p. 6)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li>None specifically tied to “actionability” as a concept; related to provenance and meta-analysis systems.</li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: AI-augmented Business Process Management Systems: A Research Manifesto</p>

<p>Authors: Marlon Dumas, Fabiana Fournier, Lior Limonad, Andrea Marrella, Marco Montali, Jana-Rebecca Rehse, Rafael Accorsi, Diego Calvanese, Giuseppe De Giacomo, Dirk Fahland, Avigdor Gal, Marcello La Rosa, Hagen Völzer, Ingo Weber</p>

<p>DOI: https://doi.org/10.1145/3576047</p>

<p>Year: 2023</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Information Systems / Business Process Management</p>

<p>Subdomain/Topic: AI-augmented BPM Systems, Process Automation, Explainability, Adaptation</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 92</p>

<p>Operationalization Score: 88</p>

<p>Actionable/Actionability Used in Paper: Yes — “Conversationally actionable” as a core characteristic (p. 7); “Actionable conversations” as a research challenge (p. 13)</p>

<p>Authors Argue for Need for Actionability Without Defining It: No — The term is explicitly defined in relation to “conversationally actionable” and “actionable conversations”</p>

<p>Contains Definition of Actionability: Yes — as “conversationally actionable,” meaning the ability to proactively communicate with human agents about process-related actions, goals, and intentions (p. 7–8)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes — ABPMS lifecycle model (Fig. 1)</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual / Manifesto</p>

<p>Study Context: Conceptual, technology-agnostic vision for AI in BPM systems</p>

<p>Geographic/Institutional Context: Multiple academic and industry institutions across Europe, Australia, and Israel</p>

<p>Target Users/Stakeholders: BPM designers, AI researchers, business process managers</p>

<p>Primary Contribution Type: Conceptual framework and research agenda</p>

<p>CL: Yes — emphasis on clear framing, constraints, goals (p. 4–5)</p>

<p>CR: Yes — context-sensitive process adaptation (p. 3–4, 7)</p>

<p>FE: Yes — feasibility tied to framing constraints and meta-framing (p. 7)</p>

<p>TI: Yes — real-time adaptation and improvement (p. 8)</p>

<p>EX: Yes — situation-aware explainability (p. 9–10)</p>

<p>GA: Yes — goal optimization and trade-offs (p. 4–5, 8)</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>AI-augmented Business Process Management Systems: A Research Manifesto  </p>

<p><strong>Authors:</strong>  </p>

<p>Marlon Dumas, Fabiana Fournier, Lior Limonad, Andrea Marrella, Marco Montali, Jana-Rebecca Rehse, Rafael Accorsi, Diego Calvanese, Giuseppe De Giacomo, Dirk Fahland, Avigdor Gal, Marcello La Rosa, Hagen Völzer, Ingo Weber  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1145/3576047  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Information Systems / Business Process Management  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>AI-augmented BPM Systems, Process Automation, Explainability, Adaptation  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper positions AI-augmented BPM Systems (ABPMSs) as a new class of process-aware information systems that integrate trustworthy AI technologies to improve adaptability, proactivity, explainability, and context-sensitivity in business processes.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Collaborative research across European, Australian, and Israeli universities and IBM Research.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Business process managers, BPM system designers, AI researchers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual / manifesto-style research agenda.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework (ABPMS lifecycle) and research challenges.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This manifesto defines AI-augmented Business Process Management Systems (ABPMSs) as process-aware systems that leverage trustworthy AI to autonomously adapt, improve, explain, and optimize business processes in real time. The authors present the ABPMS lifecycle, consisting of framing, enacting, perceiving, reasoning, explaining, adapting, and improving processes. They identify five core characteristics — framed autonomy, conversational actionability, adaptability, self-improvement, and explainability — and detail the AI capabilities needed to realize them. The paper proposes several research challenges, including situation-aware explainability, augmented automation, automated adaptation, perspective agility, and actionable conversations. The goal is to bridge AI and BPM to create systems that operate effectively in dynamic, uncertain environments while maintaining trust, compliance, and performance optimization.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>Yes</strong>  </p>

<ul>
<li><p>“Conversationally actionable to seamlessly interact with agents whenever necessary” (p. 7)  </p></li>
<li><p>“Actionable means that the ABPMS makes concrete recommendations to the user and engages in a discussion about their benefits and drawbacks” (p. 8)  </p></li>
<li><p>“Actionable conversations… initiate conversations with users… make recommendations for interventions in order to improve performance with respect to relevant performance targets” (p. 13)  </p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>No</strong> — The paper explicitly defines “actionable” in the context of “conversationally actionable” and “actionable conversations.”</p>

<hr />

<h2>How Actionability is Understood</h2>

<blockquote>
  <p>“Conversationally actionable, i.e., able to proactively communicate with human agents about process-related actions, goals, and intentions, using natural language possibly enhanced with richer interfaces… ‘Actionable’ means that the ABPMS makes concrete recommendations to the user and engages in a discussion about their benefits and drawbacks.” (p. 7–8)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Proactive Communication</strong>  </p>

<p> &gt; “Able to proactively communicate with human agents about process-related actions, goals, and intentions” (p. 7)  </p></li>
<li><p><strong>Concrete Recommendations</strong>  </p>

<p> &gt; “‘Actionable’ means that the ABPMS makes concrete recommendations to the user and engages in a discussion about their benefits and drawbacks.” (p. 8)  </p></li>
<li><p><strong>Context-Sensitive Interaction</strong>  </p>

<p> &gt; “Initiates conversations with users in order to inform them of process progression, alert them of relevant process changes… and make recommendations for interventions” (p. 13)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> ABPMS Lifecycle (Fig. 1)  </p></li>
<li><p><strong>Methods/Levers:</strong> Conversational interfaces, proactive recommendation generation, real-time monitoring, AI-driven reasoning.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Frame → Enact → Perceive → Reason → (Explain / Adapt / Improve) with conversational interaction integrated.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> KPIs, constraints, goals, contextual process data.  </p></li>
<li><p><strong>Implementation Context:</strong> Applicable across diverse process domains with varying levels of autonomy and framing flexibility.  </p></li>
</ul>

<blockquote>
  <p>“The ABPMS could present requested information as an interactive dashboard and recommend inspection of some erroneous cases… engage in a discussion to eventually find counter-measures.” (p. 8)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — clear communication of recommendations (p. 8)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — context-sensitive process adaptation and interaction (p. 7–8)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — framed by constraints and goals (p. 7)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — real-time proactive interventions (p. 8, 13)  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — situation-aware explainability (p. 9–10)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — tied to KPIs and optimal trade-offs (p. 4–5, 8)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Trustworthiness (p. 9), adaptability (p. 8), self-improvement (p. 8)  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Framing theory (Minsky, 1975)  </p></li>
<li><p>Supervisory control in discrete-event systems  </p></li>
<li><p>Hybrid Process Intelligence  </p></li>
<li><p>BDI agent models  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Achievement of KPIs  </p></li>
<li><p>Effectiveness of recommendations and interventions  </p></li>
<li><p>User acceptance and trust measures  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Need for domain knowledge in conversational systems; handling dynamic and uncertain contexts.  </p></li>
<li><p><strong>Enablers:</strong> Natural Language Processing, Machine Learning for recommendation and adaptation; integration of process-aware reasoning.  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper integrates concepts from BPM, AI planning, explainable AI, conversational interfaces, and adaptive process management, positioning actionability as a distinctive capability enabling proactive, context-aware, goal-aligned system behavior.</p>

<hr />

<h2>Summary</h2>

<p>This research manifesto defines AI-augmented BPM Systems (ABPMSs) as process-aware systems enhanced with trustworthy AI to achieve adaptability, proactivity, explainability, and context-sensitivity. Central to the concept is “conversational actionability,” meaning the ability to proactively communicate with human agents, make concrete recommendations, and collaboratively decide on interventions. The ABPMS lifecycle incorporates AI into traditional BPM steps and adds capabilities for explanation, adaptation, and improvement. The paper identifies key research challenges such as situation-aware explainability, augmented automation, automated adaptation, perspective agility, and actionable conversations. Actionability emerges as both a communication and decision-support capability, underpinned by goal alignment, contextual relevance, clarity, timeliness, feasibility, and explainability. The framework and agenda aim to guide the evolution of BPM towards intelligent, trustworthy systems capable of autonomous yet human-aligned process management.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Strong conceptual definition and integration of actionability into the ABPMS model with explicit characteristics.  </p></li>
<li><p><strong>Operationalization Score:</strong> 88 — Provides concrete mechanisms (conversational interfaces, dashboards, recommendation workflows) for achieving actionability.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Conversationally actionable, i.e., able to proactively communicate with human agents about process-related actions, goals, and intentions…” (p. 7)  </p></li>
<li><p>“‘Actionable’ means that the ABPMS makes concrete recommendations to the user and engages in a discussion about their benefits and drawbacks.” (p. 8)  </p></li>
<li><p>“Initiates conversations with users… and make recommendations for interventions in order to improve performance with respect to relevant performance targets.” (p. 13)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>[70] Muthusamy et al. (2020) on human-digital worker integration  </p></li>
<li><p>[33] Galitsky (2019) on enterprise chatbots and NLU  </p></li>
<li><p>[79] Rizk et al. (2020) on multi-agent conversational assistants  </p></li>
<li><p>[90] van der Aalst (2021) on Hybrid Process Intelligence</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Action-oriented process mining: bridging the gap between insights and actions</p>

<p>Authors: Gyunam Park, Wil M. P. van der Aalst</p>

<p>DOI: https://doi.org/10.1007/s13748-022-00281-7</p>

<p>Year: 2022</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Process Mining / Business Process Management</p>

<p>Subdomain/Topic: Action-oriented process mining, Continuous process improvement</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 93</p>

<p>Operationalization Score: 95</p>

<p>Contains Definition of Actionability: Yes</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual + Experimental</p>

<p>Study Context: Artificial IS + SAP ERP system (Order handling / Order-to-Cash)</p>

<p>Geographic/Institutional Context: RWTH Aachen University, Germany</p>

<p>Target Users/Stakeholders: Process managers, business analysts, ERP system users</p>

<p>Primary Contribution Type: Conceptual framework + implementation + empirical validation</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Yes</p>

<p>EX: Yes</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: n/a</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Action-oriented process mining: bridging the gap between insights and actions</p>

<p><strong>Authors:</strong>  </p>

<p>Gyunam Park, Wil M. P. van der Aalst</p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1007/s13748-022-00281-7</p>

<p><strong>Year:</strong>  </p>

<p>2022</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Process Mining / Business Process Management</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Action-oriented process mining, Continuous process improvement</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the missing link between process mining insights (diagnostics, monitoring) and concrete, automated management actions for operational improvement. It proposes a framework that integrates continuous monitoring of event streams, constraint evaluation, and automated action generation. Targeted at dynamic business environments, the approach combines process mining, domain knowledge, and automated execution capabilities.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>RWTH Aachen University, Germany</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process managers, business analysts, ERP system users</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework development with empirical validation (artificial IS + real-life ERP)</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework + Implementation + Experimental Evaluation</p>

<h2>General Summary of the Paper</h2>

<p>The authors propose a <strong>general framework for action-oriented process mining</strong> designed to close the gap between diagnostics from process mining and the concrete actions needed for improvement. The framework comprises a <strong>constraint monitor</strong> (detects/predicts violations in real time) and an <strong>action engine</strong> (generates and executes management actions automatically). They instantiate the action engine as a <strong>cube-based model</strong> that aggregates violations along multiple dimensions for analysis using OLAP operations. Implementation is provided as a ProM plug-in and evaluated on (1) an artificial order handling process and (2) a real-life SAP ERP Order-to-Cash process. Results show improved operational performance, validating the framework’s ability to turn insights into timely, effective actions.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionability is understood as the <strong>systematic conversion of process mining insights into automated, targeted management actions</strong> that improve operational performance.</p>

<blockquote>
  <p>“Action-oriented process mining aims at… systematically combining process mining results and domain knowledge, and also automating management actions to improve business processes.” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“…turn the insights from process mining diagnostics to management actions.” (p. 2)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Must be grounded in <strong>objective monitoring results</strong> (diagnostics + predictions).</p></li>
<li><p>Must be linked to <strong>clear operational goals</strong> (risk reduction, performance improvement).</p></li>
<li><p>Must be <strong>context-aware</strong> (relevant to process, activity, resource, object).</p></li>
<li><p>Must be <strong>timely</strong> in relation to process execution.</p></li>
<li><p>Must be <strong>feasible</strong> for automatic execution in the IS environment.</p></li>
<li><p>Must be <strong>explainable</strong> and based on transparent criteria.</p></li>
</ul>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> General framework for action-oriented process mining; Cube-based action engine.</p></li>
<li><p><strong>Methods/Levers:</strong> Continuous constraint monitoring, OLAP-based multi-dimensional analysis, automated transaction execution.</p></li>
<li><p><strong>Operational Steps / Workflow:</strong></p>

<p> 1. Define constraints from diagnostics &amp; domain knowledge.</p>

<p> 2. Monitor event streams to detect/predict violations.</p>

<p> 3. Generate constraint instances.</p>

<p> 4. Analyze violations via cube-based OLAP views.</p>

<p> 5. Map conditions to predefined management actions.</p>

<p> 6. Trigger and execute actions in source systems.</p></li>
<li><p><strong>Data &amp; Measures:</strong> Event logs (OCEL format), constraint categories, violation counts, response times, throughput measures.</p></li>
<li><p><strong>Implementation Context:</strong> ProM plug-in integrated with artificial IS and SAP ERP O2C process.</p></li>
</ul>

<blockquote>
  <p>“The action engine analyzes the constraint instances and produces action instances… automatically triggered in the underlying information system…” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“…cube-based action engine… generates actions by analyzing monitoring results in a multi-dimensional way.” (p. 9)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Actions are explicitly defined via formulas and parameter mappings.  </p>

<p> &gt; “…the action formula specifies which transactions to generate in which conditions…” (p. 8)</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Context dimension explicitly models processes, activities, resources, objects.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Actions mapped to executable IS transactions (SAP ERP, artificial IS).  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — Time dimension in cube; monitoring scheduled multiple times daily.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Violations linked to transparent constraints; explainable predictions referenced.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Actions linked to operational goals like reducing delivery failures or response delays.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Severity levels (priority), constraint categories (cost, time, quality).</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Process mining diagnostics (discovery, conformance, enhancement)  </p></li>
<li><p>Predictive process monitoring  </p></li>
<li><p>OLAP multi-dimensional analysis  </p></li>
<li><p>Action recommender systems</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Number of violations detected  </p></li>
<li><p>Violation frequency ratios (e.g., &gt;10% late responses)  </p></li>
<li><p>Throughput time reduction  </p></li>
<li><p>Change frequency in orders</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of systematic action mapping in existing tools; subjective decision-making; possible unintended consequences; organizational frictions.  </p></li>
<li><p><strong>Enablers:</strong> Formalized framework; integration with ERP; cube-based structured analysis; automated execution.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions itself as extending operational support literature by formalizing the <strong>recommendation-to-action</strong> phase, which is underdeveloped compared to detect/predict phases. Builds on Celonis Action Engine but adds systematic, multi-dimensional analysis.</p>

<h2>Summary</h2>

<p>The paper defines actionability as the <strong>ability to convert process insights into timely, context-aware, feasible, and goal-aligned automated actions</strong>. It operationalizes this through a formal framework with two components: a constraint monitor (detects/predicts violations) and an action engine (maps violations to transactions). The cube-based instantiation allows structured, OLAP-style analysis of violations across dimensions (time, context, constraint). Implementation in ProM demonstrates integration with artificial and real ERP environments, showing measurable improvements in operational KPIs. The work contributes a systematic, executable link between process mining diagnostics and management actions, addressing a gap in both literature and practice.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 93 — Provides explicit conceptualization of actionability with clear features (context, timeliness, feasibility, explainability, goal alignment) integrated in framework.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Offers detailed, formalized operationalization with methods, workflow, and empirical validation in two contexts.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[Action-oriented process mining] aims at… systematically combining process mining results and domain knowledge, and also automating management actions…” (p. 2)  </p></li>
<li><p>“The action formula specifies which transactions to generate in which conditions…” (p. 8)  </p></li>
<li><p>“The cube-based action engine… generates actions by analyzing monitoring results in a multi-dimensional way.” (p. 9)  </p></li>
<li><p>“We propose a general framework… to support continuous monitoring… and the automated execution of actions…” (p. 2)  </p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Celonis Action Engine [41]  </p></li>
<li><p>Digital twin interface model [42]  </p></li>
<li><p>Predictive monitoring frameworks [22–26]  </p></li>
<li><p>Prescriptive alarm systems [37]  </p></li>
<li><p>Process-aware recommender systems [40]</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: A visual approach to support process analysts in working with process improvement opportunities  </p>

<p>Authors: Kateryna Kubrak, Fredrik Milani, Alexander Nolte  </p>

<p>DOI: 10.1108/BPMJ-10-2021-0631  </p>

<p>Year: 2023  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Business Process Management / Process Mining  </p>

<p>Subdomain/Topic: Visualisation of process improvement opportunities  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 88  </p>

<p>Operationalization Score: 82  </p>

<p>Actionable/Actionability Used in Paper: Yes – Implicit: “...aid process analysts in working with process improvement opportunities” (p. 102); “…visualisations… to identify, prioritise and communicate business process improvement opportunities” (p. 101)  </p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes – “...impedes process analysts from taking data-driven decisions to implement process changes” (p. 102)  </p>

<p>Contains Definition of Actionability: No (implicit framing through improvement opportunity decision-making context)  </p>

<p>Contains Systematic Features/Dimensions: Yes – KPIs, impact, feasibility, cost, ease, goal alignment  </p>

<p>Contains Explainability: Partial – linked to showing underlying data and context for trust  </p>

<p>Contains Interpretability: Yes – through clarity, simplified views for stakeholders  </p>

<p>Contains Framework/Model: Yes – IRVIN mockup framework &amp; 5 principles for visualisations  </p>

<p>Operationalization Present: Yes – Detailed mockup (IRVIN) with user stories and evaluation  </p>

<p>Primary Methodology: Qualitative + Design Science Research  </p>

<p>Study Context: Process mining tool visualisation design for analysts  </p>

<p>Geographic/Institutional Context: Estonia (University of Tartu) &amp; international practitioner sample  </p>

<p>Target Users/Stakeholders: Process analysts, process mining tool developers, business stakeholders  </p>

<p>Primary Contribution Type: Framework + Design artefact evaluation  </p>

<p>CL: Yes – “...you take that piece of information or data and try to put it in a simplified context” (p. 110)  </p>

<p>CR: Yes – “...recommendation I’m making is intrinsic [...] or extrinsic to the [process]” (p. 109)  </p>

<p>FE: Yes – “...ease of addressing the improvement opportunity” (p. 118)  </p>

<p>TI: No explicit time dimension beyond process performance metrics  </p>

<p>EX: Partial – “Show me the underlying data” (p. 116)  </p>

<p>GA: Yes – “...in line with the company’s objectives” (p. 110)  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>A visual approach to support process analysts in working with process improvement opportunities  </p>

<p><strong>Authors:</strong>  </p>

<p>Kateryna Kubrak, Fredrik Milani, Alexander Nolte  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1108/BPMJ-10-2021-0631  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Business Process Management / Process Mining  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Visualisation of process improvement opportunities  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the gap in process mining where visualisations are rarely designed to support identifying, prioritising, and communicating process improvement opportunities in a holistic way. It follows a design science methodology to develop IRVIN (ImpRovement opportunities VisualIsatioN) — a mockup artefact tested with practitioners to elicit principles and requirements for actionable process visualisation.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of Tartu (Estonia) &amp; Carnegie Mellon University, with an international sample of process analysts  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process analysts, process mining software developers, business decision-makers  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Qualitative interviews + design science research with iterative prototyping and evaluation  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework and evaluated artefact (IRVIN) with design principles for actionable visualisations  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The study explores how process mining visualisations can be designed to support analysts in identifying, prioritising, and communicating process improvement opportunities. Through semi-structured interviews with practitioners across domains, the authors elicit requirements, develop the IRVIN mockup, and evaluate it with process analysts. Findings highlight that analysts need integrated process and performance views, contextual business alignment, visibility of cost/effort, KPI impact, and access to underlying data for trust. The authors distil five design principles for process mining visualisations to aid improvement opportunity analysis. Evaluation feedback was largely positive, with suggestions for clearer terminology, default KPIs, and constant access to opportunity descriptions.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>Yes – implicit through the framing of “process improvement opportunities” as the actionable output of analysis:  </p>

<ul>
<li><p>“...aid process analysts in working with process improvement opportunities” (p. 102)  </p></li>
<li><p>“...visualisations… to identify, prioritise and communicate business process improvement opportunities” (p. 101)  </p></li>
<li><p>“...impedes process analysts from taking data-driven decisions to implement process changes” (p. 102)  </p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes –  </p>

<ul>
<li><p>“...impedes process analysts from taking data-driven decisions to implement process changes” (p. 102)  </p></li>
<li><p>“...no existing approach that supports analysts in using visualisations… to identify improvement opportunities” (p. 102)  </p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicit: Actionability is framed as the capacity of process mining visualisations to provide the necessary information, context, and prioritisation criteria for process analysts to make informed improvement decisions and communicate them to stakeholders.</p>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Integration of process models &amp; performance data</strong>  </p>

<p> &gt; “...visualisation should concurrently capture the process and its performance to provide a holistic view” (p. 119)  </p></li>
<li><p><strong>Proportion of cases affected</strong>  </p>

<p> &gt; “...explicitly denote the proportion of cases… affected by implementing a change” (p. 120)  </p></li>
<li><p><strong>Alignment with business objectives/KPIs</strong>  </p>

<p> &gt; “...which KPIs of the process can be improved if the opportunity is addressed” (p. 119)  </p></li>
<li><p><strong>Cost and ease of implementation</strong>  </p>

<p> &gt; “...compare cost and ease of implementation of alternative changes” (p. 120)  </p></li>
<li><p><strong>Access to underlying data</strong>  </p>

<p> &gt; “...explore the calculation data behind visualisations to ensure transparency” (p. 120)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> IRVIN (ImpRovement opportunities VisualIsatioN)  </p></li>
<li><p><strong>Methods/Levers:</strong> Design science methodology, user stories, iterative mockup design, contextual evaluation interviews  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Exploration interviews to elicit requirements  </p>

<p> 2. Wireframe creation and mockup linking in InVision  </p>

<p> 3. Evaluation with practitioners in scenario-based tasks  </p>

<p> 4. Refinement based on additional requirements  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Process models, KPIs, case counts, variant analysis, cost/effort estimates, performance changes  </p></li>
<li><p><strong>Implementation Context:</strong> Hypothetical process mining tool with interactive improvement opportunity tab  </p></li>
</ul>

<blockquote>
  <p>“...compare identified improvement opportunities… decide how to proceed” (p. 115)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – “...simplified context that works as a narrative and easy enough to understand” (p. 110)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – “...intrinsic [...] or extrinsic to the [process]” (p. 109)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – “...ease of addressing the improvement opportunity” (p. 118)  </p></li>
<li><p><strong>TI (Timeliness):</strong> No explicit time-criticality dimension beyond performance impact  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial – “Show me the underlying data” (p. 116)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – “...in line with the company’s objectives” (p. 110)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Cost-benefit trade-off, proportion of cases affected, KPI impact</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Design science methodology (Hevner et al., 2004)  </p></li>
<li><p>Visualisation principles (Munzner, 2014; Shneiderman, 1996)  </p></li>
<li><p>Improvement Opportunity Framework (Lashkevich, 2020)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Number of cases affected  </p></li>
<li><p>KPI change (throughput time, error rate, resource utilisation)  </p></li>
<li><p>Cost of implementation  </p></li>
<li><p>Ease of implementation (resource effort)  </p></li>
<li><p>Business alignment of KPIs  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of integrated visualisations; missing cost/effort data; distrust in data quality; no existing holistic visualisation approach  </p></li>
<li><p><strong>Enablers:</strong> Combining process and performance views; alignment with KPIs; ability to drill down into underlying data; comparative cost-benefit visualisation  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Extends visualisation research in process mining beyond exploration/comparison toward decision-oriented improvement opportunity analysis. Highlights gap in commercial tools that partially support actionable insights but lack integration, cost/effort visualisation, and transparent data linkage.</p>

<hr />

<h2>Summary</h2>

<p>This paper investigates how process mining visualisations can be designed to support analysts in making actionable process improvement decisions. Using design science, the authors created and evaluated IRVIN, a mockup tool that integrates process models, performance data, and prioritisation features. Requirements were derived from practitioner interviews, resulting in user stories linked to gaps in current commercial tools. The evaluation confirmed the importance of clarity, context, KPI alignment, feasibility, and data transparency for making improvement opportunities actionable. Five design principles were proposed: integrate process and performance views, indicate proportion of cases affected, link opportunities to business KPIs, visualise cost/ease of implementation, and provide access to underlying data. While not explicitly defining “actionability,” the work operationalises it through decision-support features, making it highly relevant for process mining tool design aimed at enabling informed and implementable process changes.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 – Strong alignment with actionability via implicit conceptualisation, detailed features, and design principles, but no explicit formal definition.  </p></li>
<li><p><strong>Operationalization Score:</strong> 82 – Detailed mockup and workflow show clear means to achieve actionability, though in prototype stage without full real-world deployment.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“...visualisation should concurrently capture the process and its performance to provide a holistic view” (p. 119)  </p></li>
<li><p>“...explicitly denote the proportion of cases… affected by implementing a change” (p. 120)  </p></li>
<li><p>“...in line with the company’s objectives” (p. 110)  </p></li>
<li><p>“...compare cost and ease of implementation of alternative changes” (p. 120)  </p></li>
<li><p>“Show me the underlying data” (p. 116)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Lashkevich (2020) – Improvement Opportunity Framework  </p></li>
<li><p>Grisold et al. (2021) – Alignment of process mining with business strategy  </p></li>
<li><p>Pini et al. (2015) – Multi-perspective process visualisation  </p></li>
<li><p>Dani et al. (2019) – Visualisation of business process models  </p></li>
<li><p>Bitomsky et al. (2019) – Cost-benefit assessment in process improvement</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: A General Process Mining Framework for Correlating, Predicting and Clustering Dynamic Behavior Based on Event Logs</p>

<p>Authors: Massimiliano de Leoni, Wil M.P. van der Aalst, Marcus Dees</p>

<p>DOI: 10.1016/j.is.2015.07.003</p>

<p>Year: 2015</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Information Systems / Process Mining</p>

<p>Subdomain/Topic: Correlation analysis, prediction, and clustering in process mining</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 88</p>

<p>Operationalization Score: 90</p>

<p>Actionable/Actionability Used in Paper: Yes — “The results can also be used at run-time to provide decision support… participants can be suggested to avoid certain decisions that have been observed to likely lead to those conditions.” (p. 7–8)</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — “Corrective actions can be put in place to avoid those conditions” (p. 7), “The results can also be used at run-time to provide decision support” (p. 8)</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual + Case Study</p>

<p>Study Context: Process mining applied to event logs for correlation, prediction, and clustering</p>

<p>Geographic/Institutional Context: UWV (Employee Insurance Agency), The Netherlands</p>

<p>Target Users/Stakeholders: Process analysts, business process managers, decision-makers in organizations using PAISs</p>

<p>Primary Contribution Type: Generalizable process mining framework</p>

<p>CL: Yes — “aims to explain the values of the dependent characteristic as function of the independent characteristics” (p. 8)</p>

<p>CR: Yes — “conditions may have a negative impact on certain KPIs… corrective actions can be put in place to avoid those conditions” (p. 7)</p>

<p>FE: Yes — “low-performing branches can be closed… or moved to different tasks” (p. 7)</p>

<p>TI: No</p>

<p>EX: Yes — Decision/regression tree structure clearly highlights contributing characteristics (p. 21–23)</p>

<p>GA: Yes — “Maximize the chances of achieving a given business goal” (p. 21)</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>A General Process Mining Framework for Correlating, Predicting and Clustering Dynamic Behavior Based on Event Logs  </p>

<p><strong>Authors:</strong>  </p>

<p>Massimiliano de Leoni, Wil M.P. van der Aalst, Marcus Dees  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1016/j.is.2015.07.003  </p>

<p><strong>Year:</strong>  </p>

<p>2015  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Information Systems / Process Mining  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Correlation analysis, prediction, and clustering in process mining  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the gap in process mining research between discovery/conformance checking and the ability to correlate process characteristics for predictive and diagnostic purposes. It proposes a generalizable framework that uses enriched event logs and decision/regression trees to answer a wide range of process-centric questions, integrating multiple process perspectives.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>UWV (Employee Insurance Agency), The Netherlands  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process analysts, business process managers, decision-makers in organizations using PAISs  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework development + case study evaluation  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Generalizable process mining framework  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper proposes a unified process mining framework capable of correlating, predicting, and clustering process behaviors using event logs. Unlike ad-hoc methods, it supports a wide variety of dependent and independent process characteristics drawn from control-flow, data-flow, resource, time, and conformance perspectives. The framework enriches event logs with additional characteristics and applies decision/regression trees to produce explainable models for analysis and clustering. Implemented in ProM, it is demonstrated through case studies with the Dutch UWV agency, showing how the approach uncovers root causes, predicts outcomes, and segments event logs into more homogeneous sublogs for precise process modeling.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>Yes.  </p>

<ul>
<li><p>“Corrective actions can be put in place to avoid those conditions” (p. 7)  </p></li>
<li><p>“The results can also be used at run-time to provide decision support” (p. 8)  </p></li>
<li><p>“…participants can be suggested to avoid certain decisions that have been observed to likely lead to those conditions” (p. 8)  </p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes.  </p>

<ul>
<li><p>“Corrective actions can be put in place to avoid those conditions” (p. 7)  </p></li>
<li><p>“Maximize the chances of achieving a given business goal” (p. 21)  </p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly understood as the ability to derive conditions and rules from process analysis results that enable preventive or corrective interventions in real or near-real time.  </p>

<blockquote>
  <p>“…participants can be suggested to avoid certain decisions that have been observed to likely lead to those conditions.” (p. 8)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Clear identification of correlations between process characteristics and KPIs</p></li>
<li><p>Ability to trace back undesirable outcomes to root causes</p></li>
<li><p>Availability of decision rules from prediction trees</p></li>
<li><p>Operational feasibility of applying corrective/preventive measures</p></li>
<li><p>Context relevance (e.g., process-specific characteristics, time conditions)</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> General Process Mining Framework (implemented in ProM’s FeaturePrediction package)  </p></li>
<li><p><strong>Methods/Levers:</strong> Enrich event logs, apply event selection filters, generate decision/regression trees  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Define analysis use case (dependent variable, independent variables, event filter)  </p>

<p> 2. Manipulate/enrich event log  </p>

<p> 3. Perform analysis via tree learning  </p>

<p> 4. Optionally cluster event log based on results  </p>

<p> 5. Apply process mining to each cluster  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Event logs with multiple process perspectives, enriched with derived characteristics  </p></li>
<li><p><strong>Implementation Context:</strong> UWV unemployment and illness-management processes  </p></li>
</ul>

<blockquote>
  <p>“…Corrective actions can be put in place to avoid those conditions… The results can also be used at run-time to provide decision support.” (p. 7–8)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — “aims to explain the values of the dependent characteristic as function of the independent characteristics” (p. 8)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — “…conditions may have a negative impact on certain KPIs… corrective actions can be put in place to avoid those conditions” (p. 7)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — “…low-performing branches can be closed… or moved to different tasks” (p. 7)  </p></li>
<li><p><strong>TI (Timeliness):</strong> No — analyses are a posteriori and need repetition for updates (p. 8)  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Trees explicitly show discriminating characteristics (p. 21–23)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — “…maximize the chances of achieving a given business goal” (p. 21)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Process mining theory (van der Aalst, 2011)</p></li>
<li><p>Decision tree learning (C4.5, REPTree)</p></li>
<li><p>Perspectives in process analysis (control-flow, data-flow, resource, time, conformance)</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Correlation between characteristics and KPIs</p></li>
<li><p>Decision tree splits indicating strong predictive power</p></li>
<li><p>Process model precision improvements post-clustering</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - A posteriori analysis (no automatic real-time updates)  </p>

<p> - No explicit definition of actionability provided  </p>

<p> - Noise and outliers in event logs (requiring filtering)</p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Unified framework reduces technical burden  </p>

<p> - Multiple perspectives incorporated into analysis  </p>

<p> - Explainable models via decision/regression trees  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The authors position their work as a generalization of multiple ad-hoc correlation analysis approaches in process mining, integrating techniques from prior works on outcome prediction, remaining time prediction, and rule violation detection into a unified, configurable framework. The paper also adapts the knowledge discovery process (Fayyad et al., 1996) specifically for process mining.</p>

<hr />

<h2>Summary</h2>

<p>This paper introduces a general process mining framework designed to unify diverse correlation, prediction, and clustering analyses within one configurable environment. By defining an analysis use case, enriching event logs with computed characteristics, and applying decision/regression tree learning, analysts can derive interpretable rules linking process characteristics to outcomes or KPIs. The approach supports actionable insights by enabling preventive or corrective measures, as demonstrated in UWV case studies where root causes of delays and reclamations were identified. While lacking a formal definition of actionability, the framework operationalizes it through explicit, explainable decision rules and supports application across multiple perspectives, making it a versatile tool for process analysts.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 — Strong operationalization of actionability via explainable decision rules, but no explicit definition.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Detailed multi-perspective enrichment, event filtering, and analysis workflow provide clear steps to generate actionable insights.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Corrective actions can be put in place to avoid those conditions.” (p. 7)  </p></li>
<li><p>“The results can also be used at run-time to provide decision support… participants can be suggested to avoid certain decisions…” (p. 8)  </p></li>
<li><p>“Maximize the chances of achieving a given business goal.” (p. 21)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>[14] Maggi et al. (2014) — Predictive monitoring of business processes  </p></li>
<li><p>[15] Ghattas et al. (2014) — Improving business process decision making based on past experience  </p></li>
<li><p>[16] Conforti et al. (2013) — Supporting risk-informed decisions during business process execution  </p></li>
<li><p>[17] Rozinat &amp; van der Aalst (2006) — Decision mining in ProM  </p></li>
<li><p>[18] van der Aalst et al. (2011) — Time prediction based on process mining</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: The Action Engine – Turning Process Insights into Action</p>

<p>Authors: Peyman Badakhshan; German Bernhart; Jerome Geyer‑Klingeberg; Janina Nakladal; Steffen Schenk; Thomas Vogelgesang</p>

<p>DOI: N/A</p>

<p>Year: 2019</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Information Systems / Process Mining</p>

<p>Subdomain/Topic: Operational process support; recommendations; predictive monitoring; execution integration</p>

<p>Eligibility: Eligible (implicitly focuses on making insights actionable through analysis→recommendation→execution workflow)</p>

<p>Overall Relevance Score: 72</p>

<p>Operationalization Score: 80</p>

<p>Actionable/Actionability Used in Paper: No (terms like “actionable/actionability” not used explicitly). :contentReference[oaicite:0]{index=0}</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — e.g., “translates findings…into recommendations for operational support during process execution… and directly executes actions in the source system,” and “operationalizing insights created through process analysis.” (p. 2) :contentReference[oaicite:1]{index=1}</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual (system description) with brief case references</p>

<p>Study Context: Enterprise business processes (e.g., Purchase‑to‑Pay, Order‑to‑Cash) with demo data and industry cases</p>

<p>Geographic/Institutional Context: Developed by Celonis (Munich, Germany); cases from Germany and the Netherlands; used across “10 different companies” (p. 5). :contentReference[oaicite:2]{index=2}</p>

<p>Target Users/Stakeholders: Process owners; purchasers; order managers; broader “human users or the digital workforce” (p. 2–3). :contentReference[oaicite:3]{index=3}</p>

<p>Primary Contribution Type: System/architecture description and operational support approach</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Yes</p>

<p>EX: Partial</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>The Action Engine – Turning Process Insights into Action</p>

<p><strong>Authors:</strong>  </p>

<p>Peyman Badakhshan; German Bernhart; Jerome Geyer‑Klingeberg; Janina Nakladal; Steffen Schenk; Thomas Vogelgesang</p>

<p><strong>DOI:</strong>  </p>

<p>N/A</p>

<p><strong>Year:</strong>  </p>

<p>2019</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Information Systems / Process Mining</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Operational process support; recommendations; predictive monitoring; execution integration</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper presents a Celonis web application that connects process mining insights to operational interventions, emphasizing continuous analysis, personalized recommendations, and direct execution in source systems. (Assumption: venue is a demo/industry track paper; DOI not supplied.) :contentReference[oaicite:4]{index=4}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Celonis, Munich; deployments across “10 different companies,” including Schukat Electronic (Germany) and Elsevier (Netherlands). (p. 5) :contentReference[oaicite:5]{index=5}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process owners, purchasers, order managers, and digital workforce receiving just‑in‑time recommendations. (p. 2–3) :contentReference[oaicite:6]{index=6}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual system description with application features and short case vignettes. :contentReference[oaicite:7]{index=7}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Operational framework and tooling for turning process analysis into executable actions. :contentReference[oaicite:8]{index=8}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors introduce the Celonis Action Engine, a web application that connects process mining analyses to operational support by recommending and executing actions during process execution. The system continuously analyzes data from multiple enterprise systems, personalizes recommendations to users or bots, and can trigger workflows back in source systems. The paper details the core approach (analyze → communicate → execute), the internal “skill” construct (triggers, routing rules, signals, actions), and three trigger families (rule‑based via PQL, classification of comparable processes, and predictive process monitoring). A Purchase‑to‑Pay demo and two brief industry cases (Schukat Electronic; Elsevier) illustrate usage and reported impacts. :contentReference[oaicite:9]{index=9}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No explicit use of the terms “actionable,” “actionability,” “actionable insight,” or “actionable recommendation.” The paper consistently frames “operationalizing insights,” “recommendations,” and “execute actions,” serving the same intent. (p. 2–4) :contentReference[oaicite:10]{index=10}</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes.  </p>

<ul>
<li><p>“translates findings from automatic discovery and rule‑based process analysis into recommendations for operational support during process execution… and directly executes actions in the source system.” (Abstract, p. 2) :contentReference[oaicite:11]{index=11}  </p></li>
<li><p>“This approach… operationaliz[es] insights created through process analysis.” (Abstract, p. 2) :contentReference[oaicite:12]{index=12}  </p></li>
<li><p>“three main phases… continuously analyzes… communicates… proposes action… or actively executes this action in the source system.” (p. 2) :contentReference[oaicite:13]{index=13}</p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicit conceptualization: actionable outputs are insights converted into specific, personalized, just‑in‑time recommendations that can be directly executed in operational systems to improve process KPIs.  </p>

<blockquote>
  <p>“…providing predictions as well as recommending necessary actions… [with] all the relevant information necessary to make a decision, which then allows taking action directly out of the Action Engine… [and] identify[ing] aspects of high priority where an action is needed and where action has a high impact on pre‑defined process KPIs.” (p. 2) :contentReference[oaicite:14]{index=14}</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Personalized and assigned to a responsible user</strong>  </p>

<p> &gt; “The recommendations are always personalized and assigned to a responsible employee.” (p. 3) :contentReference[oaicite:15]{index=15}</p></li>
<li><p><strong>Just‑in‑time communication</strong>  </p>

<p> &gt; “…communicates the detected improvement opportunities to users – just‑in‑time in a personalized way.” (p. 2) :contentReference[oaicite:16]{index=16}</p></li>
<li><p><strong>Context‑rich decision support</strong>  </p>

<p> &gt; “…providing all necessary process information and the direct link to workflows.” (p. 3) :contentReference[oaicite:17]{index=17}</p></li>
<li><p><strong>Direct executability in source systems</strong>  </p>

<p> &gt; “…directly executes actions in the source system (e.g. by triggering a bot or starting a workflow).” (p. 2) :contentReference[oaicite:18]{index=18}</p></li>
<li><p><strong>Prioritization by impact on KPIs</strong>  </p>

<p> &gt; “…identify[ing] aspects of high priority where an action is needed and where action has a high impact on pre‑defined process KPIs.” (p. 2) :contentReference[oaicite:19]{index=19}</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Action Engine; “Skill” construct. (Fig. 2, p. 3) :contentReference[oaicite:20]{index=20}  </p></li>
<li><p><strong>Methods/Levers:</strong> Rule‑based triggers via PQL; classification of comparable processes (Random Forest, Naive Bayes, matching/NLP); predictive process monitoring (Random Forest, Neural Networks). (p. 3) :contentReference[oaicite:21]{index=21}  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> “1. Analyze → 2. Communicate → 3. Execute,” with signals and routing to assignees; users act from a personal signal list. (Fig. 2 &amp; text, p. 3–4) :contentReference[oaicite:22]{index=22}  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Multi‑system event logs; KPIs like throughput time, fulfillment, process costs; cycle times for prioritization. (p. 2–4) :contentReference[oaicite:23]{index=23}  </p></li>
<li><p><strong>Implementation Context:</strong> Enterprise processes (P2P, O2C); execution via SAP or bots; e.g., “Add Contract” action pre‑fills SAP transaction parameters. (Fig. 4 &amp; text, p. 4–5) :contentReference[oaicite:24]{index=24}  </p></li>
</ul>

<blockquote>
  <p>“A skill is defined as… trigger, routing rules, signals, and actions… The signal itself is the representation of a skill… Actions are recommended tasks… executed in the operational source systems.” (p. 3) :contentReference[oaicite:25]{index=25}</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> <strong>Yes.</strong> The signal window shows “all necessary process information” to decide. (p. 3–4) :contentReference[oaicite:26]{index=26}  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> <strong>Yes.</strong> Personalized, assignee‑specific signals and impact on defined process KPIs. (p. 2–3) :contentReference[oaicite:27]{index=27}  </p></li>
<li><p><strong>FE (Feasibility):</strong> <strong>Yes.</strong> One‑click action executing pre‑filled transactions in SAP; direct workflow triggers. (p. 4) :contentReference[oaicite:28]{index=28}  </p></li>
<li><p><strong>TI (Timeliness):</strong> <strong>Yes.</strong> “just‑in‑time” recommendations; continuous analysis. (p. 2) :contentReference[oaicite:29]{index=29}  </p></li>
<li><p><strong>EX (Explainability):</strong> <strong>Partial.</strong> Triggers/rules are visible (PQL derived from filters); ML models named but explanations of individual recommendations are limited. (p. 3–4) :contentReference[oaicite:30]{index=30}  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> <strong>Yes.</strong> Optimization toward target KPIs and prioritization (e.g., VIP order). (p. 2) :contentReference[oaicite:31]{index=31}  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A explicitly.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<p>Process mining (discovery/prediction/operational support); predictive process monitoring. Referenced foundational works: van der Aalst (2010, 2016), etc. (References, p. 5) :contentReference[oaicite:32]{index=32}</p>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>No formal metric for “actionability,” but actions are prioritized by “pre‑defined process KPIs” (throughput time, fulfillment rates, costs) and timeliness (cycle times). (p. 2–4) :contentReference[oaicite:33]{index=33}</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> N/A (not explicitly discussed).  </p></li>
<li><p><strong>Enablers:</strong> Continuous multi‑system analysis; just‑in‑time personalized signaling; direct execution in source systems; skills with clear routing and ownership. (p. 2–4) :contentReference[oaicite:34]{index=34}</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions the Action Engine as extending process mining from analysis to operational support, aligning with literature on prediction and proactive insights (e.g., “proactive insights engine,” predictive monitoring). (p. 2; References) :contentReference[oaicite:35]{index=35}</p>

<hr />

<h2>Summary</h2>

<p>This paper presents the Celonis Action Engine as a concrete operationalization layer atop process mining. Instead of stopping at dashboards or offline analyses, the system creates “skills” that combine triggers (rules, classification, prediction), routing rules, signals, and executable actions. A three‑step workflow—analyze, communicate, execute—ensures users receive personalized, just‑in‑time, context‑rich recommendations linked to enterprise KPIs, and can act directly in source systems such as SAP via pre‑filled transactions or workflow triggers. The approach embeds goal alignment (KPI impact), feasibility (direct executability), timeliness (continuous monitoring and signaling), and clarity (decision‑ready context). Demonstrations in Purchase‑to‑Pay and Order‑to‑Cash settings and brief case notes (Schukat Electronic; Elsevier) illustrate applicability and reported benefits. While the paper does not define “actionability” explicitly, it provides a practical architecture for transforming insights into executed process interventions, thereby meeting the functional essence of actionability in operational process support. :contentReference[oaicite:36]{index=36}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 72 — Strong implicit treatment of actionability via analyze→recommend→execute architecture, but no explicit definition or terminology, and limited theoretical framing of “actionability.”</p></li>
<li><p><strong>Operationalization Score:</strong> 80 — Concrete mechanisms (skills, PQL rules, ML triggers, routing, execution back to source systems) and detailed workflow; however, lacks formal metrics for “degree of actionability” and limited explanation facilities.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“The Action Engine… translates findings… into recommendations for operational support during process execution… and directly executes actions in the source system.” (Abstract, p. 2) :contentReference[oaicite:37]{index=37}  </p></li>
<li><p>“This approach… operationalizing insights created through process analysis.” (Abstract, p. 2) :contentReference[oaicite:38]{index=38}  </p></li>
<li><p>“There are three main phases… analyzes… communicates… proposes action… or actively executes this action in the source system.” (p. 2) :contentReference[oaicite:39]{index=39}  </p></li>
<li><p>“The recommendations are always personalized and assigned to a responsible employee.” (p. 3) :contentReference[oaicite:40]{index=40}  </p></li>
<li><p>“A skill is defined as… trigger, routing rules, signals, and actions.” (p. 3) :contentReference[oaicite:41]{index=41}  </p></li>
<li><p>“Rule‑based Triggers… defined via PQL… Event‑Condition‑Action formula.” (p. 3) :contentReference[oaicite:42]{index=42}  </p></li>
<li><p>“Classified inefficiencies are predicted… Random Forest and Neural Networks… [then] a recommendation for action is initiated.” (p. 3) :contentReference[oaicite:43]{index=43}  </p></li>
<li><p>“The appropriate SAP transaction is already executed and pre‑filled with the right parameters.” (p. 4) :contentReference[oaicite:44]{index=44}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Veit et al., “The proactive insights engine: Process mining meets machine learning and artificial intelligence” (2017). (Ref. [2]) :contentReference[oaicite:45]{index=45}  </p></li>
<li><p>van der Aalst et al., on time prediction and beyond process mining (2011; 2010). (Refs. [4], [5]) :contentReference[oaicite:46]{index=46}</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: A General Framework for Action-Oriented Process Mining  </p>

<p>Authors: Gyunam Park, Wil M.P. van der Aalst  </p>

<p>DOI: 10.1007/978-3-030-66498-5_16  </p>

<p>Year: 2020  </p>

<p>Publication Type: Conference  </p>

<p>Discipline/Domain: Process Mining / Business Process Management  </p>

<p>Subdomain/Topic: Action-Oriented Process Mining, Continuous Operational Management  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95 — Strong and explicit focus on turning diagnostics into actionable process improvements with a conceptual framework and operationalization.  </p>

<p>Operationalization Score: 90 — Detailed method (constraint monitor + action engine) with formal definitions, implementation in ProM, and proof-of-concept experiments.  </p>

<p>Actionable/Actionability Used in Paper: Yes — “insights turned into actions” (p.2); “convert the insights from process mining diagnostics to management actions” (p.3); “framework supports… automated execution of actions to improve the process” (p.2)  </p>

<p>Authors Argue for Need for Actionability Without Defining It: No — They define and operationalize it in the framework context.  </p>

<p>Contains Definition of Actionability: Yes — Defined as the transformation of process diagnostics into proactive actions for process improvement.  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial — Explanations of violations and context are embedded in constraints, but not positioned as a general explainability framework.  </p>

<p>Contains Interpretability: No  </p>

<p>Contains Framework/Model: Yes — General framework for action-oriented process mining with two components (constraint monitor, action engine).  </p>

<p>Operationalization Present: Yes — Event stream monitoring, constraint instance generation, automated action execution.  </p>

<p>Primary Methodology: Conceptual + Proof-of-Concept Experimentation  </p>

<p>Study Context: Order handling process in an e-commerce-like simulated environment.  </p>

<p>Geographic/Institutional Context: RWTH Aachen University, Germany  </p>

<p>Target Users/Stakeholders: Process managers, operational managers, BPM practitioners, process mining tool developers.  </p>

<p>Primary Contribution Type: Conceptual framework with formalization and technical implementation.  </p>

<p>CL: Yes — Clear formal definitions and workflow for converting diagnostics to actions (p.2–3)  </p>

<p>CR: Yes — Emphasis on enterprise-level multiple-object contexts and relevant constraint/action design (p.4)  </p>

<p>FE: Yes — Focus on feasibility through operationalizable constraints and automated execution (p.10–11)  </p>

<p>TI: Yes — Continuous, time-window-based monitoring enabling timely interventions (p.6–9)  </p>

<p>EX: Partial — Contextual explanations for violations but no general interpretability model (p.7)  </p>

<p>GA: Yes — Actions aligned with process improvement goals (p.2–3, p.12)  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>A General Framework for Action-Oriented Process Mining</p>

<p><strong>Authors:</strong>  </p>

<p>Gyunam Park, Wil M.P. van der Aalst</p>

<p><strong>DOI:</strong>  </p>

<p>10.1007/978-3-030-66498-5_16</p>

<p><strong>Year:</strong>  </p>

<p>2020</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Process Mining / Business Process Management</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Action-Oriented Process Mining, Continuous Operational Management</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the gap between process mining diagnostics and actual process improvement. While existing techniques provide performance/compliance diagnostics, they leave action-taking to the user. This framework formalizes how to transform diagnostics into executable actions for continuous process management.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>RWTH Aachen University, Germany  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process managers, operational managers, BPM practitioners, process mining tool developers  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual + Proof-of-Concept Experimentation  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework with formalization and technical implementation</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper proposes a general framework for <strong>action-oriented process mining</strong> aimed at bridging the gap between diagnostics from process mining and actionable interventions for process improvement. The framework comprises two core components: the <strong>constraint monitor</strong>, which evaluates real-time event streams to detect violations of predefined constraints, and the <strong>action engine</strong>, which translates these violations into actionable transactions that can be executed by information systems. Using an order handling process as a motivating example, the authors illustrate how constraints and actions can be formalized, monitored, and operationalized. The framework is implemented as a ProM plug-in, supporting object-centric event data and continuous monitoring. Proof-of-concept experiments in a simulated environment demonstrate its ability to reduce process violations when proactive actions are applied.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>Yes</strong>  </p>

<ul>
<li><p>“Convert the insights from process mining diagnostics to management actions” (p.3)  </p></li>
<li><p>“Framework supports… automated execution of actions to improve the process” (p.2)  </p></li>
<li><p>“Insights turned into actions by continuously monitoring… and automatically generating proactive actions” (p.5)  </p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>No</strong> — They provide a formal operational definition within the framework.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is understood as <strong>the ability to transform process diagnostics (constraint violations, predictions) into proactive, executable actions</strong> that improve processes.  </p>

<blockquote>
  <p>“Continuously transforms process diagnostics into proactive actions for the process improvement.” (p.12)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Direct link from diagnostics to executable actions  </p></li>
<li><p>Context-aware constraints and violations  </p></li>
<li><p>Timely detection through continuous monitoring  </p></li>
<li><p>Feasible action definitions (transactions executable by systems)  </p></li>
<li><p>Goal alignment with process performance improvement</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> General Framework for Action-Oriented Process Mining  </p></li>
<li><p><strong>Methods/Levers:</strong> Constraint monitor, action engine, object-centric event streams  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Define constraints from diagnostics  </p>

<p> 2. Monitor event streams for violations  </p>

<p> 3. Generate constraint instance streams  </p>

<p> 4. Evaluate action formulas  </p>

<p> 5. Produce action instance streams  </p>

<p> 6. Execute actions in source systems via gateways  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Event streams (OCL format), constraint formulas (CFL), action formulas (AFL)  </p></li>
<li><p><strong>Implementation Context:</strong> ProM plug-in; tested on simulated order handling process  </p></li>
</ul>

<blockquote>
  <p>“By analyzing this constraint instance stream, the action engine assesses the necessity of actions and generates the actions…” (p.3)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — “formal definitions for constraint, context, action, and transaction” (p.6–9)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — multiple-object-type, enterprise-level applicability (p.4)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — transactions are executable via information systems (p.9–10)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — uses predefined time windows and moments for continuous monitoring (p.6–8)  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — contextual descriptions embedded in constraints (p.7)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — explicitly targets process improvement (p.2–3, p.12)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Object-Centric Process Mining  </p></li>
<li><p>Conformance checking  </p></li>
<li><p>Petri-net patterns  </p></li>
<li><p>Linear Temporal Logic</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Number of violated instances over time  </p></li>
<li><p>Reduction in violations after action application (Fig. 3b)</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Traditional tools stop at diagnostics without automated action execution  </p>

<p> - Lack of streaming data support in some commercial solutions (p.12)  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Formalized constraint and action definitions  </p>

<p> - Continuous monitoring and automation  </p>

<p> - Integration with existing information systems</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper situates itself among conformance checking, predictive monitoring, and prescriptive alarm systems, noting that existing approaches often focus on instance-level improvements or lack streaming data capabilities. This framework extends these by enabling enterprise-wide, continuous, multi-level action generation.</p>

<hr />

<h2>Summary</h2>

<p>This paper delivers a formalized, operationalizable framework for <strong>action-oriented process mining</strong>, addressing a recognized gap between process mining diagnostics and actionable interventions. It defines the conceptual and technical components—<strong>constraint monitor</strong> and <strong>action engine</strong>—and specifies their functioning through precise formal definitions. The authors ground their work in object-centric process mining to handle complex, enterprise-scale, multi-object processes. Actionability here is the transformation of diagnostics into contextually relevant, timely, feasible, and goal-aligned actions executable in information systems. The framework is implemented as a ProM plug-in, using standardized data formats (OCL, CFL, AFL) and tested in a simulated order handling process, demonstrating measurable reductions in constraint violations. Its contribution is both conceptual and practical, offering a scalable method for continuous process improvement.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Explicit conceptualization of actionability with a detailed, formal, and operational framework for process mining.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Clear, step-by-step operational model with proof-of-concept implementation and measurable effects.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Convert the insights from process mining diagnostics to management actions.” (p.3)  </p></li>
<li><p>“Continuously transforms process diagnostics into proactive actions for the process improvement.” (p.12)  </p></li>
<li><p>“If there exist more than 10 (possibly) violated items… send an e-mail to the case manager.” (p.5)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Celonis Action Engine — Badakhshan et al. (2019)  </p></li>
<li><p>Prescriptive Alarm System — Fahrenkrog-Petersen et al. (2019)  </p></li>
<li><p>Recommendation System for Predicting Risks — Conforti et al. (2015)  </p></li>
<li><p>Predictive Monitoring Survey — Marquez-Chamorro et al. (2018)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: A study into the contingencies of process improvement methods  </p>

<p>Authors: Monika Malinova, Steven Gross, Jan Mendling  </p>

<p>DOI: https://doi.org/10.1016/j.is.2021.101880  </p>

<p>Year: 2022  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Information Systems / Business Process Management  </p>

<p>Subdomain/Topic: Process improvement methods, contingency theory, method mining  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 78 — The paper conceptualizes method differences as contingent on context, defines structured activity frameworks, and discusses operational vs. strategic features, but does not explicitly frame them under "actionability" terminology.  </p>

<p>Operationalization Score: 85 — The work offers a detailed operationalization via the extended Stage-Activity framework (264 activities) and guidance for method customization based on contingent factors.  </p>

<p>Actionable/Actionability Used in Paper: No — The paper does not use the term “actionability” or related terms explicitly.  </p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — Implicitly, by discussing how methods must be customized to fit contingencies and goals (incremental vs. radical improvement), and identifying strategic vs. operational activities needed to enable outcomes.  </p>

<p>Contains Definition of Actionability: No  </p>

<p>Contains Systematic Features/Dimensions: Yes — Strategic vs. operational, incremental vs. radical, inward- vs. outward-looking, analytical vs. creative.  </p>

<p>Contains Explainability: Partial — Framework offers structured decomposition of method steps, but not framed as “explainability.”  </p>

<p>Contains Interpretability: Partial — The S-A framework improves transparency of method activities and clusters.  </p>

<p>Contains Framework/Model: Yes — Extended Stage-Activity (S-A) framework and method mining procedure.  </p>

<p>Operationalization Present: Yes — Detailed extraction, categorization, and clustering of activities, plus guidelines for customization based on contingent factors.  </p>

<p>Primary Methodology: Mixed Methods (systematic literature review, process mining, statistical analysis)  </p>

<p>Study Context: Process improvement methods across industries.  </p>

<p>Geographic/Institutional Context: Methods from global literature; authors from Vienna University of Economics and Business, Humboldt-Universität zu Berlin, University of Ljubljana.  </p>

<p>Target Users/Stakeholders: Process improvement practitioners, BPM researchers, organizational change managers.  </p>

<p>Primary Contribution Type: Framework and empirical analysis of method contingencies.  </p>

<p>CL: Partial — clarity via explicit activity descriptions.  </p>

<p>CR: Yes — contextual relevance emphasized via contingency factors.  </p>

<p>FE: Yes — feasibility addressed through method customization guidance.  </p>

<p>TI: Partial — timeliness implied in implementation planning stages.  </p>

<p>EX: Partial — explanation of activity inclusion via statistical and sequence analysis.  </p>

<p>GA: Yes — goal alignment addressed through linkage to objectives and strategy.  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>A study into the contingencies of process improvement methods  </p>

<p><strong>Authors:</strong>  </p>

<p>Monika Malinova, Steven Gross, Jan Mendling  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1016/j.is.2021.101880  </p>

<p><strong>Year:</strong>  </p>

<p>2022  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Information Systems / Business Process Management  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Process improvement methods, contingency theory, method mining  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>This paper investigates why numerous process improvement methods exist, whether differences are substantial or nominal, and how they relate to contingent factors such as industry, objectives, and type of improvement. Using a multi-method design, the authors identify 264 unique activities in 90 methods and cluster them into an extended Stage-Activity (S-A) framework.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Global literature scope; authors based in Austria, Germany, Slovenia.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>BPM practitioners, process improvement consultants, researchers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed Methods — systematic literature review, process mining (“method mining”), statistical analysis.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework and contingency-based analysis of process improvement methods.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The study analyzes 90 process improvement methods to determine shared and divergent activities and the contextual contingencies influencing their use. Through a systematic literature review, method mining, and statistical modeling, the authors create an extended Stage-Activity framework with 264 activities grouped into six stages. The analysis categorizes methods by the redesign orbit dimensions (ambition, nature, perspective) and reveals three main activity clusters—strategic, operational, and mixed. Findings show most methods are incremental, analytical, and inward-looking; few support radical improvement. The paper provides practical guidelines for customizing methods according to industry type, degree of innovation, and strategic vs. operational objectives.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>No</strong> — The terms “actionable” or “actionability” are not used. The concept is implicit in method adaptation to enable effective process changes.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>Yes</strong> — The authors stress the necessity for methods to fit contingencies to achieve intended outcomes:  </p>

<blockquote>
  <p>“...a method needs to be adapted to fit the project characteristics.” (p. 3)  </p>
</blockquote>

<blockquote>
  <p>“...practitioners could immediately take advantage of the list of activities...to better fit their specific process improvement project.” (p. 16)</p>
</blockquote>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicit: Actionability is framed as the suitability and adaptability of a process improvement method to specific organizational, environmental, and strategic contingencies to enable targeted outcomes.</p>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Contingency Fit:</strong>  </p>

<p> &gt; “...differences in goals imply differences in methods and their sequence of activities.” (p. 3)  </p></li>
<li><p><strong>Strategic &amp; Operational Balance:</strong>  </p>

<p> &gt; “...incorporating strategic activities has the potential to increase the impact of the process improvement.” (p. 16)  </p></li>
<li><p><strong>Clarity of Goals &amp; Drivers:</strong>  </p>

<p> &gt; “...decide on improvement radicalness, realize need for change and identify change drivers...could determine whether the project would have an incremental or a radical impact.” (p. 16)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Extended Stage-Activity (S-A) framework; Method Mining procedure.  </p></li>
<li><p><strong>Methods/Levers:</strong> Literature review, process mining, logistic regression, hierarchical clustering.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify methods; extract activities; categorize into framework; analyze sequences and correlations with contingencies.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> 90 methods, 264 activities, clustered into 41 groups, annotated by redesign orbit dimensions.  </p></li>
<li><p><strong>Implementation Context:</strong> Process improvement across industries.  </p></li>
</ul>

<blockquote>
  <p>“...practitioners could...focus on those activities that have been labeled as outward-looking, creative and radical and customize their method...” (p. 16)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Partial — Clear activity definitions but no explicit clarity dimension.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Contingent factor alignment central.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Guidance on tailoring methods to resources, skills.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Addresses planning and execution order, but not timeliness as a property.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — Sequence and correlation analysis provides transparency.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Objectives linked to method activities.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Ambition, Nature, Perspective (from redesign orbit).  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Contingency Theory (Donaldson, 2001)  </p></li>
<li><p>Redesign Orbit model (Dumas et al., 2018)  </p></li>
<li><p>Stage-Activity framework (Kettinger et al., 1997)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A — Metrics relate to process improvement performance, not actionability per se.</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of radical methods; neglect of strategic activities; poor adaptation to process characteristics.  </p></li>
<li><p><strong>Enablers:</strong> Activity customization to context; strategic-operational activity mix; alignment with objectives and industry.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions the extended S-A framework as an evolution of Kettinger et al. (1997), integrating contingency theory and BPM redesign orbit dimensions to offer a more granular, adaptable set of method activities.</p>

<hr />

<h2>Summary</h2>

<p>This paper provides an in-depth mapping of process improvement methods to activities, contextual contingencies, and strategic/operational dimensions. While not using the term “actionability,” it addresses the concept implicitly by focusing on how method activities must be customized to fit specific organizational contexts, objectives, and industry settings to be effective. The Extended Stage-Activity framework operationalizes this by detailing 264 activities across six stages, allowing practitioners to align methods with the ambition (incremental/radical), nature (analytical/creative), and perspective (inward/outward) of their improvement initiatives. Empirical analysis highlights that most methods are incremental and analytical, with radical, creative, and outward-looking approaches underrepresented.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 78 — Strong relevance through implicit conceptualization of actionability as contextual fit; lacks explicit definition.  </p></li>
<li><p><strong>Operationalization Score:</strong> 85 — Highly detailed framework and contingency-based guidelines for implementation.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“...a method needs to be adapted to fit the project characteristics.” (p. 3)  </p></li>
<li><p>“...incorporating strategic activities has the potential to increase the impact of the process improvement.” (p. 16)  </p></li>
<li><p>“...decide on improvement radicalness, realize need for change and identify change drivers...could determine whether the improvement project would have an incremental or a radical impact.” (p. 16)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Kettinger, James, and Guha (1997) — Stage-Activity framework.  </p></li>
<li><p>Donaldson (2001) — Contingency Theory.  </p></li>
<li><p>Dumas, La Rosa, Mendling, Reijers (2018) — Redesign Orbit.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Process Mining: A Guide for Practitioners</p>

<p>Authors: Fredrik Milani; Katsiaryna Lashkevich; Fabrizio Maria Maggi; Chiara Di Francescomarino</p>

<p>DOI: 10.1007/978-3-031-05760-1_16</p>

<p>Year: 2022</p>

<p>Publication Type: Conference (LNBI/LNBIP chapter; RCIS 2022)</p>

<p>Discipline/Domain: Business Process Management / Information Systems</p>

<p>Subdomain/Topic: Process mining use cases; business-oriented questions; SLR-based framework</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 20</p>

<p>Operationalization Score: 15</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: No</p>

<p>Primary Methodology: Review</p>

<p>Study Context: Systematic Literature Review of process mining literature (searches in Feb 2020)</p>

<p>Geographic/Institutional Context: University of Tartu; Free University of Bozen-Bolzano; FBK-IRST (authors’ affiliations)</p>

<p>Target Users/Stakeholders: Practitioners and companies adopting process mining</p>

<p>Primary Contribution Type: Business-oriented categorization framework of process mining use cases</p>

<p>CL: No</p>

<p>CR: No</p>

<p>FE: No</p>

<p>TI: No</p>

<p>EX: Partial</p>

<p>GA: No</p>

<p>Reason if Not Eligible: The paper does not use the terms “actionable/actionability” nor define conditions or criteria for being actionable; it offers a value-oriented categorization and business questions for process mining rather than an actionability construct.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Process Mining: A Guide for Practitioners</p>

<p><strong>Authors:</strong>  </p>

<p>Fredrik Milani; Katsiaryna Lashkevich; Fabrizio Maria Maggi; Chiara Di Francescomarino</p>

<p><strong>DOI:</strong>  </p>

<p>10.1007/978-3-031-05760-1_16</p>

<p><strong>Year:</strong>  </p>

<p>2022</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference (LNBI/LNBIP chapter; RCIS 2022). :contentReference[oaicite:0]{index=0}</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Business Process Management / Information Systems</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Process mining use cases; business-oriented questions; SLR-based framework. :contentReference[oaicite:1]{index=1}</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the profusion of process mining techniques and the difficulty practitioners face in mapping techniques to business value and questions. It develops a business-oriented framework grounded in a systematic literature review. (pp. 265–266) :contentReference[oaicite:2]{index=2}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Authored by researchers at University of Tartu, Free University of Bozen-Bolzano, and FBK-IRST. (p. 265) :contentReference[oaicite:3]{index=3}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Practitioners/companies seeking to apply process mining to business problems. (pp. 265–266) :contentReference[oaicite:4]{index=4}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Review (Systematic Literature Review following Kitchenham). (pp. 268–270; Fig. 1 on p. 269) :contentReference[oaicite:5]{index=5}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework categorizing process mining use cases and the business-oriented questions they answer, instantiated via VBPM values. (pp. 273–276; Table 1 on p. 275) :contentReference[oaicite:6]{index=6}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors conduct a systematic literature review (SLR) to map empirically validated process mining methods to business-oriented use cases and questions. They identify common use cases such as model discovery, predictive monitoring, conformance checking, variant analysis, performance analysis, and more. Based on Value-Driven BPM (VBPM), they build a framework organizing use cases under transparency, efficiency, quality, compliance, and agility, and associate each with representative business questions. The review process is depicted in Fig. 1 and yields 839 relevant papers; Fig. 2 summarizes use-case frequency. The framework aims to help practitioners select techniques aligned with organizational value objectives. (pp. 269–276; Fig. 1 p. 269; Fig. 2 p. 271) :contentReference[oaicite:7]{index=7}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No; the paper does not use “actionable/actionability/actionable insight/recommendation/knowledge” nor define these terms. It instead frames “business-oriented questions” and value categories without articulating an actionability construct. (pp. 266, 272–276) :contentReference[oaicite:8]{index=8}</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No; the authors emphasize business value and questions but do not call for “actionable” outputs as such. (pp. 266, 273–276) :contentReference[oaicite:9]{index=9}</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> No  </p></li>
<li><p><strong>FE (Feasibility):</strong> No  </p></li>
<li><p><strong>TI (Timeliness):</strong> No  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — the framework distinguishes “explanatory” questions (e.g., deviance mining explains why cases deviate), but not as an actionability dimension. (pp. 272–274) :contentReference[oaicite:10]{index=10}  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> No</p></li>
</ul>

<p><strong>Other Dimensions Named by Authors:</strong>  </p>

<p>Instead of actionability dimensions, they adopt VBPM value categories: transparency, efficiency, quality, compliance, agility. (pp. 273–276) :contentReference[oaicite:11]{index=11}</p>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<p>Value-Driven BPM (VBPM) as the organizing lens for categories and questions. (pp. 273–274) :contentReference[oaicite:12]{index=12}</p>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> N/A  </p></li>
<li><p><strong>Enablers:</strong> N/A</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper positions itself against mapping studies and sector-specific reviews, extending beyond classical discovery/conformance/enhancement to include newer use cases (e.g., prescriptive monitoring), and complements studies on industrial adoption by guiding selection of methods via business questions. (pp. 266–268) :contentReference[oaicite:13]{index=13}</p>

<hr />

<h2>Summary</h2>

<p>This SLR-based chapter catalogues process mining methods into practical use cases and ties them to business-facing questions. It spans descriptive (e.g., “How are cases executed?”), comparative (variant and conformance differences), explanatory (why deviations occur; what affects performance), and recommendatory (prescriptive monitoring) question types. The core contribution is a VBPM-aligned framework with five value categories—transparency, efficiency, quality, compliance, agility—each subdivided into concrete use cases such as model discovery, model enhancement, performance analysis, variant analysis, conformance/compliance checking, predictive/prescriptive monitoring, and concept drift. A figure summarizes the SLR pipeline and tallies, and another shows the prominence of discovery and predictive monitoring among use cases. The instantiation table (Table 1) lists exemplar business questions and sample references per use case. While highly practitioner-oriented, the chapter does not define “actionability” or criteria for actionable insights; its focus remains on mapping techniques to value and questions rather than specifying what renders findings actionable. (pp. 269–276; Fig. 1 p. 269; Fig. 2 p. 271; Table 1 p. 275) :contentReference[oaicite:14]{index=14}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 20 — Useful background for business value alignment and questions, but lacks explicit engagement with “actionable/actionability” concepts or definitions. :contentReference[oaicite:15]{index=15}  </p></li>
<li><p><strong>Operationalization Score:</strong> 15 — Provides a categorized question bank and examples but no operational criteria or workflow specifically aimed at producing “actionable” outputs. :contentReference[oaicite:16]{index=16}</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“This paper’s main objective is to develop a business-oriented framework capturing the main process mining use cases and the business-oriented questions they can answer.” (p. 265) :contentReference[oaicite:17]{index=17}  </p></li>
<li><p>“The second [RQ]… aims at eliciting the business-oriented questions that the outputs of process mining methods can answer.” (p. 269) :contentReference[oaicite:18]{index=18}  </p></li>
<li><p>“Our categorization draws on the value-driven business process management (VBPM)…” (p. 273) :contentReference[oaicite:19]{index=19}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A — the chapter does not cite works that define or operationalize “actionability” as a construct; citations focus on process mining methods and reviews. :contentReference[oaicite:20]{index=20}</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Discovery of Improvement Opportunities in Knock-Out Checks of Business Processes</p>

<p>Authors: Katsiaryna Lashkevich, Lino Moises Mediavilla Ponce, Manuel Camargo, Fredrik Milani, Marlon Dumas</p>

<p>DOI: https://doi.org/10.1007/978-3-031-33080-3_23</p>

<p>Year: 2023</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Business Process Management / Process Mining</p>

<p>Subdomain/Topic: Knock-out checks, overprocessing waste, interpretable process mining</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 85</p>

<p>Operationalization Score: 90</p>

<p>Actionable/Actionability Used in Paper: Yes — “...suggest redesigns to reduce the overprocessing wastes...” (p. 382); “...provides further insights on knock-out check executions, explaining to analysts the logic behind the suggested redesigns.” (p. 381)</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — “...explain to analysts the logic behind the suggested redesigns... to gain confidence in making decisions based on recommendations” (p. 384)</p>

<p>Contains Definition of Actionability: No (focuses on operationalization without formal definition)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual + Experimental (synthetic and real-life evaluation)</p>

<p>Study Context: Process mining for knock-out check optimization to reduce overprocessing</p>

<p>Geographic/Institutional Context: University of Tartu; synthetic dataset; environmental permit process in the Netherlands</p>

<p>Target Users/Stakeholders: Process analysts, BPM practitioners</p>

<p>Primary Contribution Type: Methodological framework and software tool</p>

<p>CL: Yes — “...allowing analysts to understand the logic behind suggested redesigns” (p. 384)</p>

<p>CR: Yes — “...considering dependencies between activities and the actual data in the event log” (p. 389)</p>

<p>FE: Yes — “...reordering and relocating checks as early as possible in the process” (p. 389)</p>

<p>TI: Partial — time-related efficiency improvements implied but not explicitly named as timeliness</p>

<p>EX: Yes — “...interpretable machine learning techniques… explaining the logic” (p. 381)</p>

<p>GA: Yes — alignment with process improvement goals to minimize waste (p. 382)</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Discovery of Improvement Opportunities in Knock-Out Checks of Business Processes  </p>

<p><strong>Authors:</strong>  </p>

<p>Katsiaryna Lashkevich, Lino Moises Mediavilla Ponce, Manuel Camargo, Fredrik Milani, Marlon Dumas  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1007/978-3-031-33080-3_23  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Business Process Management / Process Mining  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Knock-out checks, overprocessing waste, interpretable process mining  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses overprocessing waste in processes with knock-out checks (activities that can prematurely terminate a process). Existing process mining methods either ignore overprocessing or use black-box models, limiting interpretability. The authors propose an interpretable process mining approach to discover knock-out checks, quantify overprocessing, and recommend redesigns.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of Tartu (Estonia); evaluated with synthetic data and a Dutch environmental permit application log.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process analysts, BPM professionals, organizational decision-makers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual + Experimental (synthetic and real-life evaluation).  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Methodological framework and software tool.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper proposes an interpretable process mining approach to detect and optimize knock-out checks in business processes to reduce overprocessing waste. Knock-out checks classify cases as accepted or rejected, with rejected cases representing wasted effort. The approach identifies knock-out checks, decision rules, and dependencies from event logs, calculates waste metrics, and recommends redesigns such as reordering, relocating, or adjusting rules. Implemented as a software tool, the method was validated on synthetic and real-life event logs, showing comparable accuracy to black-box models while offering interpretability. Evaluation confirmed that the method could discover improvement opportunities considering data dependencies.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>Yes:  </p>

<ul>
<li><p>“...suggest redesigns to reduce the overprocessing wastes...” (p. 382)  </p></li>
<li><p>“...provides further insights on knock-out check executions, explaining to analysts the logic behind the suggested redesigns.” (p. 381)  </p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes:  </p>

<ul>
<li>“...explain to analysts the logic behind the suggested redesigns... to gain confidence in making decisions based on recommendations” (p. 384)  </li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicit: actionability relates to producing interpretable redesign suggestions grounded in data and dependencies, enabling process analysts to make informed improvement decisions.</p>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Interpretability of recommendations</strong>  </p>

<p> &gt; “...interpretable machine learning techniques… explaining to analysts the logic behind the suggested redesigns.” (p. 381)  </p></li>
<li><p><strong>Grounding in data dependencies</strong>  </p>

<p> &gt; “...taking into account any dependencies detected between activities...” (p. 389)  </p></li>
<li><p><strong>Feasibility within process constraints</strong>  </p>

<p> &gt; “...relocate the knock-out checks as early as the case attributes required by their knock-out rules are available.” (p. 389)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Knock-out Check Discovery and Analysis  </p></li>
<li><p><strong>Methods/Levers:</strong> Event log analysis, decision rule discovery (RIPPER), dependency detection, waste metric computation  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Discover knock-out checks and decision rules from event logs  </p>

<p> 2. Detect dependencies among activities  </p>

<p> 3. Calculate overprocessing, processing time, and waiting time waste  </p>

<p> 4. Identify redesign opportunities: reordering, relocation, and rule adjustment  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Event logs with case IDs, activities, timestamps, attributes; metrics include effort-per-rejection, waste measures  </p></li>
<li><p><strong>Implementation Context:</strong> Synthetic credit application process; environmental permit process  </p></li>
</ul>

<blockquote>
  <p>“...identify improvement opportunities in knock-out checks and suggest redesigns to reduce overprocessing wastes.” (p. 382)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — “...allowing analysts to understand the logic behind suggested redesigns” (p. 384)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — “...considering dependencies between activities and the actual data in the event log” (p. 389)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — “...reordering and relocating checks as early as possible in the process” (p. 389)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — implied through efficiency improvements, not explicitly labeled  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — “...interpretable machine learning techniques… explaining the logic” (p. 381)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — aligns with waste minimization goals (p. 382)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Knock-out principle [2, 11, 17]  </p></li>
<li><p>Early knockout pattern [15]  </p></li>
<li><p>Process redesign heuristics [24]  </p></li>
<li><p>Interpretability in process mining [6, 10]  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Effort-per-rejection  </p></li>
<li><p>Overprocessing waste  </p></li>
<li><p>Processing time waste  </p></li>
<li><p>Waiting time waste  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Limited by availability and granularity of event log data (p. 390)  </p></li>
<li><p><strong>Enablers:</strong> Interpretable ML, dependency-aware ordering, process mining flexibility  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The approach builds on prior knock-out optimization research (e.g., van der Aalst 2001; Verenich et al. 2016) but diverges by using interpretable rule-based models rather than black-box predictions. It also integrates process redesign heuristics directly from event logs without requiring an as-is model.</p>

<hr />

<h2>Summary</h2>

<p>This paper introduces a process mining-based methodology to detect, analyze, and optimize knock-out checks to reduce overprocessing waste. By combining event log analysis, interpretable decision rule learning (RIPPER), and dependency detection, it provides actionable redesign recommendations such as reordering, relocating, and adjusting knock-out checks. Unlike black-box approaches, the method emphasizes interpretability, allowing analysts to understand the rationale behind suggested changes. Evaluation on synthetic and real-life datasets demonstrated high rediscovery accuracy and comparable classification performance to predictive black-box models, with the added benefit of transparency. The framework operationalizes actionability through clarity, contextual relevance, feasibility, and explainability, directly supporting waste reduction goals in business processes.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 — Strong conceptual linkage to actionable recommendations through interpretable redesigns, though no explicit definition of “actionability” is provided.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Detailed, systematic method with concrete steps, metrics, and tool implementation for achieving actionable improvements.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“...interpretable machine learning techniques… explaining to analysts the logic behind the suggested redesigns.” (p. 381)  </p></li>
<li><p>“...taking into account any dependencies detected between activities...” (p. 389)  </p></li>
<li><p>“...relocate the knock-out checks as early as the case attributes required by their knock-out rules are available.” (p. 389)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>van der Aalst, W.M.P. (2001) — Knock-out process re-engineering  </p></li>
<li><p>Verenich et al. (2016) — Predictive activity ordering for overprocessing reduction  </p></li>
<li><p>Lohrmann &amp; Reichert (2016) — Process improvement patterns  </p></li>
<li><p>Reijers &amp; Mansar (2005) — Best practices in process redesign</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Aggregating Event Knowledge Graphs for Task Analysis</p>

<p>Authors: Eva L. Klijn, Felix Mannhardt, Dirk Fahland</p>

<p>DOI: https://doi.org/10.1007/978-3-031-27815-0_36</p>

<p>Year: 2023</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Process Mining / Data Science</p>

<p>Subdomain/Topic: Event Knowledge Graphs, Task Aggregation, Process Analysis</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 20</p>

<p>Operationalization Score: 0</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes (Aggregation queries framework for EKGs)</p>

<p>Operationalization Present: Yes (Aggregation operators for summarizing tasks)</p>

<p>Primary Methodology: Conceptual + Demonstration</p>

<p>Study Context: Development of new aggregation queries for Event Knowledge Graphs applied to BPIC’17 dataset</p>

<p>Geographic/Institutional Context: Eindhoven University of Technology</p>

<p>Target Users/Stakeholders: Process mining researchers and practitioners analyzing task execution patterns</p>

<p>Primary Contribution Type: Methodological framework and query design</p>

<p>CL: No</p>

<p>CR: No</p>

<p>FE: No</p>

<p>TI: No</p>

<p>EX: No</p>

<p>GA: No</p>

<p>Reason if Not Eligible: The paper focuses exclusively on developing graph aggregation methods for analyzing tasks in event knowledge graphs. It does not use, define, or discuss “actionability” or the state of being actionable in relation to research outputs, insights, or recommendations.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Aggregating Event Knowledge Graphs for Task Analysis</p>

<p><strong>Authors:</strong>  </p>

<p>Eva L. Klijn, Felix Mannhardt, Dirk Fahland</p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1007/978-3-031-27815-0_36</p>

<p><strong>Year:</strong>  </p>

<p>2023</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Process Mining / Data Science</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Event Knowledge Graphs, Task Aggregation, Process Analysis</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the challenge of summarizing and analyzing task execution patterns in event knowledge graphs (EKGs), a graph-based process mining data model. It builds upon limitations in existing aggregation approaches to propose parameterized aggregation queries that allow more flexible summarization of tasks, both globally (inter-task) and locally (intra-task). The approach is demonstrated using the BPIC’17 dataset.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Eindhoven University of Technology, The Netherlands</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process mining researchers, data scientists, and practitioners focusing on task analysis in complex processes.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual design of aggregation operators, implemented as Cypher queries, and empirical demonstration.</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Methodological framework and algorithmic approach.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper introduces new aggregation queries for Event Knowledge Graphs (EKGs) to enable more nuanced analysis of task execution patterns. Traditional aggregation approaches in EKGs either focus on events or high-level event abstractions, but fail to handle the intermediate abstraction of “task instances” — sequences of multiple events executed by a single actor within a single case. The authors identify three requirements: aggregating similar higher-level events while preserving context (R1), aggregating underlying events to study variations (R2), and controlling aggregation level via parameters (R3). They propose two main aggregation strategies: (1) aggregating similar task instances into task classes (inter-task DFGs) and (2) aggregating events within tasks to study intra-task behavior. The framework supports parameterization for filtering, classification, and edge aggregation. The approach is demonstrated on the BPIC’17 dataset, showing new insights into actor behavior and task variability.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No — The terms “actionability,” “actionable,” “actionable insights,” or similar are not used in the paper.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No — The authors focus on data summarization and process analysis without discussing actionable qualities of outputs.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> No</p></li>
<li><p><strong>FE (Feasibility):</strong> No</p></li>
<li><p><strong>TI (Timeliness):</strong> No</p></li>
<li><p><strong>EX (Explainability):</strong> No</p></li>
<li><p><strong>GA (Goal Alignment):</strong> No</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Event Knowledge Graph (EKG) model  </p></li>
<li><p>Graph-based aggregation operators  </p></li>
<li><p>Directly-follows graph (DFG) analysis  </p></li>
<li><p>Clustering for task similarity (agglomerative clustering with silhouette index)</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> N/A  </p></li>
<li><p><strong>Enablers:</strong> N/A  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The authors position their work as an extension of prior EKG aggregation methods, task mining approaches, and organizational modeling techniques. Unlike existing methods that focus on activities, single-actor tasks, or hierarchical abstractions, their query-based approach allows flexible summarization at the task instance level, preserving process and collaboration context.</p>

<hr />

<h2>Summary</h2>

<p>This paper contributes a new set of parameterized aggregation queries for event knowledge graphs to support task analysis at multiple abstraction levels. By distinguishing between “task instances” (actor-case event sequences) and “tasks” (classes of similar task instances), the authors enable both inter-task process views and intra-task behavior analysis. The proposed methods address limitations in existing aggregation operations by allowing flexible similarity definitions, parameter-based filtering, and selective edge aggregation. Demonstrations on the BPIC’17 dataset highlight their ability to reveal differences in actor work patterns, task content variability, and collaborative structures. While methodologically rich for process mining, the work does not discuss or engage with the concept of actionability in research outputs.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 20 — The paper does not address actionability; relevance is limited to methodological interest for process mining.</p></li>
<li><p><strong>Operationalization Score:</strong> 0 — No operationalization of actionability; operationalization applies to aggregation methods, not to actionable insights.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We show… that understanding tasks in a process requires (R1) to aggregate sets of similar higher-level events to suitable constructs while preserving their behavioral context, (R2) to aggregate events underlying higher-level events to study variations among actions, and (R3) that either aggregation requires parameters for filtering and for controlling the aggregation level.” (p. 494)  </p></li>
<li><p>“We propose… parameterized aggregation operations, formalized as queries over event knowledge graphs, that address (R1–R3).” (p. 494)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Multi-perspective Concept Drift Detection: Including the Actor Perspective</p>

<p>Authors: Eva L. Klijn, Felix Mannhardt, Dirk Fahland</p>

<p>DOI: https://doi.org/10.1007/978-3-031-61057-8_9</p>

<p>Year: 2024</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Process Mining / Business Process Management</p>

<p>Subdomain/Topic: Concept Drift Detection, Actor Perspective, Event Knowledge Graphs</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 30</p>

<p>Operationalization Score: 50</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Quantitative + Experimental</p>

<p>Study Context: Concept drift detection in process mining with actor perspective</p>

<p>Geographic/Institutional Context: Eindhoven University of Technology; datasets BPIC'17 and private manufacturing process</p>

<p>Target Users/Stakeholders: Process analysts, BPM researchers, organizational performance analysts</p>

<p>Primary Contribution Type: Methodological approach for multi-perspective drift detection</p>

<p>CL: No</p>

<p>CR: No</p>

<p>FE: No</p>

<p>TI: No</p>

<p>EX: No</p>

<p>GA: No</p>

<p>Reason if Not Eligible: Paper focuses on process mining methodology for drift detection and actor-control flow integration, but does not use or conceptualize “actionability” or the state of being actionable in relation to findings or recommendations.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Multi-perspective Concept Drift Detection: Including the Actor Perspective</p>

<p><strong>Authors:</strong>  </p>

<p>Eva L. Klijn, Felix Mannhardt, Dirk Fahland</p>

<p><strong>DOI:</strong>  </p>

<p><a href="https://doi.org/10.1007/978-3-031-61057-8_9">https://doi.org/10.1007/978-3-031-61057-8_9</a></p>

<p><strong>Year:</strong>  </p>

<p>2024</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Process Mining / Business Process Management</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Concept Drift Detection, Actor Perspective, Event Knowledge Graphs</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses limitations in existing concept drift detection methods in process mining, which focus primarily on control-flow and overlook actor-driven changes. It extends drift detection to include the actor perspective via multi-layered event knowledge graphs (EKGs), enabling identification of changes in individual actors’ behaviors and their collaboration patterns.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Eindhoven University of Technology, Netherlands; datasets from BPIC’17 and a private manufacturing process.</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process analysts, BPM researchers, organizations aiming to monitor and improve processes.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative + Experimental</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Methodological approach for multi-perspective drift detection</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This study proposes a method to detect concept drift in processes by integrating both control-flow and actor perspectives, which is often neglected in traditional approaches. Using Event Knowledge Graphs (EKGs) with a task instance layer, the authors generalize existing change point detection techniques to account for actor behaviors and interactions alongside process activities. The method extracts features that capture both perspectives, such as task variants, task groupings, and task-actor combinations, and applies them to real-world datasets (BPIC’17 and a manufacturing process). Experimental results show that including the actor perspective yields more robust drift detection signals, up to 2.6 times stronger than control-flow-only features, and reveals unique changes in individual actors or collaborations not visible in aggregated process metrics.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No — The terms "actionable," "actionability," or equivalent are not used in relation to insights, recommendations, or knowledge.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No — The authors focus on methodological robustness and detection accuracy without discussing outputs in terms of being actionable.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> No</p></li>
<li><p><strong>FE (Feasibility):</strong> No</p></li>
<li><p><strong>TI (Timeliness):</strong> No</p></li>
<li><p><strong>EX (Explainability):</strong> No</p></li>
<li><p><strong>GA (Goal Alignment):</strong> No</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Event Knowledge Graphs (EKGs)</p></li>
<li><p>Change point detection via PELT algorithm</p></li>
<li><p>Multi-perspective process mining (control-flow + resource/actor perspectives)</p></li>
<li><p>Task variant and task aggregation concepts from prior process mining literature</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p>N/A</p>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper builds on prior concept drift detection research but fills a gap in incorporating the resource/actor perspective. It extends methods like those of Adams et al. (2023) by modeling actor-case interactions at the task level, enabling detection of both global and actor-specific drifts.</p>

<hr />

<h2>Summary</h2>

<p>While existing concept drift detection techniques in process mining focus primarily on control-flow changes, this paper integrates the actor perspective to capture bottom-up changes in behavior and collaboration. Leveraging multi-layered Event Knowledge Graphs, the authors generalize change point detection to extract features combining activity sequences, tasks, and actor-task mappings. Their experiments on two datasets reveal that actor-inclusive features produce stronger and more robust drift signals than activity-only features, uncovering changes invisible at the aggregate process level. The approach highlights the importance of actor behavior in understanding process evolution and supports more nuanced continuous process analysis. However, despite its contributions to methodology and insights into process changes, the paper does not engage with the notion of “actionability” or define what makes an insight actionable, making it ineligible for an actionability-focused review.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 30 — The paper contributes to process analysis but does not address or define actionability.</p></li>
<li><p><strong>Operationalization Score:</strong> 50 — The method is operationalized clearly for drift detection but unrelated to actionability.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We generalize an existing concept drift detection technique to consider actor behavior and control-flow jointly by using a multi-layered event knowledge graph.” (p. 1)</p></li>
<li><p>“Our approach led to new insights into global process changes, changes in behavior of individual actors, and change in collaborations between actors.” (p. 1)</p></li>
<li><p>“The robustness of task features in drift detection arises because a task sequentially composes multiple control-flow features, thus suppressing ‘noisy’ drift signals of individual control-flow features within the larger task.” (p. 15)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: BPMN in healthcare: Challenges and best practices</p>

<p>Authors: Luise Pufahl, Francesca Zerbato, Barbara Weber, Ingo Weber</p>

<p>DOI: https://doi.org/10.1016/j.is.2022.102013</p>

<p>Year: 2022</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Information Systems / Business Process Management</p>

<p>Subdomain/Topic: BPMN application in healthcare process modeling</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 78 – The paper provides systematic features/dimensions linked to making process models usable and precise in healthcare, implicitly addressing actionability via clarity, contextual relevance, and feasibility.</p>

<p>Operationalization Score: 85 – Offers concrete BPMN best practices, process fragments, and abstraction-level guidance to achieve actionable healthcare process models.</p>

<p>Actionable/Actionability Used in Paper: No – No explicit use of “actionable” or “actionability.”</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes – “We advocate that healthcare process modeling tasks require systematic guidance in terms of modeling tools and methods, especially to support shared understanding by different stakeholders.” (p. 2)</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Mixed Methods (design science + exploratory study)</p>

<p>Study Context: Healthcare process modeling within single medical organizations</p>

<p>Geographic/Institutional Context: Germany, Italy, Spain, Netherlands (university hospitals)</p>

<p>Target Users/Stakeholders: Process modelers, healthcare professionals, IT analysts in healthcare</p>

<p>Primary Contribution Type: Practical framework and best practices for BPMN modeling in healthcare</p>

<p>CL: Yes – “Graphical representations… are easier to grasp and less ambiguous than textual documents” (p. 1)</p>

<p>CR: Yes – “Encouraging good design practices and supporting a shared understanding among different groups of stakeholders” (p. 2)</p>

<p>FE: Yes – “The proposed best practices are meant to be used by health workers with a basic understanding of BPMN… may also help experienced modelers…” (p. 2)</p>

<p>TI: No – Timeliness is not directly addressed as a dimension of actionability</p>

<p>EX: Partial – BPMN and DMN examples explain decision logic and modeling choices, but not framed explicitly as explainability</p>

<p>GA: Yes – “Encouraging good design practices… capturing (challenging) healthcare process aspects at different levels of process abstraction” (p. 2)</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>BPMN in healthcare: Challenges and best practices  </p>

<p><strong>Authors:</strong>  </p>

<p>Luise Pufahl, Francesca Zerbato, Barbara Weber, Ingo Weber  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1016/j.is.2022.102013  </p>

<p><strong>Year:</strong>  </p>

<p>2022  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Information Systems / Business Process Management  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>BPMN application in healthcare process modeling  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the low uptake of BPMN in healthcare despite its benefits, identifying recurring modeling challenges from real projects and literature, and providing ready-to-use BPMN process fragments as best practices to improve healthcare process modeling quality.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University hospitals in Germany, Italy, Spain, Netherlands  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Healthcare professionals, process modelers, IT analysts in healthcare  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed methods – design science approach + exploratory evaluation study  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework and best practices for BPMN modeling in healthcare  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The study identifies eight recurrent challenges in healthcare process modeling (e.g., patient involvement, patient-specific needs, evidence-based decision-making, temporal constraints, monitoring, shared working behavior, centralized scheduling, diagnostic service involvement) through real-world projects and literature. It proposes BPMN best practices for each, including process fragments at different abstraction levels (descriptive, analytical, implementable). The best practices aim to improve shared understanding, standardization, and error reduction in healthcare process models. An exploratory study with junior experts in medicine and IT found that using these best practices improved syntactic and semantic model quality and was perceived as useful for learning BPMN.  </p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No – While the paper doesn’t use the term “actionability,” it addresses the practical usability of process models for decision-making and implementation indirectly.  </p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes –  </p>

<blockquote>
  <p>“We advocate that healthcare process modeling tasks require systematic guidance in terms of modeling tools and methods, especially to support shared understanding by different stakeholders.” (p. 2)  </p>
</blockquote>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicit – Actionability is framed as the ability of process models to support shared understanding, accurate representation of complex aspects, and readiness for implementation.  </p>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Clarity &amp; readability</strong>  </p>

<p> &gt; “Graphical representations… are easier to grasp and less ambiguous than textual documents.” (p. 1)  </p></li>
<li><p><strong>Contextual relevance to domain specifics</strong>  </p>

<p> &gt; “Encouraging good design practices and supporting a shared understanding among different groups of stakeholders.” (p. 2)  </p></li>
<li><p><strong>Feasibility for intended users</strong>  </p>

<p> &gt; “The proposed best practices are meant to be used by health workers with a basic understanding of BPMN… may also help experienced modelers…” (p. 2)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> BPMN Best Practices for Healthcare  </p></li>
<li><p><strong>Methods/Levers:</strong> Ready-to-use BPMN process fragments for common healthcare challenges  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify challenge → choose abstraction level (D/A/I) → apply BPMN fragment to capture aspect  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Derived from 38 process models across 8 projects + literature relevance screening  </p></li>
<li><p><strong>Implementation Context:</strong> Healthcare organizations (single-organization scope)  </p></li>
</ul>

<blockquote>
  <p>“The proposed best practices… guide process designers in capturing (challenging) healthcare process aspects at different levels of process abstraction…” (p. 2)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – “Graphical representations… easier to grasp and less ambiguous” (p. 1)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – “Supporting a shared understanding among different groups of stakeholders” (p. 2)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – “Meant to be used by health workers with a basic understanding of BPMN” (p. 2)  </p></li>
<li><p><strong>TI (Timeliness):</strong> No  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial – BPMN+DMN diagrams make decision logic explicit  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – “Encouraging good design practices… capturing… aspects at different levels” (p. 2)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Business Process Model and Notation (BPMN)  </p></li>
<li><p>Decision Model and Notation (DMN)  </p></li>
<li><p>Design science research methodology  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A – No explicit metrics, but semantic/syntactic model quality used as a proxy  </p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Complexity of healthcare processes, lack of BPMN training, advanced constructs difficult for novices  </p></li>
<li><p><strong>Enablers:</strong> Ready-to-use process fragments, abstraction level options, integration with DMN  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on BPMN extensions and domain-specific modeling patterns, but focuses on native BPMN elements to ensure tool support and adoption.  </p>

<hr />

<h2>Summary</h2>

<p>This paper offers a structured, empirically grounded set of BPMN best practices addressing eight key challenges in healthcare process modeling. While not using “actionability” explicitly, it aligns closely with the concept by improving the clarity, contextual relevance, and feasibility of process models for decision-making and implementation. Best practices are presented as modular process fragments at different abstraction levels, enabling flexibility for documentation, analysis, or execution. An exploratory evaluation with junior healthcare and IT experts showed improved model quality and perceived usefulness, though advanced constructs required higher BPMN proficiency. The approach balances domain specificity with adherence to BPMN standards, avoiding unsupported extensions, and is positioned as a reusable toolkit for healthcare process modeling initiatives.  </p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 78 – Strong link to practical utility and decision-readiness of models, though lacking explicit definition of “actionability.”  </p></li>
<li><p><strong>Operationalization Score:</strong> 85 – Provides concrete BPMN fragments, abstraction guidance, and application workflow.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We advocate that healthcare process modeling tasks require systematic guidance… especially to support shared understanding by different stakeholders.” (p. 2)  </p></li>
<li><p>“Graphical representations… easier to grasp and less ambiguous than textual documents.” (p. 1)  </p></li>
<li><p>“The proposed best practices are meant to be used by health workers with a basic understanding of BPMN…” (p. 2)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Combi et al. (2017) – Decision-intensive care pathways with BPMN+DMN  </p></li>
<li><p>Braun et al. (2014) – BPMN4CP extension for clinical pathways  </p></li>
<li><p>Müller &amp; Rogge-Solti (2011) – Shared working behavior in healthcare BPMN  </p></li>
<li><p>Zerbato et al. (2015) – BPMN modeling for temporal constraints in clinical pathways</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: The biggest business process management problems to solve before we die</p>

<p>Authors: Iris Beerepoot; Claudio Di Ciccio; Hajo A. Reijers; Stefanie Rinderle‑Ma; Wasana Bandara; Andrea Burattin; Diego Calvanese; Tianwa Chen; Izack Cohen; Benoît Depaire; Gemma Di Federico; Marlon Dumas; Christopher van Dun; Tobias Fehrer; Dominik A. Fischer; Avigdor Gal; Marta Indulska; Vatche Isahagian; Christopher Klinkmüller; Wolfgang Kratsch; Henrik Leopold; Amy Van Looy; Hugo Lopez; Sanja Lukumbuzya; Jan Mendling; Lara Meyers; Linda Moder; Marco Montali; Vinod Muthusamy; Manfred Reichert; Yara Rizk; Michael Rosemann; Maximilian Röglinger; Shazia Sadiq; Ronny Seiger; Tijs Slaats; Mantas Simkus; Ida Asadi Someh; Barbara Weber; Ingo Weber; Mathias Weske; Francesca Zerbato :contentReference[oaicite:0]{index=0}</p>

<p>DOI: 10.1016/j.compind.2022.103837 :contentReference[oaicite:1]{index=1}</p>

<p>Year: 2023</p>

<p>Publication Type: Journal (Computers in Industry)</p>

<p>Discipline/Domain: Business Process Management / Information Systems</p>

<p>Subdomain/Topic: Grand challenges in BPM; process mining; digital twins; automated (re)design; process modeling/objectivity; worker‑centric BPM; stochastic data</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 25</p>

<p>Operationalization Score: 10</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: Partial (discussed in knowledge‑augmented process mining) :contentReference[oaicite:2]{index=2}</p>

<p>Contains Interpretability: Partial (model comprehension/objectivity discussed) :contentReference[oaicite:3]{index=3}</p>

<p>Contains Framework/Model: Yes (e.g., Digital Process Twins; Automated Process Improvement Systems; Expansive BPM lenses) :contentReference[oaicite:4]{index=4}:contentReference[oaicite:5]{index=5}</p>

<p>Operationalization Present: No (for actionability; operational ideas pertain to BPM challenges generally)</p>

<p>Primary Methodology: Conceptual / Research agenda (workshop‑based synthesis) :contentReference[oaicite:6]{index=6}</p>

<p>Study Context: Identification and synthesis of nine grand problems for BPM via an open call and workshop</p>

<p>Geographic/Institutional Context: International multi‑institution collaboration; workshop co‑located with BPM 2021 conference :contentReference[oaicite:7]{index=7}</p>

<p>Target Users/Stakeholders: BPM researchers; practitioners; industry decision‑makers in data‑intensive domains (e.g., healthcare, manufacturing) :contentReference[oaicite:8]{index=8}</p>

<p>Primary Contribution Type: Agenda‑setting / problem articulation</p>

<p>CL: N/A</p>

<p>CR: N/A</p>

<p>FE: N/A</p>

<p>TI: N/A</p>

<p>EX: N/A</p>

<p>GA: N/A</p>

<p>Reason if Not Eligible: The article does not use the terms “actionable/actionability” nor does it define criteria or dimensions linked to being actionable; it presents grand challenges and high‑level requirements without framing them as actionability constructs.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>The biggest business process management problems to solve before we die</p>

<p><strong>Authors:</strong>  </p>

<p>Iris Beerepoot et al.</p>

<p><strong>DOI:</strong>  </p>

<p>10.1016/j.compind.2022.103837</p>

<p><strong>Year:</strong>  </p>

<p>2023</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal (Computers in Industry)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Business Process Management / Information Systems</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Grand challenges; process mining; digital twins; automated (re)design; process model objectivity; worker‑centric BPM; stochastic data</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper counters the “incrementalization of science” by articulating nine major open problems in BPM, curated via an open call and workshop preceding BPM 2021. :contentReference[oaicite:9]{index=9}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>International authorship; event linked to the BPM 2021 conference; submissions screened by senior scholars; ~50 participants. :contentReference[oaicite:10]{index=10}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Researchers and practitioners in BPM; sectors like healthcare and manufacturing highlighted for impact. :contentReference[oaicite:11]{index=11}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual agenda; synthesis from community submissions and workshop discussion. :contentReference[oaicite:12]{index=12}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Research agenda / problem framing.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The article presents nine grand challenges intended to shape BPM research beyond incremental contributions. Problems include value creation from data, “expansive BPM” across processes and disciplines, automated process (re)design, constructing digital process twins, lack of objectivity in process descriptions, fixed granularity for process analysis, augmenting process mining with common‑sense and domain knowledge, worker‑centric BPM, and mining with stochastic data. For each, the authors motivate importance, sketch potential solution directions, and discuss lifecycle phases and automation levels. Figures summarize lifecycle salience and anticipated automation (e.g., Fig. 10–11). The paper concludes with likely application domains (notably healthcare and manufacturing) and a call to action for the BPM community. :contentReference[oaicite:13]{index=13}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No. The paper does not use the terms “actionable,” “actionability,” “actionable insights,” or similar, nor does it frame its concepts explicitly around defining or measuring actionability.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No. While the paper discusses decision quality (e.g., requirements for digital twins) and prescriptive recommendations in BPM, it does not invoke or imply “actionability” as a construct needing definition.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A.</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A.</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A.</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> N/A  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> N/A  </p></li>
<li><p><strong>FE (Feasibility):</strong> N/A  </p></li>
<li><p><strong>TI (Timeliness):</strong> N/A  </p></li>
<li><p><strong>EX (Explainability):</strong> N/A for actionability; paper discusses explanations for knowledge‑augmented PM generally: “knowledge may be used to infer and return justifications and explanations… and to provide estimates about their degree of uncertainty.” (p. 8) :contentReference[oaicite:14]{index=14}  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> N/A  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A (dimensions are framed for BPM problems, not for actionability)</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<p>The agenda references BPM lifecycle concepts, process architectures, digital twins, and process mining (e.g., conformance checking). It situates challenges with supporting literature (e.g., Dumas et al., van der Aalst). :contentReference[oaicite:15]{index=15}:contentReference[oaicite:16]{index=16}</p>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A.</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p>N/A (not framed under actionability). Relevant BPM barriers discussed include lack of model objectivity, fixed granularity, missing domain knowledge, and stochastic/low‑quality data. :contentReference[oaicite:17]{index=17}</p>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper anchors each problem in prior BPM research (e.g., event abstraction, semantic modeling, conformance checking) and broader IS/AI themes (commonsense reasoning, ontologies). It synthesizes how solving these would improve process design, analysis, and optimization. :contentReference[oaicite:18]{index=18}:contentReference[oaicite:19]{index=19}</p>

<hr />

<h2>Summary</h2>

<p>This community‑curated research agenda identifies nine grand problems for BPM, aiming to catalyze high‑impact work beyond incremental advances. It emphasizes cross‑process and cross‑disciplinary views (“expansive BPM”), prescriptive and automated redesign, and rigorous what‑if analysis via digital process twins that must be accurate and accompanied by reliability estimates. The authors highlight structural impediments—subjective/ambiguous models, fixed event‑granularity pipelines, incomplete/messy logs—and propose augmenting process mining with common‑sense and domain knowledge to yield higher‑trust results and explanations. Worker‑centric BPM reframes tooling around the channels where work actually occurs, with automated record‑keeping. The agenda maps problems to lifecycle phases and automation levels (Fig. 10–11) and argues for strong impact in healthcare and manufacturing. While rich in BPM concepts, the paper does not articulate “actionability” as a construct, define its properties, or operationalize how to achieve it; thus, it falls outside the strict inclusion criteria of actionability‑focused research. :contentReference[oaicite:20]{index=20}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 25 — The paper is highly relevant to BPM strategy and research agendas but does not engage with actionability as a concept or define criteria/dimensions for being actionable.  </p></li>
<li><p><strong>Operationalization Score:</strong> 10 — Offers high‑level solution sketches (e.g., requirements for digital twins, interactive granularity), yet no procedures or metrics tied to actionability.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>On purpose and method: “This paper presents an overview of the nine major research problems for the Business Process Management discipline… collected by an open call… discussed and refined in a workshop setting.” (p. 1–2) :contentReference[oaicite:21]{index=21}  </p></li>
<li><p>Digital process twins—non‑functional requirements: “The predictions about the effects of interventions should be accurate… [and] accompanied by a reliability estimate.” (p. 5) :contentReference[oaicite:22]{index=22}  </p></li>
<li><p>Fixed granularity limits: analysts cannot “observe multi‑granular patterns… trace which raw events have been aggregated… [or] adjust and control the granularity level during the analysis.” (p. 7) :contentReference[oaicite:23]{index=23}  </p></li>
<li><p>Knowledge‑augmented PM: knowledge can “infer and return justifications and explanations… [and] provide estimates about their degree of uncertainty.” (p. 8) :contentReference[oaicite:24]{index=24}  </p></li>
<li><p>Worker‑centric BPM: record‑keeping becomes implicit, meeting workers “where they are,” reducing duplicate administrative steps. (p. 9–10; see Fig. 8) :contentReference[oaicite:25]{index=25}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A — The article does not cite or develop “actionability” constructs. (It cites BPM and process mining works for the identified problems.)</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: On the Origin of Questions in Process Mining Projects</p>

<p>Authors: Francesca Zerbato, Jelmer J. Koorn, Iris Beerepoot, Barbara Weber, Hajo A. Reijers</p>

<p>DOI: https://doi.org/10.1007/978-3-031-17604-3_10</p>

<p>Year: 2022</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Process Mining / Business Process Management</p>

<p>Subdomain/Topic: Question development in process mining projects</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 35</p>

<p>Operationalization Score: 40</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes – conceptual model for question formulation/refinement</p>

<p>Operationalization Present: Yes – steps for formulating and refining questions</p>

<p>Primary Methodology: Qualitative (interview study)</p>

<p>Study Context: Process mining project practices</p>

<p>Geographic/Institutional Context: Participants from academia and industry, global</p>

<p>Target Users/Stakeholders: Process mining analysts, stakeholders in process mining projects</p>

<p>Primary Contribution Type: Empirical findings and methodological recommendations</p>

<p>CL: No</p>

<p>CR: No</p>

<p>FE: No</p>

<p>TI: No</p>

<p>EX: No</p>

<p>GA: No</p>

<p>Reason if Not Eligible: The paper focuses on question formulation and refinement in process mining, without linking findings or recommendations to the concept of “actionability” or defining what makes information actionable.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>On the Origin of Questions in Process Mining Projects  </p>

<p><strong>Authors:</strong>  </p>

<p>Francesca Zerbato, Jelmer J. Koorn, Iris Beerepoot, Barbara Weber, Hajo A. Reijers  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1007/978-3-031-17604-3_10  </p>

<p><strong>Year:</strong>  </p>

<p>2022  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Process Mining / Business Process Management  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Question development in process mining projects  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper examines how questions arise and evolve within process mining projects, noting that many projects do not start with a concrete research question but rather with available event log data. Through interviews with experts, it analyzes strategies and steps taken to formulate, refine, and answer questions.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Participants from academia and industry, representing various global contexts.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process mining analysts, project stakeholders, domain experts.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Qualitative (semi-structured interviews with 33 experts).  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical findings and methodological recommendations.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper investigates the development of questions in process mining projects, focusing on situations where projects either start with no predefined question or with an initial question that requires refinement. The authors conducted an interview study with 33 process mining experts from academia and industry. They identify two main starting points—No Question and Question—and three main endpoints—Question Answered, Not a Process Mining Question, and New Question Generated. They detail activities that support question formulation (e.g., raw data inspection, exploratory analyses) and refinement (e.g., hypothesis testing, benchmarking, best practices). Based on these findings, the authors propose six recommendations to enhance process mining methodologies, stressing the importance of iterative collaboration between analysts and stakeholders.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No — the paper does not use the term "actionable," "actionability," "actionable insight," "actionable recommendation," or "actionable knowledge."</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No — while the paper addresses the need for meaningful, relevant, and refined questions, it does not frame this in terms of actionability.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> No</p></li>
<li><p><strong>FE (Feasibility):</strong> No</p></li>
<li><p><strong>TI (Timeliness):</strong> No</p></li>
<li><p><strong>EX (Explainability):</strong> No</p></li>
<li><p><strong>GA (Goal Alignment):</strong> No</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Process mining project methodologies (PM2, L* lifecycle model, question-driven methodology)</p></li>
<li><p>Exploratory vs. confirmatory question typology</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p>N/A</p>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The authors situate their work within the literature on process mining methodologies, noting that while questions are central in most frameworks, little is said about how they are developed. They build on existing typologies of questions and extend methodologies by incorporating explicit question formulation/refinement processes.</p>

<hr />

<h2>Summary</h2>

<p>This paper addresses a gap in process mining methodologies regarding how project questions are developed. Based on interviews with 33 process mining experts, the authors identify two starting points (No Question and Question) and three endpoints (Question Answered, Not a Process Mining Question, New Question Generated) in the question development process. They outline specific steps for formulating and refining questions, such as raw data inspection, exploratory process mining, predefined analyses, hypothesis testing, benchmarking, and applying best practices. The study underscores the iterative nature of question development and the importance of close collaboration between analysts and stakeholders. Six recommendations are proposed to integrate question development into existing methodologies, emphasizing exploratory use of tools, alignment of questions with analyses, and documentation of question evolution. While the work provides concrete methodological guidance, it does not engage with the concept of actionability as defined in decision-support contexts.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 35 — The study is relevant to process mining methodology improvement but does not address actionability.</p></li>
<li><p><strong>Operationalization Score:</strong> 40 — Provides detailed operational steps for question formulation/refinement, but unrelated to actionability.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“The nice idea of process mining is that it allows us to detect new research questions.” (p. 177)  </p></li>
<li><p>“So, start with the first question… get some partial answers, then refine the questions… two or three or four times… and then you converge to something that is robust.” (p. 175)  </p></li>
<li><p>“Without domain knowledge, you won’t achieve much or nothing at all.” (p. 177)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Supporting Provenance and Data Awareness in Exploratory Process Mining</p>

<p>Authors: Francesca Zerbato; Andrea Burattin; Hagen Völzer; Paul Nelson Becker; Elia Boscaini; Barbara Weber</p>

<p>DOI: 10.1007/978-3-031-34560-9_27</p>

<p>Year: 2023</p>

<p>Publication Type: Conference (LNCS/CAiSE 2023)</p>

<p>Discipline/Domain: Process Mining / Data Science / Visual Analytics</p>

<p>Subdomain/Topic: Analytic provenance; data awareness; exploratory analysis; reproducibility; validation tooling</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 20</p>

<p>Operationalization Score: 15</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes (system requirements R1–R3; provenance &amp; data views)</p>

<p>Operationalization Present: Partial (prototype and performance tests)</p>

<p>Primary Methodology: Conceptual + Proof‑of‑Concept + Performance Tests</p>

<p>Study Context: Exploratory process mining workflows and tool interactions</p>

<p>Geographic/Institutional Context: University of St. Gallen (CH) &amp; Technical University of Denmark (DK)</p>

<p>Target Users/Stakeholders: Process analysts; auditors; business stakeholders consuming analysis results</p>

<p>Primary Contribution Type: System requirements and design with prototype and feasibility evaluation</p>

<p>CL: No</p>

<p>CR: No</p>

<p>FE: No</p>

<p>TI: No</p>

<p>EX: No</p>

<p>GA: No</p>

<p>Reason if Not Eligible: The paper focuses on transparency, provenance, data awareness, and reproducibility in exploratory process mining; it neither uses nor defines “actionable/actionability” nor specifies criteria or properties for making insights actionable.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Supporting Provenance and Data Awareness in Exploratory Process Mining</p>

<p><strong>Authors:</strong>  </p>

<p>Francesca Zerbato; Andrea Burattin; Hagen Völzer; Paul Nelson Becker; Elia Boscaini; Barbara Weber</p>

<p><strong>DOI:</strong>  </p>

<p>10.1007/978-3-031-34560-9_27 :contentReference[oaicite:0]{index=0}</p>

<p><strong>Year:</strong>  </p>

<p>2023 :contentReference[oaicite:1]{index=1}</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference (CAiSE 2023, LNCS 13901) :contentReference[oaicite:2]{index=2}</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Process Mining / Data Science / Visual Analytics</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Analytic provenance; data awareness; exploratory analysis; validation &amp; reproducibility</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The work addresses challenges in exploratory process mining where analysts perform many ad‑hoc steps whose results must be validated, reproduced, communicated, and potentially reused. The authors propose a support system to capture a replayable history, provide a provenance view, and introduce data views to maintain awareness of the active data selection. (Abstract &amp; §1) :contentReference[oaicite:3]{index=3}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of St. Gallen (Switzerland) and Technical University of Denmark (Denmark). :contentReference[oaicite:4]{index=4}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process analysts, reviewers/auditors, and business stakeholders who receive analysis results (motivating scenario &amp; §2–§4). :contentReference[oaicite:5]{index=5}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual system requirements and design (R1–R3), plus a proof‑of‑concept prototype and performance tests for equivalence computations in data views (§3–§5). :contentReference[oaicite:6]{index=6}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>A requirements‑driven system design (replayable history, provenance view, multi‑level data views) with demonstration of feasibility via prototype and timing experiments. :contentReference[oaicite:7]{index=7}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper proposes a support system to improve transparency and rigor in exploratory process mining by capturing analytic provenance and enhancing data awareness. It motivates the need through a realistic scenario (road‑traffic fines) and formulates requirements: maintaining provenance (R1), tracing analysis goals and insights (R2), and increasing data awareness (R3). The design comprises a replayable history of operations, a provenance tree with branching and annotations, and multiple data views built on equivalences/abstractions over event logs. A prototype demonstrates feasibility; performance tests indicate size‑only equivalence is negligible to compute while a “complete” equivalence scales linearly with log size. Figures illustrate the scenario timeline (Fig. 1), provenance tree (Fig. 2), and data views (Fig. 3). :contentReference[oaicite:8]{index=8}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No. The terms “actionable,” “actionability,” “actionable insight/recommendation/knowledge” do not appear tied to outputs or decisions. The focus is on transparency, reproducibility, validation, and data awareness rather than defining or assessing “actionability.” :contentReference[oaicite:9]{index=9}</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No. The paper argues for transparency and rigor in exploratory analysis, not for “actionable” outputs per se. :contentReference[oaicite:10]{index=10}</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A.</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A.</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A.</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> No  </p></li>
<li><p><strong>FE (Feasibility):</strong> No  </p></li>
<li><p><strong>TI (Timeliness):</strong> No  </p></li>
<li><p><strong>EX (Explainability):</strong> No  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> No  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<p>The system design is inspired by configuration/change management and requirements tracing from systems engineering, and by analytic provenance work in visualization/scientific workflows (e.g., VisTrails, Chimera, ZOOM, InfoVis). (§6) :contentReference[oaicite:11]{index=11}</p>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A.</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p>N/A.</p>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The authors compare their approach to provenance management systems that assume pre‑specified repeatable workflows, noting a gap for supporting exploratory, ad‑hoc analysis with explicit goal tracing and multi‑perspective data views for data awareness. They also contrast with process mining pipeline tools (RapidProM, buparFlow, PM4KNIME, FilterTree) and commercial tools that lack analytic provenance capture and comparison of analysis states such as working logs. (§6) :contentReference[oaicite:12]{index=12}</p>

<hr />

<h2>Summary</h2>

<p>This paper does not conceptualize “actionability.” Instead, it tackles upstream preconditions for trustworthy analysis—provenance capture and data awareness—within exploratory process mining. It formulates three requirements (R1–R3) and proposes a system with: (i) a replayable history of tool operations sufficient to reproduce analysis states; (ii) a provenance view that organizes branching analyses, links steps to goals/hypotheses, and supports annotations for storytelling and auditing; and (iii) multiple data views derived from equivalences/abstractions over event logs to reveal when different operation sequences yield the same/different data states and to facilitate comparisons. A motivating scenario illustrates typical analyst behavior; figures show the operation timeline (Fig. 1, p. 456), the provenance tree (Fig. 2, p. 460), and data‑view graphs including a case‑count abstraction (Fig. 3, p. 462). Performance experiments indicate linear scaling for a “complete” equivalence and negligible cost for a size‑only check, supporting feasibility. While these contributions may indirectly support producing results that stakeholders can trust, the paper neither uses nor defines “actionability,” so it is not eligible under the stated criteria. :contentReference[oaicite:13]{index=13}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 20 — The work strengthens transparency and validation in exploratory analysis but does not engage with “actionable” concepts or definitions, thus low direct relevance to actionability.</p></li>
<li><p><strong>Operationalization Score:</strong> 15 — Provides concrete mechanisms (history, provenance/data views, prototype, performance tests) for provenance and data awareness, but none are framed as how to achieve actionability.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We propose a system supporting the validation, reproducibility, and reuse of analysis results via analytic provenance and data awareness. This aims at increasing the transparency and rigor of exploratory process mining analysis…” (Abstract, p. 454). :contentReference[oaicite:14]{index=14}  </p></li>
<li><p>“(R1) Maintain Provenance Information… (R2) Trace Analysis Goals and Insights… (R3) Increase Data Awareness.” (§3, pp. 457–458). :contentReference[oaicite:15]{index=15}  </p></li>
<li><p>“The provenance view is a rooted, directed tree that reflects the analysis steps performed… [and] allows the analyst to reuse previously obtained results…” (§4.2, p. 460–461). :contentReference[oaicite:16]{index=16}  </p></li>
<li><p>“Different sequences of operations resulting in the same log can be expected or unexpected… the data view can help analysts validate the effect of their actions or spot inconsistencies…” (§4.3, p. 461–463). :contentReference[oaicite:17]{index=17}  </p></li>
<li><p>“The time needed to compute the complete equivalence grows linearly with the number of events… the worst time reported is 77 s for configuration c9.” (§5.1, p. 465). :contentReference[oaicite:18]{index=18}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A (no explicit actionability references).  </p>

<p><strong>Notable related works cited (for provenance/rigor context):</strong> VisTrails [3]; Chimera [8]; ZOOM [2]; InfoVis provenance framework [15]; RapidProM [1]; buparFlow [16]; PM4KNIME [11]; FilterTree [12]. (§6) :contentReference[oaicite:19]{index=19}</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Preface: Special Issue on Knowledge Representation and Reasoning for Healthcare Processes</p>

<p>Authors: Francesca Zerbato; Luise Pufahl; Annette ten Teije</p>

<p>DOI: 10.1016/j.artmed.2023.102631</p>

<p>Year: 2023</p>

<p>Publication Type: Journal Editorial</p>

<p>Discipline/Domain: Artificial Intelligence in Medicine; Business Process Management; Medical Informatics</p>

<p>Subdomain/Topic: Knowledge representation and reasoning for healthcare processes; CIGs; process monitoring; healthcare process mining</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 10</p>

<p>Operationalization Score: 5</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes (as a survey of included papers)</p>

<p>Operationalization Present: No</p>

<p>Primary Methodology: Conceptual (Editorial overview)</p>

<p>Study Context: N/A (editorial overview of special-issue contributions)</p>

<p>Geographic/Institutional Context: Authors from Switzerland, Germany, Netherlands; special issue spans Europe, North America, South America, Australia</p>

<p>Target Users/Stakeholders: Researchers in AI in Medicine, BPM, MI; clinicians and healthcare organizations interested in guideline-driven processes</p>

<p>Primary Contribution Type: Editorial synthesis of nine papers</p>

<p>CL: No</p>

<p>CR: Partial</p>

<p>FE: No</p>

<p>TI: No</p>

<p>EX: No</p>

<p>GA: No</p>

<p>Reason if Not Eligible: The preface is an editorial overview; it does not define or analyze “actionability” nor present properties/conditions for actionability. A single mention of “actionable graphs” refers to another paper and does not provide a definition or criteria.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Preface: Special Issue on Knowledge Representation and Reasoning for Healthcare Processes</p>

<p><strong>Authors:</strong>  </p>

<p>Francesca Zerbato; Luise Pufahl; Annette ten Teije</p>

<p><strong>DOI:</strong>  </p>

<p>10.1016/j.artmed.2023.102631</p>

<p><strong>Year:</strong>  </p>

<p>2023</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Editorial</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Artificial Intelligence in Medicine; Business Process Management; Medical Informatics</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Knowledge representation and reasoning for healthcare processes; computer‑interpretable guidelines (CIGs); monitoring/coordinating multiple guidelines; healthcare process mining. </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The editorial introduces a special issue collecting nine peer‑reviewed articles across construction, monitoring, and analysis/mining phases of healthcare process lifecycles. </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Authors are affiliated with University of St. Gallen (Switzerland), Technical University of Munich (Germany), and Vrije Universiteit Amsterdam (Netherlands); the issue includes contributions from Europe, North America, South America, and Australia. </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Researchers and practitioners working on clinical guidelines, decision support, and process mining; clinicians involved in modeling and executing care pathways. </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual (editorial overview/synthesis). </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Synthesis and positioning of nine research articles in AI in Medicine focused on knowledge representation and reasoning for healthcare processes. </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This editorial frames a special issue on knowledge representation and reasoning for healthcare processes, arguing for cross‑fertilization between AI in Medicine, BPM, and Medical Informatics. It groups nine contributions into three phases: (1) construction of clinical guidelines and healthcare processes (including translating CPGs into CIGs and collaborative modeling), (2) monitoring and coordination of concurrently applied guidelines (including conflict detection and runtime support), and (3) analysis and process mining with contextual and cost data as well as resource profiling. The editors briefly summarize each article’s focus and note themes such as multimorbidity, collaboration, and incorporation of context. </p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No.  </p>

<p><em>Note:</em> The term “actionable” appears only once as part of a description of another paper’s “actionable graphs” and is not developed conceptually in the preface itself. &gt; “task network model representation of CPGs (<strong>actionable graphs</strong>)” (p. 1). </p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No. The editorial emphasizes collaboration, monitoring, context, and multimorbidity challenges, but does not argue for “actionability” as a concept nor define it. </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A.</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A.</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A.</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Partial — the editorial highlights the “importance of capturing medical knowledge as ‘context’ and incorporating it in the representation and analysis of healthcare processes.” &gt; “the importance of capturing medical knowledge as ‘<strong>context</strong>’ and incorporating it in the representation … and analysis …” (p. 2).   </p></li>
<li><p><strong>FE (Feasibility):</strong> No  </p></li>
<li><p><strong>TI (Timeliness):</strong> No  </p></li>
<li><p><strong>EX (Explainability):</strong> No  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> No  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> None explicitly tied to actionability.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<p>The editorial references communities and approaches (AIME, BPM, MI), CIGs, BPMN, Petri nets, temporal logic, process mining; however, no theory of “actionability” is articulated. </p>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A.</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Not framed as actionability; generally notes challenges in collaboration among clinical experts, managing multimorbidity, and integrating context. &gt; “need to devise better support for <strong>collaboration and knowledge sharing</strong> among … experts …” (p. 2); &gt; “ways to handle <strong>interactions and conflicts</strong> among [guidelines]” (p. 2).   </p></li>
<li><p><strong>Enablers:</strong> Not framed as actionability; references methods such as asynchronous expert collaboration (ProDeM), automata‑based monitoring, and context‑aware process mining as enablers for KR&amp;R in healthcare processes. </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions the special issue within ongoing efforts on CIGs and healthcare process mining, citing prior reviews and manifestos, and emphasizes cross‑community collaboration. </p>

<hr />

<h2>Summary</h2>

<p>This editorial synthesizes nine contributions on knowledge representation and reasoning for healthcare processes across guideline construction, runtime monitoring, and data‑driven analysis. It highlights trends toward translating clinical guidelines into executable representations, enabling asynchronous expert collaboration, and managing concurrent guidelines for multimorbid patients. In monitoring, formal verification and distributed execution mechanisms support conflict detection and coordination. In analysis, process mining is extended with exogenous context, micro‑costing for decision analytics, and context‑aware resource profiling capturing multitasking and duration. The editors underscore the importance of incorporating contextual medical knowledge and improving collaboration among stakeholders. While the piece surfaces practical challenges and thematic enablers, it does not define or operationalize “actionability” as a construct; references to actionability are indirect and tied to individual included articles rather than to an editorial framework. </p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 10 — The editorial does not define “actionability” nor provide criteria or mechanisms specific to being actionable; it only mentions “actionable graphs” in passing while summarizing another paper.   </p></li>
<li><p><strong>Operationalization Score:</strong> 5 — No explicit operationalization of “actionability”; operational details concern KR&amp;R and process mining generally, not how to produce actionable insights per se. </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“The special issue includes nine peer‑reviewed articles … arranged along the three phases of … construction, … monitoring … and … analysis and mining of healthcare processes.” (p. 1).   </p></li>
<li><p>“Their framework is based on the task network model representation of CPGs (<strong>actionable graphs</strong>).” (p. 1).   </p></li>
<li><p>“The articles … present different approaches to represent and reason about medical knowledge for healthcare processes.” (p. 2).   </p></li>
<li><p>“need to devise better support for <strong>collaboration and knowledge sharing</strong> …” (p. 2).   </p></li>
<li><p>“importance of capturing medical knowledge as ‘<strong>context</strong>’ and incorporating it in the representation … and analysis …” (p. 2). </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li>Michalowski et al. (2023) — task network model for CPGs (“actionable graphs”) and graph rewriting to manage multimorbidity.</li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Enhancing Discovered Process Models with Data Object Lifecycles</p>

<p>Authors: Dorina Bano, Francesca Zerbato, Barbara Weber, Mathias Weske</p>

<p>DOI: 10.1109/EDOC52215.2021.00023</p>

<p>Year: 2021</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Process Mining / Business Process Management</p>

<p>Subdomain/Topic: Data-aware process discovery, data object lifecycle discovery</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 30 – The paper focuses on enhancing process models with data objects and lifecycles but does not engage with the concept of "actionability" or being "actionable" in relation to insights, recommendations, or knowledge.</p>

<p>Operationalization Score: 60 – Provides a well-defined multi-step operational procedure for discovering data objects and their lifecycles from event logs, but not in the context of making outputs actionable.</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes – Proposes a stepwise approach combining attribute-access event log extraction, attribute-change matrix, grouping into data objects, lifecycle derivation, and model enhancement.</p>

<p>Operationalization Present: Yes – Fully operationalizes their method for data object lifecycle integration.</p>

<p>Primary Methodology: Conceptual + Quantitative evaluation with real-life event logs</p>

<p>Study Context: Process mining using event logs from healthcare (hospital billing) and public administration (traffic fines).</p>

<p>Geographic/Institutional Context: Not explicitly bound to a region; authors affiliated with Hasso Plattner Institute (Germany), University of St. Gallen (Switzerland), Eindhoven University of Technology (Netherlands).</p>

<p>Target Users/Stakeholders: Process mining researchers, process analysts, business process management professionals.</p>

<p>Primary Contribution Type: Methodological framework for enriching process models with data-flow perspective.</p>

<p>CL: N/A</p>

<p>CR: N/A</p>

<p>FE: N/A</p>

<p>TI: N/A</p>

<p>EX: N/A</p>

<p>GA: N/A</p>

<p>Reason if Not Eligible: The paper does not address "actionability" or actionable insights/recommendations/knowledge, nor does it conceptualize or define these notions. The focus is on process model enhancement with data objects and lifecycles.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Enhancing Discovered Process Models with Data Object Lifecycles</p>

<p><strong>Authors:</strong>  </p>

<p>Dorina Bano, Francesca Zerbato, Barbara Weber, Mathias Weske</p>

<p><strong>DOI:</strong>  </p>

<p>10.1109/EDOC52215.2021.00023</p>

<p><strong>Year:</strong>  </p>

<p>2021</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Process Mining / Business Process Management</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Data-aware process discovery, data object lifecycle discovery</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the lack of data-flow information in conventionally discovered process models. It proposes a method to automatically detect data objects and their lifecycles from event logs, using attribute behavior analysis, and integrate them into process models to provide a richer view of process execution.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Authored by researchers affiliated with institutions in Germany, Switzerland, and the Netherlands.</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process mining researchers, analysts, and BPM practitioners.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework with quantitative evaluation on real event logs.</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Methodological approach for integrating data object lifecycle information into process models.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper presents a systematic method to enrich process models discovered through process mining by incorporating data objects and their lifecycles. The method begins by extracting attribute-access event logs (AAELs) for each optional attribute in the event log, discovers attribute-access behaviors using process discovery algorithms, and constructs an attribute-change matrix. These inputs are then used to group attributes into data objects, derive their lifecycles, and map them onto the process model. The approach is demonstrated on two real-life event logs — Hospital Billing and Road Traffic Fine Management — showing how the enhanced models can reveal insights about data manipulation patterns and discrepancies between control-flow and data-flow. The authors conclude that such enriched models can help analysts better understand process execution.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No. The paper does not reference "actionability," "actionable insight," "actionable recommendation," or similar terms.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No. The paper does not make such an argument.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> N/A</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> N/A</p></li>
<li><p><strong>FE (Feasibility):</strong> N/A</p></li>
<li><p><strong>TI (Timeliness):</strong> N/A</p></li>
<li><p><strong>EX (Explainability):</strong> N/A</p></li>
<li><p><strong>GA (Goal Alignment):</strong> N/A</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>BPMN for process modeling  </p></li>
<li><p>Data-flow representation through data objects and lifecycles  </p></li>
<li><p>Attribute-access behavior modeling  </p></li>
<li><p>Use of Inductive Visual Miner and PM4Py framework</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p>N/A</p>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper situates itself in the context of process mining research that integrates data-flow perspectives. It compares its approach to artifact-centric and object-centric process mining, as well as to methods for discovering data-based conditions influencing control-flow. It distinguishes itself by deriving data objects and lifecycles solely from event log attribute behavior rather than predefined data-object mappings.</p>

<hr />

<h2>Summary</h2>

<p>This paper introduces a method for automatically discovering and incorporating data object lifecycles into process models derived from event logs. The authors identify the gap in conventional process mining approaches that focus primarily on control-flow, leaving the data-flow perspective underrepresented. The proposed approach consists of multiple steps: extracting attribute-specific event logs, discovering attribute-access behaviors, building an attribute-change matrix, grouping attributes into data objects, deriving lifecycles, and mapping these onto the process model. The method is applied to two real-life event logs, demonstrating its capacity to reveal mismatches between data-flow and control-flow and provide statistics about data object usage. While the approach is well-structured and operationalized, it does not address "actionability" as defined in decision-making contexts; instead, it focuses on structural and behavioral completeness of process models.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 30 – The content does not engage with the notion of actionability in decision-making contexts; relevance is limited to methodological parallels.</p></li>
<li><p><strong>Operationalization Score:</strong> 60 – Offers a clear, stepwise operational method, but unrelated to producing actionable outputs.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We propose an approach to group the event log attributes into data objects and, afterwards, their lifecycle is derived.” (p. 4)  </p></li>
<li><p>“A holistic view combining control-flow and data-flow can support process experts in making decisions…” (p. 2) — While decision-making is mentioned, it is not framed as “actionability” and lacks explicit definition.  </p></li>
<li><p>“Enriching the discovered process model with data objects helps the process experts to understand how data is manipulated through business process execution.” (p. 9)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: A Fresh Approach to Analyze Process Outcomes</p>

<p>Authors: Hagen Völzer, Francesca Zerbato, Timothy Sulzer, Barbara Weber</p>

<p>DOI: 10.1109/ICPM60904.2023.10271968</p>

<p>Year: 2023</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Process Mining / Business Process Management</p>

<p>Subdomain/Topic: Multi-perspective outcome analysis, process mining explanation techniques</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 78 — The paper does not explicitly define “actionability” but clearly addresses producing outcome-oriented insights for decision-making in process improvement. Strong implicit conceptualization via techniques to produce validated, interpretable explanations.</p>

<p>Operationalization Score: 85 — Provides concrete, step-by-step operational methods (Outcome Flow Diagrams, Rule Induction, Attribute Enrichment/Hiding) for producing validated, actionable explanations of process outcomes.</p>

<p>Actionable/Actionability Used in Paper: No — Terms “actionability” or “actionable” not explicitly used.</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — “...assist process analysts in creating and documenting simple yet rigorously validated outcome-oriented insights” (p. 2); “...link is necessary to foster process understanding and inform improvement actions to maximize desired outcomes” (p. 2).</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: Yes (implicit — see CL, CR, FE, EX)</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes — Outcome Flow Diagrams, Outcome Explanation Method</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual + Case Study</p>

<p>Study Context: Outcome analysis of Road Traffic Fine Management event log</p>

<p>Geographic/Institutional Context: Local police force in Italy; University of St. Gallen (Switzerland)</p>

<p>Target Users/Stakeholders: Process analysts, business process managers</p>

<p>Primary Contribution Type: Methodological framework and tool-supported analysis method</p>

<p>CL: Yes — Clear predicate-based definitions of outcomes</p>

<p>CR: Yes — Multi-perspective integration ensures relevance to process goals</p>

<p>FE: Yes — Focus on implementable predicates, measurable by event log attributes</p>

<p>TI: Partial — Some time-based rules and deadlines, but not generalized timeliness dimension</p>

<p>EX: Yes — Explicit outcome explanations via interpretable rules</p>

<p>GA: Partial — Goal alignment implied via linking process outcomes to improvement goals</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>A Fresh Approach to Analyze Process Outcomes  </p>

<p><strong>Authors:</strong>  </p>

<p>Hagen Völzer, Francesca Zerbato, Timothy Sulzer, Barbara Weber  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1109/ICPM60904.2023.10271968  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Process Mining / Business Process Management  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Multi-perspective outcome analysis, process mining explanation techniques  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper introduces new techniques to analyze final or intermediate business process outcomes, combining multi-perspective event log enrichment, visualization via outcome flow diagrams, and interpretable outcome explanations using automated rule induction. These aim to help analysts derive validated, understandable insights for process improvement.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Local police force in Italy (case study dataset), University of St. Gallen (Switzerland)  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process analysts, business process managers, organizational improvement teams  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework with case study demonstration  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Methodological framework and tool-supported operationalization  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper proposes a novel approach for analyzing business process outcomes using multi-perspective event log enrichment, outcome flow diagrams (Sankey-based visualizations of decision paths and their contribution to outcomes), and an interactive method for generating and validating explanations for outcomes through automated rule induction. The approach leverages <em>case predicates</em>—formally defined conditions combining control-flow, data, time, and resource perspectives—to consistently describe both final and intermediate outcomes. The authors demonstrate the method on the well-documented “Road Traffic Fine Management” dataset, deriving previously undocumented insights into why nearly 20% of cases remain unresolved. The work emphasizes interpretability, interactive refinement, and formal validation, making it suitable for practical decision-making in process improvement.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No explicit use of the terms “actionable” or “actionability.”  </p>

<p>However, outcome analysis is repeatedly framed in terms of supporting improvement actions and deriving validated insights for decision-making.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes — Examples:  </p>

<ul>
<li><p>“...link is necessary to foster process understanding and inform improvement actions to maximize desired outcomes as well as outcome-cost ratios” (p. 2)  </p></li>
<li><p>“...assist process analysts in creating and documenting simple yet rigorously validated outcome-oriented insights” (p. 2)</p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly understood as producing <em>outcome-oriented insights</em> that are rigorously validated, interpretable, and directly useful for guiding improvement actions in process management.</p>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Outcome clearly defined via case predicates</p></li>
<li><p>Multi-perspective integration (control-flow, data, time, resources)</p></li>
<li><p>Visualization of decision-to-outcome relationships</p></li>
<li><p>Interpretable, validated explanation rules</p></li>
<li><p>Iterative refinement ensuring meaningfulness to analysts</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Outcome Flow Diagrams; Outcome Explanation Method  </p></li>
<li><p><strong>Methods/Levers:</strong> Case predicate formalization, event log enrichment, Sankey-based decision visualization, automated rule induction (RIPPER), attribute hiding/enrichment, threshold optimization  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Define outcomes → Enrich event log → Select decision predicates → Build outcome flow diagram → Apply iterative rule induction &amp; refinement → Validate with precision/recall → Document insights  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Event attributes, aggregated measures (e.g., payment sums), delays, activity counts  </p></li>
<li><p><strong>Implementation Context:</strong> Road Traffic Fine Management dataset  </p></li>
</ul>

<blockquote>
  <p>“We believe that our approach can assist process analysts in creating and documenting simple yet rigorously validated outcome-oriented insights” (p. 2)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Outcomes formalized via unambiguous case predicates.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Decisions tied to specific process perspectives and organizational goals.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Implemented with common process mining tools, operationalized via event log attributes.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Time thresholds/delays used in some rules but not generalized.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Rules are interpretable and refined for meaningfulness to analysts.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — Outcome improvement as implicit organizational goal.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Case predicates as unified multi-perspective interface  </p></li>
<li><p>Rule learning foundations (RIPPER)  </p></li>
<li><p>Outcome-oriented predictive process monitoring literature  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Precision and recall of explanatory rules  </p></li>
<li><p>Coverage of outcome cases by explanations  </p></li>
<li><p>Complexity reduction metrics (edges and paths in diagrams)</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Multi-collinearity in data; unclear/missing outcome codes; incomplete logs  </p></li>
<li><p><strong>Enablers:</strong> Attribute enrichment; interactive refinement; visualization-driven analysis</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions the work as extending decision mining and root cause analysis in process mining by integrating multi-perspective enrichment, addressing multi-collinearity, and emphasizing interactive, interpretable rule derivation.</p>

<hr />

<h2>Summary</h2>

<p>This paper presents a methodological framework for process outcome analysis that is implicitly aimed at producing actionable insights for process improvement. It combines a formalized definition of outcomes through case predicates, a visualization tool (Outcome Flow Diagram) for mapping decision paths to outcomes, and an interactive explanation method leveraging automated rule induction. The approach is demonstrated on the Road Traffic Fine Management dataset, revealing novel explanations for unresolved cases, including data quality issues and patterns in payment behavior. While “actionability” is not explicitly defined, the authors’ emphasis on interpretability, validation, and decision-oriented insights aligns closely with actionable research outputs. The operationalization is concrete and replicable, supported by open-source code, making the framework directly applicable for practitioners in process mining and BPM.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 78 — Strong implicit conceptualization of actionability, but lacks explicit definition; aligns with actionable insight generation.  </p></li>
<li><p><strong>Operationalization Score:</strong> 85 — Provides concrete steps, tool-supported methods, and open-source implementation for producing validated, interpretable explanations.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“...link is necessary to foster process understanding and inform improvement actions to maximize desired outcomes as well as outcome-cost ratios” (p. 2)  </p></li>
<li><p>“...assist process analysts in creating and documenting simple yet rigorously validated outcome-oriented insights” (p. 2)  </p></li>
<li><p>“Our methods are intrinsically interactive and would benefit from rich tool support for ease of use” (p. 9)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>[2] Teinemaa et al. (2019) — Outcome-oriented predictive process monitoring  </p></li>
<li><p>[6] Mannhardt (2018) — Multi-perspective process mining  </p></li>
<li><p>[21] Suriadi et al. (2013) — Root cause analysis with enriched process logs</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Defining and visualizing process execution variants from partially ordered event data  </p>

<p>Authors: Daniel Schuster, Francesca Zerbato, Sebastiaan J. van Zelst, Wil M.P. van der Aalst  </p>

<p>DOI: https://doi.org/10.1016/j.ins.2023.119958  </p>

<p>Year: 2024  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Process Mining / Information Systems  </p>

<p>Subdomain/Topic: Variant analysis and visualization for partially ordered event data with heterogeneous temporal information  </p>

<p>Eligibility: Not Eligible  </p>

<p>Overall Relevance Score: 10  </p>

<p>Operationalization Score: 15  </p>

<p>Actionable/Actionability Used in Paper: No  </p>

<p>Authors Argue for Need for Actionability Without Defining It: No  </p>

<p>Contains Definition of Actionability: No  </p>

<p>Contains Systematic Features/Dimensions: No  </p>

<p>Contains Explainability: No  </p>

<p>Contains Interpretability: No  </p>

<p>Contains Framework/Model: Yes (Variant definition and visualization model)  </p>

<p>Operationalization Present: Yes (Variant computation and visualization workflows)  </p>

<p>Primary Methodology: Conceptual + Quantitative Evaluation (Automated experiments, user study)  </p>

<p>Study Context: Process mining analysis for event data with heterogeneous temporal granularity  </p>

<p>Geographic/Institutional Context: Fraunhofer FIT, RWTH Aachen University, University of St. Gallen  </p>

<p>Target Users/Stakeholders: Process analysts, researchers, process mining tool developers  </p>

<p>Primary Contribution Type: Conceptual framework with implemented tool support  </p>

<p>CL: No  </p>

<p>CR: No  </p>

<p>FE: No  </p>

<p>TI: No  </p>

<p>EX: No  </p>

<p>GA: No  </p>

<p>Reason if Not Eligible: The paper does not discuss actionability, actionable insights, or actionable knowledge, nor does it provide criteria or conditions for being actionable. Its focus is on variant definitions and visualization in process mining without linking to decision-making actionability concepts.  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Defining and visualizing process execution variants from partially ordered event data  </p>

<p><strong>Authors:</strong>  </p>

<p>Daniel Schuster, Francesca Zerbato, Sebastiaan J. van Zelst, Wil M.P. van der Aalst  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1016/j.ins.2023.119958  </p>

<p><strong>Year:</strong>  </p>

<p>2024  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Process Mining / Information Systems  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Variant analysis and visualization for partially ordered event data with heterogeneous temporal information  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses limitations in current process mining variant visualizations, which often assume totally ordered, time-point-based activities. It proposes new high-level and low-level variant definitions that handle partially ordered event data containing both time-point and time-interval activities, enhancing expressiveness and accuracy in representing process executions.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Fraunhofer FIT, RWTH Aachen University, University of St. Gallen  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process analysts, researchers, and process mining tool developers  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual definition + quantitative evaluation through automated experiments and a user study  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework with implemented tool support  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper introduces two complementary definitions for process execution variants—high-level and low-level—that extend existing process mining approaches to support partially ordered event data with heterogeneous temporal information (time points and intervals). High-level variants abstract temporal details to show control-flow equivalence, while low-level variants preserve detailed temporal relationships. Both are supported by new visualization methods implemented in the open-source process mining tool Cortado. The authors also discuss how temporal granularity adjustments affect variant computation. Automated experiments on real-life event logs demonstrate scalability and applicability, while a user study shows that high-level variant visualizations are perceived as more useful and easier to use compared to existing approaches.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No. The paper does not use the terms <em>actionable</em>, <em>actionability</em>, <em>actionable insight</em>, <em>actionable recommendation</em>, or <em>actionable knowledge</em>.  </p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No. There is no discussion implying the need for actionable outputs or decision-support framing in terms of actionability.  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A  </p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A  </p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A  </p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> No  </p></li>
<li><p><strong>FE (Feasibility):</strong> No  </p></li>
<li><p><strong>TI (Timeliness):</strong> No  </p></li>
<li><p><strong>EX (Explainability):</strong> No  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> No  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Partial order theory for event data  </p></li>
<li><p>Allen’s interval algebra for temporal relations  </p></li>
<li><p>Graph partitioning for sequential/parallel activity grouping  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A  </p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p>N/A  </p>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper builds on prior work in variant definitions for totally ordered and partially ordered event data, extending them to mixed temporal granularity. It critiques limitations in forced sequentialization and loss of expressiveness and positions its definitions as more accurate representations of parallelism and timing in process executions.  </p>

<hr />

<h2>Summary</h2>

<p>This study develops two formal variant definitions—high-level and low-level—for process mining that accommodate partially ordered event data with both time-point and time-interval activity instances. High-level variants abstract temporal detail to focus on control-flow equivalence and parallelism, while low-level variants provide fine-grained temporal sequencing. Both definitions are paired with novel visualization techniques implemented in the Cortado tool, enabling process analysts to better explore and filter event logs. The approach also incorporates temporal granularity modifiers, allowing analysts to adjust abstraction levels based on analysis needs. Empirical evaluation demonstrates scalability to large real-life event logs, and a user study shows that high-level visualizations improve perceived usefulness, ease of use, and accuracy in identifying control-flow patterns compared to existing methods. The paper does not engage with the concept of actionability in decision-making terms, making it ineligible under the defined screening criteria.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 10 — The paper does not address actionability, actionable insights, or conditions for being actionable; its contribution is purely in process visualization methodology.  </p></li>
<li><p><strong>Operationalization Score:</strong> 15 — While the paper details operational procedures for computing and visualizing variants, these are unrelated to achieving actionability in the decision-support sense.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We focus on visualizing variants describing process executions that are control flow equivalent.” (p. 1)  </p></li>
<li><p>“We propose high-level and low-level variants covering different levels of abstraction and present corresponding visualizations.” (p. 1)  </p></li>
<li><p>“Compared to existing variant visualizations, we support partially ordered event data and allow for heterogeneous temporal information per event.” (p. 1)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>None. The cited works are on process mining, variant visualization, temporal relations, and process analysis—not on actionability concepts.</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Leveraging Digital Trace Data to Investigate and Support Human-Centered Work Processes</p>

<p>Authors: Barbara Weber, Amine Abbad-Andaloussi, Marco Franceschetti, Ronny Seiger, Hagen Völzer, Francesca Zerbato</p>

<p>DOI: https://doi.org/10.1007/978-3-031-64182-4_1</p>

<p>Year: 2024</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Computer Science / Process Science</p>

<p>Subdomain/Topic: Digital Trace Data, Process Mining, Human-Centered Work Processes</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 25 — The paper provides valuable methodological discussion relevant to actionability in terms of designing interventions and feedback mechanisms, but it does not explicitly or implicitly conceptualize “actionability” as a defined state or set of criteria.</p>

<p>Operationalization Score: 40 — Offers concrete methods for interventions and feedback loops, but these are framed under process science activities rather than as a way to achieve “actionability” as a quality.</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: Partial — Provides interpretable feedback concepts, but not tied to actionability as a concept.</p>

<p>Contains Interpretability: Partial — Discusses interpretable feedback in process contexts.</p>

<p>Contains Framework/Model: Yes — Process Science activities framework (discovery, explanation, intervention).</p>

<p>Operationalization Present: Yes — Specific workflows for data collection, event log generation, feedback systems.</p>

<p>Primary Methodology: Conceptual / Multi-case study</p>

<p>Study Context: Smart factory automation, process mining practice, software artifact comprehension, healthcare (phlebotomy)</p>

<p>Geographic/Institutional Context: University of St. Gallen, Switzerland; Swiss National Science Foundation projects</p>

<p>Target Users/Stakeholders: Process analysts, software engineers, healthcare workers</p>

<p>Primary Contribution Type: Conceptual framework with illustrative case studies</p>

<p>CL: No</p>

<p>CR: No</p>

<p>FE: No</p>

<p>TI: No</p>

<p>EX: Partial — Interpretable feedback tied to user process context</p>

<p>GA: No</p>

<p>Reason if Not Eligible: The paper does not define or conceptualize “actionability” nor tie its methods or interventions to an explicit or implicit framework of what makes something actionable; instead, it focuses on process science activity categories and their technical implementation.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Leveraging Digital Trace Data to Investigate and Support Human-Centered Work Processes  </p>

<p><strong>Authors:</strong>  </p>

<p>Barbara Weber, Amine Abbad-Andaloussi, Marco Franceschetti, Ronny Seiger, Hagen Völzer, Francesca Zerbato  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1007/978-3-031-64182-4_1  </p>

<p><strong>Year:</strong>  </p>

<p>2024  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Process Science  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Digital Trace Data, Process Mining, Human-Centered Work Processes  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper introduces process science as an interdisciplinary approach leveraging digital trace data to study human-centered work processes. It organizes the approach into three main activities—discovery, explanation, and intervention—illustrated through four case studies: smart factory processes, process of process mining, software artifact comprehension, and phlebotomy.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of St. Gallen, Switzerland; funded by Swiss National Science Foundation  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process analysts, software engineers, healthcare workers  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual / Multi-case study  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework with illustrative applications  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper explores how digital trace data can be leveraged to study and support human-centered work processes, extending the focus beyond traditional business process mining into the broader field of process science. It organizes process science into three main activities—discovery (capturing and describing processes), explanation (understanding why and how processes unfold), and intervention (shaping processes toward desired outcomes). Four case studies demonstrate this framework: automated smart factory workflows, the cognitive and analytical processes of process mining analysts, comprehension of software artifacts, and manual healthcare procedures like blood drawing. For each case, the paper outlines methods for data collection, event log generation, and analysis, emphasizing challenges in observability, synchronization, and abstraction. It concludes with lessons learned, highlighting the importance of multi-perspective analysis, careful data collection planning, and leveraging process knowledge for better event abstraction.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No — The paper does not use the terms “actionable,” “actionability,” or related variants.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No — While the paper discusses interpretable feedback and interventions, these are not framed as fulfilling a need for “actionability.”</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A — While the paper offers operationalization for process interventions, these are not tied to an actionability framework.</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> No</p></li>
<li><p><strong>FE (Feasibility):</strong> No</p></li>
<li><p><strong>TI (Timeliness):</strong> No</p></li>
<li><p><strong>EX (Explainability):</strong> Partial — Interpretable feedback mechanisms are discussed (e.g., pinpointing parts of artifacts causing cognitive load; informing healthcare workers of nonconformance).</p></li>
<li><p><strong>GA (Goal Alignment):</strong> No</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Process Science framework (discovery, explanation, intervention)</p></li>
<li><p>Complex Event Processing (CEP)</p></li>
<li><p>Prediction Error Minimization theory for PPM cognitive modeling</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Low observability in manual processes; difficulty synchronizing distributed data sources; abstraction challenges.</p></li>
<li><p><strong>Enablers:</strong> Process-driven execution engines; artifact-linked interaction logs; IoT-enriched event logs; synchronized data collection.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper situates itself within process mining literature but extends to process science, referencing prior works on analyzing change dynamics with digital trace data, hybrid process models, and IoT-enabled conformance checking.</p>

<hr />

<h2>Summary</h2>

<p>This paper extends the scope of process analysis from traditional process mining to a broader process science perspective, focusing on leveraging digital trace data for understanding and supporting human-centered work processes. Organized around the three activities of discovery, explanation, and intervention, it demonstrates applications in diverse domains via four case studies. The authors detail methods for increasing process observability, collecting synchronized multi-source data, generating enriched event logs, and providing interpretable feedback. Although the paper offers robust operationalization for process improvement, it does not conceptualize or define actionability as a quality of insights or outputs, and therefore falls outside the eligibility criteria for actionability-focused research. Its main value lies in methodological innovations for capturing and contextualizing complex processes, which could indirectly support actionable insights in future applications.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 25 — Relevant methodologies for creating process interventions, but no conceptual or definitional link to “actionability.”</p></li>
<li><p><strong>Operationalization Score:</strong> 40 — Provides concrete operational workflows for interventions and feedback but not in an actionability-specific context.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Process Science is the ‘interdisciplinary study of continuous change’… Process science activities can be divided into discovery, explanation, and intervention.” (p. 2)</p></li>
<li><p>“Interpretable Feedback is a form of intervention that can be provided in both offline and online settings… pinpoint the difficult parts of an artifact… indicate the correct course of action.” (p. 16)</p></li>
<li><p>“We envision that interpretable feedback could be provided… to inform the user about nonconforming behavior… and indicate the correct course of action.” (p. 16)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Explaining Process Dynamics: A Process Mining Context Taxonomy for Sense-Making  </p>

<p>Authors: Sandro Franzoi, Sophie Hartl, Thomas Grisold, Han van der Aa, Jan Mendling, Jan vom Brocke  </p>

<p>DOI: 10.1007/s44311-025-00008-6  </p>

<p>Year: 2025  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Business Process Management / Process Mining  </p>

<p>Subdomain/Topic: Contextualization, sense-making, process dynamics, taxonomy development  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 85  </p>

<p>Actionable/Actionability Used in Paper: Yes — “offers actionable guidance to enhance the interpretability of process mining efforts” (Abstract, p. 2)  </p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — “Contextual factors are crucial for correctly interpreting process behavior and deriving relevant actions” (p. 3)  </p>

<p>Contains Definition of Actionability: No (uses term in practical guidance sense but does not define conceptually)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes — Process Mining Context Taxonomy  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual + Empirical Demonstration + User Study (Mixed Methods)  </p>

<p>Study Context: Development and evaluation of a taxonomy for contextual sense-making in process mining  </p>

<p>Geographic/Institutional Context: European research institutions; demonstration case in a European financial institution  </p>

<p>Target Users/Stakeholders: Process analysts, process mining practitioners, BPM researchers  </p>

<p>Primary Contribution Type: Framework (taxonomy) + usage guidance for actionable interpretation of process mining results  </p>

<p>CL: Yes — “systematically examine each dimension… more clarity and guidance” (E1, E13, p. 18)  </p>

<p>CR: Yes — taxonomy organizes context levels and dimensions relevant for interpreting specific process scenarios  </p>

<p>FE: Yes — supports identification of practical interventions based on contextual understanding (e.g., backlog resolution, role reassignments)  </p>

<p>TI: Partial — timeliness implied in dynamic detection but not a formal dimension  </p>

<p>EX: Yes — explains process changes via linked contextual evidence (e.g., IT system feature changes, regulatory impacts)  </p>

<p>GA: Partial — goal alignment implied in analysis paths, not an explicit dimension  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Explaining Process Dynamics: A Process Mining Context Taxonomy for Sense-Making  </p>

<p><strong>Authors:</strong>  </p>

<p>Sandro Franzoi, Sophie Hartl, Thomas Grisold, Han van der Aa, Jan Mendling, Jan vom Brocke  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1007/s44311-025-00008-6  </p>

<p><strong>Year:</strong>  </p>

<p>2025  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Business Process Management / Process Mining  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Contextualization, sense-making, process dynamics, taxonomy development  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the challenge of interpreting process mining results without adequate consideration of context, which can lead to misdiagnosis of process dynamics. Drawing on BPM, routine dynamics, and process mining research, it develops a taxonomy of contextual factors—organized into process-immediate, organization-internal, and organization-external levels—to support actionable sense-making.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>European universities and research institutions; case study in a European financial institution.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process analysts, process mining practitioners, BPM researchers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed methods — conceptual taxonomy development (guided by Kundisch et al.’s ETDP), empirical validation via literature coding, demonstration in real-world case, and user study evaluation.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework (taxonomy) and practical usage guidance for actionable interpretation of process mining results.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The study develops the <em>Process Mining Context Taxonomy</em> to address the gap in contextual interpretation of process mining results. Current process mining outputs often lack sufficient information to explain observed process dynamics, leading to misinterpretation. By synthesizing literature from BPM and routine dynamics, the authors identify three context levels—process-immediate, organization-internal, and organization-external—each with three dimensions. The taxonomy is validated through systematic literature coding, demonstrated in a financial institution’s onboarding process, and evaluated via a user study with 20 experts. The paper proposes two usage paths (insights-driven and context-driven) and outlines how the taxonomy enhances sense-making, supports data integration, and leads to actionable insights for process improvement.  </p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>Yes.  </p>

<ul>
<li><p>“offers actionable guidance to enhance the interpretability of process mining efforts” (Abstract, p. 2)  </p></li>
<li><p>“contextual factors are crucial for… deriving relevant actions” (p. 3)  </p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes.  </p>

<ul>
<li><p>“Contextual factors are crucial for correctly interpreting process behavior and deriving relevant actions” (p. 3)  </p></li>
<li><p>“Our study… offers actionable guidance to enhance the interpretability of process mining efforts” (Abstract, p. 2)  </p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly: Actionability is tied to the ability of process analysts to interpret mining results in context to support relevant, targeted interventions.  </p>

<blockquote>
  <p>“Contextual factors are crucial for correctly interpreting process behavior and deriving relevant actions” (p. 3)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Contextual clarity</strong> — linking contextual changes to process mining data.  </p>

<p> &gt; “link[ing] contextual factors to event data… to make sense of the process mining results” (p. 17)  </p></li>
<li><p><strong>Organizational relevance</strong> — ensuring explanations align with the specific organizational setting.  </p>

<p> &gt; “systematic identification of contextual factors that exert an influence on the business process” (p. 17)  </p></li>
<li><p><strong>Dynamic explanation</strong> — explaining observed variations and changes.  </p>

<p> &gt; “support[s] analysts in explaining observed variations and changes within a business process” (p. 18)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Process Mining Context Taxonomy  </p></li>
<li><p><strong>Methods/Levers:</strong> Three context levels (proce</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Exploring Object Centric Process Mining with MIMIC IV: Unlocking Insights in Healthcare</p>

<p>Authors: Anukriti Tripathi, Aneesh, Yuvraj Shivam, Swetank Pandey, Aamod Vyas, O.P. Vyas</p>

<p>DOI: 10.1007/978-3-031-61003-5_30</p>

<p>Year: 2024</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Process Mining / Healthcare Informatics</p>

<p>Subdomain/Topic: Object-Centric Process Mining (OCPM) in MIMIC IV data</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 20 – The paper focuses on extracting and analyzing healthcare workflows via OCPM but does not engage with the concept of "actionability" or define properties/criteria of actionable insights.</p>

<p>Operationalization Score: 40 – The paper operationalizes OCPM methods in a healthcare context, but not in relation to producing actionable insights.</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes – Workflow for converting MIMIC IV event logs to OCEL and discovering Petri Nets.</p>

<p>Operationalization Present: Yes – Detailed OCPM operational steps provided.</p>

<p>Primary Methodology: Conceptual + Technical Implementation</p>

<p>Study Context: Emergency department patient flow analysis in MIMIC IV dataset.</p>

<p>Geographic/Institutional Context: Boston hospital dataset (MIMIC IV); research by IIIT Allahabad, India and Hof University, Germany.</p>

<p>Target Users/Stakeholders: Healthcare researchers, hospital administrators, process mining practitioners.</p>

<p>Primary Contribution Type: Method development for direct OCEL extraction and analysis.</p>

<p>CL: No</p>

<p>CR: No</p>

<p>FE: No</p>

<p>TI: No</p>

<p>EX: No</p>

<p>GA: No</p>

<p>Reason if Not Eligible: The study does not use or discuss "actionability" as a concept, nor does it define features or conditions making information actionable.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Exploring Object Centric Process Mining with MIMIC IV: Unlocking Insights in Healthcare  </p>

<p><strong>Authors:</strong>  </p>

<p>Anukriti Tripathi, Aneesh, Yuvraj Shivam, Swetank Pandey, Aamod Vyas, O.P. Vyas  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1007/978-3-031-61003-5_30  </p>

<p><strong>Year:</strong>  </p>

<p>2024  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Process Mining / Healthcare Informatics  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Object-Centric Process Mining (OCPM) in MIMIC IV data  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper applies Object-Centric Process Mining to the MIMIC IV dataset to better capture the complexity of patient journeys in a hospital setting. Unlike case-centric approaches, OCPM considers multiple object types (patients, admissions, transfers) and their interrelationships, aiming to reveal richer insights into healthcare workflows.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Boston hospital dataset (MIMIC IV); Indian Institute of Information Technology Allahabad, India; Hof University of Applied Sciences, Germany.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Healthcare researchers, process mining practitioners, hospital administrators.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual + Technical Implementation  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Method development for direct OCEL extraction and analysis.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This study investigates the application of Object-Centric Process Mining (OCPM) to the MIMIC IV healthcare dataset to better understand complex patient flows, particularly in emergency department settings. The authors develop a method to directly extract relevant objects (patients, hospital admissions, transfers) from MIMIC IV and convert them into Object-Centric Event Logs (OCEL) without traditional intermediate formats. Algorithms for identifying object relationships and visualizing divergence/convergence are presented. The analysis includes process discovery using Petri nets to model interactions between objects and activities, highlighting multi-object and multi-event relationships. Results show that OCPM enables a more comprehensive representation of healthcare processes compared to traditional case-centric methods.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A – While the paper operationalizes OCPM, it does not tie methods to the creation of actionable insights.</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> No</p></li>
<li><p><strong>FE (Feasibility):</strong> No</p></li>
<li><p><strong>TI (Timeliness):</strong> No</p></li>
<li><p><strong>EX (Explainability):</strong> No</p></li>
<li><p><strong>GA (Goal Alignment):</strong> No</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> None</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Object-Centric Process Mining theory (van der Aalst, 2019, 2023)</p></li>
<li><p>OCEL standard for object-centric event logs</p></li>
<li><p>Process discovery and conformance checking methodologies (PM4PY, ProM)</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p>N/A</p>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions the study within prior work on OCPM, OCEL, and event log generation from MIMIC IV. Highlights the gap in applying OCPM specifically to MIMIC IV healthcare data and the potential for richer insights over traditional case-centric methods.</p>

<hr />

<h2>Summary</h2>

<p>The paper presents a method for applying Object-Centric Process Mining to the MIMIC IV dataset, aiming to uncover complex relationships in patient care workflows. It bypasses traditional XES-to-OCEL conversions by directly extracting relevant objects—patients, admissions, and transfers—and mapping their interrelations. Visualization of divergence and convergence in patient flows allows identification of multi-department interactions and potential bottlenecks. Process discovery is performed using Petri nets, providing a clear yet comprehensive depiction of hospital processes. While the paper advances technical implementation of OCPM in healthcare and offers valuable workflow insights, it does not engage with the concept of actionability or define conditions for actionable insights, making it ineligible for actionability-focused literature synthesis.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 20 – Relevant to process mining and healthcare workflow analysis but unrelated to actionability as a concept.</p></li>
<li><p><strong>Operationalization Score:</strong> 40 – Strong technical operationalization of OCPM; no operationalization of actionability.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“OCPM offers a novel perspective by shifting its focus from individual cases to the objects which represent entities crucial to patient care.” (p. 2)</p></li>
<li><p>“By simplifying the discovery model and concentrating on the core elements of patient admissions and transfers, the study provides valuable insights into the operational dynamics of hospital processes.” (p. 8)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>None — no actionability references cited.</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Even If Explanations: Prior Work, Desiderata &amp; Benchmarks for Semi-Factual XAI  </p>

<p>Authors: Saugat Aryal, Mark T. Keane  </p>

<p>DOI: 10.24963/ijcai.2023/732  </p>

<p>Year: 2023  </p>

<p>Publication Type: Conference Paper  </p>

<p>Discipline/Domain: Artificial Intelligence, Explainable AI  </p>

<p>Subdomain/Topic: Semi-factual explanations, counterfactual reasoning, XAI benchmarking  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 92  </p>

<p>Operationalization Score: 88  </p>

<p>Contains Definition of Actionability: Yes (implicit, through desiderata)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual + Quantitative benchmarking  </p>

<p>Study Context: Survey and benchmarking of semi-factual explanation methods  </p>

<p>Geographic/Institutional Context: University College Dublin, Ireland  </p>

<p>Target Users/Stakeholders: AI researchers, XAI practitioners, policymakers, domain experts in decision-support systems  </p>

<p>Primary Contribution Type: Conceptual framework + empirical benchmarking  </p>

<p>CL: Yes — clarity is implied as important for convincingness (desiderata b, d)  </p>

<p>CR: Yes — contextual relevance via plausible/mutable/actionable changes within data manifold (desiderata c)  </p>

<p>FE: Yes — feasibility tied to plausibility and robustness of changes (desiderata f)  </p>

<p>TI: Partial — timeliness not a primary focus, but relevance in immediate interpretability  </p>

<p>EX: Yes — convincingness, surprise, and causal model change imply explainability (desiderata d, e)  </p>

<p>GA: Partial — goal alignment implied in fairness/ethical criteria (desiderata f)  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Even If Explanations: Prior Work, Desiderata &amp; Benchmarks for Semi-Factual XAI  </p>

<p><strong>Authors:</strong>  </p>

<p>Saugat Aryal, Mark T. Keane  </p>

<p><strong>DOI:</strong>  </p>

<p>10.24963/ijcai.2023/732  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference Paper  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Artificial Intelligence, Explainable AI  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Semi-factual explanations, counterfactual reasoning, XAI benchmarking  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the underexplored concept of semi-factual explanations (“even if” statements) in XAI. Unlike counterfactuals, semi-factuals describe changes to input features that do <strong>not</strong> alter the model’s decision outcome. The authors connect philosophical and psychological origins of the concept to computational implementations, propose desiderata, and benchmark historical and novel methods.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University College Dublin, Ireland  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>AI researchers, XAI practitioners, policymakers, and domain experts in decision-support contexts such as medicine, finance, and agriculture  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual analysis and quantitative benchmarking  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework (desiderata), historical survey, and empirical benchmarking  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper surveys the philosophical, psychological, and AI literature on semi-factuals — “even if” explanations that assert changes to inputs without affecting the model’s output. Building on insights from prior work, the authors define computational and psychological desiderata for effective semi-factual explanations. They classify historical approaches, introduce a new “Most Distant Neighbor” (MDN) benchmark, and conduct a comparative study against four existing methods (three KLEOR variants and a Local Region method) across seven tabular datasets. The evaluation uses multiple metrics, including distance measures, sparsity, and proximity to decision boundaries. Results show that MDN and Local Region methods offer strong baselines, though each has trade-offs in sparsity versus distance. The paper calls for further user studies and cautions about ethical use.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is implicitly understood through the <strong>desiderata for semi-factuals</strong>, which define the properties necessary for them to be meaningful and persuasive to end-users. An actionable semi-factual must be:</p>

<ul>
<li><p>Plausible and within the data manifold</p></li>
<li><p>Sparse in changes, ideally affecting key mutable features</p></li>
<li><p>Convincing, even if counterintuitive</p></li>
<li><p>Robust and fair, avoiding misleading proxy variables  </p></li>
</ul>

<blockquote>
  <p>“The key-feature(s) changed should be plausible/mutable/actionable; that is, the SF produced by the change should be within the data-manifold.” (p. 4)  </p>
</blockquote>

<blockquote>
  <p>“If people accept SF, it will change their perception of the causal role of the key-feature(s)… causes may be updated/deleted/refined.” (p. 4)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Change to key features without altering the outcome (desiderata a)  </p></li>
<li><p>Sparse and targeted feature changes, ideally one feature (b)  </p></li>
<li><p>Plausibility and mutability within domain constraints (c)  </p></li>
<li><p>Convincingness, even if surprising (d)  </p></li>
<li><p>Ability to alter user’s causal understanding (e)  </p></li>
<li><p>Ethical robustness, avoiding proxies, maintaining domain causality, and adhering to fairness (f)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Desiderata framework; benchmark methods including KLEOR variants, Local Region, MDN  </p></li>
<li><p><strong>Methods/Levers:</strong> Nearest unlike neighbors, feature-utility ranking, local logistic regression, most distant same-class instances  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Identify query instance and class  </p>

<p> 2. Search same-class instances meeting sparse-change and plausibility criteria  </p>

<p> 3. Rank candidates based on distance, convincingness, and domain constraints  </p>

<p> 4. Output semi-factual with maximum persuasive potential  </p></li>
<li><p><strong>Data &amp; Measures:</strong> L2 and Mahalanobis distances, kNN separation, sparsity (L0-norm)  </p></li>
<li><p><strong>Implementation Context:</strong> Benchmarked on seven binary-class tabular datasets  </p></li>
</ul>

<blockquote>
  <p>“SF will be a good explanation of Q if… diff(x, x′) with no outcome change, y = y′.” (p. 4)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — “Sparse changes to key-feature(s) … fewer is assumed to be better for psychological reasons.” (p. 4)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Plausible and within data-manifold (p. 4)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Changes must be plausible/mutable and robust (p. 4)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Implied in providing immediate interpretability, but not explicitly stated  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Convincingness and causal model updating (p. 4)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — Ethical and fairness constraints (p. 4)  </p></li>
<li><p><strong>Other Dimensions:</strong> Surprise/counter-intuitiveness as an explanatory asset (p. 4)  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Philosophy of conditionals (Bennett, Goodman)  </p></li>
<li><p>Psychology of counterfactual/semi-factual thinking (Byrne, McCloy)  </p></li>
<li><p>Case-Based Reasoning and Nearest Neighbor methods  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Query-to-SF distance (L2)  </p></li>
<li><p>Query-to-SF kNN percentage  </p></li>
<li><p>SF-to-query-class Mahalanobis distance  </p></li>
<li><p>SF-to-NUN distance  </p></li>
<li><p>MDN distance score  </p></li>
<li><p>Sparsity (1-, 2-, &gt;3-diff features)  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> High knowledge-engineering costs (feature-utility methods), lack of user studies, ethical risks of misleading explanations  </p></li>
<li><p><strong>Enablers:</strong> Plausible feature selection, distance-based search, benchmarking for standardized comparison  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Links psychological effects of semi-factuals to their potential in AI explanations, extending counterfactual literature with a novel operational class and providing the first systematic desiderata.</p>

<hr />

<h2>Summary</h2>

<p>This paper systematically defines and operationalizes semi-factual explanations in XAI, drawing from philosophy, psychology, and AI research. The authors establish computational and psychological desiderata that frame actionability as requiring plausibility, sparsity, convincingness, and robustness. They survey prior work, categorize historical approaches, introduce the MDN benchmark, and compare it to existing methods on multiple datasets. The results highlight trade-offs between distance and sparsity, with MDN and Local Region emerging as strong baselines. While the paper provides concrete operational metrics and a public repository, it stresses the need for user studies and ethical safeguards to ensure actionability is responsibly achieved.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Clear implicit definition of actionability through desiderata; strong linkage of features to actionability  </p></li>
<li><p><strong>Operationalization Score:</strong> 88 — Detailed benchmarking and algorithmic procedures directly tied to achieving actionability in semi-factual XAI  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“SF will be a good explanation of Q if… diff(x, x′) with no outcome change, y = y′.” (p. 4)  </p></li>
<li><p>“The key-feature(s) changed should be plausible/mutable/actionable; that is, the SF… should be within the data-manifold.” (p. 4)  </p></li>
<li><p>“If people accept SF, it will change their perception of the causal role of the key-feature(s)… causes may be updated/deleted/refined.” (p. 4)  </p></li>
<li><p>“For fairness and ethical reasons, the asserted differences… should not be misleading.” (p. 4)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Bennett (1982, 2003); Goodman (1947) — Philosophy of conditionals  </p></li>
<li><p>McCloy &amp; Byrne (2002); Parkinson &amp; Byrne (2017) — Psychology of semi-factual reasoning  </p></li>
<li><p>Doyle et al. (2004, 2006); Cummins &amp; Bridge (2006) — AI semi-factual algorithms  </p></li>
<li><p>Kenny &amp; Keane (2021) — GAN-based semi-factual generation  </p></li>
<li><p>Artelt &amp; Hammer (2022); Mertes et al. (2022) — Modern semi-factual applications</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Decomposing Counterfactual Explanations for Consequential Decision Making  </p>

<p>Authors: Martin Pawelczyk, Lea Tiyavorabun, Gjergji Kasneci  </p>

<p>DOI: arXiv:2211.02151  </p>

<p>Year: 2022  </p>

<p>Publication Type: Conference/Preprint (arXiv)  </p>

<p>Discipline/Domain: Machine Learning / Explainable AI  </p>

<p>Subdomain/Topic: Algorithmic Recourse, Counterfactual Explanations, Feature Dependencies  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 92  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (implicit and explicit in recourse context)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (DEAR)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual + Quantitative experiments  </p>

<p>Study Context: Automated decision-making systems (e.g., credit scoring, recidivism prediction)  </p>

<p>Geographic/Institutional Context: Not geographically bounded; datasets from U.S. contexts  </p>

<p>Target Users/Stakeholders: Affected individuals seeking recourse; developers of ML systems  </p>

<p>Primary Contribution Type: Framework + empirical evaluation  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: No explicit (timeliness not discussed as requirement)  </p>

<p>EX: Partial (mechanistic explainability of direct/indirect costs)  </p>

<p>GA: Partial (goal is implicitly favorable outcome alignment)  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Decomposing Counterfactual Explanations for Consequential Decision Making  </p>

<p><strong>Authors:</strong>  </p>

<p>Martin Pawelczyk, Lea Tiyavorabun, Gjergji Kasneci  </p>

<p><strong>DOI:</strong>  </p>

<p>arXiv:2211.02151  </p>

<p><strong>Year:</strong>  </p>

<p>2022  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference/Preprint (arXiv)  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Machine Learning / Explainable AI  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Algorithmic Recourse, Counterfactual Explanations, Feature Dependencies  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses limitations of existing algorithmic recourse methods—especially their reliance on either the Independently Manipulable Feature (IMF) assumption or strong causal models—by introducing a framework that models feature dependencies without causal graphs. It focuses on consequential domains like credit scoring and criminal justice risk assessments.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Methods tested on datasets from the U.S. (Adult Income, COMPAS, Give Me Credit).  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Individuals affected by automated decisions; AI practitioners seeking to implement actionable recourse.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework development + empirical experiments with benchmarks.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework proposal (DEAR) + quantitative and qualitative evaluation.  </p>

<h2>General Summary of the Paper</h2>

<p>The authors present DEAR (DisEntangling Algorithmic Recourse), a novel framework for generating actionable counterfactual explanations in the presence of feature dependencies without relying on full causal models. DEAR separates features into directly actionable ones and those indirectly affected, using a disentangled latent representation to model dependencies. This allows realistic, low-cost recourses that remain in dense regions of the data distribution. The paper derives theoretical cost decompositions (direct vs. indirect), proposes training with Hessian penalties to enforce disentanglement, and provides an optimization procedure for minimal-cost recourse. Empirical tests on three real-world datasets show DEAR reduces costs and improves reliability compared to manifold-based and graph-based recourse methods.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as the ability to reverse unfavorable decisions by providing <strong>realistic, feasible, and low-cost changes</strong> to input features that can be implemented by the affected individual, while respecting dependencies between features.</p>

<blockquote>
  <p>“Counterfactual explanations provide a means for actionable model explanations at feature level… an instruction on how to act to arrive at a desirable outcome.” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“…generate recourses by disentangling the latent representation of co-varying features from a subset of promising recourse features to capture the main practical desiderata…” (p. 1)  </p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Adheres to <strong>feature dependencies</strong> (avoids unrealistic independence assumptions)  </p></li>
<li><p>Lies in <strong>dense regions</strong> of the data distribution  </p></li>
<li><p>Is <strong>attainable at low and controllable cost</strong> for the individual  </p></li>
<li><p>Produces <strong>interpretable direct and indirect actions</strong>  </p></li>
<li><p>Avoids reliance on strong causal assumptions  </p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name:</strong> DEAR (DisEntangling Algorithmic Recourse)  </p></li>
<li><p><strong>Methods/Levers:</strong> Disentangled latent-variable generative modeling; cost decomposition; Hessian penalty regularization; ResNet for identity mapping; constrained optimization for recourse search  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Train conditional autoencoder with disentanglement via Hessian penalty to separate direct features (xS) from latent v  </p>

<p> 2. Ensure identity mapping for xS to allow controllable direct actions  </p>

<p> 3. Optimize direct actions dS to flip prediction with minimal cost, tracking indirect changes  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Adult, COMPAS, Give Me Credit datasets; evaluation via recourse cost (<code>L1</code>), success rate (SR), constraint violations (CV), neighborhood support (YNN)  </p></li>
<li><p><strong>Implementation Context:</strong> Black-box or differentiable classifiers; tabular decision-making tasks  </p></li>
</ul>

<blockquote>
  <p>“Our framework generates recourses by disentangling the latent representation of co-varying features… to capture the main practical desiderata.” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“DEAR requires two steps: first… obtain a latent space representation v independent of xS… second… identify the nearest counterfactual.” (p. 5)  </p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — actions are expressed in original feature space (interpretable direct actions).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — recourses adhere to actual feature dependencies.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — costs decomposed to ensure attainable low-cost changes.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No explicit discussion.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — direct/indirect cost split provides mechanistic explanation.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — implicit aim to achieve favorable classification outcome.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Reliability (success rate), proximity to data manifold.  </p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Counterfactual explanations literature (Wachter et al., causal recourse approaches)  </p></li>
<li><p>Disentangled representation learning (Hessian penalty; ResNet identity mapping)  </p></li>
<li><p>Cost decomposition into direct/indirect effects  </p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Recourse cost (<code>L1</code> norm)  </p></li>
<li><p>Success rate (SR) of flipping prediction  </p></li>
<li><p>Constraint violations (CV) for immutable features  </p></li>
<li><p>Neighborhood support (YNN) from positive-class instances  </p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Strong causal assumptions in prior methods hinder practical deployment  </p>

<p> - IMF assumption yields unrealistic recommendations in dependent-feature settings  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Disentanglement to reduce indirect costs  </p>

<p> - Explicit modeling of dependencies without causal graphs  </p>

<p> - Search in interpretable input space  </p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions DEAR as bridging manifold-based recourse (realistic but ignores dependencies) and causal recourse (dependency-aware but assumption-heavy), offering dependency modeling without causal graphs.</p>

<h2>Summary</h2>

<p>The paper proposes DEAR, a framework for generating actionable counterfactual explanations that handle feature dependencies without requiring causal models. It does this by disentangling direct-action features from dependent features in a generative model, enabling interpretable, low-cost recourses that stay in dense data regions. Actionability here entails feasibility, contextual realism, and interpretability. The authors provide theoretical cost decomposition, a training method enforcing disentanglement, and an optimization routine for recourse search. Experiments on real-world datasets show DEAR reduces median costs by up to 50% and achieves perfect success rates, outperforming both manifold-based and graph-based baselines.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Strong conceptualization of actionability in recourse setting, explicit criteria (dependencies, realism, cost), clear link between features and actionability.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Detailed algorithmic steps, optimization objectives, disentanglement training procedure; strong empirical validation.  </p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Counterfactual explanations provide a means for actionable model explanations at feature level… an instruction on how to act to arrive at a desirable outcome.” (p. 1)  </p></li>
<li><p>“Our framework generates recourses by disentangling the latent representation of co-varying features from a subset of promising recourse features…” (p. 2)  </p></li>
<li><p>“The framework should allow recourses to adhere to feature dependencies… lie in dense regions… ensure attainable low and controllable cost.” (p. 2)  </p></li>
<li><p>“DEAR requires two steps: first… obtain a latent space representation v independent of xS… second… identify the nearest counterfactual.” (p. 5)  </p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Wachter et al. (2018) — IMF assumption recourse  </p></li>
<li><p>Karimi et al. (2021) — causal recourse approaches  </p></li>
<li><p>Antorán et al. (2021), Joshi et al. (2019), Pawelczyk et al. (2020) — manifold-based recourse  </p></li>
<li><p>Peebles et al. (2020) — Hessian penalty for disentanglement</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: An Actionability Assessment Tool for Explainable AI</p>

<p>Authors: Ronal Singh, Tim Miller, Liz Sonenberg, Eduardo Velloso, Frank Vetere, Piers Howe, Paul Dourish</p>

<p>DOI: arXiv:2407.09516</p>

<p>Year: 2024</p>

<p>Publication Type: Journal Article (Preprint on arXiv)</p>

<p>Discipline/Domain: Artificial Intelligence / Human-Computer Interaction</p>

<p>Subdomain/Topic: Explainable AI (XAI), Algorithmic Recourse, Human-Centred Design</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 95</p>

<p>Operationalization Score: 90</p>

<p>Contains Definition of Actionability: Yes</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Mixed Methods (Conceptual development + Empirical user studies)</p>

<p>Study Context: Credit scoring and employee turnover prediction scenarios</p>

<p>Geographic/Institutional Context: Australia (with online MTurk participants from the US)</p>

<p>Target Users/Stakeholders: AI researchers, practitioners, system designers, end-users seeking recourse</p>

<p>Primary Contribution Type: Tool development and validation</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Partial</p>

<p>EX: Yes</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>An Actionability Assessment Tool for Explainable AI</p>

<p><strong>Authors:</strong>  </p>

<p>Ronal Singh, Tim Miller, Liz Sonenberg, Eduardo Velloso, Frank Vetere, Piers Howe, Paul Dourish</p>

<p><strong>DOI:</strong>  </p>

<p>arXiv:2407.09516</p>

<p><strong>Year:</strong>  </p>

<p>2024</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article (arXiv preprint)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Artificial Intelligence / Human-Computer Interaction</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Explainable AI, Algorithmic Recourse, Actionable Explanations</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the lack of a clear, human-centred definition and measurement of "actionability" in explainable AI (XAI), specifically for algorithmic recourse. It develops and validates a seven-question Actionability Assessment Tool inspired by frameworks from patient education, management research, and cybersecurity advice evaluation.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Developed by Australian researchers (CSIRO, University of Queensland, University of Melbourne, University of Sydney) with experimental participants from the US via MTurk.</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>AI system designers, XAI researchers, practitioners providing explanations for algorithmic decisions, and end-users seeking actionable guidance.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed methods — conceptual synthesis of existing tools and empirical validation through two user studies.</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Practical tool for assessing actionability in XAI explanations, validated via empirical studies.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This work introduces a seven-question Actionability Assessment Tool for Explainable AI (XAI), aiming to measure whether an explanation enables algorithmic recourse — concrete steps a user can take to change an unfavourable decision. Drawing from instruments in patient education, management research, and cybersecurity, the authors distilled five core topics: clarity, decision understanding, personal relevance, correction of misunderstandings, and actionable steps. They evaluated the tool in two domains (credit scoring and employee turnover) using three explanation types — prototypical, counterfactual, and directive. Two user studies compared human judgements of actionability with tool-based ratings, showing strong alignment. The tool effectively distinguished between explanation types, with directive explanations consistently rated as most actionable. Findings underscore the importance of clarity, contextual relevance, and explicit step-by-step guidance, while also revealing how user roles affect perceived actionability.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is defined as:  </p>

<blockquote>
  <p>“An explanation of a decision is actionable if people can use the information to identify actions to take to change the decision.” (p. 1)</p>
</blockquote>

<p>The authors emphasise a <strong>human-centred</strong> rather than purely technical definition, focusing on the recipient’s ability to derive feasible steps from the explanation.</p>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Clarity and understandability</p></li>
<li><p>Explanation of the decision’s reasoning</p></li>
<li><p>Personal relevance and contextual fit</p></li>
<li><p>Social appropriateness of recommendations</p></li>
<li><p>Ability to correct misunderstandings</p></li>
<li><p>Identification of at least one feasible action</p></li>
<li><p>Breakdown of actions into explicit steps</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Actionability Assessment Tool for XAI</p></li>
<li><p><strong>Methods/Levers:</strong> Seven-question survey instrument across five dimensions.</p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Present explanation to participant/user.  </p>

<p> 2. Rate it using Q1–Q7.  </p>

<p> 3. Analyse item-level scores rather than aggregated totals.</p></li>
<li><p><strong>Data &amp; Measures:</strong> Likert-scale ratings per question; statistical tests (Friedman, Nemenyi) for discrimination.</p></li>
<li><p><strong>Implementation Context:</strong> Tested in credit scoring and employee turnover with three explanation types.</p></li>
</ul>

<blockquote>
  <p>“The information allows me to identify at least one feasible action to achieve my desired outcome.” (Q6, p. 3)  </p>
</blockquote>

<blockquote>
  <p>“The information allows me to break down any action into explicit steps.” (Q7, p. 3)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — “The information is clear and easy to understand.” (Q1)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — “The information is relevant to my personal circumstances.” (Q3)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — “The information allows me to identify at least one feasible action…” (Q6)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Timeliness not explicitly measured but implied via domain specificity.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Includes decision reasoning clarity (Q2).  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Embedded in contextual relevance and social appropriateness (Q4).  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Social appropriateness, correction of misunderstandings.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Patient Education Materials Assessment Tool (PEMAT)  </p></li>
<li><p>Actionability frameworks from management research  </p></li>
<li><p>Shared decision-making instruments  </p></li>
<li><p>Cybersecurity advice evaluation frameworks</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Seven-item Likert-scale instrument  </p></li>
<li><p>Dimension-level discrimination between explanation types  </p></li>
<li><p>Median ratings per item across explanation types and contexts</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of clarity, irrelevance to user context, absence of explicit action steps, role misalignment between recipient and intended actor.  </p></li>
<li><p><strong>Enablers:</strong> Direct, step-by-step directives; personal relevance; ability to identify misunderstandings; contextual tailoring.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The tool draws directly from validated assessment instruments in other fields, translating them into XAI. It responds to critiques that actionability claims in XAI are often intuitive and unfalsifiable.</p>

<hr />

<h2>Summary</h2>

<p>Singh et al. (2024) present the first empirically validated, human-centred tool for assessing the actionability of explanations in XAI. By synthesising prior instruments from multiple domains, they identify seven core questions across five dimensions that capture essential features of actionable information. Tested in two domains and with three explanation types, the tool discriminates effectively between levels of perceived actionability, aligning with human judgements. Directive explanations consistently rank highest, especially when providing explicit steps, while prototypical explanations rate lowest. Contextual and role-related factors influence perceived actionability, suggesting the need for domain-specific adaptations. The tool offers a systematic, falsifiable way to assess and design actionable explanations for algorithmic recourse.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Provides explicit, clear definition of actionability; identifies systematic, multi-dimensional criteria directly tied to concept; grounded in literature.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Fully operationalises actionability into a validated 7-question tool; tested in multiple contexts with statistical analysis; slight deduction as timeliness is only implicit.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“An explanation of a decision is actionable if people can use the information to identify actions to take to change the decision.” (p. 1)  </p></li>
<li><p>“The information is clear and easy to understand.” (Q1, p. 3)  </p></li>
<li><p>“The information allows me to break down any action into explicit steps.” (Q7, p. 3)  </p></li>
<li><p>“Directive explanations… clearly outlined specific steps… most actionable.” (p. 1–2)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Shoemaker et al. (2014) — PEMAT tool  </p></li>
<li><p>HakemZadeh &amp; Baba (2016) — Actionability in management research  </p></li>
<li><p>Redmiles et al. (2020) — Cybersecurity advice evaluation  </p></li>
<li><p>Scholl et al. (2011) — Shared decision-making measures  </p></li>
<li><p>Russell (2019), Singh et al. (2023) — Counterfactual and directive explanations in XAI</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: The Art and Science of Cause and Effect (Epilogue to <em>Causality: Models, Reasoning, and Inference</em>, 2nd ed.)</p>

<p>Authors: Judea Pearl</p>

<p>DOI: https://doi.org/10.1017/CBO9780511803161.014</p>

<p>Year: 2009 (lecture delivered 1996)</p>

<p>Publication Type: Book Chapter</p>

<p>Discipline/Domain: Statistics, Artificial Intelligence, Philosophy of Science</p>

<p>Subdomain/Topic: Causal Inference, Structural Models, Graphical Models</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 95</p>

<p>Operationalization Score: 95</p>

<p>Contains Definition of Actionability: Yes (framed as the ability to predict consequences under interventions)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes (causal diagrams, do-calculus, intervention-as-surgery model)</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual &amp; Applied Methodological</p>

<p>Study Context: General scientific reasoning across disciplines; illustrated with examples from engineering, statistics, economics, AI, epidemiology</p>

<p>Geographic/Institutional Context: UCLA Faculty Research Lecture</p>

<p>Target Users/Stakeholders: Researchers in statistics, economics, social sciences, epidemiology, AI, philosophy of science</p>

<p>Primary Contribution Type: Conceptual framework + practical tools for causal analysis</p>

<p>CL: Yes — clarity is essential to express causation in a formal language</p>

<p>CR: Yes — contextual relevance is explicitly tied to usefulness of causal models in domains</p>

<p>FE: Yes — feasibility addressed through computational tools and graphical methods</p>

<p>TI: Yes — timeliness via real-time applicability in policy analysis and epidemiology</p>

<p>EX: Yes — explainability tied to “deep understanding” and prediction under hypothetical scenarios</p>

<p>GA: Yes — goal alignment linked to ability to answer “what if” and “how to” questions for decision-making</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>The Art and Science of Cause and Effect  </p>

<p><strong>Authors:</strong>  </p>

<p>Judea Pearl  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1017/CBO9780511803161.014  </p>

<p><strong>Year:</strong>  </p>

<p>2009 (lecture delivered 1996)  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Book Chapter  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Statistics, Artificial Intelligence, Philosophy of Science  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Causal Inference, Structural Models, Graphical Models  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>Pearl addresses causality as a universal concern across disciplines, focusing on how to formally represent, reason about, and operationalize cause–effect relations. His examples span engineering systems, statistical inference, economic policy, epidemiology, and AI, showing how a formal “mathematical language” for causation allows scientists to design interventions and predict outcomes.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of California, Los Angeles (UCLA Faculty Research Lectureship Program)  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Researchers, statisticians, economists, epidemiologists, social scientists, AI practitioners, philosophers of science  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual and applied methodological exposition  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Integration of historical, philosophical, and technical perspectives into a unified operational framework for causal inference  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This epilogue presents Judea Pearl’s synthesis of centuries of debate on causality and his solution: a formal, graphical, and algebraic framework that enables prediction under hypothetical interventions. After a historical overview from ancient attributions of causality to gods, through Galileo’s mathematical empiricism and Hume’s skepticism, Pearl identifies the limitations of traditional probability theory in expressing causation. He introduces “intervention-as-surgery” on structural equations, represented in causal diagrams, to preserve autonomy of mechanisms and enable computation of causal effects. The lecture demonstrates do-calculus as an “algebra of doing,” solving practical problems such as confounding adjustment, policy evaluation, and mediating variables. Examples include randomized trials, tax policy effects, smoking–lung cancer debates, and Simpson’s paradox. The overarching message: causality is neither mystical nor subjective—it can be expressed in a precise, computable, and transferable language.  </p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Pearl frames actionability as the <strong>capacity to predict the consequences of interventions</strong>—whether natural, experimental, or hypothetical—on a system, given a causal model.</p>

<blockquote>
  <p>“The very essence of causation – the ability to predict the consequences of abnormal eventualities and new manipulations” (p. 415)  </p>
</blockquote>

<blockquote>
  <p>“Causation means predicting the consequences of such a surgery [on equations]” (p. 417)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Ability to predict outcomes under new, possibly unobserved, scenarios  </p></li>
<li><p>Representation of independent mechanisms (autonomy) to allow localized changes without altering the whole system  </p></li>
<li><p>Clear mapping from intervention to altered model (“surgery” on equations)  </p></li>
<li><p>Capability to distinguish causal from purely correlational relationships  </p></li>
<li><p>Formal language enabling precise computation and communication across studies  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Structural Causal Models (SCMs), Causal Diagrams, do-Calculus, Intervention-as-Surgery  </p></li>
<li><p><strong>Methods/Levers:</strong> Graph-based representation of causal mechanisms, algebra of interventions (do-operator), back-door/front-door criteria, graphical adjustment rules  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Represent system as a causal diagram with autonomous mechanisms  </p>

<p> 2. Specify intervention by removing/replacing mechanism(s) (surgery)  </p>

<p> 3. Use graphical criteria to identify adjustment sets or mediation paths  </p>

<p> 4. Apply do-calculus rules to transform interventional queries into observational ones when possible  </p>

<p> 5. Compute quantities from data under the transformed model  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Observational data, experimental data, and auxiliary variables (mediators, covariates)  </p></li>
<li><p><strong>Implementation Context:</strong> Demonstrated in epidemiology (smoking/cancer), economics (tax policy), and social science (Simpson’s paradox cases)  </p></li>
</ul>

<blockquote>
  <p>“Intervention amounts to a surgery on equations (guided by a diagram)” (p. 417)  </p>
</blockquote>

<blockquote>
  <p>“The door is open for deduction, and the result is given in the… rules of causal calculus” (p. 422)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — causality must be expressed in a formal, diagrammatic, and algebraic language (p. 412)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — models are tied to specific domains and interventions (p. 418–419)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — computational procedures (do-calculus, graphical tests) make implementation possible (p. 422–425)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — applicable to real-time decision problems (e.g., policy analysis) (p. 418)  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — causal models offer “deep understanding” by predicting under hypothetical scenarios (p. 415)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — explicitly linked to “what if” and “how to” queries central to decision-making (p. 405)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Autonomy of mechanisms; capacity for counterfactual reasoning  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Hume’s problem of induction and spurious correlations  </p></li>
<li><p>Russell’s critique of causality in physics  </p></li>
<li><p>Structural equation modeling (S. Wright)  </p></li>
<li><p>Herman Wold’s “surgery” idea in econometrics  </p></li>
<li><p>Graph theory and Bayesian networks  </p></li>
<li><p>Galileo’s “description before explanation” principle  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Identifiability of causal effect given a model and data  </p></li>
<li><p>Graphical criteria (back-door, front-door) satisfied  </p></li>
<li><p>Ability to eliminate the “do” operator from expressions using do-calculus rules  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Lack of formal language for causation in mainstream statistics (p. 412)  </p>

<p> - Historical skepticism and avoidance of causal vocabulary  </p>

<p> - Endogeneity in observational data without clear intervention modeling  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Adoption of causal diagrams in model specification  </p>

<p> - Computational rules for interventions (do-calculus)  </p>

<p> - Combining domain expertise with graphical structure  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Pearl contrasts his operationalization with:  </p>

<ul>
<li><p>Classical philosophy (Aristotle, Hume, Russell)  </p></li>
<li><p>Correlation-based statistics (Galton, Pearson)  </p></li>
<li><p>SEM traditions in social sciences  </p></li>
</ul>

<p>He positions causal diagrams and do-calculus as bridging the gap between probabilistic and structural approaches, unifying manipulation-based and counterfactual definitions.  </p>

<hr />

<h2>Summary</h2>

<p>Judea Pearl’s epilogue reframes causality as a fully operational, mathematically tractable concept. He defines actionability in terms of a model’s ability to predict consequences under interventions, and he provides the structural and graphical machinery to achieve it. His “intervention-as-surgery” approach, combined with the do-calculus, enables translation of interventional questions into observational data analysis, overcoming limitations of correlation-based reasoning. The framework is domain-independent, allowing application in diverse fields from epidemiology to AI, and is built to be clear, computationally feasible, and aligned with decision-making goals.  </p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Strong, explicit conceptualization of actionability and detailed enumeration of its structural features.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Fully worked-out procedural tools (graphs, algebra, examples) to implement actionability in practice.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“The very essence of causation – the ability to predict the consequences of abnormal eventualities and new manipulations” (p. 415)  </p></li>
<li><p>“Causation means predicting the consequences of such a surgery” (p. 417)  </p></li>
<li><p>“Viewing causality this way explains why scientists pursue causal explanations with such zeal” (p. 415)  </p></li>
<li><p>“The door is open for deduction… rules of causal calculus” (p. 422)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Wright, S. (1920) <em>Proceedings of the National Academy of Sciences</em> — path diagrams  </p></li>
<li><p>Wold, H. (1960) — econometric intervention-as-surgery concept  </p></li>
<li><p>Galton, F.; Pearson, K. — correlation vs causation debate  </p></li>
<li><p>Russell, B. (1913); Suppes, P. — philosophical positions on causality  </p></li>
<li><p>Fisher, R.A. — randomized experiments</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI  </p>

<p>Authors: Alejandro Barredo Arrieta, Natalia Díaz-Rodríguez, Javier Del Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garcia, Sergio Gil-Lopez, Daniel Molina, Richard Benjamins, Raja Chatila, Francisco Herrera  </p>

<p>DOI: 10.1016/j.inffus.2019.12.012  </p>

<p>Year: 2020  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Artificial Intelligence / Machine Learning  </p>

<p>Subdomain/Topic: Explainable Artificial Intelligence (XAI), Responsible AI  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (implicit as “explainability” and audience-specific usefulness)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (taxonomy of XAI methods; Responsible AI conceptual model)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Review / Conceptual Analysis  </p>

<p>Study Context: Broad AI/ML application domains, including critical sectors (health, finance, transport)  </p>

<p>Geographic/Institutional Context: Multi-institutional (Europe-based with international perspective)  </p>

<p>Target Users/Stakeholders: AI researchers, developers, policy-makers, domain experts, affected users  </p>

<p>Primary Contribution Type: Conceptual framework and taxonomy with operational guidelines toward Responsible AI  </p>

<p>CL: Yes – “...explanations should make the model’s functioning clear or easy to understand to the audience...” (p.7)  </p>

<p>CR: Yes – “...clarity targeted by XAI techniques...reverts on different application purposes such as trustworthiness...” (p.8)  </p>

<p>FE: Yes – Feasibility implied via implementability and robustness as necessary for practical deployment (p.3)  </p>

<p>TI: Partial – Timeliness is not a main dimension but is relevant in regulatory/audit contexts (p.8, Figure 2)  </p>

<p>EX: Yes – Explainability explicitly defined (p.7)  </p>

<p>GA: Yes – Goal alignment implied in audience-specific and purpose-driven explainability (p.7–9)  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI  </p>

<p><strong>Authors:</strong>  </p>

<p>Alejandro Barredo Arrieta, Natalia Díaz-Rodríguez, Javier Del Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garcia, Sergio Gil-Lopez, Daniel Molina, Richard Benjamins, Raja Chatila, Francisco Herrera  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1016/j.inffus.2019.12.012  </p>

<p><strong>Year:</strong>  </p>

<p>2020  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Artificial Intelligence / Machine Learning  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Explainable Artificial Intelligence (XAI), Responsible AI  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper surveys and systematizes the state of research in explainable AI, especially in machine learning and deep learning, and links it to the broader concept of Responsible AI, which integrates fairness, accountability, and privacy. It addresses multi-stakeholder contexts, from regulatory agencies to domain experts and affected users.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Multi-institutional, with primary affiliations in Spain and France; international scope.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Researchers, ML engineers, policy-makers, regulatory bodies, domain experts, end users affected by AI decisions.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Review / Conceptual Analysis  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Comprehensive conceptual framework and taxonomies for XAI, linked to operational challenges and Responsible AI principles.  </p>

<h2>General Summary of the Paper</h2>

<p>This paper delivers a comprehensive review of Explainable Artificial Intelligence (XAI), defining its core concepts, clarifying terminology (interpretability, transparency, comprehensibility), and stressing the role of the audience in determining explainability. It proposes a novel audience-centric definition of XAI, outlines purposes (trustworthiness, causality, transferability, informativeness, fairness, accessibility, privacy awareness), and develops two taxonomies: one distinguishing transparent models from post-hoc techniques, and another tailored to deep learning. The authors discuss challenges, including the interpretability-performance trade-off, metric development, and integration with fairness, privacy, and accountability under Responsible AI. Operationalization examples span model simplification, feature relevance, visualization, and hybrid symbolic–subsymbolic approaches.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>The authors conceptualize actionability implicitly through “explainability” as the model’s ability to provide clear, audience-appropriate details and reasons for its functioning, enabling trust, informed decision-making, regulatory compliance, and ethical use.  </p>

<blockquote>
  <p>“Given an audience, an explainable Artificial Intelligence is one that produces details or reasons to make its functioning clear or easy to understand.” (p.7)  </p>
</blockquote>

<blockquote>
  <p>“Ease of understanding and clarity…reverts on different application purposes, such as better trustworthiness of the model’s output by the audience.” (p.8)  </p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Clarity of functioning for the intended audience  </p></li>
<li><p>Contextual relevance to stakeholder goals  </p></li>
<li><p>Feasibility and robustness in implementation  </p></li>
<li><p>Alignment with regulatory, ethical, and operational objectives  </p></li>
<li><p>Support for trustworthiness, causality analysis, and fairness audits  </p></li>
<li><p>Ability to inform decisions and provide accessible, understandable outputs  </p></li>
</ul>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Taxonomy of XAI methods; Responsible AI framework  </p></li>
<li><p><strong>Methods/Levers:</strong> Transparent model design, post-hoc techniques (model simplification, feature relevance, visualization), hybrid symbolic–subsymbolic methods  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Select model type based on interpretability needs; apply post-hoc methods if necessary; tailor explanations to audience; integrate fairness, privacy, and accountability checks  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Model parameters, feature importance scores, saliency maps, counterfactual examples, rule sets, user feedback  </p></li>
<li><p><strong>Implementation Context:</strong> Applicable across ML/DL models in sectors such as health, finance, autonomous systems  </p></li>
</ul>

<blockquote>
  <p>“XAI proposes creating…techniques that…enable humans to understand, appropriately trust, and effectively manage…” (p.3)  </p>
</blockquote>

<blockquote>
  <p>“Target audience…as the cognitive skills and pursued goal of the users…must be taken into account…” (p.6–7)  </p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — audience-specific clarity is central (p.7)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — explanations linked to purposes like trust, compliance (p.8–9)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — tied to implementability, robustness, and meaningful variable use (p.3)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — relevant in compliance/audit timelines (p.8, Figure 2)  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — explicit definition provided (p.7)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — alignment with stakeholder goals and Responsible AI principles (p.8–9)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Trustworthiness, causality, transferability, informativeness, confidence, fairness, accessibility, interactivity, privacy awareness  </p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>DARPA XAI definition (Gunning, 2017)  </p></li>
<li><p>Social sciences of explanation (Miller, 2019)  </p></li>
<li><p>Michalski’s concept of comprehensibility  </p></li>
<li><p>Responsible AI principles (Fairness, Accountability, Privacy)  </p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Degree of audience understanding  </p></li>
<li><p>Trustworthiness levels  </p></li>
<li><p>Feature relevance and stability metrics  </p></li>
<li><p>Model simplification degree  </p></li>
<li><p>Fairness measures (statistical parity, equalized odds)  </p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of consensus on definitions; interpretability-performance trade-off; absence of standard metrics; privacy risks in explanation; complexity of DL models  </p></li>
<li><p><strong>Enablers:</strong> Transparent model design; tailored post-hoc methods; audience-aware explanations; integration with fairness and accountability frameworks  </p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Builds on existing XAI surveys but advances an audience-centric definition and unified taxonomies; connects XAI explicitly to Responsible AI principles and privacy/data fusion contexts.  </p>

<h2>Summary</h2>

<p>This paper reframes explainability as inherently audience-dependent, situating it as a core component of actionability in AI systems. It provides a dual taxonomy of methods (transparent vs post-hoc; deep learning-specific) and links them to stakeholder goals such as trust, compliance, and fairness. The operational pathway includes selecting interpretable models where possible, applying targeted post-hoc techniques, and embedding explanations within Responsible AI frameworks that also address privacy and accountability. Actionability emerges from clarity, contextual relevance, feasibility, goal alignment, and the ability to inform decisions in a trustworthy, ethical, and auditable manner.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Clear definition, comprehensive features list, integration with broader Responsible AI context.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Detailed pathways and taxonomies for achieving explainability across model types.  </p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Given an audience, an explainable Artificial Intelligence is one that produces details or reasons to make its functioning clear or easy to understand.” (p.7)  </p></li>
<li><p>“Ease of understanding and clarity…reverts on different application purposes, such as better trustworthiness of the model’s output…” (p.8)  </p></li>
<li><p>“Target audience…must be taken into account jointly with the intelligibility and comprehensibility of the model in use.” (p.6)  </p></li>
<li><p>“XAI proposes…techniques that…enable humans to understand, appropriately trust, and effectively manage…” (p.3)  </p></li>
</ul>

<h2>Actionability References to Other</h2>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records</p>

<p>Authors: Bum Chul Kwon; Min-Je Choi; Joanne Taery Kim; Edward Choi; Young Bin Kim; Soonwook Kwon; Jimeng Sun; Jaegul Choo</p>

<p>DOI: 10.1109/TVCG.2018.2865027</p>

<p>Year: 2019</p>

<p>Publication Type: Journal (IEEE Transactions on Visualization and Computer Graphics)</p>

<p>Discipline/Domain: Computer Science — Visualization &amp; Explainable AI</p>

<p>Subdomain/Topic: Visual analytics; RNN interpretability; healthcare EMR risk prediction</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 25</p>

<p>Operationalization Score: 20</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: Yes (model interpretability/attention):contentReference[oaicite:0]{index=0}</p>

<p>Contains Interpretability: Yes (central focus):contentReference[oaicite:1]{index=1}</p>

<p>Contains Framework/Model: Yes — RetainEX model + RetainVis system:contentReference[oaicite:2]{index=2}:contentReference[oaicite:3]{index=3}</p>

<p>Operationalization Present: No (for actionability)</p>

<p>Primary Methodology: Mixed Methods (design study + quantitative experiments + qualitative case study):contentReference[oaicite:4]{index=4}:contentReference[oaicite:5]{index=5}</p>

<p>Study Context: Predicting future diagnosis risk (heart failure, cataract) from EMRs using attention-based RNNs:contentReference[oaicite:6]{index=6}</p>

<p>Geographic/Institutional Context: Republic of Korea; HIRA-NPS national patient sample EMR dataset:contentReference[oaicite:7]{index=7}</p>

<p>Target Users/Stakeholders: Physicians, health professionals, medical researchers:contentReference[oaicite:8]{index=8}</p>

<p>Primary Contribution Type: System &amp; Method (interpretable, interactive RNN + visual analytics tool):contentReference[oaicite:9]{index=9}</p>

<p>CL: N/A</p>

<p>CR: N/A</p>

<p>FE: N/A</p>

<p>TI: N/A</p>

<p>EX: N/A (explainability not framed as a dimension of “actionability”)</p>

<p>GA: N/A</p>

<p>Reason if Not Eligible: The paper focuses on model interpretability and interactive what‑if analyses for RNNs on EMR data. It does not use the terms actionable/actionability nor define what makes outputs “actionable” or provide criteria explicitly tied to actionability; any links to decision support are indirect.:contentReference[oaicite:10]{index=10}:contentReference[oaicite:11]{index=11}</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records</p>

<p><strong>Authors:</strong>  </p>

<p>Bum Chul Kwon; Min-Je Choi; Joanne Taery Kim; Edward Choi; Young Bin Kim; Soonwook Kwon; Jimeng Sun; Jaegul Choo</p>

<p><strong>DOI:</strong>  </p>

<p>10.1109/TVCG.2018.2865027</p>

<p><strong>Year:</strong>  </p>

<p>2019</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal (IEEE TVCG)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science — Visualization &amp; Explainable AI</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Visual analytics; interpretable deep learning; RNN attention; EMR-based risk prediction</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The work addresses the “black-box” nature of RNNs in healthcare by coupling an interpretable attention-based model (RetainEX) with a visual analytics interface (RetainVis) to explore EMR data and conduct what‑if analyses. Assumes clinical decision support needs transparency and interactivity.:contentReference[oaicite:12]{index=12}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Republic of Korea; HIRA National Patient Sample (HIRA‑NPS) EMR dataset (∼1.4M patients sampled; data 2014–2015).:contentReference[oaicite:13]{index=13}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Physicians, health professionals, medical researchers working with EMRs.:contentReference[oaicite:14]{index=14}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed methods: iterative design study; quantitative evaluation (AUC/AP); qualitative case study.:contentReference[oaicite:15]{index=15}:contentReference[oaicite:16]{index=16}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>System &amp; method (RetainEX interpretable/interactive RNN + RetainVis visual analytics).:contentReference[oaicite:17]{index=17}:contentReference[oaicite:18]{index=18}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper presents RetainVis, a visual analytics system built around RetainEX, an interpretable, interactive recurrent neural network for predicting diagnosis risk (heart failure and cataract) from electronic medical records. RetainEX augments the RETAIN model with bidirectional RNNs, explicit time-interval features, and dual embedding matrices to enable attention-based contribution scores at visit and code levels and to support rapid user‑driven “retraining.”:contentReference[oaicite:19]{index=19} The interface provides cohort overviews, patient summaries, detailed patient timelines, and an editor for what‑if analyses that modify codes or visit intervals and update predictions in near real time.:contentReference[oaicite:20]{index=20} Quantitatively, RetainEX outperforms GRU and RETAIN baselines on AUC/AP; qualitatively, contribution patterns align with known comorbidities and medications for heart failure.:contentReference[oaicite:21]{index=21}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No. The terms “actionable,” “actionability,” “actionable insight/recommendation/knowledge” do not appear, nor are they explicitly linked to outputs. Focus is on interpretability and interactivity for decision support.:contentReference[oaicite:22]{index=22}:contentReference[oaicite:23]{index=23}</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No. The paper argues for <em>interpretability</em> and <em>interactivity</em> (to enable what‑if analyses and model steering) rather than for “actionability” per se.:contentReference[oaicite:24]{index=24}</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A.</p>

<blockquote>
  <p>N/A</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A.</p>

<ul>
<li><p>Property/Condition: N/A  </p>

<p> &gt; N/A</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A.</p>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> N/A  </p></li>
<li><p><strong>Methods/Levers:</strong> N/A  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> N/A  </p></li>
<li><p><strong>Data &amp; Measures:</strong> N/A  </p></li>
<li><p><strong>Implementation Context:</strong> N/A  </p></li>
</ul>

<blockquote>
  <p>N/A</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<p><em>(None are framed as part of “actionability” in this paper.)</em></p>

<ul>
<li><p><strong>CL (Clarity):</strong> N/A  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> N/A  </p></li>
<li><p><strong>FE (Feasibility):</strong> N/A  </p></li>
<li><p><strong>TI (Timeliness):</strong> N/A  </p></li>
<li><p><strong>EX (Explainability):</strong> N/A (Explainability is a central theme, but not as a sub‑dimension of actionability.)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> N/A  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<p>Attention mechanisms for interpretability in RNNs; bidirectional RNNs; model‑agnostic interpretability context (e.g., LIME/Shapley cited), but not tied to actionability.:contentReference[oaicite:25]{index=25}</p>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A.</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p>N/A.</p>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper situates itself within EMR deep learning and visualization of black‑box models, highlighting RETAIN as an interpretable baseline and extending it with temporal features and interactive retraining. It reviews interactive ML/visual analytics but does not engage with “actionability” frameworks.:contentReference[oaicite:26]{index=26}</p>

<hr />

<h2>Summary</h2>

<p>This paper tackles the opacity of RNNs in clinical prediction by proposing RetainEX (an interpretable, attention‑based, time‑aware, bidirectional RNN with dual embeddings) and integrating it into RetainVis, a visual analytics tool. Users (clinicians/researchers) can browse cohorts, inspect patient‑level contributions at visit and medical‑code levels, and perform what‑if edits (adding/removing codes, adjusting visit intervals, and nudging contribution scores) with rapid recomputation to explore hypotheses and steer the model. Quantitative evaluations on Korean national EMR samples for heart failure and cataract show improved AUC/AP over GRU and RETAIN, and qualitative checks confirm medically plausible contributors (e.g., hypertension, ischemic heart disease, carvedilol, aspirin). While highly relevant to explainability and interactive decision support, the work does not define or analyze “actionability” nor specify criteria for outputs to be actionable; its contributions are best understood as enabling interpretability and interactive exploration rather than prescribing action‑ready knowledge.:contentReference[oaicite:27]{index=27}:contentReference[oaicite:28]{index=28}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 25 — The paper is adjacent to actionability via decision support and what‑if analysis, but it neither uses the term nor defines/structures “actionability” or its criteria.</p></li>
<li><p><strong>Operationalization Score:</strong> 20 — Strong operationalization of interpretability and interactivity (RetainEX/RetainVis workflow), but no operationalization of “actionability” itself.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Such <strong>black‑box</strong> nature of RNNs can impede its wide adoption in clinical practice… our design study aims to provide a visual analytics solution to increase <strong>interpretability and interactivity</strong> of RNNs.” (Abstract):contentReference[oaicite:29]{index=29}  </p></li>
<li><p>“We introduce an <strong>interpretable, interactive</strong> deep learning model, called <strong>RetainEX</strong>… We design and develop a <strong>visual analytics tool</strong>, called <strong>RetainVis</strong>.”:contentReference[oaicite:30]{index=30}  </p></li>
<li><p>“Users want to understand <strong>why each prediction is made</strong>… show the relationship between inputs (patient records) and outputs (prediction scores).” (Task T5):contentReference[oaicite:31]{index=31}  </p></li>
<li><p>“<strong>Conduct What‑If Case Analyses</strong>… users can check whether the prediction score decreases as they insert a hypothetical visit…” (Task T6):contentReference[oaicite:32]{index=32}  </p></li>
<li><p>“We… incorporate <strong>time intervals</strong> between visits… three different time values… performance… significantly improves.”:contentReference[oaicite:33]{index=33}  </p></li>
<li><p>“This interaction allows users to <strong>provide feedback</strong> onto <strong>contribution scores</strong>… the model… updated within a second after 20 iterations of <strong>retraining</strong>.”:contentReference[oaicite:34]{index=34}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A — The paper cites interpretability/attention and interactive ML literature but does not cite works defining or operationalizing “actionability.”</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: DACE: Distribution-Aware Counterfactual Explanation by Mixed-Integer Linear Optimization  </p>

<p>Authors: Kentaro Kanamori, Takuya Takagi, Ken Kobayashi, Hiroki Arimura  </p>

<p>DOI: 10.24963/ijcai.2020/391  </p>

<p>Year: 2020  </p>

<p>Publication Type: Conference  </p>

<p>Discipline/Domain: Artificial Intelligence, Machine Learning  </p>

<p>Subdomain/Topic: Explainable AI, Counterfactual Explanations, Optimization  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 82  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (implicit, framed as “realistic actions” in CE)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (DACE framework)  </p>

<p>Operationalization Present: Yes (MILO formulation, algorithmic steps)  </p>

<p>Primary Methodology: Conceptual + Quantitative (algorithm development and evaluation)  </p>

<p>Study Context: Post-hoc explanations for ML model decisions, focusing on financial datasets  </p>

<p>Geographic/Institutional Context: Japan (Hokkaido University, Fujitsu Laboratories, Tokyo Institute of Technology)  </p>

<p>Target Users/Stakeholders: End-users of ML systems, decision-makers in domains like finance and credit scoring  </p>

<p>Primary Contribution Type: New framework &amp; algorithm for actionable counterfactual explanations  </p>

<p>CL: Yes — “an action suggested by CE should be executable for users” (p. 2)  </p>

<p>CR: Yes — “evaluate its reality on the empirical data distribution” (p. 2)  </p>

<p>FE: Yes — “suggest an executable action for users” (p. 2)  </p>

<p>TI: Partial — timeliness not a central theme but actions are meant for decision contexts  </p>

<p>EX: Yes — cost function grounded in explainable metrics (MD, LOF)  </p>

<p>GA: Partial — goal alignment implied through user-desired outcomes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>DACE: Distribution-Aware Counterfactual Explanation by Mixed-Integer Linear Optimization  </p>

<p><strong>Authors:</strong>  </p>

<p>Kentaro Kanamori, Takuya Takagi, Ken Kobayashi, Hiroki Arimura  </p>

<p><strong>DOI:</strong>  </p>

<p>10.24963/ijcai.2020/391  </p>

<p><strong>Year:</strong>  </p>

<p>2020  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Artificial Intelligence, Machine Learning  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Explainable AI, Counterfactual Explanations, Optimization  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the challenge of generating counterfactual explanations (CE) that are realistic and executable for end-users, particularly in domains like finance. Traditional CE methods often ignore feature correlations and outlier risks, producing implausible recommendations.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Japan — Hokkaido University, Fujitsu Laboratories Ltd., Tokyo Institute of Technology  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>End-users of ML systems, decision-makers (e.g., loan officers, credit applicants)  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual + Quantitative (algorithm development and comparative experiments)  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Novel framework &amp; optimization method for actionable counterfactual generation  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper proposes <em>Distribution-Aware Counterfactual Explanation</em> (DACE), a method for generating counterfactual actions that are both plausible and executable for users by incorporating empirical data distribution into the cost function. It introduces a new cost function combining Mahalanobis Distance (MD) to account for feature correlations and Local Outlier Factor (LOF) to avoid outlier recommendations. This cost function is optimized via a mixed-integer linear optimization (MILO) formulation that accommodates both linear and tree ensemble classifiers. Experiments on FICO and German credit datasets show that DACE produces more realistic counterfactuals than existing methods (MAD, TLPS, PCC) in terms of both MD and LOF scores, albeit at higher computational cost. Sensitivity analysis of the trade-off parameter λ demonstrates the method's flexibility in balancing plausibility and reliability.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is framed implicitly as producing <strong>realistic, executable actions</strong> that users can directly follow to change a model’s decision outcome. It is linked to plausibility in the empirical data space and avoiding unrealistic or statistically improbable changes.  </p>

<blockquote>
  <p>“The action suggested by CE should be executable for users” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“To extract realistic actions, we need to define a cost function C that considers the empirical distribution” (p. 2)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Alignment with <strong>empirical feature correlations</strong> (avoid impossible or uncorrelated changes)  </p></li>
<li><p>Avoidance of <strong>outlier regions</strong> in feature space  </p></li>
<li><p>Feasibility for the user to execute  </p></li>
<li><p>Model outcome change to desired target class  </p></li>
<li><p>Preservation of plausibility given real-world constraints</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name:</strong> Distribution-Aware Counterfactual Explanation (DACE)  </p></li>
<li><p><strong>Methods/Levers:</strong> Cost function combining squared Mahalanobis Distance and k-Local Outlier Factor; λ as trade-off parameter  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Define feasible action set A per feature constraints  </p>

<p> 2. Calculate MD and LOF for candidate actions  </p>

<p> 3. Formulate optimization as MILO problem  </p>

<p> 4. Solve using MILO solvers (e.g., CPLEX)  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Feature correlations from covariance matrix; density-based outlier scores from training set  </p></li>
<li><p><strong>Implementation Context:</strong> Works with linear and tree ensemble classifiers  </p></li>
</ul>

<blockquote>
  <p>“We propose a new cost function based on the Mahalanobis’ distance… and Local Outlier Factor… to evaluate the reality of actions” (p. 3)  </p>
</blockquote>

<blockquote>
  <p>“We formulate the problem… as a mixed-integer linear optimization problem” (p. 3)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — clear, interpretable perturbation vector linked to decision change  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — grounded in empirical distribution  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — avoids unrealistic changes  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — not central, but decisions are framed in near-term contexts  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — uses explainable statistical measures  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — aligns with user’s desired prediction outcome  </p></li>
<li><p><strong>Other Dimensions:</strong> Avoidance of outliers, maintenance of feature dependencies</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Mahalanobis Distance for correlated feature space measurement  </p></li>
<li><p>Local Outlier Factor for density-based anomaly detection  </p></li>
<li><p>Mixed-Integer Linear Optimization for discrete-continuous decision problems  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Low Mahalanobis Distance (plausibility with respect to feature correlations)  </p></li>
<li><p>Low LOF (avoidance of statistically rare configurations)  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> High computation time; requirement for feature covariance and neighborhood statistics; complexity for large datasets  </p></li>
<li><p><strong>Enablers:</strong> Use of MILO solvers; tunable λ for balancing plausibility vs. feasibility  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Extends integer linear optimization CE methods (e.g., Ustun et al., 2019; Russell, 2019) to nonlinear cost functions incorporating MD and LOF. Addresses robustness and plausibility concerns highlighted in prior critiques (e.g., Laugel et al., 2019; Rudin, 2019).</p>

<hr />

<h2>Summary</h2>

<p>The DACE framework reconceptualizes actionability in counterfactual explanations as the ability to produce <strong>realistic, empirically plausible, and user-executable changes</strong>. It introduces a distribution-aware cost function combining Mahalanobis Distance for respecting feature correlations and Local Outlier Factor for avoiding outlier regions. This function is optimized through a mixed-integer linear approach compatible with linear and tree ensemble models. Experiments on credit datasets show DACE yields counterfactuals with lower MD and LOF than prior methods, suggesting more realistic recommendations. The trade-off parameter λ offers flexibility for balancing plausibility and reliability, enabling multiple viable action options. The approach’s main strength lies in tightly coupling action generation with statistical properties of the training data, ensuring generated recommendations are both actionable and grounded in observed distributions.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 82 — Strong conceptualization of actionability as realistic, distribution-grounded change; explicit link to user execution  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Fully specified computational method with steps, constraints, and implementation details  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“The action suggested by CE should be executable for users” (p. 2)  </p></li>
<li><p>“Evaluate its reality on the empirical data distribution” (p. 2)  </p></li>
<li><p>“We propose a new cost function based on the Mahalanobis’ distance… and Local Outlier Factor… to evaluate the reality of actions” (p. 3)  </p></li>
<li><p>“Our aim is to find an action… that minimizes the cost… subject to H(x̄ + a) = t” (p. 5)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Ustun et al., 2019 (Actionable recourse in linear classification)  </p></li>
<li><p>Russell, 2019 (Diverse coherent explanations)  </p></li>
<li><p>Ballet et al., 2019 (Imperceptible adversarial attacks)  </p></li>
<li><p>Laugel et al., 2019 (Connectedness and proximity in CE)  </p></li>
<li><p>Rudin, 2019 (Critique of post-hoc explanations)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Explainable AI: A Review of Machine Learning Interpretability Methods  </p>

<p>Authors: Pantelis Linardatos, Vasilis Papastefanopoulos, Sotiris Kotsiantis  </p>

<p>DOI: https://doi.org/10.3390/e23010018  </p>

<p>Year: 2021  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Artificial Intelligence, Machine Learning  </p>

<p>Subdomain/Topic: Explainable AI (XAI), Interpretability Methods  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 78  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: No (focuses on interpretability/explainability, not "actionability" per se)  </p>

<p>Contains Systematic Features/Dimensions: Yes (criteria, taxonomies, method categories)  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (taxonomy of interpretability methods)  </p>

<p>Operationalization Present: Yes (taxonomy + method-by-method review with applicability guidance)  </p>

<p>Primary Methodology: Literature Review  </p>

<p>Study Context: Survey of ML interpretability methods across data types, algorithms, and use cases  </p>

<p>Geographic/Institutional Context: University of Patras, Greece  </p>

<p>Target Users/Stakeholders: ML practitioners, researchers, applied data scientists, policymakers in regulated domains  </p>

<p>Primary Contribution Type: Taxonomy and comparative survey of methods  </p>

<p>CL: Partial (clarity linked to interpretability but not as "actionability" dimension)  </p>

<p>CR: Yes (methods often linked to model/data context)  </p>

<p>FE: Partial (some mention of feasibility of application but not as formal dimension)  </p>

<p>TI: No (timeliness not explicitly tied to interpretability)  </p>

<p>EX: Yes (explainability as separate but related concept to interpretability)  </p>

<p>GA: Partial (alignment with goals implied in fairness and trustworthiness contexts)  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Explainable AI: A Review of Machine Learning Interpretability Methods  </p>

<p><strong>Authors:</strong>  </p>

<p>Pantelis Linardatos, Vasilis Papastefanopoulos, Sotiris Kotsiantis  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.3390/e23010018  </p>

<p><strong>Year:</strong>  </p>

<p>2021  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Artificial Intelligence, Machine Learning  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Explainable AI (XAI), Interpretability Methods  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper surveys the growing field of Explainable AI (XAI) in response to the challenges posed by black-box machine learning models in high-stakes domains such as healthcare, finance, and autonomous systems. It focuses on categorizing interpretability methods based on model specificity, scope (local vs. global), data type, and purpose, offering detailed descriptions, limitations, and links to implementations.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of Patras, Greece  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Machine learning practitioners, researchers, data scientists, domain experts, and policymakers  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Literature Review  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Taxonomy and comparative synthesis of methods</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper presents a comprehensive literature review of machine learning interpretability methods, offering a detailed taxonomy that classifies techniques by their application to specific models (model-specific vs. model-agnostic), scope (local vs. global), and purpose (explaining black-box models, creating white-box models, promoting fairness, and analyzing sensitivity). The authors differentiate between interpretability and explainability, review evaluation methods, and compare tools for various data types (tabular, image, text, graph). The review includes strengths, weaknesses, and implementation resources. While not focused on “actionability” in the decision-making sense, it operationalizes interpretability by guiding method selection for practical use cases.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>The paper does not directly define “actionability,” but implicitly links interpretability/explainability to trustworthiness, fairness, and the ability to derive meaningful, human-understandable insights that can inform decisions.  </p>

<blockquote>
  <p>“Interpretability… is the degree to which a human can understand the cause of a decision” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“Explainability… is associated with the internal logic and mechanics inside a ML system” (p. 3)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<p>Implicitly, for interpretability methods to be “usable” in decisions, they must:  </p>

<ul>
<li><p>Relate model outputs to human-understandable inputs/features  </p></li>
<li><p>Provide transparency on decision mechanisms  </p></li>
<li><p>Support evaluation of fairness and bias  </p></li>
<li><p>Offer reproducible, context-relevant explanations  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Taxonomy of Interpretability Methods  </p></li>
<li><p><strong>Methods/Levers:</strong> Categorization by model specificity, scope, and purpose; detailed method descriptions with pros/cons and applicability  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify problem constraints → Choose category (e.g., explain black-box, create white-box) → Filter by scope, model compatibility, and data type → Apply method using provided tools/resources  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Not quantitative for “actionability,” but qualitative criteria for method selection (e.g., data type, local/global scope, fairness needs)  </p></li>
<li><p><strong>Implementation Context:</strong> Works across domains where interpretability is required for trust, compliance, or stakeholder understanding  </p></li>
</ul>

<blockquote>
  <p>“This taxonomy… identifies four major categories for interpretability methods… methods for explaining complex black-box models… creating white-box models… promoting fairness… analyzing sensitivity” (p. 5)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Partial — clarity is implied through interpretability  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — method applicability linked to model/data context  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — feasibility discussed for method choice, not as formal criterion  </p></li>
<li><p><strong>TI (Timeliness):</strong> No  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — explicitly discussed as distinct from interpretability  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — fairness and trustworthiness goals referenced  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Fairness, Sensitivity, Model scope, Data type  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Distinction between interpretability and explainability (Doshi-Velez &amp; Kim, Miller)  </p></li>
<li><p>Prior taxonomies (Gilpin et al., Adadi &amp; Berrada, Guidotti et al.)  </p></li>
<li><p>Fairness frameworks (Hardt et al.)  </p></li>
<li><p>Sensitivity analysis foundations (Sobol, Saltelli)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>No formal “actionability” metrics; evaluation focuses on interpretability quality via:  </p>

<ul>
<li><p>Application-grounded, human-grounded, functionally-grounded evaluation (Doshi-Velez &amp; Kim)  </p></li>
<li><p>Fairness measures (e.g., disparate impact, equalized odds)  </p></li>
<li><p>Sensitivity indices  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of formal definitions, context-specific constraints, model complexity, limited generalizability across domains  </p></li>
<li><p><strong>Enablers:</strong> Availability of open-source tools, clear taxonomies, method-model-data mapping  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions itself as more comprehensive than prior surveys by integrating model-agnostic/specific, local/global, and data-type dimensions into a unified taxonomy. Expands beyond deep learning explainability to include fairness and sensitivity analysis as part of interpretability.</p>

<hr />

<h2>Summary</h2>

<p>While not directly about “actionability,” the paper presents a mature operationalization of interpretability that enables informed method selection for practical contexts. The taxonomy and detailed review offer guidance on aligning explanation techniques with model type, scope, and data modality, indirectly supporting actionable decision-making in high-stakes domains. The inclusion of fairness and sensitivity methods adds a governance dimension, further connecting interpretability to responsible AI practices.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 78 — Strong on conceptual clarity for interpretability/explainability; lacks explicit actionability definitions but covers enabling dimensions.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Well-developed taxonomy with implementation guidance; practical pathway for selecting and applying methods.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Interpretability… is the ability to explain or present in understandable terms to a human” (p. 2)  </p></li>
<li><p>“Explainability… is associated with the internal logic and mechanics inside a ML system” (p. 3)  </p></li>
<li><p>“This taxonomy… identifies four major categories for interpretability methods…” (p. 5)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Doshi-Velez &amp; Kim (interpretability definition, evaluation methods)  </p></li>
<li><p>Miller (interpretability as cause understanding)  </p></li>
<li><p>Gilpin et al., Adadi &amp; Berrada, Guidotti et al. (prior taxonomies)  </p></li>
<li><p>Hardt et al. (fairness framework)  </p></li>
<li><p>Sobol, Saltelli (sensitivity analysis)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Counterfactual Explanations and Algorithmic Recourses for Machine Learning: A Review  </p>

<p>Authors: Sahil Verma, Varich Boonsanong, Minh Hoang, Keegan Hines, John Dickerson, Chirag Shah  </p>

<p>DOI: https://doi.org/10.1145/3677119  </p>

<p>Year: 2024  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Computer Science / Machine Learning  </p>

<p>Subdomain/Topic: Explainable AI, Counterfactual Explanations, Algorithmic Recourse  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (explicit and implicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (rubric of desiderata, operational frameworks)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Review  </p>

<p>Study Context: Counterfactual explanations in ML for classification, primarily tabular data  </p>

<p>Geographic/Institutional Context: Global research literature, University of Washington &amp; Arthur AI  </p>

<p>Target Users/Stakeholders: ML practitioners, policymakers, system designers, regulated industries (finance, healthcare)  </p>

<p>Primary Contribution Type: Comprehensive literature review and taxonomy with evaluation rubric  </p>

<p>CL: Yes — “An effective counterfactual only proposes small changes in the features relative to the starting point” (p. 7)  </p>

<p>CR: Yes — “Recommendation should never change immutable features... preference order among mutable features” (p. 7)  </p>

<p>FE: Yes — Feasibility implied in actionability constraints and plausibility requirements (p. 7-8)  </p>

<p>TI: Partial — Timeliness is implicit in “amortized inference” and generation time metrics but not core desideratum  </p>

<p>EX: Yes — Explainability core to the survey’s scope (p. 2-3)  </p>

<p>GA: Yes — Goal alignment implicit in actionable, realistic, user-preference-aligned changes (p. 7)  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Counterfactual Explanations and Algorithmic Recourses for Machine Learning: A Review</p>

<p><strong>Authors:</strong>  </p>

<p>Sahil Verma, Varich Boonsanong, Minh Hoang, Keegan Hines, John Dickerson, Chirag Shah</p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1145/3677119</p>

<p><strong>Year:</strong>  </p>

<p>2024</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Machine Learning</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Explainable AI, Counterfactual Explanations, Algorithmic Recourse</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper synthesizes a fast-growing body of research on counterfactual explanations (CFEs) and algorithmic recourse, particularly in supervised ML classification for tabular data. It links CFEs to legal mandates (e.g., GDPR, ECOA), fairness, and trust in high-stakes decision-making domains like finance and healthcare.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of Washington (Seattle, USA), Arthur AI (Washington DC, USA)</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>ML researchers, practitioners, policymakers, legal analysts, and regulated industry developers</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Comprehensive literature review (&gt;350 papers) with comparative evaluation rubric</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Taxonomy of CFE approaches, evaluation against desiderata, identification of gaps and open challenges</p>

<h2>General Summary of the Paper</h2>

<p>This survey reviews more than 350 papers proposing algorithms for generating CFEs and recourses in machine learning. CFEs provide actionable feedback — suggesting minimal, feasible feature changes to flip a model’s decision — without requiring access to model internals. The authors define a set of key desiderata (validity, actionability, sparsity, plausibility, causality) and assess each method’s handling of them. They also catalog datasets, evaluation metrics, and methodological variants, mapping the field's evolution since the seminal 2017 work by Wachter et al. The review highlights operational considerations such as model access requirements, amortization, handling of categorical variables, and integration of user preferences, while identifying unresolved challenges like robustness, bias mitigation, privacy, and real-world deployment.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as the feasibility of user-implementable changes to achieve a desired outcome without altering immutable or legally protected attributes, and while respecting real-world causal constraints.  </p>

<blockquote>
  <p>“A recommended counterfactual should never change the immutable features… applicant might have a preference order amongst the mutable features” (p. 7)  </p>
</blockquote>

<blockquote>
  <p>“Realistic and actionable… of little use if the recommendation were to decrease age by 10 years” (p. 6)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Changes must be <strong>valid</strong> (yield the desired class outcome)</p></li>
<li><p>Must target <strong>mutable, non-sensitive</strong> features</p></li>
<li><p>Should be <strong>sparse</strong> (few changes)</p></li>
<li><p>Must be <strong>plausible</strong> and close to the data manifold</p></li>
<li><p>Should respect <strong>causal dependencies</strong> among features</p></li>
<li><p>Align with <strong>user preferences</strong> and feasibility constraints</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Wachter et al. optimization framework; FACE; CounterNet; FastAR; GAN-based generators; VAE-based recourse  </p></li>
<li><p><strong>Methods/Levers:</strong> Distance minimization, sparsity-inducing norms, causal graph constraints, manifold regularization, preference modeling  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify mutable features, solve constrained optimization problem, optionally generate multiple diverse CFEs, evaluate on metrics like proximity and validity  </p></li>
<li><p><strong>Data &amp; Measures:</strong> L1/L2 distance, manifold closeness (VAE reconstruction error, k-NN distance), causal constraint satisfaction  </p></li>
<li><p><strong>Implementation Context:</strong> Mostly tabular ML classification, but extendable to images, text, graphs  </p></li>
</ul>

<blockquote>
  <p>“arg min … subject to f(x′)=y′ … updated to take into account actionable features A” (p. 7)  </p>
</blockquote>

<blockquote>
  <p>“Adding the data manifold loss term encourages… even if path is longer” (p. 8)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Minimal, interpretable changes as core design goal (p. 7)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Must respect feature mutability and legal context (p. 7)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Operational constraints and plausibility (p. 6-8)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Addressed through efficiency metrics (p. 14)  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Core motivation of CFEs (p. 2-3)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Tailored to help users achieve desired outcomes (p. 6-7)  </p></li>
<li><p><strong>Other Dimensions:</strong> Causality, Sparsity, Diversity</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Optimization-based definition from Wachter et al. (2017)</p></li>
<li><p>Thagard’s theory of explanatory coherence</p></li>
<li><p>Structural causal models (SCM)</p></li>
<li><p>Legal frameworks (GDPR, ECOA)</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li>Validity, Proximity, Number of Features Changed, Generation Time, Diversity, Plausibility, Causal Constraint Satisfaction</li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Bias in underlying model, lack of user preference data, privacy risks from query access, model dynamics (drift), handling categorical features  </p></li>
<li><p><strong>Enablers:</strong> Amortized inference, causal modeling, manifold regularization, interactive user interfaces</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Builds on the 2017 Wachter et al. framework and extends to fairness, interpretability, and causal reasoning literature. Integrates findings from psychology and philosophy on counterfactual reasoning.</p>

<h2>Summary</h2>

<p>The paper positions counterfactual explanations as a bridge between explainability and actionable change in ML, providing end-users with specific, feasible steps to alter outcomes. Actionability is defined through mutability constraints, minimality, plausibility, and causal consistency. The authors operationalize these criteria in an evaluation rubric applied to 350+ CFE methods, categorizing them by model access, optimization strategy, amortization, and feature handling. By combining a rigorous taxonomy with practical performance metrics, the work advances both conceptual clarity and implementation guidance for CFEs, while surfacing unresolved challenges in robustness, fairness, deployment, and user interaction.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Strong explicit and implicit definition of actionability, systematic feature list, comprehensive conceptual grounding.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Multiple concrete frameworks and workflows for achieving actionability, though timeliness and deployment aspects are less fully developed.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“A recommended counterfactual should never change the immutable features… preference order amongst the mutable features” (p. 7)  </p></li>
<li><p>“It is easier… to focus on changing a few things instead of many… advice which is realistic and actionable” (p. 6)  </p></li>
<li><p>“Adding the data manifold loss term encourages… path that follows data manifold” (p. 8)  </p></li>
<li><p>“CFE applicable to black-box models… place no restrictions on model complexity” (p. 3)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Wachter et al. (2017) — Foundational optimization formulation  </p></li>
<li><p>Thagard (1989) — Explanatory coherence theory  </p></li>
<li><p>Ustun et al. (2019) — Actionable recourse  </p></li>
<li><p>Karimi et al. (2020, 2021) — Causality in recourse  </p></li>
<li><p>Binns et al. (2018), Dodge et al. (2019) — User preference studies</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Navigating explanatory multiverse through counterfactual path geometry  </p>

<p>Authors: Kacper Sokol, Edward Small, Yueqing Xuan  </p>

<p>DOI: 10.1007/s10994-025-06769-2  </p>

<p>Year: 2025  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Machine Learning, Explainable AI  </p>

<p>Subdomain/Topic: Counterfactual Explanations, Explainability, Geometry of Explanations  </p>

<p>Eligibility: Yes  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 80  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual and Experimental  </p>

<p>Study Context: Counterfactual Explanations in Machine Learning Models  </p>

<p>Geographic/Institutional Context: International  </p>

<p>Target Users/Stakeholders: ML Practitioners, Researchers, AI Developers, Data Scientists  </p>

<p>Primary Contribution Type: Conceptual Framework, Experimental Evaluation  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong> Navigating explanatory multiverse through counterfactual path geometry  </p>

<p><strong>Authors:</strong> Kacper Sokol, Edward Small, Yueqing Xuan  </p>

<p><strong>DOI:</strong> 10.1007/s10994-025-06769-2  </p>

<p><strong>Year:</strong> 2025  </p>

<p><strong>Publication Type:</strong> Journal  </p>

<p><strong>Discipline/Domain:</strong> Machine Learning, Explainable AI  </p>

<p><strong>Subdomain/Topic:</strong> Counterfactual Explanations, Explainability, Geometry of Explanations  </p>

<p><strong>Contextual Background:</strong> The paper introduces the "explanatory multiverse" concept to explain counterfactual reasoning in machine learning (ML). It emphasizes the geometric relation between counterfactual paths, offering a more structured and human-centered way of navigating, comparing, and reasoning about counterfactual explanations. The concept includes novel spatially-aware desiderata—such as agency, loss of opportunity, and choice complexity—that enhance the decision-making process for explainees.  </p>

<p><strong>Geographic/Institutional Context:</strong> International research collaboration  </p>

<p><strong>Target Users/Stakeholders:</strong> Machine learning practitioners, AI developers, researchers in explainability  </p>

<p><strong>Primary Methodology:</strong> Conceptual framework development, experimental evaluation on tabular and image datasets  </p>

<p><strong>Primary Contribution Type:</strong> Conceptual framework for counterfactual explainability, experimental results  </p>

<h2>General Summary of the Paper</h2>

<p>The paper presents a novel framework called "explanatory multiverse" to address the multiplicity of counterfactual explanations in machine learning. Traditional counterfactual methods often overlook the relationships between paths leading to counterfactuals. The authors propose a geometry-based approach that accounts for properties like branching, divergence, and convergence in counterfactual paths. They introduce an all-in-one metric, "opportunity potential," to quantify these spatial properties and enable more informed decision-making for explainees. The method is tested on various tabular and image datasets, demonstrating the flexibility and effectiveness of explanatory multiverse in providing diverse and actionable insights.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<p>Reason if Not Eligible: n/a  </p>

<h2>How Actionability is Understood</h2>

<p>The paper defines actionability in the context of counterfactual explanations as the ability for explainees to navigate and select explanations based not only on their absolute differences but also on the properties of their connecting paths. This gives explainees more agency by allowing them to make informed decisions based on the structure and feasibility of different counterfactual paths.  </p>

<blockquote>
  <p>“Explanatory multiverse enhances the actionability of counterfactuals by considering the geometric relationships between paths and enabling more informed decision-making” (p. 3).  </p>
</blockquote>

<blockquote>
  <p>“The method grants explainees more agency, allowing them to select counterfactuals based on the path characteristics” (p. 4).</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<p>The key factors that make counterfactual explanations actionable in this context are:</p>

<ul>
<li><p><strong>Spatial Awareness:</strong> The geometry of counterfactual paths, including branching, divergence, and convergence, enables more informed decision-making.  </p></li>
<li><p><strong>User Agency:</strong> Explainees can select paths not only based on the counterfactual's outcome but also on the characteristics of the journey, such as how many changes are involved or how quickly they diverge.  </p></li>
<li><p><strong>Choice Complexity:</strong> The framework reduces cognitive load by offering a manageable set of diverse paths, avoiding overwhelming the explainee with too many options.  </p></li>
</ul>

<blockquote>
  <p>“Actionability is achieved by offering explainees diverse counterfactual options, reducing cognitive load and empowering them to make better decisions” (p. 8).  </p>
</blockquote>

<blockquote>
  <p>“By considering the spatial relationship between counterfactual paths, we allow explainees to choose paths that suit their needs and preferences” (p. 7).</p>
</blockquote>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<p>Actionability is operationalized through the development of the explanatory multiverse framework, which includes:</p>

<ul>
<li><p><strong>Geometric Representation of Counterfactual Paths:</strong> Paths are represented as vectors in a space, with properties such as length, branching, and divergence captured and quantified.  </p></li>
<li><p><strong>Opportunity Potential Metric:</strong> A novel metric that quantifies how much a counterfactual path can contribute to reaching alternative counterfactual outcomes, balancing between length and diversity.  </p></li>
<li><p><strong>Graph-based Implementation:</strong> A practical implementation using directed graphs to model counterfactual journeys, supporting diverse data types like tabular and image data.  </p></li>
</ul>

<blockquote>
  <p>“The explanatory multiverse framework is operationalized by applying vector spaces and graph-based models to represent counterfactual paths” (p. 9).  </p>
</blockquote>

<blockquote>
  <p>“The opportunity potential metric helps prioritize counterfactual paths that provide the best balance of actionability and distance” (p. 13).</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – The framework allows explainees to clearly understand the paths available and their characteristics.  </p>

<p> &gt; “The geometry of counterfactual paths, when made clear, allows explainees to navigate their choices with greater clarity” (p. 8).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – The paths are designed to be relevant to the explainee’s specific needs and constraints.  </p>

<p> &gt; “The framework tailors counterfactual paths to the individual needs and domain-specific constraints of the explainee” (p. 7).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – The paths are feasible, considering real-world constraints and limitations in the decision-making process.  </p>

<p> &gt; “Feasibility is embedded in the method, as paths are designed to account for the real-world constraints of feature changes” (p. 7).  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes – The approach supports timely decision-making by offering fast, actionable insights.  </p>

<p> &gt; “The ability to make quick decisions is facilitated by the ease of navigating through the counterfactual multiverse” (p. 8).  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – The framework makes counterfactual explanations more interpretable by considering the geometry of the paths.  </p>

<p> &gt; “Explainability is enhanced by the structured approach that allows users to visualize and compare the paths leading to different counterfactuals” (p. 7).  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – The framework ensures that counterfactuals align with the explainee’s goals, offering relevant and actionable outcomes.  </p>

<p> &gt; “Paths are designed to align with the user’s goal, whether it is achieving a certain classification outcome or finding alternative strategies” (p. 8).</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<p>The authors draw on the notion of "possible worlds" from philosophy (Lewis, 1973) and cognitive science, where different counterfactual scenarios are seen as alternate worlds that can be navigated. This perspective informs their approach to counterfactual reasoning and the concept of the "explanatory multiverse."  </p>

<blockquote>
  <p>“The concept of explanatory multiverse is grounded in the idea of multiple possible worlds, which provides a richer framework for counterfactual explanations” (p. 7).</p>
</blockquote>

<h2>Indicators or Metrics for Actionability</h2>

<p>The key metric for actionability is <strong>opportunity potential</strong>, which quantifies the fraction of the reference path that contributes to reaching alternative counterfactual outcomes.  </p>

<blockquote>
  <p>“Opportunity potential is the all-in-one metric that helps quantify how well a counterfactual path can contribute to achieving alternative outcomes” (p. 13).</p>
</blockquote>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Cognitive overload from too many counterfactual options, lack of clarity in path properties, and the complexity of navigating multiple paths.  </p></li>
<li><p><strong>Enablers:</strong> Spatially-aware counterfactual paths, the ability to prioritize based on agency and feasibility, and the use of interactive explainability tools.  </p></li>
</ul>

<blockquote>
  <p>“By considering the geometry of counterfactual paths, we reduce cognitive overload and empower explainees with better agency” (p. 7).  </p>
</blockquote>

<blockquote>
  <p>“Enabling users to explore multiple paths at their own pace increases their ability to make meaningful decisions” (p. 8).</p>
</blockquote>

<h2>Relation to Existing Literature</h2>

<p>The paper positions its approach within the existing body of work on counterfactual explanations, noting how it extends traditional methods by incorporating geometric relationships and offering a more interactive and user-centered framework for explainability.  </p>

<blockquote>
  <p>“Explanatory multiverse is a step forward from current counterfactual methods, which typically ignore the relationships between different counterfactual paths” (p. 8).</p>
</blockquote>

<h2>Summary</h2>

<p>This paper introduces explanatory multiverse, a novel framework for navigating counterfactual explanations by considering the geometric relationships between counterfactual paths. It enhances actionability by giving explainees more agency, reducing cognitive overload, and providing more flexible and actionable insights. The approach is validated experimentally on various datasets, demonstrating its effectiveness and flexibility. The authors propose an all-in-one metric, opportunity potential, to quantify the benefits of their method, emphasizing the trade-off between user agency and explanation length.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 – The framework addresses key gaps in the current counterfactual explanation literature, offering a human-centered approach that enhances interpretability and actionability.  </p></li>
<li><p><strong>Operationalization Score:</strong> 80 – The approach is well operationalized through a novel metric and a graph-based implementation, though the methodology could be expanded further for broader applications.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“The method grants explainees more agency, allowing them to select counterfactuals based on the path characteristics” (p. 4).  </p></li>
<li><p>“Feasibility is embedded in the method, as paths are designed to account for the real-world constraints of feature changes” (p. 7).  </p></li>
<li><p>“Opportunity potential is the all-in-one metric that helps quantify how well a counterfactual path can contribute to achieving alternative outcomes” (p. 13).  </p></li>
<li><p>“The concept of explanatory multiverse is grounded in the idea of multiple possible worlds, which provides a richer framework for counterfactual explanations” (p. 7).</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Lewis, D. (1973). Counterfactuals. Harvard University Press.  </p></li>
<li><p>Sokol, K., &amp; Flach, P. (2020a). Glass-Box: Explaining AI decisions with counterfactual statements through conversation with a voice-enabled virtual assistant.  </p></li>
<li><p>van Looveren, A., &amp; Klaise, J. (2021). Interpretable counterfactual explanations guided by prototypes.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Medical-informed machine learning: integrating prior knowledge into medical decision systems  </p>

<p>Authors: Christel Sirocchi, Alessandro Bogliolo, Sara Montagna  </p>

<p>DOI: 10.1186/s12911-024-02582-4  </p>

<p>Year: 2024  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Medical Informatics, Machine Learning  </p>

<p>Subdomain/Topic: Medical Decision Support Systems, Actionable Machine Learning Models  </p>

<p>Eligibility: Yes  </p>

<p>Overall Relevance Score: 80  </p>

<p>Operationalization Score: 70  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Mixed Methods (Review and Case Study)  </p>

<p>Study Context: Medical, Healthcare Sector  </p>

<p>Geographic/Institutional Context: Italy, University of Urbino  </p>

<p>Target Users/Stakeholders: Clinicians, Healthcare Providers, Medical Researchers  </p>

<p>Primary Contribution Type: Conceptual Framework, Case Study  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong> Medical-informed machine learning: integrating prior knowledge into medical decision systems  </p>

<p><strong>Authors:</strong> Christel Sirocchi, Alessandro Bogliolo, Sara Montagna  </p>

<p><strong>DOI:</strong> 10.1186/s12911-024-02582-4  </p>

<p><strong>Year:</strong> 2024  </p>

<p><strong>Publication Type:</strong> Journal  </p>

<p><strong>Discipline/Domain:</strong> Medical Informatics, Machine Learning  </p>

<p><strong>Subdomain/Topic:</strong> Medical Decision Support Systems, Actionable Machine Learning Models  </p>

<p><strong>Contextual Background:</strong> The paper addresses how machine learning (ML) models can be more effectively integrated with medical domain knowledge for better decision-making in clinical settings. The case study focuses on diabetes prediction, illustrating how integration at different stages of the ML pipeline enhances both performance and practical adoption in healthcare.  </p>

<p><strong>Geographic/Institutional Context:</strong> University of Urbino, Italy  </p>

<p><strong>Target Users/Stakeholders:</strong> Healthcare professionals, ML researchers in healthcare, medical decision support developers  </p>

<p><strong>Primary Methodology:</strong> Mixed Methods (Review and Case Study)  </p>

<p><strong>Primary Contribution Type:</strong> Conceptual Framework, Case Study  </p>

<h2>General Summary of the Paper</h2>

<p>The paper explores the integration of domain knowledge into machine learning models to improve the actionability of clinical decision systems. The authors argue that while ML has shown success in medical contexts, integrating clinical expertise at various stages of the ML pipeline can improve accuracy, interpretability, and compliance with medical guidelines. The case study on diabetes prediction highlights how rules, causal networks, and thresholds informed by clinical knowledge enhance model performance, particularly in data-limited scenarios.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<p>Reason if Not Eligible: n/a  </p>

<h2>How Actionability is Understood</h2>

<p>The paper defines actionability as the capacity of ML models to generate predictions that are not only accurate but also clinically relevant, interpretable, and aligned with medical protocols. It emphasizes the importance of making these predictions usable by clinicians in real-world scenarios.  </p>

<blockquote>
  <p>“The integration of medical domain knowledge throughout the ML pipeline is crucial for ensuring that predictions are not only accurate but also interpretable and aligned with clinical guidelines” (p. 5).</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<p>The authors identify several conditions necessary for an actionable ML model:</p>

<ul>
<li><p>Alignment with clinical guidelines and protocols  </p></li>
<li><p>Interpretability for healthcare practitioners  </p></li>
<li><p>Feasibility in real-world medical contexts  </p></li>
<li><p>Ensuring model decisions are both accurate and explainable  </p></li>
</ul>

<blockquote>
  <p>“Models must adhere to existing clinical protocols to ensure their acceptance in practice” (p. 3).  </p>
</blockquote>

<blockquote>
  <p>“The interpretability of the model plays a key role in gaining trust from healthcare professionals” (p. 7).</p>
</blockquote>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<p>The paper proposes operationalizing actionability by integrating medical knowledge at different stages of the ML pipeline:</p>

<ul>
<li><p><strong>Data Preprocessing:</strong> Use of expert-defined thresholds for discretizing continuous data, handling missing data with Bayesian inference based on domain knowledge.  </p></li>
<li><p><strong>Feature Engineering:</strong> Deriving composite indices or selecting features informed by clinical relevance, such as insulin sensitivity in diabetes models.  </p></li>
<li><p><strong>Model Learning:</strong> Custom loss functions penalize deviations from clinical rules, ensuring the model adheres to established medical knowledge.  </p></li>
<li><p><strong>Output Evaluation:</strong> Combining ML predictions with rule-based systems to filter out predictions inconsistent with clinical guidelines.  </p></li>
</ul>

<blockquote>
  <p>“Using a custom loss function helps improve recall, ensuring the model’s outputs are clinically relevant and accurate” (p. 12).  </p>
</blockquote>

<blockquote>
  <p>“The integration of rule-based modules alongside ML outputs increases adherence to clinical guidelines” (p. 13).</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – Clarity is explicitly linked to actionability.  </p>

<p> &gt; “Decision trees trained on discretized data provide more interpretable results, which are essential for clinical application” (p. 9).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – Actionability is directly tied to the relevance of model outcomes in the clinical context.  </p>

<p> &gt; “The model’s outcomes must align with established clinical knowledge to be actionable” (p. 4).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – Feasibility is tied to the integration of prior knowledge and the practical applicability of ML in clinical settings.  </p>

<p> &gt; “Integrating domain knowledge helps mitigate the feasibility challenges posed by limited data” (p. 7).  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes – The paper mentions that actionability also depends on the timeliness of predictions in healthcare.  </p>

<p> &gt; “Timely predictions are crucial, especially in clinical settings where decisions must be made quickly” (p. 9).  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – Explainability is a key feature for ensuring model adoption in clinical practice.  </p>

<p> &gt; “Explainability is necessary to gain trust and make the model usable in real-world clinical settings” (p. 7).  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – The paper explicitly states that alignment with clinical goals is critical.  </p>

<p> &gt; “Models must be aligned with healthcare goals to ensure they are actionable and integrate effectively into clinical practice” (p. 5).</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<p>The authors base their conceptualization of actionability on the principles of explainable AI (XAI) and informed machine learning, integrating expert knowledge into machine learning models to improve both performance and interpretability in healthcare contexts.</p>

<h2>Indicators or Metrics for Actionability</h2>

<p>The paper does not propose explicit metrics for actionability, but it implies that models must demonstrate:</p>

<ul>
<li><p>High accuracy and recall (critical for clinical decision support)  </p></li>
<li><p>Interpretability and adherence to clinical guidelines  </p></li>
</ul>

<blockquote>
  <p>“Recall was significantly improved by integrating domain knowledge, making the model more clinically reliable” (p. 12).</p>
</blockquote>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of unified medical knowledge representation, conflicting clinical guidelines.  </p></li>
<li><p><strong>Enablers:</strong> Access to medical data, integration of expert knowledge, domain-specific custom loss functions.  </p></li>
</ul>

<blockquote>
  <p>“Barriers include inconsistencies in medical terminology, which can undermine the model’s performance” (p. 14).  </p>
</blockquote>

<blockquote>
  <p>“Enabling factors include the availability of structured domain knowledge, which facilitates knowledge integration into the ML pipeline” (p. 6).</p>
</blockquote>

<h2>Relation to Existing Literature</h2>

<p>The paper builds on existing work in informed machine learning and explainable AI, highlighting that integrating medical knowledge at every stage of the ML pipeline can overcome challenges inherent in purely data-driven models. It positions its approach within a growing body of literature that emphasizes the importance of domain knowledge integration in ML applications in healthcare.</p>

<h2>Summary</h2>

<p>The paper emphasizes the importance of integrating medical knowledge into machine learning models to ensure that they are actionable. This is achieved through methods such as using expert-defined thresholds, incorporating composite features, applying domain-specific loss functions, and combining ML with rule-based systems for output evaluation. The authors argue that these strategies improve the relevance, clarity, and interpretability of ML models, thus making them more suitable for clinical adoption.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 80 – The paper offers a well-rounded conceptualization of actionability, addressing key attributes like interpretability, relevance, and alignment with clinical goals.  </p></li>
<li><p><strong>Operationalization Score:</strong> 70 – The paper proposes clear methods for integrating domain knowledge into the ML pipeline but lacks detailed operational steps for broad implementation.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Models must adhere to existing clinical protocols to ensure their acceptance in practice” (p. 3).  </p></li>
<li><p>“The interpretability of the model plays a key role in gaining trust from healthcare professionals” (p. 7).  </p></li>
<li><p>“Using a custom loss function helps improve recall, ensuring the model’s outputs are clinically relevant and accurate” (p. 12).  </p></li>
<li><p>“Enabling factors include the availability of structured domain knowledge, which facilitates knowledge integration into the ML pipeline” (p. 6).</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Von Rueden L, Mayer S, Beckh K, Georgiev B, Giesselbach S, Heese R, et al. (2021). Informed Machine Learning: A Taxonomy and Survey of Integrating Prior Knowledge into Learning Systems. IEEE Trans Knowl Data Eng.  </p></li>
<li><p>Leiser F, Rank S, Schmidt-Kraepelin M, et al. (2023). Medical-informed machine learning: A scoping review and future research directions. Artif Intell Med.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: An Explanatory Model Steering System for Collaboration between Domain Experts and AI  </p>

<p>Authors: Aditya Bhattacharya, Simone Stumpf, Katrien Verbert  </p>

<p>DOI: https://doi.org/10.1145/3631700.3664886  </p>

<p>Year: 2024  </p>

<p>Publication Type: Conference (Adjunct Proceedings, ACM UMAP ’24)  </p>

<p>Discipline/Domain: Human-Computer Interaction (HCI) / Machine Learning (ML)  </p>

<p>Subdomain/Topic: Explainable AI (XAI), Interactive Machine Learning (IML), Human-AI Collaboration  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 88  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Implicit  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (Explanatory Model Steering System – EXMOS)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual + Experimental (user studies with healthcare experts)  </p>

<p>Study Context: AI model steering in healthcare prediction (diabetes)  </p>

<p>Geographic/Institutional Context: KU Leuven (Belgium), University of Glasgow (Scotland)  </p>

<p>Target Users/Stakeholders: Domain experts (healthcare professionals)  </p>

<p>Primary Contribution Type: System design and evaluation for human-in-the-loop AI steering  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>An Explanatory Model Steering System for Collaboration between Domain Experts and AI  </p>

<p><strong>Authors:</strong>  </p>

<p>Aditya Bhattacharya, Simone Stumpf, Katrien Verbert  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1145/3631700.3664886  </p>

<p><strong>Year:</strong>  </p>

<p>2024  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference (ACM UMAP ’24 Adjunct Proceedings)  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Human-Computer Interaction / Machine Learning  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Explainable AI, Interactive ML, Human-AI Collaboration  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The work targets high-stakes domains, especially healthcare, where domain experts need to understand and improve AI predictions. The system, EXMOS, integrates multifaceted explanations with manual and automated data configuration, enabling experts to use their domain knowledge to steer models and address biases.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>KU Leuven (Belgium), University of Glasgow (Scotland)  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Healthcare professionals and other domain experts without deep ML expertise.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual system design + experimental evaluation (three user studies, 174 healthcare experts).  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Interactive system enabling domain expert-driven model refinement.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper presents EXMOS, an <em>Explanatory Model Steering</em> system designed to enhance collaboration between domain experts and AI systems. It combines a multifaceted explanation dashboard (integrating data-centric and model-centric explanations) with manual and automated data configuration tools to fine-tune training data. The system aims to help experts identify biases, correct anomalies, and steer prediction models effectively. Evaluated in a healthcare-focused diabetes prediction use case with 174 healthcare professionals, the results underscore the value of expert involvement and the combination of explanation types for improved trust, understanding, and performance.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly, the authors frame actionability as the <strong>capacity for domain experts to meaningfully influence and improve AI model behavior through explainability and direct data intervention</strong>. Actionable factors are those that can be manipulated to change model outputs reliably and beneficially.  </p>

<blockquote>
  <p>“...obtaining important actionable and non-actionable factors” (p. 3)  </p>
</blockquote>

<blockquote>
  <p>“...steer prediction models by configuring the training data” (p. 2)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Identifiable through multifaceted explanations (data-centric + model-centric).</p></li>
<li><p>Directly modifiable in the data to affect predictions.</p></li>
<li><p>Relevant to domain goals (e.g., clinically significant features in healthcare).</p></li>
<li><p>Understandable to non-ML experts.</p></li>
<li><p>Feasible for correction or adjustment (manual or automated).  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Explanatory Model Steering System (EXMOS)  </p></li>
<li><p><strong>Methods/Levers:</strong>  </p>

<p> - Multifaceted explanations (data-centric: data quality, distributions, statistics; model-centric: SHAP importances, decision rules).</p>

<p> - Manual configuration: feature selection, filtering, guardrails.</p>

<p> - Automated configuration: issue detection, quantified impact, auto-corrections.</p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Present model explanations via dashboard.</p>

<p> 2. Domain expert inspects and identifies issues.</p>

<p> 3. Apply manual or automated configuration.</p>

<p> 4. Retrain and update explanations.</p></li>
<li><p><strong>Data &amp; Measures:</strong> Model accuracy before/after steering, data quality metrics, predictor variable distributions.</p></li>
<li><p><strong>Implementation Context:</strong> Healthcare (diabetes prediction).  </p></li>
</ul>

<blockquote>
  <p>“...manual configuration provides more control… remove corrupt, biased, or unimportant predictor variables” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“...automated configuration… identify data issues and offer potential corrections” (p. 2)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – explanations designed for understandability.  </p>

<p> &gt; “...enhancing user understandability” (p. 3)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – domain-specific, relevant features and predictors.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – manual and automated tools for implementing changes.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial – system allows immediate retraining, but timeliness not deeply explored.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – core to the system design.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial – aligns with expert goals implicitly via domain-specific features.  </p></li>
<li><p><strong>Other Dimensions:</strong> Control level (manual vs. automated), bias mitigation.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Data-centric AI principles.</p></li>
<li><p>Explainable AI theory (global explanations, SHAP, surrogate models).</p></li>
<li><p>Human-in-the-loop model steering.</p></li>
<li><p>Prior work on multifaceted explanations.</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Change in model accuracy post-configuration.</p></li>
<li><p>Data quality scores.</p></li>
<li><p>Distribution shifts in predictor variables.</p></li>
<li><p>Quantified impact of identified issues.</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lower control in automated configuration; expertise needed for interpreting explanations.  </p></li>
<li><p><strong>Enablers:</strong> Multifaceted explanations; interactive tools; retraining with feedback.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Extends work on XAI and IML by integrating multifaceted explanations with direct data configuration, drawing on Bhattacharya et al. (2024) CHI findings and data-centric AI literature.</p>

<hr />

<h2>Summary</h2>

<p>This paper introduces EXMOS, a system enabling domain experts to act on AI models through clear, relevant, and manipulable explanations. Actionability here is tied to the capacity to identify, understand, and adjust model-relevant data and features—either manually or automatically—to improve performance and alignment with domain needs. The system’s evaluation in healthcare shows the importance of combining explanation modalities and giving users control over model steering. The approach is both conceptually grounded in XAI theory and operationalized via an interactive, technically robust tool, making it a strong candidate for cross-domain application.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 — Strong implicit conceptualization of actionability, tied to concrete features and human-in-the-loop design.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Clear, domain-tested methods for achieving actionability via multifaceted explanations and data configuration.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“...obtaining important actionable and non-actionable factors” (p. 3)  </p></li>
<li><p>“...manual configuration provides more control… remove corrupt, biased, or unimportant predictor variables” (p. 2)  </p></li>
<li><p>“...automated configuration… identify data issues and offer potential corrections” (p. 2)  </p></li>
<li><p>“...enhancing user understandability” (p. 3)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Bhattacharya et al. (2024) – EXMOS: Multifaceted explanations and data configurations (CHI ’24)  </p></li>
<li><p>Daochen Zha et al. (2023) – Data-centric AI survey  </p></li>
<li><p>Teso &amp; Kersting (2019) – Explanatory Interactive Machine Learning  </p></li>
<li><p>Lundberg &amp; Lee (2017) – SHAP values framework</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Explanation User Interfaces: A Systematic Literature Review  </p>

<p>Authors: Eleonora Cappuccio, Andrea Esposito, Francesco Greco, Giuseppe Desolda, Rosa Lanzilotti, Salvatore Rinzivillo  </p>

<p>DOI: https://doi.org/XXXXXXX.XXXXXXX  </p>

<p>Year: 2025  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Human-Computer Interaction, Artificial Intelligence  </p>

<p>Subdomain/Topic: Explainable AI (XAI), Explanation User Interfaces (XUIs), Human-Centered AI (HCAI)  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 92  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes (implicit, as actionable explanations in XUIs)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (HERMES)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Systematic Literature Review  </p>

<p>Study Context: Global, multi-domain XUI design and evaluation research  </p>

<p>Geographic/Institutional Context: Various academic and industry contexts worldwide  </p>

<p>Target Users/Stakeholders: Domain experts, non-experts, AI experts, system designers  </p>

<p>Primary Contribution Type: Comprehensive SLR + Design Framework (HERMES)  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: —  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Explanation User Interfaces: A Systematic Literature Review  </p>

<p><strong>Authors:</strong>  </p>

<p>Eleonora Cappuccio, Andrea Esposito, Francesco Greco, Giuseppe Desolda, Rosa Lanzilotti, Salvatore Rinzivillo  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/XXXXXXX.XXXXXXX  </p>

<p><strong>Year:</strong>  </p>

<p>2025  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Human-Computer Interaction, Artificial Intelligence  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Explainable AI (XAI), Explanation User Interfaces (XUIs), Human-Centered AI (HCAI)  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper synthesizes research on Explanation User Interfaces—UIs that present AI explanations to users—through a systematic review of 146 publications. It integrates algorithmic, design, and evaluation perspectives to close the gap between XAI theory and practical, human-centered deployment.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Global, with case studies and literature spanning multiple sectors.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Domain experts (e.g., clinicians, financial analysts), non-experts, AI experts, XUI designers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Systematic Literature Review (Kitchenham protocol + PRISMA).  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Comprehensive SLR and practical design framework (HERMES).  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This SLR examines 146 studies on Explanation User Interfaces, covering design influences, XAI techniques, evaluation practices, and guiding principles. It categorizes findings by application domain, user type, data type, AI model, and explanation modality. The review identifies dominant methods (e.g., SHAP, feature importance, counterfactuals), visualization preferences (heatmaps, bar charts), and user evaluation metrics (trust, usability, workload). From this synthesis, the authors derive HERMES—a framework enabling practitioners to design, evaluate, and tailor XUIs to domain, task, and user context, with guidelines embedded in an interactive web tool.  </p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>The paper treats <em>actionability</em> as the capacity of explanations to enable users to make informed, context-relevant decisions. Explanations in XUIs should be <strong>meaningful</strong>, <strong>contextualized</strong>, and <strong>integrated into user workflows</strong>, enabling trust, understanding, and effective use.  </p>

<blockquote>
  <p>“Placing explanations together with additional contextual information enhances their relevance and interpretability…” (p. 24)  </p>
</blockquote>

<blockquote>
  <p>“Their primary concern is whether an explanation supports their decision-making process rather than simply revealing model internals.” (p. 22)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Alignment with user goals and expertise level.  </p></li>
<li><p>Clear, jargon-free communication.  </p></li>
<li><p>Contextual information supporting interpretation.  </p></li>
<li><p>Interactivity allowing exploration and “what-if” reasoning.  </p></li>
<li><p>Multi-level visualizations offering both overview and detail.  </p></li>
<li><p>Adaptability/personalization to user background and cognitive style.  </p></li>
<li><p>Trust-building through transparency, reliability indicators, and meaningful feature selection.  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> HERMES (Human-cEnteRed developMent of Explainable user interfaceS)  </p></li>
<li><p><strong>Methods/Levers:</strong> Literature-derived guidelines; filters for AI model, task, domain, user type, XAI model, and explanation modality.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify project constraints → query HERMES → receive guideline cards with references → integrate into design → evaluate using suggested methods and metrics.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> User type, domain, AI/XAI techniques, explanation modality, evaluation metrics (trust, usability, workload, helpfulness).  </p></li>
<li><p><strong>Implementation Context:</strong> Multi-domain; adaptable to expert/non-expert users in high- and low-stakes settings.  </p></li>
</ul>

<blockquote>
  <p>“HERMES… enables designers to either align their XUIs with an existing use context or explore potential design directions…” (p. 23)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — “clear, jargon-free language that adapts to the user’s context” (p. 19).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — “placing explanations together with additional contextual information enhances relevance” (p. 24).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — “adaptable to user’s expertise… without overwhelming the user” (p. 24).  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — timeliness implied via integration into workflows and interactive, on-demand exploration.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — multiple explanation modalities and transparency-building techniques.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — guidelines stress aligning with user mental models and decision-making needs.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Interactivity, personalization, trust calibration, workload management.  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>DARPA XAI framework.  </p></li>
<li><p>Human-Centered Design (ISO 9241-210).  </p></li>
<li><p>Human-Centered AI (Shneiderman).  </p></li>
<li><p>Value Sensitive Design.  </p></li>
<li><p>SAFE-AI (Situation Awareness Framework).  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Trust, usability, workload, satisfaction, perceived effectiveness, helpfulness.  </p></li>
<li><p>Task performance metrics tied to explanation use.  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of co-design practices; limited transparency evaluation; generic rather than context-specific guidelines; underuse of participatory methods.  </p></li>
<li><p><strong>Enablers:</strong> Human-centered, iterative design; multimodal explanation formats; integration with domain workflows; adaptable detail level; trust calibration methods.  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Integrates and extends prior work on interactivity, transparency, and tailoring explanations to user needs. Moves beyond isolated algorithmic or HCI perspectives by linking XAI techniques, UI presentation, and user evaluation in one framework.  </p>

<hr />

<h2>Summary</h2>

<p>This SLR reframes XUI research around actionability, emphasizing that explanations must be not only technically accurate but also embedded in human workflows, personalized, and context-rich. The HERMES framework operationalizes this by providing design guidelines filtered by domain, user type, AI/XAI model, and explanation modality, plus evaluation method recommendations. Actionability here is multi-dimensional—clarity, relevance, feasibility, trust, adaptability—achieved through human-centered design, interactive exploration, and context-aware presentation. The paper’s novelty lies in unifying algorithmic, design, and evaluation insights into a practical tool that supports the deployment of effective, trustworthy XUIs.  </p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Strong implicit definition of actionability with extensive feature mapping and multi-domain validation.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — HERMES provides concrete, adaptable design-to-evaluation workflow grounded in literature.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[XUI is] the sum of outputs of an XAI system that the user can directly interact with…” (p. 5)  </p></li>
<li><p>“Placing explanations together with additional contextual information enhances their relevance and interpretability…” (p. 24)  </p></li>
<li><p>“Their primary concern is whether an explanation supports their decision-making process rather than simply revealing model internals.” (p. 22)  </p></li>
<li><p>“HERMES… enables designers to either align their XUIs with an existing use context or explore potential design directions…” (p. 23)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>[13] Barda et al., 2020 — User-centered displays in healthcare.  </p></li>
<li><p>[72] Jansen et al., 2024 — Contextualizing explanations for low AI-literacy.  </p></li>
<li><p>[83] Kim et al., 2023 — Aligning explanations with human reasoning.  </p></li>
<li><p>[126] Okolo et al., 2024 — Accessible language for community health workers.  </p></li>
<li><p>[174] Wysocki et al., 2023 — Trust and utility in clinical decision-making.  </p></li>
<li><p>[183] Zytek et al., 2022 — Usability challenges in high-stakes AI.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: DECE: Decision Explorer with Counterfactual Explanations for Machine Learning Models  </p>

<p>Authors: Furui Cheng, Yao Ming, Huamin Qu  </p>

<p>DOI: 10.1109/TVCG.2020.3030342  </p>

<p>Year: 2021  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Computer Science / Human-Computer Interaction / Explainable AI  </p>

<p>Subdomain/Topic: Counterfactual Explanations, Visual Analytics, Decision Support  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (explicitly framed through counterfactual explanations)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (DECE system architecture and workflow)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: System Design + Use Cases + Expert Interview  </p>

<p>Study Context: Explainable ML for decision-making tasks across domains (healthcare, finance, education)  </p>

<p>Geographic/Institutional Context: Hong Kong University of Science and Technology; Bloomberg L.P.  </p>

<p>Target Users/Stakeholders: Model developers, decision-makers, decision subjects  </p>

<p>Primary Contribution Type: Interactive Visualization System with integrated counterfactual generation &amp; subgroup analysis  </p>

<p>CL: Yes — “counterfactual explanations… tell the user how to gain the desired prediction with minimal changes to the input” (Abstract)  </p>

<p>CR: Yes — contextual constraints in counterfactual generation ensure relevance to user needs (p. 1440–1441)  </p>

<p>FE: Yes — feasibility addressed through constraints on feature changes and post-hoc validity (p. 1441)  </p>

<p>TI: Partial — timeliness not a focus, though DECE supports interactive, on-demand exploration  </p>

<p>EX: Yes — explainability central to both instance- and subgroup-level counterfactual visualizations (p. 1439)  </p>

<p>GA: Yes — users tailor explanations to specific goals via constraints/preferences (p. 1440)  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong> DECE: Decision Explorer with Counterfactual Explanations for Machine Learning Models  </p>

<p><strong>Authors:</strong> Furui Cheng, Yao Ming, Huamin Qu  </p>

<p><strong>DOI:</strong> 10.1109/TVCG.2020.3030342  </p>

<p><strong>Year:</strong> 2021  </p>

<p><strong>Publication Type:</strong> Journal  </p>

<p><strong>Discipline/Domain:</strong> Computer Science / Human-Computer Interaction / Explainable AI  </p>

<p><strong>Subdomain/Topic:</strong> Counterfactual Explanations, Visual Analytics, Decision Support  </p>

<p><strong>Contextual Background:</strong> Focuses on making ML model decisions interpretable and actionable for a variety of decision-making contexts (loan approval, medical diagnosis, admissions). Uses counterfactuals to bridge human interpretability and actionability.  </p>

<p><strong>Geographic/Institutional Context:</strong> Hong Kong University of Science and Technology; Bloomberg L.P.  </p>

<p><strong>Target Users/Stakeholders:</strong> Model developers, decision-makers, and decision subjects.  </p>

<p><strong>Primary Methodology:</strong> System design and implementation with three use cases and an expert interview.  </p>

<p><strong>Primary Contribution Type:</strong> Interactive visualization platform integrating counterfactual generation with subgroup-level exploratory analysis.</p>

<h2>General Summary of the Paper</h2>

<p>The paper introduces <strong>DECE</strong>, a model-agnostic visualization system that combines counterfactual explanation generation with interactive subgroup analysis to explore and understand ML decisions. Counterfactuals are framed as inherently actionable because they indicate minimal changes needed to achieve a desired outcome. DECE supports instance-level customization (constraints, preference-based adjustments) and subgroup-level comparative analysis to reveal decision boundaries, biases, and general patterns. The system is evaluated through three domain-specific use cases (healthcare, finance, education) and expert interviews with medical trainees, demonstrating its flexibility and capacity to yield actionable insights.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>Actionability is defined through <strong>counterfactual explanations</strong> — minimal, feasible changes to input features that would result in a desired prediction.  </p>

<blockquote>
  <p>“A counterfactual explanation tells the user how to gain the desired prediction with minimal changes to the input” (Abstract)  </p>
</blockquote>

<blockquote>
  <p>“Counterfactual explanations aim to find a minimal change in data that ‘flips’ the model’s prediction… They provide actionable guidance to end-users in a user-friendly way” (p. 1439)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Minimal, targeted changes to features (proximity)</p></li>
<li><p>Feasibility of changes in real-world context (constraints, post-hoc validity)</p></li>
<li><p>Diversity of possible actionable paths (multiple CF examples)</p></li>
<li><p>Sparsity (few features changed for interpretability)</p></li>
<li><p>Customizability to user’s preferences and constraints</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> DECE system, R-counterfactuals method  </p></li>
<li><p><strong>Methods/Levers:</strong> Integration of DiCE framework; multi-objective optimization (validity, proximity, diversity); interactive constraint setting; rule-support counterfactuals for subgroup exploration  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Generate raw CFs → apply constraints/preferences → sparsity refinement → post-hoc validation → visualize in instance or subgroup views → refine hypotheses through R-counterfactuals  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Uses tabular classification datasets; measures validity, proximity (weighted Manhattan), diversity, sparsity  </p></li>
<li><p><strong>Implementation Context:</strong> Instance view for personal actionable guidance; table view for subgroup hypothesis testing and comparative bias analysis  </p></li>
</ul>

<blockquote>
  <p>“We want to offer diverse options (R1)… and allow them to add constraints (R2) to reflect their preferences” (p. 1440)  </p>
</blockquote>

<blockquote>
  <p>“Post-hoc validity… ensures that generated CF examples are feasible solutions in reality” (p. 1441)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — minimal, clear changes make CFs easy to interpret (Abstract)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — constraints ensure applicability to user’s context (p. 1440–1441)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — feasibility addressed via constraints and real-world ranges (p. 1441)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — DECE supports real-time interaction, but timeliness not deeply theorized  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — visualization and explanation central (p. 1439)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — constraints allow tailoring to user’s personal or institutional goals (p. 1440)  </p></li>
<li><p><strong>Other Dimensions:</strong> Diversity, sparsity as explanation-enhancing factors</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Wachter et al.’s unconditional counterfactual explanations  </p></li>
<li><p>DiCE framework for diverse counterfactual generation  </p></li>
<li><p>Exploratory Data Analysis principles (Tukey) for subgroup hypothesis refinement</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Validity (flips prediction)</p></li>
<li><p>Proximity (minimal change)</p></li>
<li><p>Diversity (variety of actionable paths)</p></li>
<li><p>Sparsity (few features change)</p></li>
<li><p>Post-hoc validity (feasible in real-world domain constraints)</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Overwhelming complexity of unconstrained CFs; infeasible feature changes; user knowledge gaps  </p></li>
<li><p><strong>Enablers:</strong> Interactive constraints, subgroup hypothesis refinement, clear visualization of CF-feature relationships</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Builds on counterfactual explanation literature (Wachter et al., Mothilal et al.) but extends to subgroup-level exploratory analysis with integrated visualization. Contrasts with model-specific explainability tools by offering a model-agnostic, tabular-data-focused solution.</p>

<h2>Summary</h2>

<p>Cheng et al. (2021) present <strong>DECE</strong>, an interactive, model-agnostic visual analytics system integrating counterfactual explanations for actionable and explainable ML decision support. Actionability is explicitly tied to counterfactuals that specify minimal, feasible, and interpretable changes leading to desired outcomes. The system operationalizes actionability through a multi-step, user-driven workflow — generating, constraining, validating, and visualizing CF examples — and extends beyond individual instances to subgroup-level hypothesis testing using R-counterfactuals. Three diverse use cases and expert interviews show DECE’s capacity to aid decision-makers, reveal model biases, and provide tailored actionable recommendations.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Direct, explicit definition of actionability; strong conceptual framing; detailed feature set (clarity, relevance, feasibility, etc.)  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Full workflow and algorithmic approach to achieving actionable insights, integrated into a usable system</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“A counterfactual explanation tells the user how to gain the desired prediction with minimal changes to the input” (Abstract)  </p></li>
<li><p>“Counterfactual explanations aim to find a minimal change in data that ‘flips’ the model’s prediction… They provide actionable guidance to end-users” (p. 1439)  </p></li>
<li><p>“We want to offer diverse options… and allow them to add constraints… to reflect their preferences” (p. 1440)  </p></li>
<li><p>“Post-hoc validity… ensures that generated CF examples are feasible solutions in reality” (p. 1441)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Wachter et al. (2017) — Unconditional counterfactuals framework  </p></li>
<li><p>Mothilal et al. (2020) — DiCE framework for diverse CFs  </p></li>
<li><p>Ustun et al. (2019) — Actionable recourse in linear classification</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Data-Driven Simulation in Process Mining: Introducing a Reference Model</p>

<p>Authors: Mahsa Pourbafrani, Wil M.P. van der Aalst</p>

<p>DOI: N/A</p>

<p>Year: 2023</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Process Mining / Business Process Simulation</p>

<p>Subdomain/Topic: Data-driven discrete event simulation; process simulation meta-model; event log–based modeling</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 80 – The paper does not define “actionability” explicitly, but aligns with the implicit notion of actionable models by focusing on producing simulation outputs that support decision-making and benchmarking, and by specifying clear conditions and parameters for executable simulations.</p>

<p>Operationalization Score: 90 – Provides a concrete, detailed reference meta-model, simulation parameter taxonomy, and executable implementation methods directly tied to process mining insights.</p>

<p>Actionable/Actionability Used in Paper: Yes – Implicit. “…providing a digital platform that reflects the real process while the changes in the real process are reflected in the digital twin” (p. 1); “…provide prescribing models” (p. 1); “…enables faster and more confident decision-making” (p. 9).</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes – “…enable the creation of process simulations and the comparison of approaches…” (p. 1); “…the model should be made directly executable” (p. 9).</p>

<p>Contains Definition of Actionability: No – Concept is implied through the design of executable, decision-supporting models.</p>

<p>Contains Systematic Features/Dimensions: Yes – Explicit structured parameter taxonomy and process aspects.</p>

<p>Contains Explainability: Partial – The meta-model structure is transparent, but focus is on completeness and reproducibility rather than interpretability of results.</p>

<p>Contains Interpretability: Partial – Some transparency in parameter-source mapping.</p>

<p>Contains Framework/Model: Yes – Reference meta-model for simulation in process mining.</p>

<p>Operationalization Present: Yes – Detailed workflow, parameter definitions, and implementation in CPN Tools and process trees.</p>

<p>Primary Methodology: Conceptual + Implementation Demonstration</p>

<p>Study Context: Process mining applied to discrete event simulation; includes literature review and model-based implementations.</p>

<p>Geographic/Institutional Context: RWTH Aachen University, Germany</p>

<p>Target Users/Stakeholders: Process analysts, simulation engineers, operations managers</p>

<p>Primary Contribution Type: Reference meta-model and practical implementation for event log–based simulation</p>

<p>CL: Yes – Parameters and model structure are explicitly described (e.g., activity properties, execution configurations).</p>

<p>CR: Yes – Model is derived from process mining event logs, ensuring contextual fidelity.</p>

<p>FE: Yes – Provides concrete parameterization and implementation paths.</p>

<p>TI: Partial – Simulation duration and stopping conditions are specified, but timeliness in decision cycles is not explicitly discussed.</p>

<p>EX: Partial – Explains model structure and components but less on outcome rationale.</p>

<p>GA: Yes – Focused on simulation for process performance improvement and decision support.</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Data-Driven Simulation in Process Mining: Introducing a Reference Model  </p>

<p><strong>Authors:</strong>  </p>

<p>Mahsa Pourbafrani, Wil M.P. van der Aalst  </p>

<p><strong>DOI:</strong>  </p>

<p>N/A  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Process Mining / Business Process Simulation  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Data-driven discrete event simulation; process simulation meta-model; event log–based modeling  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>This work addresses challenges in generating process simulation models from event logs, including the lack of systematic validation, arbitrary inclusion of process aspects, and unclear distinction between parameter extraction and regeneration. It proposes a reference meta-model integrating process mining insights and discrete event simulation requirements, with practical implementation examples.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>RWTH Aachen University, Germany  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process analysts, simulation engineers, operations managers  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual + Implementation Demonstration  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Reference meta-model and practical implementation for event log–based simulation  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper introduces a reference meta-model for generating simulation models in process mining, addressing inconsistencies and arbitrary decisions in current approaches. It reviews existing simulation techniques and tools, identifies essential process aspects from event logs, and distinguishes between the design and execution phases of simulation model creation. The meta-model encompasses process models derived from event logs, execution configurations, activity and resource properties, and regeneration methods for simulation parameters. Implementation is demonstrated through automatic generation of Colored Petri Net (CPN) models and simulation of process trees, using real event logs. The authors position the meta-model as a foundation for designing, verifying, and comparing simulation models, with the ultimate aim of supporting decision-making and digital twin applications.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>Yes – Implicit</strong>  </p>

<ul>
<li><p>“…providing a digital platform that reflects the real process while the changes in the real process are reflected in the digital twin” (p. 1)  </p></li>
<li><p>“…provide prescribing models” (p. 1)  </p></li>
<li><p>“…enables faster and more confident decision-making” (p. 9)  </p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>Yes</strong>  </p>

<ul>
<li><p>“…enable the creation of process simulations and the comparison of approaches…” (p. 1)  </p></li>
<li><p>“…the model should be made directly executable” (p. 9)  </p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly understood as the ability to produce executable simulation models that accurately reflect real processes and can inform operational decisions and comparisons between approaches.  </p>

<blockquote>
  <p>“…process mining support can be extended to provide organizations with their digital twins, which enables faster and more confident decision-making.” (p. 9)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Reflects Real Process Accurately:</strong>  </p>

<p> &gt; “…how close the simulation model is to the real process” (p. 1)  </p></li>
<li><p><strong>Uses Historical Data Effectively:</strong>  </p>

<p> &gt; “…determine how much of the available historical information… is used” (p. 1)  </p></li>
<li><p><strong>Executable for Scenario Testing:</strong>  </p>

<p> &gt; “…should be made directly executable… by using the generated XML format” (p. 9)  </p></li>
<li><p><strong>Comprehensive Parameterization:</strong>  </p>

<p> &gt; “…includes all the possible extractable insights from processes as simulation parameters and all the possible directions to regenerate those insights” (p. 9)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Reference Meta-model for Simulation in Process Mining  </p></li>
<li><p><strong>Methods/Levers:</strong> Event log analysis, process mining techniques (discovery, conformance checking), structured parameter taxonomy  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Extract process aspects from event logs (design phase).  </p>

<p> 2. Specify execution configurations (start/end conditions, case generation).  </p>

<p> 3. Define activity and resource properties.  </p>

<p> 4. Choose regeneration method (fixed, random, rule-based, predictive).  </p>

<p> 5. Generate executable model (e.g., CPN Tools, process trees).  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Case attributes, activity flows, durations, resource schedules, queuing strategies, decision logic.  </p></li>
<li><p><strong>Implementation Context:</strong> Demonstrated with BPI Challenge 2012 event log; implemented via Python-based automatic model generators to CPN Tools and process trees.  </p></li>
</ul>

<blockquote>
  <p>“…translate them to the CPN Tools model in the XML format, i.e., readable for the CPN Tools engine.” (p. 8)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – “The designed reference meta-model is shown in Figure 7… two main blocks are considered” (p. 6)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – Derived from event logs of the actual process (p. 1–2).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – Concrete steps for model execution (p. 6–8).  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial – Simulation duration and stop conditions specified, but not linked to decision time windows (p. 6).  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial – Structure and parameters explained, less focus on output interpretability (p. 6–7).  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – Designed for process performance improvement and decision-making (p. 9).  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Process mining perspectives (van der Aalst 2016)  </p></li>
<li><p>Discrete Event Simulation principles (Fishman 2001)  </p></li>
<li><p>Prior process simulation meta-models (Tumay 1996; García et al. 2014; Martin et al. 2014)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A – No explicit KPIs for “actionability,” but includes process simulation performance metrics (e.g., accuracy of reproduced behavior, completeness of parameter extraction).  </p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of systematic validation; incomplete or inconsistent process aspect consideration; technical limitations in automatic discovery (e.g., queue types).  </p></li>
<li><p><strong>Enablers:</strong> Structured reference meta-model; integration of process mining insights; executable implementations.  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The work extends existing meta-models by explicitly incorporating both design and execution phases, covering a wider set of process aspects (including queuing, resource pooling, interruption handling) and providing regeneration options. It builds on Rozinat et al. (2009) but formalizes a broader taxonomy and implementation pathway.  </p>

<hr />

<h2>Summary</h2>

<p>This paper proposes a reference meta-model for data-driven simulation in process mining, aiming to standardize the extraction, parameterization, and regeneration of process simulation models from event logs. By structuring both the design and execution phases, it addresses gaps in existing approaches where parameter regeneration and validation are often neglected. The model organizes process aspects into categories (process, activity, resource) and defines execution configurations and regeneration functions (fixed, random, rule-based, predictive). Practical implementations demonstrate automatic translation of event log insights into executable simulations in CPN Tools and process trees, using real-life datasets like BPI Challenge 2012. The authors position the meta-model as a foundation for designing, verifying, and benchmarking simulation models, enabling their use in digital twins and decision-support contexts. While “actionability” is not explicitly defined, the model operationalizes it through completeness, contextual fidelity, and executability of simulation models.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 80 – Strong alignment with implicit actionability via decision-supporting, executable simulations; lacks explicit definition.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 – Detailed, reproducible implementation steps and parameterization directly tied to process mining insights.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Process mining support can be extended to provide organizations with their digital twins, which enables faster and more confident decision-making.” (p. 9)  </p></li>
<li><p>“…determine how much of the available historical information… is used and how close the simulation model is to the real process.” (p. 1)  </p></li>
<li><p>“…includes all the possible extractable insights from processes as simulation parameters and all the possible directions to regenerate those insights.” (p. 9)  </p></li>
<li><p>“…translate them to the CPN Tools model in the XML format, i.e., readable for the CPN Tools engine.” (p. 8)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Rozinat et al. (2009) – Discovering simulation models.  </p></li>
<li><p>Martin et al. (2014, 2016) – Event log knowledge and structuring simulation model construction.  </p></li>
<li><p>Camargo et al. (2019, 2020, 2022) – Automated discovery of simulation models from event logs, including deep learning approaches.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: What Constitutes an “Actionable Insight” in Learning Analytics?</p>

<p>Authors: Rasmus Leth Jørnø; Karsten Gynther</p>

<p>DOI: 10.18608/jla.2018.53.13</p>

<p>Year: 2018</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Learning Analytics / Education</p>

<p>Subdomain/Topic: Conceptualization and definition of “actionable insight”</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 90</p>

<p>Operationalization Score: 45</p>

<p>Actionable/Actionability Used in Paper: Yes — e.g., “We contend that ‘actionable insights’ should be interpreted as data that allows a corrective procedure, or feedback loop, to be established for a set of actions.” (p. 198) :contentReference[oaicite:0]{index=0}</p>

<p>Authors Argue for Need for Actionability Without Defining It: No — they both problematize the lack of definitions and advance their own interpretation (pp. 198–199). :contentReference[oaicite:1]{index=1}</p>

<p>Contains Definition of Actionability: Yes — “So ‘actionable’ here means ‘belonging to the same set of actions that produce the data,’ while ‘insight’ means ‘data that allows a (self-)corrective procedure.’” (pp. 209–210) :contentReference[oaicite:2]{index=2}</p>

<p>Contains Systematic Features/Dimensions: Yes — perspective/agency, feedback loop, alignment of subject–object–client, instructional sensitivity, transparency (pp. 201–210). :contentReference[oaicite:3]{index=3}</p>

<p>Contains Explainability: Partial — emphasizes “transparency in risk calculations” as essential for acting on predictions (p. 202). :contentReference[oaicite:4]{index=4}</p>

<p>Contains Interpretability: Partial — stresses mapping workflows and couplings so data becomes interpretable for action (pp. 198, 209–210). :contentReference[oaicite:5]{index=5}</p>

<p>Contains Framework/Model: Yes — discusses/uses existing models (Clow’s cycle, Rienties’ A4AEF; Cooper’s subject–object–client distinctions) and proposes an agency–impact schematic (Fig. 1) (pp. 204–209). :contentReference[oaicite:6]{index=6}</p>

<p>Operationalization Present: Partial — recommends mapping action capabilities and feedback loops; not a concrete step-by-step method (pp. 209–210). :contentReference[oaicite:7]{index=7}</p>

<p>Primary Methodology: Review (selective literature review)</p>

<p>Study Context: Selective review focused on campus-based learning; category B papers on learning design/support structures; 26 documents read (pp. 203–205). :contentReference[oaicite:8]{index=8}</p>

<p>Geographic/Institutional Context: Authors at University College Absalon (Denmark); field-wide review (p. 198). :contentReference[oaicite:9]{index=9}</p>

<p>Target Users/Stakeholders: Educators, designers, advisors, students, administrators, researchers — different agencies/impacts (Fig. 1, p. 206). :contentReference[oaicite:10]{index=10}</p>

<p>Primary Contribution Type: Conceptual clarification and critique; proposed reframing of actionability around feedback loops and action capabilities (pp. 198, 209–210). :contentReference[oaicite:11]{index=11}</p>

<p>CL: Partial</p>

<p>CR: Yes</p>

<p>FE: Partial</p>

<p>TI: Partial</p>

<p>EX: Partial</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>What Constitutes an “Actionable Insight” in Learning Analytics?</p>

<p><strong>Authors:</strong>  </p>

<p>Rasmus Leth Jørnø; Karsten Gynther</p>

<p><strong>DOI:</strong>  </p>

<p>10.18608/jla.2018.53.13</p>

<p><strong>Year:</strong>  </p>

<p>2018</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Learning Analytics / Education</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Conceptualization and definition of “actionable insight”</p>

<p><strong>Contextual Background:</strong>  </p>

<p>Learning analytics (LA) literature frequently invokes “actionable insights” but rarely defines them. This selective review examines how the term is used, critiques the dominant rational-actor, data-informed decision-making perspective, and advances a feedback-loop interpretation of actionability. (pp. 198–205) :contentReference[oaicite:12]{index=12}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Field-wide; authors affiliated with University College Absalon, Denmark. (p. 198) :contentReference[oaicite:13]{index=13}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Students, mentors/advisors, teachers/administrators, researchers/designers — each with distinct agency and impact (Fig. 1). (pp. 206–207) :contentReference[oaicite:14]{index=14}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Review (selective literature review per Kitchenham &amp; Charters guidelines). (pp. 203–205) :contentReference[oaicite:15]{index=15}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual clarification/definition and critical synthesis.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper surveys how “actionable insight(s)” is used within learning analytics, noting that most sources rely on implicit meanings. It identifies a prevailing “data‑informed decision‑making” perspective that assumes a rational actor who mines insights and then acts, often toward institutional goals like retention. The authors contrast this with examples and frameworks across actors (students, mentors, teachers, designers), highlighting how agency and context shape what counts as actionable. They argue for reframing actionability around feedback loops tied to concrete action capabilities and goals, proposing that insights become actionable when they enable corrective procedures within the same set of actions that produced the data. (pp. 198–210) :contentReference[oaicite:16]{index=16}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>Yes. Direct quotes:</strong></p>

<ul>
<li><p>“We contend that ‘actionable insights’ should be interpreted as data that allows a corrective procedure, or feedback loop, to be established for a set of actions.” (p. 198) :contentReference[oaicite:17]{index=17}  </p></li>
<li><p>“So ‘actionable’ here means ‘belonging to the same set of actions that produce the data,’ while ‘insight’ means ‘data that allows a (self-)corrective procedure.’” (pp. 209–210) :contentReference[oaicite:18]{index=18}  </p></li>
<li><p>“The review points to a dominant perspective… of a rational actor, where actionable insights are treated as insights mined from data and subsequently acted upon.” (p. 198) :contentReference[oaicite:19]{index=19}</p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>No.</strong> They explicitly diagnose the definitional gap and propose a definition/interpretation.  </p>

<ul>
<li>“At the time of this review, we only found a single source… that discusses the definition of ‘actionable insights.’” (p. 198) :contentReference[oaicite:20]{index=20}</li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability = insight tied to a <strong>feedback loop</strong> within the <strong>same set of actions</strong> that generated the data, enabling corrective procedures by an actor with relevant action capabilities.  </p>

<blockquote>
  <p>“So ‘actionable’ here means ‘belonging to the same set of actions that produce the data,’ while ‘insight’ means ‘data that allows a (self-)corrective procedure.’” (pp. 209–210) :contentReference[oaicite:21]{index=21}</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Belongs to the same action set that produced the data</strong>  </p>

<p> &gt; “From such a perspective, the term ‘actionable insight’ has been approached from the wrong end… it is from specific action capabilities that insights are engendered.” (p. 209) :contentReference[oaicite:22]{index=22}</p></li>
<li><p><strong>Enables a corrective feedback loop</strong>  </p>

<p> &gt; “‘Actionable insights’ simply means creating a feedback loop… data that allows a (self-)corrective procedure.” (pp. 209–210) :contentReference[oaicite:23]{index=23}</p></li>
<li><p><strong>Mapped workflow, goals, and couplings identified</strong>  </p>

<p> &gt; “…map out the workflow of actions, the end goals of the actors involved, and the relevant couplings between them.” (p. 198) :contentReference[oaicite:24]{index=24}</p></li>
<li><p><strong>Alignment of subject–object–client</strong>  </p>

<p> &gt; “In order to set up a feedback loop, the subject, object, and client must always refer to the same set of actions.” (p. 209) :contentReference[oaicite:25]{index=25}</p></li>
<li><p><strong>Transparency sufficient to guide action</strong>  </p>

<p> &gt; “This transparency in risk calculations is essential in order for instructors and students to understand how best to act upon the predictions.” (p. 202) :contentReference[oaicite:26]{index=26}</p></li>
<li><p><strong>Instructional sensitivity (effects of interventions are traceable)</strong>  </p>

<p> &gt; “Having assessment tools with high instructional sensitivity will… allow a teacher to accurately gauge and adjust her intervention.” (p. 210) :contentReference[oaicite:27]{index=27}</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong>  </p>

<p> Clow’s Learning Analytics Cycle; Rienties et al.’s Analytics4Action Evaluation Framework (A4AEF); Cooper’s subject–object–client distinctions; authors’ agency–impact schematic (Fig. 1). (pp. 204–209) :contentReference[oaicite:28]{index=28}</p></li>
<li><p><strong>Methods/Levers:</strong>  </p>

<p> Identify actor’s action capabilities; align data with those actions; ensure transparency; measure instructional sensitivity; close the loop through interventions appropriate to the actor’s agency. (pp. 206–210) :contentReference[oaicite:29]{index=29}</p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1) Map actors, goals, and current workflows; 2) Determine which actions generate data; 3) Align subject–object–client to the same action set; 4) Design feedback that is traceably linked to interventions; 5) Evaluate impact and adjust. (pp. 209–210) :contentReference[oaicite:30]{index=30}</p></li>
<li><p><strong>Data &amp; Measures:</strong>  </p>

<p> Validity/reliability, statistical significance/confidence (as necessary qualifiers for action); instructional sensitivity to detect intervention effects. (pp. 200, 210) :contentReference[oaicite:31]{index=31}</p></li>
<li><p><strong>Implementation Context:</strong>  </p>

<p> Varies by actor (students, mentors, teachers, designers, administrators), each with different agency/impact (Fig. 1). (pp. 206–207) :contentReference[oaicite:32]{index=32}  </p></li>
</ul>

<blockquote>
  <p>“Asking what insights a data set can yield requires that we ask what actions produced the data and… who performed the actions and to what end.” (p. 209) :contentReference[oaicite:33]{index=33}</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Partial — the paper stresses lack of definitional clarity in the field and calls for explicit mapping/definitions. &gt; “At the time of this review, we only found a single source… that discusses the definition of ‘actionable insights.’” (p. 198) :contentReference[oaicite:34]{index=34}  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — actionability depends on <em>whose</em> actions and goals are at stake. &gt; “It matters who has acted to produce the data… what the producer’s… goals are.” (p. 209) :contentReference[oaicite:35]{index=35}  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — emphasis on actor <strong>action capabilities</strong> as precondition for action. &gt; “Insights are ‘actionable’ because it is possible to act upon them as feedback information…” (p. 210) :contentReference[oaicite:36]{index=36}  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — distinguishes real‑time vs ongoing vs redesign impacts in Fig. 1; timeliness affects action impact. (p. 206) :contentReference[oaicite:37]{index=37}  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — insists on transparency to enable action. &gt; “This transparency in risk calculations is essential…” (p. 202) :contentReference[oaicite:38]{index=38}  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — warns against conflating retention with learning; urges explicit end goals. &gt; “The question of what constitutes an actionable insight thus forms part of the more general question of what goals we are pursuing.” (p. 205) :contentReference[oaicite:39]{index=39}  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Agency/impact across actors (Fig. 1); alignment of subject–object–client; instructional sensitivity (pp. 206–210). :contentReference[oaicite:40]{index=40}</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li>Cybernetics/feedback loops; reflective practitioner; rational decision‑making critique; Cooper’s analytics characteristics incl. subject–object–client; learning analytics cycles/frameworks (Clow; A4AEF). (pp. 200–210) :contentReference[oaicite:41]{index=41}</li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Presence of a <strong>feedback loop</strong> linking data to the same action set. (pp. 209–210) :contentReference[oaicite:42]{index=42}  </p></li>
<li><p><strong>Validity/reliability qualifiers</strong> (e.g., statistical significance/confidence) to judge whether action is warranted. (p. 200) :contentReference[oaicite:43]{index=43}  </p></li>
<li><p><strong>Instructional sensitivity</strong> to detect intervention effects in the data. (p. 210) :contentReference[oaicite:44]{index=44}</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Dominant “data‑informed decision‑making” mindset focused on retention (pp. 204–205). :contentReference[oaicite:45]{index=45}  </p>

<p> - Assuming a single rational actor and conflating learning with institutional performance (pp. 201–205). :contentReference[oaicite:46]{index=46}  </p>

<p> - Ad hoc interpretations when educators must infer actions from opaque data (p. 211). :contentReference[oaicite:47]{index=47}</p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Mapping <strong>workflows, goals, couplings</strong> between actors (p. 198). :contentReference[oaicite:48]{index=48}  </p>

<p> - Aligning <strong>subject–object–client</strong> to the same action set (p. 209). :contentReference[oaicite:49]{index=49}  </p>

<p> - Ensuring <strong>transparency</strong> and <strong>instructional sensitivity</strong> so interventions are traceable (pp. 202, 210). :contentReference[oaicite:50]{index=50}</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper notes that only one prior source explicitly defines “actionable insights” and that most LA works implicitly assume a rational, data‑mining‑then‑action pipeline, often in service of retention. It situates its contribution alongside established LA frameworks (Clow’s cycle; A4AEF) and Cooper’s analytics distinctions, arguing these should be interpreted through the lens of feedback loops and actor‑specific action capabilities rather than generic decision support. (pp. 198–209) :contentReference[oaicite:51]{index=51}</p>

<hr />

<h2>Summary</h2>

<p>This article provides one of the clearest conceptual treatments of “actionable insight” in learning analytics. Reviewing LA literature, the authors show that most accounts assume a rational actor who mines data for insights and then acts, frequently toward institutional ends like retention. They argue that this perspective masks heterogeneity in actors’ goals and agencies and leaves educators with opaque data and ad hoc responses. Reframing actionability, they define it as information that enables a <strong>corrective feedback loop</strong> within the <strong>same set of actions</strong> that generated the data, contingent on the actor’s <strong>action capabilities</strong> and explicit <strong>goals</strong>. The paper operationalizes this reframing by urging alignment of <strong>subject–object–client</strong>, ensuring <strong>transparency</strong> and <strong>instructional sensitivity</strong>, and using existing cycles/frameworks to close the loop. While rich conceptually, guidance remains high‑level; concrete step‑by‑step procedures are limited. Still, the piece advances the field by offering a precise, workflow‑anchored account of what it means for insights to be truly actionable. (pp. 198–211) :contentReference[oaicite:52]{index=52}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 — Provides an explicit definition and a coherent conceptual reframing (feedback loops, actor capabilities), directly centered on “actionable insight(s).”</p></li>
<li><p><strong>Operationalization Score:</strong> 45 — Offers actionable principles (map workflows, align subject–object–client, ensure transparency/instructional sensitivity) and references existing frameworks, but lacks detailed procedures or evaluated toolchains.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[W]e contend that ‘actionable insights’ should be interpreted as data that allows a corrective procedure, or feedback loop, to be established for a set of actions.” (p. 198) :contentReference[oaicite:53]{index=53}  </p></li>
<li><p>“So ‘actionable’ here means ‘belonging to the same set of actions that produce the data,’ while ‘insight’ means ‘data that allows a (self-)corrective procedure.’” (pp. 209–210) :contentReference[oaicite:54]{index=54}  </p></li>
<li><p>“Asking what insights a data set can yield requires that we ask what actions produced the data and… who performed the actions and to what end.” (p. 209) :contentReference[oaicite:55]{index=55}  </p></li>
<li><p>“This transparency in risk calculations is essential in order for instructors and students to understand how best to act upon the predictions.” (p. 202) :contentReference[oaicite:56]{index=56}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Cooper (2012b) — Definition and characteristics of analytics and “actionable insights”; introduces subject–object–client distinctions referenced by the authors. (pp. 200, 208–209) :contentReference[oaicite:57]{index=57}  </p></li>
<li><p>Clow (2012) — Learning analytics cycle emphasizing closing the feedback loop. (pp. 205–206) :contentReference[oaicite:58]{index=58}  </p></li>
<li><p>Rienties et al. (2016) — A4AEF six‑phase model for translating insights into interventions. (p. 205) :contentReference[oaicite:59]{index=59}  </p></li>
<li><p>Pardo et al. (2016) — Emphasis on transparency for actionability of predictive models. (p. 202) :contentReference[oaicite:60]{index=60}</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: What Clinicians Want: Contextualizing Explainable Machine Learning for Clinical End Use</p>

<p>Authors: Sana Tonekaboni; Shalmali Joshi; Melissa D. McCradden; Anna Goldenberg</p>

<p>DOI: 10.48550/arXiv.1905.05134</p>

<p>Year: 2019</p>

<p>Publication Type: Preprint (arXiv)</p>

<p>Discipline/Domain: Healthcare AI / Clinical Machine Learning</p>

<p>Subdomain/Topic: Explainable AI (XAI), clinician trust, evaluation metrics for explanations</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 78</p>

<p>Operationalization Score: 62</p>

<p>Actionable/Actionability Used in Paper: Yes — e.g., “Provide parsimonious and actionable steps clinicians can undertake.” (p. 6); section “Potential Actionability.” (pp. 9–10)</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — they emphasize explanations that inform follow‑up clinical workflow and are “parsimonious and timely,” while not formalizing a standalone definition of actionability (pp. 9–10)</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes (conceptual classes of explanations + evaluation metrics)</p>

<p>Operationalization Present: Yes (qualitative-to-technical mapping; classes of explanations; evaluation metrics)</p>

<p>Primary Methodology: Qualitative</p>

<p>Study Context: Semi-structured interviews with 10 clinicians in acute care (ICU and ED) using hypothetical ML tools</p>

<p>Geographic/Institutional Context: University of Toronto; Vector Institute; The Hospital for Sick Children (Toronto, Canada)</p>

<p>Target Users/Stakeholders: ICU and ED clinicians (junior and senior)</p>

<p>Primary Contribution Type: Conceptual framework informed by qualitative stakeholder study</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Yes</p>

<p>EX: Yes</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>What Clinicians Want: Contextualizing Explainable Machine Learning for Clinical End Use</p>

<p><strong>Authors:</strong>  </p>

<p>Sana Tonekaboni; Shalmali Joshi; Melissa D. McCradden; Anna Goldenberg</p>

<p><strong>DOI:</strong>  </p>

<p>10.48550/arXiv.1905.05134</p>

<p><strong>Year:</strong>  </p>

<p>2019</p>

<p><strong>Publication Type:</strong>  </p>

<p>Preprint (arXiv)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Healthcare AI / Clinical Machine Learning</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Explainable AI (XAI), clinician trust, evaluation metrics for explanations</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper explores how to align explainable ML with clinicians’ needs to support adoption in high‑stakes, time‑critical settings. It elicits clinician perceptions via interviews and derives explanation classes and evaluation metrics oriented to clinical workflows. :contentReference[oaicite:0]{index=0}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Toronto, Canada (University of Toronto; Vector Institute; The Hospital for Sick Children). :contentReference[oaicite:1]{index=1}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Intensive Care Unit (ICU) and Emergency Department (ED) clinicians (n=10; 6 ICU, 4 ED; junior and senior). :contentReference[oaicite:2]{index=2}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Qualitative (interviews; upstream stakeholder engagement), with conceptual synthesis. :contentReference[oaicite:3]{index=3}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework: classes of explanations and evaluation metrics tailored to clinical end‑use. :contentReference[oaicite:4]{index=4}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors interview 10 acute‑care clinicians (ICU and ED) to understand when and how explainability fosters trust in clinical ML tools. From qualitative analysis, they derive explanation classes (feature importance, instance‑level examples, uncertainty, temporal explanations, transparent design) and propose evaluation metrics (domain‑appropriate representation, potential actionability, consistency). They situate these asks against existing XAI methods, highlighting gaps for clinical usability (e.g., calibration, temporal reasoning, patient‑level attributions). The paper contributes a clinician‑informed agenda for explainable ML in healthcare. :contentReference[oaicite:5]{index=5}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>Yes.</strong>  </p>

<ul>
<li><p>“<strong>Provide parsimonious and actionable steps clinicians can undertake.</strong> (e.g., potential interventions or data collection).” (p. 6) :contentReference[oaicite:6]{index=6}  </p></li>
<li><p>Section title and content: “<strong>Potential Actionability</strong> … explanations … should inform follow‑up clinical workflow… The explanation should be <strong>parsimonious and timely</strong>.” (pp. 9–10) :contentReference[oaicite:7]{index=7}</p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>Yes.</strong>  </p>

<ul>
<li>“Given a model that satisfies minimal trust… any complementary <strong>explanation should inform follow‑up clinical workflow</strong>… explanations that are informative… but <strong>have no impact on the workflow are of less importance</strong>. Similarly, the explanation should be <strong>parsimonious and timely</strong>.” (pp. 9–10) :contentReference[oaicite:8]{index=8}</li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly, an explanation is actionable if it <em>guides concrete next steps</em> (interventions, tests, data collection), <em>fits the clinical context</em>, and is <em>timely and concise</em> so clinicians can use it under time pressure.  </p>

<blockquote>
  <p>“Provide <strong>parsimonious and actionable steps</strong> clinicians can undertake.” (p. 6) :contentReference[oaicite:9]{index=9}  </p>
</blockquote>

<blockquote>
  <p>“Explanations… should <strong>inform follow‑up clinical workflow</strong>… <strong>parsimonious and timely</strong>.” (pp. 9–10) :contentReference[oaicite:10]{index=10}</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Workflow‑directing:</strong> Must inform what to do next.  </p>

<p> &gt; “Explanations… should <strong>inform follow‑up clinical workflow</strong>…” (pp. 9–10) :contentReference[oaicite:11]{index=11}</p></li>
<li><p><strong>Parsimony &amp; Timeliness:</strong> Concise and fast to interpret.  </p>

<p> &gt; “The explanation should be <strong>parsimonious and timely</strong>.” (pp. 9–10) :contentReference[oaicite:12]{index=12}</p></li>
<li><p><strong>Context Fit (Domain‑appropriate):</strong> Relevant to the care setting and current task.  </p>

<p> &gt; “The quality of the explanation should be evaluated… <strong>coherent with respect to the application task</strong>… careful filtering of the information most useful at any instant.” (p. 9) :contentReference[oaicite:13]{index=13}</p></li>
<li><p><strong>Consistency/Robustness:</strong> Explanations should vary sensibly with predictions and be stable to design variations.  </p>

<p> &gt; “The set of explanations should be <strong>injective</strong>… and <strong>invariant to underlying design variations</strong>… Lack of consistency… <strong>violates reliable actionability</strong>.” (p. 10) :contentReference[oaicite:14]{index=14}</p></li>
<li><p><strong>Feasibility of Action:</strong> Should suggest plausible interventions or data to collect.  </p>

<p> &gt; “Provide… <strong>actionable steps</strong>… (e.g., <strong>potential interventions or data collection</strong>).” (p. 6) :contentReference[oaicite:15]{index=15}</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Classes of explanations + evaluation metrics tailored to clinical end‑use. :contentReference[oaicite:16]{index=16}  </p></li>
<li><p><strong>Methods/Levers:</strong> Feature importance (patient‑level + population‑level), instance‑level examples (with cautions on similarity), <strong>uncertainty</strong> (calibration, individual‑level error), <strong>temporal explanations</strong> (patient trajectories), <strong>transparent design</strong> (rules/trees/distillation). (pp. 6–9) :contentReference[oaicite:17]{index=17}  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1) Present prediction with <strong>certainty score</strong>; 2) surface <strong>clinically relevant features</strong> (patient‑specific when possible); 3) show <strong>temporal change</strong> in patient state when applicable; 4) ensure <strong>domain‑appropriate representation</strong>; 5) design for <strong>consistency</strong>; 6) link to <strong>specific next steps</strong> (tests/interventions/data collection). (pp. 6–10) :contentReference[oaicite:18]{index=18}  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Temporal vitals/EHR signals; metrics such as calibration and user‑study‑based evaluation of representation and consistency. (pp. 6–9) :contentReference[oaicite:19]{index=19}  </p></li>
<li><p><strong>Implementation Context:</strong> Acute care (ICU/ED) with time constraints and alarm fatigue; explanations must not add cognitive overload. (pp. 7, 10) :contentReference[oaicite:20]{index=20}  </p></li>
</ul>

<blockquote>
  <p>“Presenting <strong>certainty score</strong> on model performance or predictions is perceived… as a sort of explanation…” (p. 7) :contentReference[oaicite:21]{index=21}</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> <strong>Yes.</strong> Identification of “the variables that have derived the decision of the model” to rationalize actions. (p. 5) :contentReference[oaicite:22]{index=22}  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> <strong>Yes.</strong> “Domain Appropriate Representation… coherent with respect to the application task.” (p. 9) :contentReference[oaicite:23]{index=23}  </p></li>
<li><p><strong>FE (Feasibility):</strong> <strong>Yes.</strong> “Provide… <strong>actionable steps</strong>… (e.g., potential interventions or data collection).” (p. 6) :contentReference[oaicite:24]{index=24}  </p></li>
<li><p><strong>TI (Timeliness):</strong> <strong>Yes.</strong> “The explanation should be <strong>parsimonious and timely</strong>.” (pp. 9–10) :contentReference[oaicite:25]{index=25}  </p></li>
<li><p><strong>EX (Explainability):</strong> <strong>Yes.</strong> Define explainability as “a set of <strong>measurable, quantifiable, and transferable attributes</strong>…” (p. 3) :contentReference[oaicite:26]{index=26}  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> <strong>Yes.</strong> Emphasis on aligning with clinical evidence and expectations; “<strong>alignment with expectations and clinical presentation</strong>.” (p. 5) :contentReference[oaicite:27]{index=27}  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> <strong>Consistency</strong> (“injective… invariant…”), <strong>Calibration/Uncertainty</strong> (confidence scores), <strong>Parsimony</strong> (avoid cognitive overload). (pp. 7, 10) :contentReference[oaicite:28]{index=28}</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Evidence‑based medical decision‑making as an analogue for transparent model reasoning. (p. 9) :contentReference[oaicite:29]{index=29}  </p></li>
<li><p>Formal evaluation desiderata for XAI (domain‑appropriate representation, actionability, consistency). (pp. 9–10) :contentReference[oaicite:30]{index=30}</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p><strong>Domain‑appropriate representation</strong> (fit to task/workflow). (p. 9)  </p></li>
<li><p><strong>Potential actionability</strong> (impact on follow‑up workflow; parsimony; timeliness). (pp. 9–10)  </p></li>
<li><p><strong>Consistency/robustness</strong> of explanations. (p. 10) :contentReference[oaicite:31]{index=31}</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Alarm/click fatigue; cognitive overload; poor calibration/individual‑level errors; mis‑specification; inconsistent attention‑based explanations; inadequate similarity definitions. (pp. 7–8, 9–10) :contentReference[oaicite:32]{index=32}  </p></li>
<li><p><strong>Enablers:</strong> Calibration and uncertainty reporting; patient‑level feature attributions; temporal trajectory views; transparent/rule‑based designs when appropriate; alignment with clinical protocols and expectations. (pp. 6–9) :contentReference[oaicite:33]{index=33}</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper maps clinician‑requested explanation classes to prominent XAI techniques (e.g., LIME/Anchors/SHAP, influence functions, attention‑based temporal models, rule lists) and flags clinical shortcomings (consistency, calibration, temporal reasoning, trade‑offs). It advocates rigorous, stakeholder‑grounded evaluation rather than algorithm‑centric diagnostics. (pp. 10–12) :contentReference[oaicite:34]{index=34}</p>

<hr />

<h2>Summary</h2>

<p>This clinician‑informed study reframes explainability for clinical end‑use by emphasizing <em>actionability</em> in context. Through interviews with ICU/ED clinicians, the authors identify what explanations must do: recalibrate trust, validate with domain knowledge, disseminate predictions with task‑appropriate representations, and <strong>suggest concrete next steps</strong>. They operationalize these needs via five explanation classes (feature importance, instance examples, uncertainty, temporal explanations, transparent design) and three evaluation metrics—<strong>domain‑appropriate representation</strong>, <strong>potential actionability</strong> (parsimonious, timely, workflow‑relevant), and <strong>consistency</strong>. The analysis shows that common XAI tools require tailoring (e.g., patient‑level attributions, calibrated uncertainty, robust temporal reasoning) to be clinically useful. The contribution is a practical, criteria‑based framework that connects clinician expectations to technical XAI properties, aiming to improve adoption and sustained use of ML in acute care. :contentReference[oaicite:35]{index=35}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> <strong>78/100.</strong> Strong, explicit linkage of explanations to actionability (workflow impact, parsimony, timeliness, consistency). Lacks a formal, standalone <em>definition</em> of “actionability,” but provides clear criteria. :contentReference[oaicite:36]{index=36}  </p></li>
<li><p><strong>Operationalization Score:</strong> <strong>62/100.</strong> Offers actionable classes and evaluation metrics and sketches workflows (e.g., certainty scores, patient‑level features, temporal views). However, it remains conceptual—no implemented toolkit or quantitative user study validating actionability metrics. :contentReference[oaicite:37]{index=37}</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“For the purpose of this manuscript, we define <strong>‘Explainability in ML for Healthcare’</strong> as a set of <strong>measurable, quantifiable, and transferable attributes</strong> associated with an ML system targeted for clinicians.” (p. 3) :contentReference[oaicite:38]{index=38}  </p></li>
<li><p>“Clinical thought process… consists of… <strong>understanding</strong> and <strong>rationalizing</strong> the predictions.” (p. 5) :contentReference[oaicite:39]{index=39}  </p></li>
<li><p>“Knowing <strong>‘the variables that have derived the decision of the model’</strong> was brought up…” (p. 5) :contentReference[oaicite:40]{index=40}  </p></li>
<li><p>“<strong>Provide parsimonious and actionable steps</strong> clinicians can undertake.” (p. 6) :contentReference[oaicite:41]{index=41}  </p></li>
<li><p>“Presenting <strong>certainty score</strong> on model performance or predictions is perceived… as a sort of explanation…” (p. 7) :contentReference[oaicite:42]{index=42}  </p></li>
<li><p>“The explanation should be <strong>parsimonious and timely</strong>.” (pp. 9–10) :contentReference[oaicite:43]{index=43}  </p></li>
<li><p>“The set of explanations should be <strong>injective</strong>… and <strong>invariant</strong> to underlying design variations… Lack of consistency… <strong>violates reliable actionability</strong>.” (p. 10) :contentReference[oaicite:44]{index=44}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Doshi‑Velez &amp; Kim (2017) — evaluation of interpretability methods/user studies.  </p></li>
<li><p>Guo et al. (2017) — calibration of modern neural networks (supports uncertainty as actionable complement).  </p></li>
<li><p>Lakkaraju et al. (2016); Wang &amp; Rudin (2015) — rule‑based transparent designs.  </p></li>
<li><p>Choi et al. (2016); Xu et al. (2018) — temporal/attention‑based models (with cautions on consistency).  </p></li>
</ul>

<p><em>(Cited within the paper’s related work and summary table as relevant to actionable explanations.)</em> :contentReference[oaicite:45]{index=45}</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Visual Analytics: Definition, Process, and Challenges</p>

<p>Authors: Daniel A. Keim; Gennady Andrienko; Jean-Daniel Fekete; Carsten Görg; Jörn Kohlhammer; Guy Melançon</p>

<p>DOI: 10.1007/978-3-540-70956-5_7</p>

<p>Year: 2008</p>

<p>Publication Type: Journal/Conference Chapter (LNCS book chapter)</p>

<p>Discipline/Domain: Visualization / Visual Analytics / Human–Computer Interaction</p>

<p>Subdomain/Topic: Definition and scope of visual analytics; integration of automated analysis and interactive visualization; process and challenges</p>

<p>Eligibility: Eligible (implicit and substantive treatment of making insights usable for decisions and “action”)</p>

<p>Overall Relevance Score: 78</p>

<p>Operationalization Score: 52</p>

<p>Actionable/Actionability Used in Paper: No (term not used explicitly). Closest phrasing ties results to “decision making,” “assessments,” and “action”: “Provide timely, defensible, and understandable assessments. – Communicate assessment effectively for action.” (p. 157). :contentReference[oaicite:0]{index=0}</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — “The goal of visual analytics is the creation of tools and techniques to enable people to … Provide timely, defensible, and understandable assessments. – Communicate assessment effectively for action.” (p. 157); “visualization becomes the medium of a semi-automated analytical process … for the most effective results.” (pp. 155–156). :contentReference[oaicite:1]{index=1}</p>

<p>Contains Definition of Actionability: No (but defines visual analytics in decision/action terms). Quote: “Visual analytics combines automated analysis techniques with interactive visualizations for an effective understanding, reasoning and decision making…” (p. 157). :contentReference[oaicite:2]{index=2}</p>

<p>Contains Systematic Features/Dimensions: Yes (timeliness, defensibility/understandability, relevance to task, uncertainty/quality representation, scalability, level-of-detail, interaction, evaluation). (pp. 157, 167–168). :contentReference[oaicite:3]{index=3}</p>

<p>Contains Explainability: Partial (transparency of processes; communicating procedures and quality/uncertainty). (pp. 155, 167). :contentReference[oaicite:4]{index=4}</p>

<p>Contains Interpretability: Partial (understandable assessments; readable visual representations). (pp. 157, 171). :contentReference[oaicite:5]{index=5}</p>

<p>Contains Framework/Model: Yes (sense-making loop; “Analyze first…” mantra; VA pipeline). (pp. 164–165, 159). :contentReference[oaicite:6]{index=6}</p>

<p>Operationalization Present: Partial (high-level workflow and design levers; illustrative applications). (pp. 164–171). :contentReference[oaicite:7]{index=7}</p>

<p>Primary Methodology: Conceptual / Position paper with illustrative application cases</p>

<p>Study Context: Conceptual cross-domain agenda; examples in movement analysis and air-transport networks</p>

<p>Geographic/Institutional Context: Multi-institution (Konstanz, Fraunhofer IAIS/IGD, INRIA, Georgia Tech; EU/US collaboration)</p>

<p>Target Users/Stakeholders: Analysts, decision-makers, engineers, public safety analysts, financial analysts, socio-economic policymakers</p>

<p>Primary Contribution Type: Definition + research agenda + process model + challenge taxonomy</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Partial</p>

<p>TI: Yes</p>

<p>EX: Partial</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Visual Analytics: Definition, Process, and Challenges</p>

<p><strong>Authors:</strong>  </p>

<p>Daniel A. Keim; Gennady Andrienko; Jean-Daniel Fekete; Carsten Görg; Jörn Kohlhammer; Guy Melançon</p>

<p><strong>DOI:</strong>  </p>

<p>10.1007/978-3-540-70956-5_7</p>

<p><strong>Year:</strong>  </p>

<p>2008</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal/Conference Chapter (LNCS book chapter)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Visualization / Visual Analytics / HCI</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Definition, process model, interdisciplinary scope, and research challenges of visual analytics</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper responds to “information overload” and argues that effective decision support requires integrating automated analysis with human-centered interactive visualization, making the path from data to decisions transparent and discussable. Assumption: audience is visualization/analytics researchers and practitioners. :contentReference[oaicite:8]{index=8}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Authored across German, French, and US institutions (Konstanz; Fraunhofer IAIS/IGD; INRIA; Georgia Tech). :contentReference[oaicite:9]{index=9}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Decision-makers, analysts, engineers, emergency response teams, financial and public safety analysts. :contentReference[oaicite:10]{index=10}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual/position statement with two application vignettes (movement data; air-transport network). :contentReference[oaicite:11]{index=11}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Field definition, goals, process model, interdisciplinary map, and challenge taxonomy. :contentReference[oaicite:12]{index=12}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors define visual analytics (VA) as combining automated analysis with interactive visualizations to enable understanding, reasoning, and decision making over large, complex data. They motivate VA by the information overload problem and argue for transparency and human–machine cooperation along the data-to-decision path. The paper distinguishes VA from traditional information visualization, emphasizes interdisciplinary integration (data management, mining, perception &amp; cognition, HCI), and outlines a sense-making loop and mantra (“Analyze first…”) that foreground analytics throughout interaction. It presents application sketches (movement data analysis; multilevel air-transport networks) and enumerates technical challenges: scalability, uncertainty/quality representation, level-of-detail, interaction, device adaptation, evaluation, and infrastructure. :contentReference[oaicite:13]{index=13}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>No (term not explicit).</strong> Closest, explicit action-oriented phrasing:  </p>

<ul>
<li><p>“Provide timely, defensible, and understandable assessments.” and “Communicate assessment effectively for action.” (p. 157). :contentReference[oaicite:14]{index=14}  </p></li>
<li><p>“visualization becomes the medium of a semi-automated analytical process … for the most effective results.” (pp. 155–156). :contentReference[oaicite:15]{index=15}</p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>Yes.</strong>  </p>

<ul>
<li><p>“Visual analytics combines automated analysis techniques with interactive visualizations for an effective understanding, reasoning and decision making…” (p. 157). :contentReference[oaicite:16]{index=16}  </p></li>
<li><p>Goal statements include “Provide timely, defensible, and understandable assessments” and “Communicate assessment effectively for action.” (p. 157). :contentReference[oaicite:17]{index=17}  </p></li>
<li><p>The vision is to “turn the information overload into an opportunity” and make processing “transparent for an analytic discourse,” enabling evaluation and improvement of models and decisions (pp. 155–156). :contentReference[oaicite:18]{index=18}</p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p><strong>Implicit conceptualization:</strong> Actionable outcomes are decision-ready assessments that are timely, defensible, understandable, and communicated in a way that enables action; they arise from tight integration of automated analysis with interactive visualization and human judgment.  </p>

<blockquote>
  <p>“Visual analytics combines automated analysis techniques with interactive visualizations for an effective understanding, reasoning and decision making…” (p. 157). :contentReference[oaicite:19]{index=19}  </p>
</blockquote>

<blockquote>
  <p>“Provide timely, defensible, and understandable assessments. – Communicate assessment effectively for action.” (p. 157). :contentReference[oaicite:20]{index=20}</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Timeliness:</strong>  </p>

<p> &gt; “Provide timely … assessments.” (p. 157). :contentReference[oaicite:21]{index=21}</p></li>
<li><p><strong>Defensibility/Validity:</strong>  </p>

<p> &gt; “Provide … defensible … assessments.” (p. 157). :contentReference[oaicite:22]{index=22}</p></li>
<li><p><strong>Understandability/Clarity:</strong>  </p>

<p> &gt; “Provide … understandable assessments.” (p. 157). :contentReference[oaicite:23]{index=23}</p></li>
<li><p><strong>Communication for Action:</strong>  </p>

<p> &gt; “Communicate assessment effectively for action.” (p. 157). :contentReference[oaicite:24]{index=24}</p></li>
<li><p><strong>Task/Goal Alignment:</strong>  </p>

<p> &gt; “The user has to be the ultimate authority in giving the direction of the analysis along his or her specific task.” (p. 156). :contentReference[oaicite:25]{index=25}</p></li>
<li><p><strong>Quality/Uncertainty Transparency:</strong>  </p>

<p> &gt; “the notion of data quality, and the confidence of the analysis algorithm needs to be appropriately represented … The user needs to be aware of these … at any stage” (p. 167). :contentReference[oaicite:26]{index=26}</p></li>
<li><p><strong>Scalability &amp; Level of Detail:</strong>  </p>

<p> &gt; “Techniques need to be able to scale with the size and dimensionality…”; “visualize … on several levels of detail” (pp. 167–168). :contentReference[oaicite:27]{index=27}</p></li>
<li><p><strong>Effective Interaction:</strong>  </p>

<p> &gt; “novel interaction techniques … seamless, intuitive visual communication … memorizing insights and making informed decisions.” (p. 168). :contentReference[oaicite:28]{index=28}</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Sense-making loop (after van Wijk); Visual Analytics pipeline; “Analyze first, Show the Important, Zoom, filter and analyze further, Details on demand.” (pp. 164–165, 159). :contentReference[oaicite:29]{index=29}  </p></li>
<li><p><strong>Methods/Levers:</strong> Tight integration of automated algorithms (clustering, classification, summarization) with interactive, task-driven visualization; representation of uncertainty/quality; scalable data management; human-in-the-loop parameter steering. (pp. 159, 167–170). :contentReference[oaicite:30]{index=30}  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Initial analysis → visualization &amp; interaction → exploration &amp; analysis → hypothesis and specification → analyze further (iterative loop). (Fig. 4, p. 165). :contentReference[oaicite:31]{index=31}  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Heterogeneous, high-dimensional, spatio-temporal and network data; measures include clustering outputs, temporal histograms, derived routes/communities. (pp. 169–172). :contentReference[oaicite:32]{index=32}  </p></li>
<li><p><strong>Implementation Context:</strong> Examples in GPS movement analysis (stops, clusters, routes) and multilevel airline network communities, demonstrating how computational summaries plus interactive visualization enable interpretation and decision-relevant insights. (pp. 169–172). :contentReference[oaicite:33]{index=33}  </p></li>
</ul>

<blockquote>
  <p>“Visualization enables human cognition and reasoning, which, in turn, direct and control the further analysis by means of … database, computational, and visual techniques.” (p. 170). :contentReference[oaicite:34]{index=34}</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> <strong>Yes.</strong> “understandable assessments” (p. 157). :contentReference[oaicite:35]{index=35}</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> <strong>Yes.</strong> “presented in a decision- or task-oriented way” (p. 155); “user … along his or her specific task” (p. 156). :contentReference[oaicite:36]{index=36}</p></li>
<li><p><strong>FE (Feasibility):</strong> <strong>Partial.</strong> Emphasis on efficient, interactive systems and infrastructure that trades time with quality (pp. 168). :contentReference[oaicite:37]{index=37}</p></li>
<li><p><strong>TI (Timeliness):</strong> <strong>Yes.</strong> “Provide timely … assessments.” (p. 157). :contentReference[oaicite:38]{index=38}</p></li>
<li><p><strong>EX (Explainability):</strong> <strong>Partial.</strong> Make processes transparent; represent uncertainty and confidence (pp. 155, 167). :contentReference[oaicite:39]{index=39}</p></li>
<li><p><strong>GA (Goal Alignment):</strong> <strong>Yes.</strong> User-driven analysis direction tied to specific tasks; decision support (pp. 156–157). :contentReference[oaicite:40]{index=40}</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> <strong>Scalability</strong> and <strong>Level-of-Detail/Abstraction</strong> as prerequisites for usable assessments (pp. 167–168). :contentReference[oaicite:41]{index=41}</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>van Wijk’s model of the value of visualization and sense-making loop (Fig. 4, p. 165). :contentReference[oaicite:42]{index=42}  </p></li>
<li><p>Distinction from information visualization; integration across data mining, data management, perception/cognition, and HCI (pp. 157–160). :contentReference[oaicite:43]{index=43}</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>No explicit metrics; the paper calls for evaluation frameworks and emphasizes qualities (timeliness, defensibility, understandability, uncertainty communication) that imply potential indicators but does not formalize them. (pp. 157, 168). :contentReference[oaicite:44]{index=44}</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Information overload; heterogeneity; uncertainty/missing data; limited scalability; lack of evaluation standards; complex UIs (pp. 155, 161, 167–168). :contentReference[oaicite:45]{index=45}  </p></li>
<li><p><strong>Enablers:</strong> Tight human–machine integration; representation of quality/uncertainty; multi-level detail; intuitive interaction; appropriate infrastructure and evaluation methodology (pp. 156–160, 167–168). :contentReference[oaicite:46]{index=46}</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on Thomas &amp; Cook’s definition of VA as analytical reasoning via interactive visual interfaces, but reframes VA with a stronger emphasis on integrating automated analysis and on decision/action-oriented outcomes. It maps adjacent fields (data mining, HCI, cognition) and highlights spatio-temporal and network sub-communities. It aligns with van Wijk’s model to structure a sense-making loop and calls for standardized evaluation and infrastructure. (pp. 157–165). :contentReference[oaicite:47]{index=47}</p>

<hr />

<h2>Summary</h2>

<p>Keim et al. define visual analytics as the integration of automated analysis and interactive visualization to enable understanding, reasoning, and <strong>decision making</strong> on large, complex data. While they do not use the word <em>actionable</em>, they repeatedly target <strong>decision-ready</strong> outputs: timely, defensible, and understandable assessments that are effectively communicated <strong>for action</strong>. The paper operationalizes this at a high level through a <strong>sense-making loop</strong> and an <strong>“Analyze first…” mantra</strong>, emphasizing that human analysts steer tasks aligned with their goals, while systems provide scalable computation, multi-level views, and explicit representations of uncertainty and data quality. Two vignettes (movement data and airline networks) show how computational summarization plus interaction can surface patterns relevant for decisions. The authors articulate a research agenda—scalability, level-of-detail, quality/uncertainty, interaction metaphors, evaluation, and infrastructure—that together constitute the <strong>conditions</strong> under which insights become usable for timely and defensible decisions. :contentReference[oaicite:48]{index=48}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> <strong>78/100.</strong> Strong, explicit linkage from insights to decision/action (timeliness, defensibility, communication for action), clear process model, and enumerated attributes. Lacks an explicit formal definition of <em>actionability</em> or quantitative criteria. :contentReference[oaicite:49]{index=49}  </p></li>
<li><p><strong>Operationalization Score:</strong> <strong>52/100.</strong> Provides high-level workflows and examples but few concrete, generalizable KPIs or step-by-step procedures directly tied to measuring “actionability.” :contentReference[oaicite:50]{index=50}</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[<strong>Definition</strong>] ‘Visual analytics combines automated analysis techniques with interactive visualizations for an effective understanding, reasoning and decision making…’” (p. 157). :contentReference[oaicite:51]{index=51}  </p></li>
<li><p>“[<strong>Criteria/features</strong>] ‘Provide timely, defensible, and understandable assessments.’ ‘Communicate assessment effectively for action.’” (p. 157). :contentReference[oaicite:52]{index=52}  </p></li>
<li><p>“[<strong>Operationalization step</strong>] ‘The process then enters a loop where the user can gain knowledge on the data … interacting on the visual representation… ultimately confirm hypotheses…’ (sense-making loop; Fig. 4)” (p. 165). :contentReference[oaicite:53]{index=53}  </p></li>
<li><p>“[<strong>Quality/uncertainty</strong>] ‘the notion of data quality, and the confidence of the analysis algorithm needs to be appropriately represented … The user needs to be aware of these … at any stage’” (p. 167). :contentReference[oaicite:54]{index=54}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Thomas &amp; Cook (2005) <em>Illuminating the Path</em> — foundational VA definition focused on analytical reasoning (cited p. 157). :contentReference[oaicite:55]{index=55}  </p></li>
<li><p>van Wijk (2005) — model of the value of visualization; basis for sense-making loop and evaluation perspective (p. 165, refs pp. 174–175). :contentReference[oaicite:56]{index=56}</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: The role of explainability in creating trustworthy artificial intelligence for health care: a comprehensive survey of the terminology, design choices, and evaluation strategies</p>

<p>Authors: Aniek F. Markus; Jan A. Kors; Peter R. Rijnbeek</p>

<p>DOI: https://doi.org/10.1016/j.jbi.2020.103655</p>

<p>Year: 2020</p>

<p>Publication Type: Journal (pre-proof)</p>

<p>Discipline/Domain: Biomedical Informatics / Artificial Intelligence in Health Care</p>

<p>Subdomain/Topic: Explainable AI (XAI); Trustworthy AI; Evaluation metrics; Method selection framework</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 38</p>

<p>Operationalization Score: 30</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: Yes (for explainability: clarity, parsimony, completeness, soundness)</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes (step-by-step design framework for choosing XAI methods)</p>

<p>Operationalization Present: Yes (for explainability evaluation/design), but not for “actionability”</p>

<p>Primary Methodology: Review / Conceptual Survey</p>

<p>Study Context: AI systems for health care; high-stakes clinical decision support</p>

<p>Geographic/Institutional Context: Erasmus University Medical Center, Rotterdam, The Netherlands</p>

<p>Target Users/Stakeholders: AI developers, clinicians, healthcare organizations, regulators</p>

<p>Primary Contribution Type: Conceptual synthesis; taxonomy; evaluation guidance; method-selection framework</p>

<p>CL: Yes — defined as “clarity”</p>

<p>CR: Partial — contextual dependence of explanations noted (user- and use-case dependent)</p>

<p>FE: Partial — feasibility implied via trade-offs between performance and explainability; not formalized as such</p>

<p>TI: No — timeliness not developed as a dimension</p>

<p>EX: Yes — explainability treated in depth; interpretable vs. faithful explanations</p>

<p>GA: Partial — alignment with goals like trust, legality, robustness is discussed but not framed as “goal alignment” metric</p>

<p>Reason if Not Eligible: The article focuses on explainability for trustworthy AI and does not use or define “actionable/(actionability)” nor provide criteria explicitly tied to making findings “actionable.” It discusses properties of explanations (clarity, parsimony, completeness, soundness) and a design/evaluation framework, not actionability per se. :contentReference[oaicite:0]{index=0}</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>The role of explainability in creating trustworthy artificial intelligence for health care: a comprehensive survey of the terminology, design choices, and evaluation strategies</p>

<p><strong>Authors:</strong>  </p>

<p>Aniek F. Markus; Jan A. Kors; Peter R. Rijnbeek</p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1016/j.jbi.2020.103655</p>

<p><strong>Year:</strong>  </p>

<p>2020</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal (pre-proof), Journal of Biomedical Informatics</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Biomedical Informatics / Artificial Intelligence in Health Care</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Explainable AI (XAI), interpretability vs. fidelity, evaluation strategies, method selection</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper surveys and formalizes terminology and evaluation strategies for explainable AI in health care, arguing explainability can support trustworthy AI where stakes are high. Assumption: audience includes practitioners designing or adopting clinical AI. :contentReference[oaicite:1]{index=1}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Erasmus University Medical Center, Rotterdam, The Netherlands. :contentReference[oaicite:2]{index=2}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>AI researchers/developers, clinicians/end users, deployers, and regulators in healthcare. :contentReference[oaicite:3]{index=3}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Review / Conceptual synthesis (non-systematic survey of recent literature). :contentReference[oaicite:4]{index=4}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework; taxonomy; evaluation guidance for XAI in healthcare. :contentReference[oaicite:5]{index=5}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This comprehensive survey clarifies terminology around explainability, interpretability, and fidelity, proposing a structured set of properties—clarity and parsimony (interpretability), completeness and soundness (fidelity)—that explanations should satisfy. It classifies XAI approaches into model-based, attribution-based, and example-based methods, each with global or local scope, and maps which properties are satisfied or measurable. The authors assess available quantitative evaluation metrics, highlighting gaps (e.g., limited metrics for clarity of local explanations and for example-based methods). They provide a step-by-step framework to choose between explainable modeling and post‑hoc explanations based on application needs and trade-offs with predictive performance, and argue that explainable modeling often best supports trustworthy AI in health care, complemented by measures like data quality reporting, external validation, and regulation. :contentReference[oaicite:6]{index=6}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No. The paper does not use “actionable,” “actionability,” or closely related phrases in relation to outputs or decisions. Focus is on explainability and trust, not actionability. :contentReference[oaicite:7]{index=7}</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No. Needs are framed as “trustworthy AI,” “explainability,” regulatory compliance, and evaluation—without invoking “actionability.” :contentReference[oaicite:8]{index=8}</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A — not addressed. The paper defines explainability (interpretability + fidelity), not actionability. :contentReference[oaicite:9]{index=9}</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A — not discussed. (Paper enumerates properties of explanations rather than conditions for “actionability.”) :contentReference[oaicite:10]{index=10}</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A — operationalization pertains to explainability methods and evaluation, not actionability. :contentReference[oaicite:11]{index=11}</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<p><em>(Interpreted for completeness; the paper defines attributes of explainability, not actionability.)</em></p>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — “the explanation is unambiguous… provides a single rationale…” (Definition 2a, p. 7). :contentReference[oaicite:12]{index=12}  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Partial — usefulness depends on “expertise, preferences, and other contextual values of the target user” (p. 7–8). :contentReference[oaicite:13]{index=13}  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — trade-offs and costs of explanations are discussed (e.g., “explanations can be costly…” p. 9, 19), but not formalized as feasibility. :contentReference[oaicite:14]{index=14}  </p></li>
<li><p><strong>TI (Timeliness):</strong> No — not specified.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — central theme; “An AI system is explainable if…” (Definition 1, p. 6). :contentReference[oaicite:15]{index=15}  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — alignment with aims like verifying desiderata, managing social interaction, or gaining insights is discussed (pp. 8–10, 20–22). :contentReference[oaicite:16]{index=16}  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Parsimony, completeness, soundness as core properties (pp. 6–7). :contentReference[oaicite:17]{index=17}</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Distinction between interpretability and fidelity; formal properties (clarity, parsimony, completeness, soundness).  </p></li>
<li><p>Taxonomy of XAI methods (model-based, attribution-based, example-based; global vs. local).  </p></li>
<li><p>Step-by-step selection framework (Figure 2) balancing predictive performance, interpretability, and fidelity. (pp. 10–22, 18–21). :contentReference[oaicite:18]{index=18}</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A — metrics discussed are for explainability evaluation (e.g., fidelity agreement, model size/complexity, axioms for attribution methods). (pp. 15–18). :contentReference[oaicite:19]{index=19}</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p><em>(Reinterpreted as barriers/enablers to explainability &amp; trustworthy AI)</em></p>

<ul>
<li><p><strong>Barriers:</strong> Lack of standardized evaluation metrics; potential for misleading post‑hoc explanations; costs of explanation; underdeveloped methods for example-based evaluation (pp. 15–18, 19–21). :contentReference[oaicite:20]{index=20}  </p></li>
<li><p><strong>Enablers:</strong> Explainable modeling; quantitative proxy metrics where available; external validation; reporting data quality; evolving regulation (pp. 21–24). :contentReference[oaicite:21]{index=21}</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper synthesizes prior surveys and conceptual works to propose precise property definitions and a practical design framework, bridging gaps such as inconsistent terminology and limited evaluation standards. It extends literature by mapping which XAI classes satisfy or can quantify given properties and by emphasizing fidelity vs. interpretability trade‑offs tied to specific needs (verification, social interaction, knowledge discovery). (pp. 3–7, 15–22). :contentReference[oaicite:22]{index=22}</p>

<hr />

<h2>Summary</h2>

<p>This survey argues that explainability should be understood as the combination of interpretability and fidelity, each with concrete sub‑properties: clarity and parsimony for interpretability, completeness and soundness for fidelity. It classifies XAI approaches—model‑based, attribution‑based, example‑based—and assesses which properties are either satisfied by definition or can be measured with quantitative proxies. The authors note major gaps, particularly metrics for clarity in local explanations and for example‑based methods. A step‑wise framework guides developers to choose between explainable modeling (often preferred for trustworthy AI in health care) and post‑hoc explanations, depending on whether predictive performance or explanation fidelity/interpretability is paramount. They also stress that explainability alone may be insufficient for trust, advocating complementary practices like data quality reporting, external validation, and appropriate regulation. The paper does not discuss “actionability” and thus falls outside eligibility for an actionability‑focused synthesis. :contentReference[oaicite:23]{index=23}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 38 — Strong conceptual clarity on explainability but no explicit or implicit treatment of “actionability” as defined in the eligibility criteria. :contentReference[oaicite:24]{index=24}  </p></li>
<li><p><strong>Operationalization Score:</strong> 30 — Provides operational steps for choosing XAI methods and some evaluation proxies, yet none pertain to operationalizing “actionability.” :contentReference[oaicite:25]{index=25}</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[<strong>Definition 1: explainability</strong>] ‘An AI system is explainable if the task model is intrinsically interpretable… or if the non‑interpretable task model is complemented with an interpretable and faithful explanation.’” (p. 6). :contentReference[oaicite:26]{index=26}  </p></li>
<li><p>“[<strong>Definition 2: interpretability</strong>] ‘An explanation is unambiguous… (clarity)… [and] not too complex… (parsimony).’” (p. 7). :contentReference[oaicite:27]{index=27}  </p></li>
<li><p>“[<strong>Definition 3: fidelity</strong>] ‘An explanation is faithful if… [it provides] completeness… and… is truthful to the task model (soundness).’” (p. 7). :contentReference[oaicite:28]{index=28}  </p></li>
<li><p>“We distinguish three reasons why explainability can be useful: [verifying desiderata; managing social interaction; discovering new insights].” (pp. 8–10). :contentReference[oaicite:29]{index=29}  </p></li>
<li><p>“Based on… findings… we propose the step‑by‑step guide… to select the most appropriate class of explainable AI methods.” (p. 18; see Figure 2). :contentReference[oaicite:30]{index=30}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A — the article does not cite or define literature on “actionability”; references address explainability, interpretability, evaluation, and trustworthy AI. :contentReference[oaicite:31]{index=31}</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: The GuideLine Interchange Format: A Model for Representing Guidelines</p>

<p>Authors: Lucila Ohno‑Machado; John H. Gennari; Shawn N. Murphy; Nilesh L. Jain; Samson W. Tu; Diane E. Oliver; Edward Pattison‑Gordon; Robert A. Greenes; Edward H. Shortliffe; G. Octo Barnett</p>

<p>DOI: N/A</p>

<p>Year: 1998</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Medical Informatics / Health Informatics</p>

<p>Subdomain/Topic: Representation and interchange of clinical practice guidelines; decision support interoperability</p>

<p>Eligibility: Eligible (implicit and substantive treatment of what makes guidelines actionable via formal representation, criteria, branching, and operational workflow)</p>

<p>Overall Relevance Score: 78</p>

<p>Operationalization Score: 85</p>

<p>Actionable/Actionability Used in Paper: No (term not used explicitly)</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — e.g., “Providing a common format for expressing guidelines is a necessary (but not sufficient) step… [and would] encourage guideline authors to be rigorous… producing guidelines with less ambiguity and fewer errors.” (p. 358–359) :contentReference[oaicite:0]{index=0}</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes (GLIF model + syntax)</p>

<p>Operationalization Present: Yes (encoding steps, criteria, branching, synchronization; pilot encodings)</p>

<p>Primary Methodology: Conceptual + Pilot Evaluation</p>

<p>Study Context: Representation standard for clinical guidelines; evaluation by encoding four real guidelines</p>

<p>Geographic/Institutional Context: InterMed Collaboratory (Columbia, Harvard/Brigham &amp; Women’s + MGH, Stanford) in the U.S.</p>

<p>Target Users/Stakeholders: Guideline authors; CDS developers; informatics researchers; clinicians (indirect users via CDS)</p>

<p>Primary Contribution Type: Representation framework/specification and feasibility evaluation</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Partial</p>

<p>TI: Partial</p>

<p>EX: Partial</p>

<p>GA: Partial</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>The GuideLine Interchange Format: A Model for Representing Guidelines</p>

<p><strong>Authors:</strong>  </p>

<p>Lucila Ohno‑Machado; John H. Gennari; Shawn N. Murphy; Nilesh L. Jain; Samson W. Tu; Diane E. Oliver; Edward Pattison‑Gordon; Robert A. Greenes; Edward H. Shortliffe; G. Octo Barnett</p>

<p><strong>DOI:</strong>  </p>

<p>N/A</p>

<p><strong>Year:</strong>  </p>

<p>1998</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal (JAMIA)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Medical Informatics / Health Informatics</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Interchange/representation of clinical practice guidelines for decision support</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper responds to pressures to improve quality and reduce costs by sharing and implementing computable guidelines across institutions; it proposes a common format (GLIF) to move from paper to machine‑interpretable guidelines. Assumption: “actionability” is treated as implementability/decision‑directed computability. (pp. 357–360) :contentReference[oaicite:1]{index=1}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>InterMed Collaboratory: Columbia University; Harvard (Brigham &amp; Women’s Hospital, Massachusetts General Hospital); Stanford University. (p. 357–358) :contentReference[oaicite:2]{index=2}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Guideline authors, CDS developers, informatics teams; clinicians and patients benefit via implemented systems. (pp. 358–360) :contentReference[oaicite:3]{index=3}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual specification (model + syntax) + pilot encoding study of four guidelines to assess expressivity and variability. (pp. 358, 366–369) :contentReference[oaicite:4]{index=4}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework/model/specification (GLIF) and evaluation.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors introduce GLIF, a guideline interchange specification comprising an object‑oriented model (classes for guideline entities such as steps, criteria, actions) and a textual syntax for encoding guidelines so they can be shared and executed by different applications. They analyze four precursor systems (Arden/MLMs, GEODE‑CM, MBTA, EON) to derive representational requirements (steps, branching, criteria, eligibility, actions, synchronization, links to didactics). They then present GLIF’s classes and control‑flow constructs and demonstrate a worked example (vaccine recommendation). A pilot study encodes four real guidelines (influenza vaccine, cholesterol management, breast‑mass workup, breast‑cancer protocol), finding GLIF expressive but revealing variability across encoders and highlighting needs for standard vocabularies, formal criterion logic, temporal reasoning, and uncertainty handling. (pp. 360–366, 366–371) :contentReference[oaicite:5]{index=5}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No explicit use of the words “actionable/actionability.” The paper consistently treats <em>implementable, computable, and sharable</em> guideline representations as the route to practice‑directing recommendations. (pp. 358–365) :contentReference[oaicite:6]{index=6}</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes. Selected quotes:</p>

<ul>
<li><p>“Providing a common format for expressing guidelines is a necessary (but not sufficient) step… [It] would encourage guideline authors to be rigorous… producing guidelines with less ambiguity and fewer errors.” (p. 358–359) :contentReference[oaicite:7]{index=7}  </p></li>
<li><p>“If guidelines could be encoded in a common representation… we would reap four benefits… [including] tools that help practitioners retrieve and use guideline information.” (p. 358) :contentReference[oaicite:8]{index=8}  </p></li>
<li><p>“Computer‑based systems offer new opportunities for guideline implementation.” (p. 359) :contentReference[oaicite:9]{index=9}</p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicit: a guideline is “actionable” when encoded in a formal structure that specifies eligibility, decisions, and actions with sufficient precision for computer systems to generate patient‑specific recommendations and direct next steps.  </p>

<blockquote>
  <p>“The GLIF specification consists of… classes for guideline entities… [and] a format of the text file that contains the encoding.” (p. 365) :contentReference[oaicite:10]{index=10}</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Explicit eligibility criteria to enter the guideline</strong>  </p>

<p> &gt; “Eligibility criteria… are conditions that must be true before a guideline can be applied to a particular patient.” (p. 365) :contentReference[oaicite:11]{index=11}</p></li>
<li><p><strong>Structured steps specifying actions and control flow</strong>  </p>

<p> &gt; “There are four types of guideline steps: action steps, conditional steps, branch steps, and synchronization steps.” (p. 365) :contentReference[oaicite:12]{index=12}</p></li>
<li><p><strong>Criteria (“conditions”) that gate transitions</strong>  </p>

<p> &gt; “A conditional step contains a condition… If the condition is true… otherwise…” (p. 365) :contentReference[oaicite:13]{index=13}</p></li>
<li><p><strong>Support for branching and synchronization of parallel tasks</strong>  </p>

<p> &gt; “The author specifies whether all, some, or only one of these steps must take place… [with] a synchronization step.” (p. 366) :contentReference[oaicite:14]{index=14}</p></li>
<li><p><strong>Patient‑data elements bound to actions/assessments</strong>  </p>

<p> &gt; “If the action involves the collection of patient data, such data are specified as a set of data elements…” (p. 365) :contentReference[oaicite:15]{index=15}</p></li>
<li><p><strong>Didactic links and explanations to support use and rationale</strong>  </p>

<p> &gt; “Didactics provide background… locally as text… or by reference to a URL… Other classes… allow optional inclusion of external didactic information.” (p. 365) :contentReference[oaicite:16]{index=16}</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> GuideLine Interchange Format (GLIF). (p. 358) :contentReference[oaicite:17]{index=17}  </p></li>
<li><p><strong>Methods/Levers:</strong> Object‑oriented classes (Guideline, Guideline Step, Action Specification, Criterion, Patient Data, Supplemental Material); explicit control‑flow (conditional/branch/synchronization); eligibility; start step. (pp. 364–366; <em>Figure 1</em>, p. 364 shows class hierarchy) :contentReference[oaicite:18]{index=18}  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Encode guideline into GLIF syntax → map eligibility, steps, criteria, data elements, and didactics → (optionally) decompose complex actions into subguidelines → execute in CDS applications that read GLIF. The <em>Figure 3</em> flowchart (p. 366) demonstrates end‑to‑end control flow for vaccination. :contentReference[oaicite:19]{index=19}  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Patient data elements with types, acceptable values, and temporal constraints; criteria evaluated to direct next actions. (p. 365) :contentReference[oaicite:20]{index=20}  </p></li>
<li><p><strong>Implementation Context:</strong> Pilot encodings of four guidelines (influenza, cholesterol, breast‑mass workup, breast‑cancer protocol) across sites to test expressivity and identify variability. (pp. 366–368; Table 1, Table 2) :contentReference[oaicite:21]{index=21}  </p></li>
</ul>

<blockquote>
  <p>“The encoders reported that GLIF was adequately expressive… [but] a comparison… revealed substantial variability.” (p. 358) :contentReference[oaicite:22]{index=22}</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> <strong>Yes</strong> — reduces ambiguity via explicit steps/criteria.  </p>

<p> &gt; “Encourage guideline authors to be rigorous… less ambiguity and fewer errors.” (p. 359) :contentReference[oaicite:23]{index=23}</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> <strong>Yes</strong> — patient‑specific eligibility/criteria and data binding.  </p>

<p> &gt; “Eligibility criteria… before a guideline can be applied to a particular patient.” (p. 365) :contentReference[oaicite:24]{index=24}</p></li>
<li><p><strong>FE (Feasibility):</strong> <strong>Partial</strong> — implementable control‑flow; notes limits (vocabulary, temporal logic, uncertainty).  </p>

<p> &gt; “GLIF needs improvement in… representation of medical concepts… temporal information, and uncertainty.” (pp. 369–370) :contentReference[oaicite:25]{index=25}</p></li>
<li><p><strong>TI (Timeliness):</strong> <strong>Partial</strong> — rapid dissemination envisioned via common electronic format.  </p>

<p> &gt; “A common electronic format would allow guideline amendments and modifications to be disseminated rapidly.” (p. 358) :contentReference[oaicite:26]{index=26}</p></li>
<li><p><strong>EX (Explainability):</strong> <strong>Partial</strong> — didactics and MBTA “explainers” concept carried into links; GLIF includes didactic materials.  </p>

<p> &gt; “Didactics provide background or supporting information… links to the World Wide Web.” (p. 365) :contentReference[oaicite:27]{index=27}</p></li>
<li><p><strong>GA (Goal Alignment):</strong> <strong>Partial</strong> — “guideline intention” attribute specifies purpose.  </p>

<p> &gt; “The guideline intention is a characterization of the purpose of the guideline…” (p. 365) :contentReference[oaicite:28]{index=28}</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Decomposability/Modularity (subguidelines). (p. 365) :contentReference[oaicite:29]{index=29}</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<p>Comparative analysis of prior systems (Arden/MLMs, GEODE‑CM, MBTA, EON) to derive requirements; influence from logic/temporal reasoning literature; emphasis on formal criteria and control‑flow semantics. (pp. 360–365, 369–371) :contentReference[oaicite:30]{index=30}</p>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>None formalized; variability across encoders used diagnostically to identify missing standardization (vocabulary, criteria structure, temporal patterns). (pp. 367–369) :contentReference[oaicite:31]{index=31}</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of standard vocabularies and data models; informal criterion logic; temporal complexity; uncertainty handling; human encoding variability. (pp. 369–370) :contentReference[oaicite:32]{index=32}  </p></li>
<li><p><strong>Enablers:</strong> Common representation; explicit eligibility/criteria/steps; didactics; authoring tools; repository and dissemination infrastructure. (pp. 358–366, 370) :contentReference[oaicite:33]{index=33}</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions GLIF alongside/intended to interoperate with or improve upon existing approaches (Arden Syntax/MLMs, EON, MBTA, GEODE‑CM) and contemporary languages (ASBRU, SPIN, DGPM/PRESTIGE), noting shared elements (actions, transitions, intentions) and GLIF’s broader scope beyond treatment protocols. (pp. 369–371) :contentReference[oaicite:34]{index=34}</p>

<hr />

<h2>Summary</h2>

<p>This paper proposes GLIF, a sharable, computable representation for clinical practice guidelines that encodes eligibility criteria, explicit control flow (conditional, branch, synchronization), and action specifications tied to patient‑data elements and supporting didactics. By structuring guideline logic and data requirements, GLIF moves guidelines from narrative descriptions to machine‑interpretable pathways capable of producing patient‑specific recommendations—capturing the essence of <em>actionability</em> without naming it explicitly. A pilot study encoding four guidelines across institutions shows GLIF’s expressivity but surfaces variability due to divergent modeling choices, nonstandard vocabularies, informal criterion syntax, and temporal/uncertainty gaps. The authors outline future work—formal criterion languages, temporal representations, uncertainty handling, authoring tools, and repositories—to reduce ambiguity and speed dissemination and use. Figures in the paper (notably <em>Figure 1</em>, class hierarchy, and <em>Figure 3</em>, vaccine flow) concretize how the model operationalizes decision‑directing guidance. (pp. 364–366, 366–371) :contentReference[oaicite:35]{index=35}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 78 — Strong, explicit treatment of what makes guidance <em>usable for decisions</em> (eligibility, criteria, control flow, data binding) though the term “actionability” is not defined explicitly. :contentReference[oaicite:36]{index=36}</p></li>
<li><p><strong>Operationalization Score:</strong> 85 — Detailed model and syntax, worked example, and pilot encodings provide concrete steps to produce decision‑directing outputs; limitations are identified (vocabulary, temporal logic, uncertainty) but do not negate the operational pathway. (pp. 365–369) :contentReference[oaicite:37]{index=37}</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[A] common format for expressing guidelines is a necessary (but not sufficient) step… [It would] encourage… less ambiguity and fewer errors.” (p. 358–359) :contentReference[oaicite:38]{index=38}  </p></li>
<li><p>“There are four types of guideline steps: action steps, conditional steps, branch steps, and synchronization steps.” (p. 365) :contentReference[oaicite:39]{index=39}  </p></li>
<li><p>“Eligibility criteria… must be true before a guideline can be applied to a particular patient.” (p. 365) :contentReference[oaicite:40]{index=40}  </p></li>
<li><p>“GLIF needs improvement in… representation of medical concepts, criterion logic, temporal information, and uncertainty.” (pp. 369–370) :contentReference[oaicite:41]{index=41}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>References to related representation/implementation approaches that inform GLIF’s operationalization and limits: Arden Syntax/MLMs (pp. 360–362, 371), GEODE‑CM (p. 361), MBTA (pp. 361–362), EON (pp. 362–363), ASBRU (pp. 369–370), SPIN (p. 369), DGPM/PRESTIGE (pp. 369–370). :contentReference[oaicite:42]{index=42}</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Illuminating the Path: The Research and Development Agenda for Visual Analytics</p>

<p>Authors: James J. Thomas; Kristin A. Cook (eds.) + contributing authors</p>

<p>DOI: N/A</p>

<p>Year: 2005</p>

<p>Publication Type: Report/Book (Research &amp; Development Agenda)</p>

<p>Discipline/Domain: Visual Analytics; Human–Computer Interaction; Data Science</p>

<p>Subdomain/Topic: Analytics reasoning; data representations &amp; transformations; production, presentation &amp; dissemination; evaluation methods</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 25</p>

<p>Operationalization Score: 30</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — “The goal of visual analytics is to facilitate the analytical reasoning process through the creation of software that maximizes human capacity to perceive, understand, and reason about complex and dynamic data and situations.” (p. 68) :contentReference[oaicite:0]{index=0}</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual (agenda-setting, with synthesized recommendations)</p>

<p>Study Context: National research agenda initiated by DHS NVAC for security/terrorism analysis use cases, generalized to broader analytics</p>

<p>Geographic/Institutional Context: United States; Department of Homeland Security (DHS); NVAC</p>

<p>Target Users/Stakeholders: Analysts, researchers, engineers, tool developers, government agencies</p>

<p>Primary Contribution Type: Research &amp; development agenda with thematic recommendations</p>

<p>CL: N/A</p>

<p>CR: N/A</p>

<p>FE: N/A</p>

<p>TI: N/A</p>

<p>EX: Partial</p>

<p>GA: Partial</p>

<p>Reason if Not Eligible: The document does not use or define “actionable/actionability/actionable insight/knowledge/recommendation” nor specify criteria that make outputs actionable; it discusses decision support and evaluation broadly without articulating actionability as a construct.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Illuminating the Path: The Research and Development Agenda for Visual Analytics</p>

<p><strong>Authors:</strong>  </p>

<p>James J. Thomas; Kristin A. Cook (eds.) + contributing authors. :contentReference[oaicite:1]{index=1}</p>

<p><strong>DOI:</strong>  </p>

<p>N/A</p>

<p><strong>Year:</strong>  </p>

<p>2005 (NVAC agenda; contemporaneous DHS references). :contentReference[oaicite:2]{index=2}</p>

<p><strong>Publication Type:</strong>  </p>

<p>Report/Book (Research &amp; Development Agenda)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Visual Analytics; HCI; Data Science</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Analytic reasoning; data representations &amp; transformations; production/presentation/dissemination; evaluation methodologies. :contentReference[oaicite:3]{index=3}</p>

<p><strong>Contextual Background:</strong>  </p>

<p>DHS chartered NVAC to define a 5‑year R&amp;D agenda addressing pressing needs for visual analytics to aid national security and broader analytic tasks; the report consolidates community input and recommends research thrusts across representation, interaction, production/dissemination, and evaluation. :contentReference[oaicite:4]{index=4}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>United States; Department of Homeland Security; NVAC. :contentReference[oaicite:5]{index=5}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Analysts, researchers, engineers, developers, and policy/government decision-makers. :contentReference[oaicite:6]{index=6}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual (agenda-setting with synthesized recommendations, illustrative examples). :contentReference[oaicite:7]{index=7}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Research agenda and recommendations guiding future VA research, tooling, and evaluation. :contentReference[oaicite:8]{index=8}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The report outlines a national research and development agenda for visual analytics (VA) initiated by DHS’s NVAC. It frames VA as the science of enabling analytic reasoning through interactive visual interfaces and proposes research needs in data representation/transformations, interaction techniques, information synthesis, and production/presentation/dissemination. The document emphasizes evaluation methodologies, scalability concerns, and bridging research to practice with concrete recommendations. Its aim is to coordinate multi‑disciplinary efforts that can handle complex, dynamic data and support effective analyst workflows. </p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes. Representative passages (decision/use‑orientation without defining “actionable”):  </p>

<ul>
<li><p>“The goal of visual analytics is to facilitate the analytical reasoning process… [so] analysts… have a true discourse with their information.” (p. 68). :contentReference[oaicite:10]{index=10}  </p></li>
<li><p>Emphasis on “production, presentation, and dissemination of results… the most time‑consuming part of analysis” to “share… with their audiences.” (p. 34). :contentReference[oaicite:11]{index=11}</p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A — the paper does not define “actionability”. It frames effectiveness in terms of supporting analytic reasoning, evaluation, and communication.</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A — no explicit or implicit criteria tied to “actionability” as such.</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A for “actionability” specifically. (The report operationalizes VA research areas and evaluation, not actionability.)</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> N/A  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> N/A  </p></li>
<li><p><strong>FE (Feasibility):</strong> N/A  </p></li>
<li><p><strong>TI (Timeliness):</strong> N/A  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — repeated calls to support analytic reasoning and evaluation imply needs for transparency/explanation but not framed as “actionability.” (e.g., developing evaluation methodologies for VA tools and reasoning effectiveness). :contentReference[oaicite:12]{index=12}  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — recurring emphasis on aligning tools with analyst tasks and decision contexts, but not as actionability criteria. :contentReference[oaicite:13]{index=13}  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<p>The agenda organizes VA around analytic reasoning supported by visual interfaces, data transformations, and evaluation. It references cognitive/perceptual considerations and human-information discourse rather than an actionability theory. </p>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A.</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> N/A  </p></li>
<li><p><strong>Enablers:</strong> N/A</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The agenda builds on national reports and security-driven research needs, proposing structured research recommendations across VA components (representation, interaction, synthesis, dissemination, evaluation). It cites evaluation challenges and the need for measurable benefits of VA techniques, but not actionability constructs. :contentReference[oaicite:15]{index=15}</p>

<hr />

<h2>Summary</h2>

<p>This DHS‑initiated R&amp;D agenda positions visual analytics as an interdisciplinary effort to enable analytic reasoning via interactive visual interfaces. It delineates research thrusts in data representations and transformations, interaction techniques, information synthesis, and the production/presentation/dissemination of results, all underpinned by robust evaluation methodologies. The document repeatedly stresses bridging research and practice, scalability to massive and dynamic data, and developing metrics and user‑centered evaluation to demonstrate value. While intensely oriented toward decision support and communication of results, the report neither uses nor defines “actionability,” nor does it specify criteria that render insights actionable. Consequently, its relevance to an actionability‑focused review lies in its structured agenda and evaluation emphasis, which may indirectly inform how visual analytics could contribute to actionable outcomes, even though the construct itself is absent. </p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 25 — The paper is decision‑oriented and evaluation‑focused but does not use or define actionability, nor present criteria that make insights actionable.  </p></li>
<li><p><strong>Operationalization Score:</strong> 30 — It offers detailed VA research recommendations and evaluation needs, yet none are linked to operationalizing “actionability” as a construct.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[VA] must address… evaluation methodologies for visual analytics… that can be demonstrated to improve the analyst work environment.” (p. 155). :contentReference[oaicite:17]{index=17}  </p></li>
<li><p>“The goal of visual analytics is to facilitate the analytical reasoning process… maximize human capacity… and reason about complex and dynamic data and situations.” (p. 68). :contentReference[oaicite:18]{index=18}  </p></li>
<li><p>“Production, presentation, and dissemination of results are often the most time‑consuming part of analysis… to be shared with their audiences.” (p. 34). :contentReference[oaicite:19]{index=19}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A — actionability is not referenced or defined in this report.</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Predictive Business Process Monitoring with LSTM Neural Networks</p>

<p>Authors: Niek Tax, Ilya Verenich, Marcello La Rosa, Marlon Dumas</p>

<p>DOI: 10.1007/978-3-319-59536-8_30</p>

<p>Year: 2017</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Process Mining / Business Process Management</p>

<p>Subdomain/Topic: Predictive Process Monitoring using LSTM Neural Networks</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 20</p>

<p>Operationalization Score: 30</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Quantitative (Experimental evaluation of LSTM models)</p>

<p>Study Context: Predictive process monitoring tasks (next activity, timestamp, suffix, remaining time prediction) on real-life event logs</p>

<p>Geographic/Institutional Context: Italy (helpdesk dataset), Netherlands (environmental permit dataset), international benchmark datasets (BPI’12)</p>

<p>Target Users/Stakeholders: Process analysts, business process managers, data scientists</p>

<p>Primary Contribution Type: Predictive modeling technique (LSTM architectures for process monitoring)</p>

<p>CL: No</p>

<p>CR: No</p>

<p>FE: No</p>

<p>TI: No</p>

<p>EX: No</p>

<p>GA: No</p>

<p>Reason if Not Eligible: The paper focuses on predictive accuracy of LSTM-based models for business process monitoring without discussing, defining, or conceptualizing “actionability” or actionable insights.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Predictive Business Process Monitoring with LSTM Neural Networks</p>

<p><strong>Authors:</strong>  </p>

<p>Niek Tax, Ilya Verenich, Marcello La Rosa, Marlon Dumas</p>

<p><strong>DOI:</strong>  </p>

<p>10.1007/978-3-319-59536-8_30</p>

<p><strong>Year:</strong>  </p>

<p>2017</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Process Mining / Business Process Management</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Predictive Process Monitoring using LSTM Neural Networks</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses limitations of existing predictive process monitoring methods that are often task-specific and sensitive to datasets. It proposes LSTM architectures capable of handling multiple predictive tasks (next event, time prediction, full case continuation, remaining cycle time) in a generalized manner and evaluates them against tailor-made baselines.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Case datasets include helpdesk logs from Italy, environmental permit logs from a Dutch municipality, and international benchmarks (BPI’12).</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process analysts, business process managers, data scientists.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative (experimental evaluation on multiple datasets).</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Predictive modeling technique using LSTM neural networks.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper explores the application of Long Short-Term Memory (LSTM) neural networks to predictive business process monitoring, aiming to deliver consistently accurate results across diverse prediction tasks and datasets. The authors present LSTM-based approaches for predicting the next event and its timestamp, the continuation of an ongoing case, and the remaining cycle time of a process instance. They compare their architectures—single-task, fully shared multi-task, and hybrid multi-task—against established baselines, including process mining techniques and other predictive models. Using real-life event logs, the results show LSTMs outperform baselines, especially on shorter prefixes. The study also identifies challenges in handling logs with repeated activities. The approach is shown to be extensible to other prediction problems within process monitoring.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A — While the paper operationalizes predictive modeling, it does not link results to "actionability."</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> No</p></li>
<li><p><strong>FE (Feasibility):</strong> No</p></li>
<li><p><strong>TI (Timeliness):</strong> No</p></li>
<li><p><strong>EX (Explainability):</strong> No</p></li>
<li><p><strong>GA (Goal Alignment):</strong> No</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Long Short-Term Memory (LSTM) neural networks</p></li>
<li><p>Recurrent Neural Networks (RNNs)</p></li>
<li><p>Multi-task learning principles</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> N/A (focus is on prediction accuracy)</p></li>
<li><p><strong>Enablers:</strong> N/A</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The authors situate their work among existing predictive monitoring methods (e.g., Petri nets, transition systems, probabilistic models, Markov chains) and prior applications of LSTMs in process mining. They aim to generalize predictive capabilities across multiple tasks, addressing dataset-specific sensitivity and the need for consistent performance.</p>

<hr />

<h2>Summary</h2>

<p>This paper proposes and evaluates LSTM neural network architectures for predictive business process monitoring tasks: predicting the next activity and timestamp, full case continuation, and remaining cycle time. Unlike traditional methods that are task-specific and dataset-sensitive, the authors’ approach uses LSTMs to model sequential dependencies in event logs, leveraging multi-task learning to improve performance. Experimental results on real-life datasets (helpdesk, BPI’12, environmental permits) show LSTM models outperform established baselines across most scenarios, particularly in short-to-medium prefixes. The study also identifies limitations when handling logs with repeated identical events, leading to overestimation in cycle time prediction. While technically strong in predictive modeling, the work does not address “actionability” in the sense of decision-oriented insight, focusing instead on prediction accuracy and model generalizability.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 20 — Strong predictive modeling contribution, but no conceptualization of actionability.</p></li>
<li><p><strong>Operationalization Score:</strong> 30 — Clear operationalization of prediction tasks, but not tied to actionable decision-making.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Predictive business process monitoring methods exploit logs of completed cases of a process in order to make predictions about running cases thereof.” (p. 1)  </p></li>
<li><p>“Existing predictive process monitoring approaches are tailor-made for specific prediction tasks and not readily generalizable.” (p. 2)  </p></li>
<li><p>“The foremost contribution of this paper is a technique to predict the next activity of a running case and its timestamp using LSTM neural networks.” (p. 14)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Planning for Action: The Impact of an Asthma Action Plan Decision Support Tool Integrated into an Electronic Health Record (EHR) at a Large Health Care System  </p>

<p>Authors: Lindsay Kuhn, Kelly Reeves, Yhenneko Taylor, Hazel Tapp, Andrew McWilliams, Andrew Gunter, Jeffrey Cleveland, Michael Dulin  </p>

<p>DOI: 10.3122/jabfm.2015.03.140248  </p>

<p>Year: 2015  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Healthcare, Decision Support Systems  </p>

<p>Subdomain/Topic: Asthma Management, Clinical Decision Support  </p>

<p>Eligibility: Yes  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 85  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Experimental and Empirical Analysis  </p>

<p>Study Context: Asthma management in large healthcare systems  </p>

<p>Geographic/Institutional Context: Carolinas HealthCare System, USA  </p>

<p>Target Users/Stakeholders: Healthcare Providers, Asthma Patients, Decision Support System Developers  </p>

<p>Primary Contribution Type: Platform implementation, outcome analysis  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong> Planning for Action: The Impact of an Asthma Action Plan Decision Support Tool Integrated into an Electronic Health Record (EHR) at a Large Health Care System  </p>

<p><strong>Authors:</strong> Lindsay Kuhn, Kelly Reeves, Yhenneko Taylor, Hazel Tapp, Andrew McWilliams, Andrew Gunter, Jeffrey Cleveland, Michael Dulin  </p>

<p><strong>DOI:</strong> 10.3122/jabfm.2015.03.140248  </p>

<p><strong>Year:</strong> 2015  </p>

<p><strong>Publication Type:</strong> Journal  </p>

<p><strong>Discipline/Domain:</strong> Healthcare, Decision Support Systems  </p>

<p><strong>Subdomain/Topic:</strong> Asthma Management, Clinical Decision Support  </p>

<p><strong>Contextual Background:</strong> The paper evaluates the integration of an electronic asthma action plan (eAAP) decision support tool into the Electronic Health Record (EHR) at the Carolinas HealthCare System. The aim of the eAAP is to streamline asthma management by providing evidence-based recommendations and creating individualized patient handouts to improve self-management. The study explores the impact of this decision support tool on asthma outcomes, including reductions in asthma exacerbations and medication use.  </p>

<p><strong>Geographic/Institutional Context:</strong> Carolinas HealthCare System, USA  </p>

<p><strong>Target Users/Stakeholders:</strong> Healthcare providers, asthma patients, decision support system developers  </p>

<p><strong>Primary Methodology:</strong> Empirical analysis of asthma outcomes before and after eAAP receipt, using propensity score matching for control comparisons  </p>

<p><strong>Primary Contribution Type:</strong> Platform implementation, outcome analysis  </p>

<h2>General Summary of the Paper</h2>

<p>This study investigates the impact of an electronic asthma action plan (eAAP) decision support tool integrated into the Electronic Health Record (EHR) system. The tool was designed to provide real-time, guideline-based decision support to healthcare providers and create personalized patient handouts. The study measured the outcomes of patients receiving the eAAP, particularly focusing on reductions in asthma exacerbations, hospital visits, and oral steroid use. Results indicated that children who received the eAAP had significantly fewer exacerbations, fewer oral steroid prescriptions, and a lower likelihood of asthma-related emergency visits. The tool was successfully integrated across multiple practices within the healthcare system, showing promise in improving patient outcomes and asthma management.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<p>Reason if Not Eligible: n/a  </p>

<h2>How Actionability is Understood</h2>

<p>In this context, actionability refers to the ability of patients and providers to use the asthma action plan to take appropriate actions in managing asthma. The eAAP provides actionable information by offering tailored recommendations for asthma management, outlining daily medications, recognizing symptom changes, and guiding patients on when to seek medical care.  </p>

<blockquote>
  <p>“Actionable information in the eAAP is delivered through clear, individualized instructions, empowering patients to manage their asthma effectively” (p. 5).  </p>
</blockquote>

<blockquote>
  <p>“Actionability is achieved by providing patients with a structured plan that includes clear instructions on what to do in the event of worsening asthma symptoms” (p. 6).</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<p>The authors identify several key factors that contribute to making asthma management actionable:</p>

<ul>
<li><p><strong>Clear Instructions:</strong> Detailed guidance on what actions to take in different scenarios (e.g., daily medication, when to use rescue medication, when to seek urgent care).  </p></li>
<li><p><strong>Personalization:</strong> The tool tailors the plan to each patient, ensuring that the instructions are relevant to their specific asthma severity and medication requirements.  </p></li>
<li><p><strong>Ease of Use:</strong> The tool is embedded within the EHR, allowing for seamless integration into the workflow, thus reducing barriers to implementation.  </p></li>
</ul>

<blockquote>
  <p>“Actionability is facilitated when patients receive tailored, clear, and contextually relevant recommendations, which are easy to implement within their daily routines” (p. 7).  </p>
</blockquote>

<blockquote>
  <p>“The eAAP's integration into the EHR allows for a streamlined and efficient process that ensures providers can easily offer actionable recommendations” (p. 8).</p>
</blockquote>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<p>The eAAP operationalizes actionability by providing a decision support tool embedded within the EHR. This tool:</p>

<ol>
<li><p><strong>Generates Tailored Action Plans:</strong> For each patient, the eAAP creates an individualized action plan based on the latest clinical guidelines.  </p></li>
<li><p><strong>Offers Real-Time Decision Support:</strong> The system provides guideline-based recommendations at the point of care, helping providers make informed decisions.  </p></li>
<li><p><strong>Supports Patient Self-Management:</strong> It generates patient handouts that provide clear instructions on how to manage asthma symptoms and when to take specific actions.  </p></li>
</ol>

<blockquote>
  <p>“The eAAP ensures actionability by offering real-time, actionable recommendations embedded within the provider's workflow, making it easier to manage asthma care” (p. 9).  </p>
</blockquote>

<blockquote>
  <p>“Patient handouts generated by the tool are tailored to individual needs, making them practical and actionable for self-management” (p. 10).</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – The action plan provides clear instructions that are easy for patients to understand and follow.  </p>

<p> &gt; “Clarity is vital to ensure that the patient understands when and how to take specific actions in response to worsening asthma” (p. 8).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – The eAAP tailors the recommendations based on the patient’s individual asthma severity and medication needs.  </p>

<p> &gt; “Contextual relevance ensures that the action plan aligns with the patient’s specific asthma control status and history” (p. 7).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – The tool integrates seamlessly into the provider’s workflow, making it feasible for providers to deliver actionable plans.  </p>

<p> &gt; “Feasibility is ensured by embedding the tool into the EHR, making it accessible at the point of care without disrupting workflow” (p. 9).  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes – The eAAP provides timely guidance that can be acted upon immediately in the event of an exacerbation.  </p>

<p> &gt; “Timeliness is critical in asthma management, and the eAAP ensures that recommendations are available when needed” (p. 9).  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – The plan is easy to understand, and the rationale behind each recommendation is clear.  </p>

<p> &gt; “Explainability is embedded in the tool's design, which provides easily understandable instructions for both patients and providers” (p. 8).  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – The recommendations align with the patient’s goal of managing asthma effectively and avoiding exacerbations.  </p>

<p> &gt; “Goal alignment ensures that the action plan helps patients achieve better asthma control, reducing hospitalizations and emergency visits” (p. 7).</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<p>The eAAP is grounded in evidence-based asthma management guidelines from the National Heart, Lung, and Blood Institute (NHLBI). The tool aims to streamline and simplify these guidelines for providers, ensuring that patients receive appropriate care and guidance.  </p>

<blockquote>
  <p>“The eAAP is based on evidence from the NHLBI asthma guidelines, which are integrated into the tool to provide real-time decision support” (p. 7).</p>
</blockquote>

<h2>Indicators or Metrics for Actionability</h2>

<p>The primary metrics for actionability in this study are <strong>asthma exacerbations</strong>, <strong>ED visits</strong>, and <strong>use of oral steroids</strong>. The study also tracks the <strong>frequency of eAAP usage</strong> as an indicator of how often the tool is being applied in practice.  </p>

<blockquote>
  <p>“Actionability is evaluated by tracking reductions in asthma exacerbations and hospital visits, as well as the uptake and use of the eAAP” (p. 6).</p>
</blockquote>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Provider resistance to new tools, complexity of asthma management guidelines, lack of incentives for using the eAAP.  </p></li>
<li><p><strong>Enablers:</strong> Integration of the tool into the EHR, clear and actionable recommendations, ease of use, and provider feedback during the pilot phase.  </p></li>
</ul>

<blockquote>
  <p>“Provider adoption was a key enabler of the tool’s success, but without clear incentives, its use may remain limited” (p. 8).  </p>
</blockquote>

<blockquote>
  <p>“Embedding the eAAP within the EHR ensured that it was easy to use and available at the point of care, making it more likely to be acted upon” (p. 9).</p>
</blockquote>

<h2>Relation to Existing Literature</h2>

<p>The paper builds on existing research around asthma self-management and clinical decision support tools. It addresses gaps in the literature by evaluating the real-world impact of an EHR-integrated asthma action plan on patient outcomes.  </p>

<blockquote>
  <p>“This study contributes to the literature on asthma self-management by demonstrating the impact of technology in improving asthma care and reducing exacerbations” (p. 10).</p>
</blockquote>

<h2>Summary</h2>

<p>The paper examines the impact of an electronic asthma action plan (eAAP) decision support tool integrated into the EHR. The tool provides evidence-based, individualized recommendations at the point of care and generates patient handouts to support self-management. The results suggest that children receiving the eAAP had significantly fewer asthma exacerbations, fewer oral steroid prescriptions, and reduced emergency visits. The study highlights the importance of technology in streamlining asthma care and improving patient outcomes.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 – The paper offers valuable insights into the impact of decision support tools on asthma management and patient outcomes.  </p></li>
<li><p><strong>Operationalization Score:</strong> 85 – The eAAP is well-implemented and evaluated in a real-world healthcare setting, though broader dissemination and impact could be further studied.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Actionable information is delivered through clear, individualized instructions, empowering patients to manage their asthma effectively” (p. 5).  </p></li>
<li><p>“The eAAP’s integration into the EHR allows for a streamlined and efficient process that ensures providers can easily offer actionable recommendations” (p. 9).  </p></li>
<li><p>“Goal alignment ensures that the action plan helps patients achieve better asthma control, reducing hospitalizations and emergency visits” (p. 7).  </p></li>
<li><p>“This study contributes to the literature on asthma self-management by demonstrating the impact of technology in improving asthma care and reducing exacerbations” (p. 10).</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>National Heart, Lung, and Blood Institute (2007). Expert Panel Report 3: Guidelines for the Diagnosis and Management of Asthma.  </p></li>
<li><p>Roberts, N., et al. (2010). Development of an Electronic Pictorial Asthma Action Plan. Patient Educ Couns.  </p></li>
<li><p>Hanson, T.K., et al. (2013). Increasing Availability to and Ascertaining Value of Asthma Action Plans. J School Health.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: The GuideLine Implementability Appraisal (GLIA): Development of an instrument to identify obstacles to guideline implementation</p>

<p>Authors: Richard N. Shiffman, Jane Dixon, Cynthia Brandt, Abdelwaheb Essaihi, Allen Hsiao, George Michel, Ryan O'Connell</p>

<p>DOI: 10.1186/1472-6947-5-23</p>

<p>Year: 2005</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Medical Informatics / Health Services Research</p>

<p>Subdomain/Topic: Clinical Practice Guideline Implementation</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 92</p>

<p>Operationalization Score: 90</p>

<p>Actionable/Actionability Used in Paper: Yes — “Implementability refers to a set of characteristics that predict ease of (and obstacles to) guideline implementation.” (p. 2)</p>

<p>Authors Argue for Need for Actionability Without Defining It: No — Definition provided.</p>

<p>Contains Definition of Actionability: Yes — “Implementability refers to a set of characteristics that predict the relative ease of implementation of guideline recommendations.” (p. 3)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes — GLIA instrument with 10 dimensions</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Mixed Methods</p>

<p>Study Context: Development and validation of an instrument to assess guideline implementability</p>

<p>Geographic/Institutional Context: Yale University, USA; national and international guideline experts</p>

<p>Target Users/Stakeholders: Guideline developers, guideline implementers</p>

<p>Primary Contribution Type: Tool/Instrument development and validation</p>

<p>CL: Yes — clarity addressed under executability and decidability criteria (p. 6)</p>

<p>CR: Yes — includes context-specific considerations such as novelty and effect on process of care (p. 3)</p>

<p>FE: Yes — feasibility linked to process changes, equipment, skills (p. 6)</p>

<p>TI: No</p>

<p>EX: Partial — implicit in the need for unambiguous statements (p. 6)</p>

<p>GA: Yes — recommendations aligned with intended use by healthcare providers (p. 3)</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>The GuideLine Implementability Appraisal (GLIA): Development of an instrument to identify obstacles to guideline implementation</p>

<p><strong>Authors:</strong>  </p>

<p>Richard N. Shiffman, Jane Dixon, Cynthia Brandt, Abdelwaheb Essaihi, Allen Hsiao, George Michel, Ryan O'Connell</p>

<p><strong>DOI:</strong>  </p>

<p>10.1186/1472-6947-5-23</p>

<p><strong>Year:</strong>  </p>

<p>2005</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Medical Informatics / Health Services Research</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Clinical Practice Guideline Implementation</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the problem that many clinical practice guidelines fail to achieve intended practice change due to intrinsic barriers in their design. It develops and validates an instrument (GLIA) to systematically identify and address such barriers.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Yale University, USA; collaboration with national and international guideline experts.</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Guideline developers, healthcare organizations implementing guidelines.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed methods — literature review, expert consensus, instrument development, pilot testing, validation exercises.</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Development and validation of an appraisal tool (GLIA).</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper introduces the GuideLine Implementability Appraisal (GLIA), an instrument designed to identify intrinsic obstacles to the successful implementation of clinical practice guidelines. The authors define "implementability" as characteristics predicting the ease or difficulty of translating recommendations into practice. Drawing from literature, expert consensus, and existing guideline appraisal tools, the authors distilled 31 items across 10 dimensions, such as Decidability, Executability, and Novelty/Innovation. The instrument was refined through validation steps including expert ranking exercises, content validity assessment, and application to real-world draft guidelines (e.g., otitis media with effusion). GLIA proved useful in revealing ambiguities, feasibility challenges, and alignment issues, enabling developers to revise recommendations for greater clarity and feasibility. The authors argue that GLIA can improve both selection and operationalization of guidelines, potentially leading to better adherence and patient outcomes.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>Yes</strong>  </p>

<ul>
<li><p>“Implementability refers to a set of characteristics that predict ease of (and obstacles to) guideline implementation.” (p. 2)  </p></li>
<li><p>“We define implementability to refer to a set of characteristics that predict the relative ease of implementation of guideline recommendations.” (p. 3)  </p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>No</strong> — The paper explicitly defines implementability.</p>

<hr />

<h2>How Actionability is Understood</h2>

<blockquote>
  <p>“Implementability refers to a set of characteristics that predict the relative ease of implementation of guideline recommendations.” (p. 3)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Clarity of what to do (Executability)</strong>  </p>

<p> &gt; “Any recommendation that does not clearly communicate what to do … is not fully ready for implementation.” (p. 6)  </p></li>
<li><p><strong>Clarity of when to do it (Decidability)</strong>  </p>

<p> &gt; “Any recommendation that does not clearly communicate … when to do it … is not fully ready for implementation.” (p. 6)  </p></li>
<li><p><strong>Compatibility with existing processes and beliefs</strong>  </p>

<p> &gt; “… may not be compatible with existing attitudes and beliefs of the guideline’s intended users …” (p. 5)  </p></li>
<li><p><strong>Feasibility in terms of resources</strong>  </p>

<p> &gt; “… requires acquisition of new equipment for many providers …” (p. 5)</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> GLIA (GuideLine Implementability Appraisal)  </p></li>
<li><p><strong>Methods/Levers:</strong> Identification of barriers via structured criteria across 10 dimensions.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Apply 9 of 10 dimensions to each recommendation; record failed criteria; suggest remedies; reach consensus among raters.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> 31 items with 4-point response options (Y/N/?/NA).  </p></li>
<li><p><strong>Implementation Context:</strong> Clinical practice guidelines in healthcare (tested on otitis media guideline).  </p></li>
</ul>

<blockquote>
  <p>“GLIA proved to be useful in identifying barriers to implementation in the draft guideline and the guideline was revised accordingly.” (p. 2)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — “what to do” and “when to do it” must be stated specifically and unambiguously. (p. 6)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — dimensions include Novelty/Innovation, Effect on Process of Care. (p. 3)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — addresses time, staff, equipment needs. (p. 5)  </p></li>
<li><p><strong>TI (Timeliness):</strong> No explicit reference.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — linked to removing ambiguity but not explicitly framed as “explainability.”  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — recommendations assessed for compatibility with intended use. (p. 3)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Presentation &amp; Formatting, Measurable Outcomes, Apparent Validity, Computability.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Diffusion of Innovation Theory  </p></li>
<li><p>Existing guideline appraisal instruments (AGREE, Cluzeau, Shaneyfelt)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Presence of unambiguous criteria (Executability, Decidability)  </p></li>
<li><p>Resource requirements (Effect on Process of Care)  </p></li>
<li><p>Compatibility with user and patient expectations (Novelty/Innovation)  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Ambiguous language; conflicting statements; resource requirements; misalignment with expectations.  </p></li>
<li><p><strong>Enablers:</strong> Clear, specific recommendations; early implementability review; consensus process for rating.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The authors build on guideline quality appraisal tools but emphasize implementability at the level of individual recommendations rather than the guideline as a whole. They position GLIA as complementary to tools like AGREE.</p>

<hr />

<h2>Summary</h2>

<p>The GLIA framework offers a systematic method for assessing and improving the implementability of clinical practice guidelines. By focusing on intrinsic characteristics that predict ease of implementation, GLIA helps identify and remediate barriers such as ambiguity, resource constraints, and misalignment with user expectations. The tool’s 10 dimensions cover clarity, contextual fit, feasibility, and computability, among others, and its validation shows consistent alignment with expert judgments. GLIA stands out for its granular application to individual recommendations, enabling targeted revisions and strategic implementation planning. While further testing is needed for reliability and predictive validity, the instrument represents a significant advance in operationalizing the concept of actionability in guideline development.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Clear definition of implementability with explicit link to actionability features; detailed conceptual framework.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Concrete instrument with defined items, dimensions, rating process, and application examples.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Implementability refers to a set of characteristics that predict the relative ease of implementation of guideline recommendations.” (p. 3)  </p></li>
<li><p>“Any recommendation that does not clearly communicate what to do … or when to do it … is not fully ready for implementation.” (p. 6)  </p></li>
<li><p>“GLIA proved to be useful in identifying barriers to implementation in the draft guideline and the guideline was revised accordingly.” (p. 2)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Thorsen &amp; Mäkelä (1999) on implementation strategies.  </p></li>
<li><p>Solberg et al. (2000) on success factors in guideline implementation.  </p></li>
<li><p>Grilli &amp; Lomas (1994) on complexity, trialability, and observability.  </p></li>
<li><p>Grol et al. (1998) on attributes differentiating followed vs. unfollowed guidelines.  </p></li>
<li><p>AGREE Collaboration (2003) on guideline quality appraisal.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Knowledge Generation Model for Visual Analytics</p>

<p>Authors: Dominik Sacha, Andreas Stoffel, Florian Stoffel, Bum Chul Kwon, Geoffrey Ellis, Daniel A. Keim</p>

<p>DOI: 10.1109/TVCG.2014.2346481</p>

<p>Year: 2014</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Visual Analytics / Computer Science</p>

<p>Subdomain/Topic: Knowledge Generation, Human-Computer Interaction, Sensemaking Models</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 88</p>

<p>Operationalization Score: 82</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — “...to support complex decision making and data exploration” (p. 2); “…valuable for future research to have an integrated framework… relevant for knowledge generation with visual analytics” (p. 2)</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes — Knowledge Generation Model for Visual Analytics</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual with comparative application</p>

<p>Study Context: Visual analytics processes and tools</p>

<p>Geographic/Institutional Context: University of Konstanz, IBM Research, Siemens Logistics</p>

<p>Target Users/Stakeholders: Visual analytics researchers, system designers, domain analysts</p>

<p>Primary Contribution Type: Integrated conceptual framework and comparative system assessment</p>

<p>CL: Yes — “...interpret them in the context of the problem domain” (p. 4)</p>

<p>CR: Yes — “...must be representative and related to the analytical problem” (p. 3)</p>

<p>FE: Partial — Implied in discussions on feasibility of system support for loops</p>

<p>TI: Partial — Mention of real-time monitoring for streaming data (p. 9)</p>

<p>EX: Yes — Discusses patterns, models, and system transparency</p>

<p>GA: Yes — Hypothesis-driven loops align analysis with goals</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Knowledge Generation Model for Visual Analytics  </p>

<p><strong>Authors:</strong>  </p>

<p>Dominik Sacha, Andreas Stoffel, Florian Stoffel, Bum Chul Kwon, Geoffrey Ellis, Daniel A. Keim  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1109/TVCG.2014.2346481  </p>

<p><strong>Year:</strong>  </p>

<p>2014  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Visual Analytics / Computer Science  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Knowledge Generation, Human-Computer Interaction, Sensemaking Models  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the lack of an integrated framework linking system- and human-focused models in visual analytics. It extends prior process models to incorporate human reasoning loops (exploration, verification, knowledge generation) alongside computational processes to improve understanding, system design, and evaluation.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of Konstanz, IBM Research, Siemens Logistics  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Researchers, system designers, visual analytics practitioners  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual model development with comparative application on four systems (Jigsaw, Knime, Tableau, HARVEST)  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Integrated conceptual framework and comparative system assessment  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper proposes an extended <em>Knowledge Generation Model</em> for visual analytics that unites system-based process models with human reasoning frameworks. It integrates data, models, and visualizations on the computational side with abductive, deductive, and inductive reasoning on the human side, organized into three feedback loops: exploration, verification, and knowledge generation. The model aims to improve understanding of how visual analytics tools support reasoning and decision-making, provide a common language for researchers, and identify gaps in tool support. The authors apply the model to real systems, illustrating its evaluative potential. Comparative analysis of Jigsaw, Knime, Tableau, and HARVEST shows varied strengths in supporting different loops. The discussion covers collaborative use, streaming data contexts, and opportunities for automated support.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No — The term “actionable” is not explicitly used in the sense of actionable insights, though decision-making support is repeatedly mentioned.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes  </p>

<blockquote>
  <p>“…to support complex decision making and data exploration” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“…valuable for future research to have an integrated framework of all processes and models relevant for knowledge generation with visual analytics” (p. 2)  </p>
</blockquote>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly: Actionability is tied to the ability of visual analytics processes and systems to produce knowledge that supports complex decision-making through iterative human–machine interaction.</p>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Contextual relevance of data:</strong>  </p>

<p> &gt; “…must be representative and related to the analytical problem…” (p. 3)  </p></li>
<li><p><strong>Interpretability in problem domain:</strong>  </p>

<p> &gt; “…interpret them in the context of the problem domain” (p. 4)  </p></li>
<li><p><strong>Evidence quality and trustworthiness:</strong>  </p>

<p> &gt; “The evidence has different qualities, which directly affects the trustworthiness of the concluded knowledge.” (p. 5)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Knowledge Generation Model for Visual Analytics  </p></li>
<li><p><strong>Methods/Levers:</strong> Integration of computational processes (data, models, visualizations) with human reasoning loops (exploration, verification, knowledge generation)  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Iterative cycles of actions, findings, hypotheses, insights, and knowledge; mapping of actions to visual or model components; feedback loops for reasoning refinement  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Use of representative, high-quality data; provenance metadata for trust assessment  </p></li>
<li><p><strong>Implementation Context:</strong> Applied to multiple visual analytics systems (Jigsaw, Knime, Tableau, HARVEST) for comparative evaluation  </p></li>
</ul>

<blockquote>
  <p>“Our model… provides a useful guideline when developing and evaluating such systems.” (p. 2)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — “…interpret them in the context of the problem domain.” (p. 4)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — “…must be representative and related to the analytical problem…” (p. 3)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — Discusses practical constraints of system support for loops (p. 8–9)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Mentions adaptation to streaming data and real-time monitoring (p. 9)  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Model emphasizes interpreting system outputs and patterns (p. 4–5)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Hypotheses drive loops and align analysis with objectives (p. 4–5)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Trustworthiness of evidence (p. 5)  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Keim et al. visual analytics process model  </p></li>
<li><p>KDD process (Fayyad et al.)  </p></li>
<li><p>InfoVis pipeline (Card et al.)  </p></li>
<li><p>Sensemaking model (Pirolli &amp; Card)  </p></li>
<li><p>Human Cognition Model (Green et al.)  </p></li>
<li><p>Interaction taxonomies (Brehmer &amp; Munzner; Norman)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Evidence quality and provenance for trust assessment  </p></li>
<li><p>Degree of support for exploration, verification, and knowledge generation loops  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Limited system support for higher-level loops; restricted model manipulation capabilities; Gulf of Execution/Evaluation gaps  </p></li>
<li><p><strong>Enablers:</strong> Integrated human–machine reasoning; provenance tracking; flexible visual–model coupling  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The model bridges system-centric and human-centric perspectives, drawing on established process, sensemaking, and interaction models, and unifies them into a holistic knowledge generation framework for visual analytics.</p>

<hr />

<h2>Summary</h2>

<p>This paper develops a <em>Knowledge Generation Model for Visual Analytics</em> that explicitly integrates computational processes (data, models, visualizations) with human reasoning loops (exploration, verification, knowledge generation). It builds upon existing system pipelines (KDD, InfoVis) and human cognition models (sensemaking, interaction taxonomies) to create a unified framework for understanding and evaluating how visual analytics tools support knowledge creation. The model defines core components—actions, findings, hypotheses, insights, and knowledge—and details their interconnections via iterative feedback loops. Applying the model to four systems (Jigsaw, Knime, Tableau, HARVEST) demonstrates its utility for comparative assessment and identifying gaps, such as insufficient support for higher-level reasoning loops. The authors discuss implications for collaborative analytics, streaming data, and automated support, emphasizing trustworthiness, interpretability, and goal alignment as key factors. While the paper does not use the term “actionable,” it addresses conditions that make outputs usable for decision-making, making it relevant for actionability studies.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 — Strong conceptual alignment with actionability in terms of conditions and mechanisms, though the term is not explicitly used.  </p></li>
<li><p><strong>Operationalization Score:</strong> 82 — Detailed operational steps through the model’s loops; examples of application to real systems; minor gaps in explicit measurement of actionability.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“...must be representative and related to the analytical problem…” (p. 3)  </p></li>
<li><p>“…interpret them in the context of the problem domain.” (p. 4)  </p></li>
<li><p>“The evidence has different qualities, which directly affects the trustworthiness of the concluded knowledge.” (p. 5)  </p></li>
<li><p>“Our model… provides a useful guideline when developing and evaluating such systems.” (p. 2)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Keim et al. [15, 16] — Visual analytics process model  </p></li>
<li><p>Fayyad et al. [8] — Knowledge Discovery in Databases (KDD) process  </p></li>
<li><p>Pirolli &amp; Card [29] — Sensemaking model  </p></li>
<li><p>Green et al. [14] — Human Cognition Model  </p></li>
<li><p>Brehmer &amp; Munzner [4] — Multi-level task typology</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: On Sense Making and the Generation of Knowledge in Visual Analytics  </p>

<p>Authors: Milena Vuckovic, Johanna Schmidt  </p>

<p>DOI: 10.3390/analytics1020008  </p>

<p>Year: 2022  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Visual Analytics, Cognitive Science  </p>

<p>Subdomain/Topic: Data Visualization, Mental Models, Knowledge Generation  </p>

<p>Eligibility: Yes  </p>

<p>Overall Relevance Score: 85  </p>

<p>Operationalization Score: 80  </p>

<p>Contains Definition of Actionability: No  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual, Qualitative  </p>

<p>Study Context: Cognitive processes in interactive visual systems  </p>

<p>Geographic/Institutional Context: Austria  </p>

<p>Target Users/Stakeholders: Data Analysts, Visualization Practitioners, Cognitive Scientists  </p>

<p>Primary Contribution Type: Conceptual Framework, Cognitive Models  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong> On Sense Making and the Generation of Knowledge in Visual Analytics  </p>

<p><strong>Authors:</strong> Milena Vuckovic, Johanna Schmidt  </p>

<p><strong>DOI:</strong> 10.3390/analytics1020008  </p>

<p><strong>Year:</strong> 2022  </p>

<p><strong>Publication Type:</strong> Journal  </p>

<p><strong>Discipline/Domain:</strong> Visual Analytics, Cognitive Science  </p>

<p><strong>Subdomain/Topic:</strong> Data Visualization, Mental Models, Knowledge Generation  </p>

<p><strong>Contextual Background:</strong> The paper explores the cognitive mechanisms behind sense-making and knowledge generation in the context of visual analytics (VA). It addresses how analysts use visualizations and interactive data systems to form mental models, which evolve through interaction with data. The paper focuses on understanding the interplay between external representations (data visualizations) and internal cognitive processes. It aims to contribute to the understanding of how interactive systems impact the formation of mental models and influence decision-making during data analysis tasks.  </p>

<p><strong>Geographic/Institutional Context:</strong> VRVis GmbH, Vienna, Austria  </p>

<p><strong>Target Users/Stakeholders:</strong> Data analysts, researchers in visual analytics and cognitive science  </p>

<p><strong>Primary Methodology:</strong> Conceptual analysis of mental models, qualitative assessment of data exploration tasks  </p>

<p><strong>Primary Contribution Type:</strong> Cognitive framework, exploration of mental model formation in data analysis  </p>

<h2>General Summary of the Paper</h2>

<p>This paper discusses the role of sense-making and cognitive processes in visual analytics, particularly focusing on how data visualization tools influence the generation of knowledge. The authors explore mental models—the cognitive imprints of data systems—formed by analysts during interactive data exploration. The paper identifies key cognitive phases involved in the data science workflow, such as discovery, integration, profiling, modeling, and reporting, and describes how these phases shape and refine mental models. Through the analysis of different visualization tools, the authors provide insights into how distinct systems (scientific, commercial, and notebook-based) affect cognitive activities and sense-making processes. The findings highlight the dynamic nature of mental models and their evolution through interaction with external visual systems.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<p>Reason if Not Eligible: n/a  </p>

<h2>How Actionability is Understood</h2>

<p>The paper does not directly address actionability in terms of user decision-making or interventions. However, it implies that actionability in visual analytics is achieved when analysts can effectively navigate and manipulate visualizations to generate meaningful insights. The cognitive models described help clarify how users interact with and make sense of data, which indirectly informs how actionable knowledge is extracted from visual systems.  </p>

<blockquote>
  <p>“The cognitive process of generating mental models from visual data systems enables analysts to make informed decisions based on visual representations and interactions” (p. 5).</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<p>The factors that contribute to actionability in visual analytics are:</p>

<ul>
<li><p><strong>Clear Visual Representations:</strong> Effective visualizations help users form accurate mental models.  </p></li>
<li><p><strong>Interactivity:</strong> The ability to interact with the data facilitates deeper engagement and clearer insights.  </p></li>
<li><p><strong>Cognitive Models:</strong> Mental models that evolve through interaction with visual systems enable users to act upon the insights derived from the data.  </p></li>
</ul>

<blockquote>
  <p>“Interactive visual systems are essential in helping users build the necessary cognitive models that drive actionable insights” (p. 6).  </p>
</blockquote>

<blockquote>
  <p>“Actionability is achieved when analysts can make sense of complex data through evolving mental models, guided by visual cues” (p. 7).</p>
</blockquote>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<p>While the paper does not explicitly define a formal process for operationalizing actionability, it suggests that actionability in visual analytics can be facilitated through:</p>

<ul>
<li><p><strong>Tool Design:</strong> The design of visualization tools should support cognitive processes by enabling the creation and refinement of mental models.  </p></li>
<li><p><strong>Iterative Interaction:</strong> Analysts’ continuous interaction with data visualizations allows for refinement of mental models, leading to actionable insights.  </p></li>
<li><p><strong>Task-Oriented Exploration:</strong> Engaging with specific tasks like data discovery, integration, and modeling helps create actionable knowledge through the evolution of mental models.  </p></li>
</ul>

<blockquote>
  <p>“Actionability is achieved through interactive tools that help analysts engage with data in an iterative, task-driven manner” (p. 6).  </p>
</blockquote>

<blockquote>
  <p>“The interaction with diverse visualization systems fosters a cycle of refining mental models, which ultimately leads to actionable insights” (p. 7).</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – The clarity of the visual representation and the mental model it generates is crucial for actionability.  </p>

<p> &gt; “Clear visual cues allow analysts to form coherent mental models, which are essential for actionable insights” (p. 5).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – The mental models formed are highly contextual, shaped by both the data and the system’s organizational structure.  </p>

<p> &gt; “The context in which the data is explored plays a significant role in shaping the mental models and actionable insights” (p. 7).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – The ease of use and interaction with the visual system influences the feasibility of generating actionable knowledge.  </p>

<p> &gt; “The usability of visualization tools directly impacts the feasibility of generating actionable insights” (p. 7).  </p></li>
<li><p><strong>TI (Timeliness):</strong> No – The paper does not focus on timeliness in decision-making or how quickly actionability can be achieved.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – The explainability of the visual system and the underlying data contributes to actionable knowledge.  </p>

<p> &gt; “Explainable visualizations help analysts understand the data, thereby making the resulting insights actionable” (p. 6).  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – The mental models and visualizations must align with the user’s goals to ensure that the insights generated are actionable.  </p>

<p> &gt; “The alignment of visual tools with the analyst’s goals is essential for ensuring that the insights are actionable” (p. 6).</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<p>The paper draws on several theories regarding cognitive processes, particularly in the context of sense-making and knowledge generation, such as the “cognitive collage” theory by Liu and Stasko (2010) and the “sense-making loop” by Pirolli and Card (2005). These theories inform the authors’ approach to understanding how mental models evolve during data exploration and how these models guide decision-making.  </p>

<blockquote>
  <p>“Mental models evolve iteratively through interaction with visual systems, forming a cycle of understanding that drives decision-making” (p. 6).</p>
</blockquote>

<h2>Indicators or Metrics for Actionability</h2>

<p>The paper does not present explicit metrics for actionability but suggests that actionability can be assessed through the quality of mental models and their ability to facilitate data-driven decision-making.  </p>

<blockquote>
  <p>“Actionability can be evaluated through the effectiveness of the mental models in driving informed decisions” (p. 7).</p>
</blockquote>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Complexity of data, inadequate tool design, lack of interactivity, insufficient domain knowledge.  </p></li>
<li><p><strong>Enablers:</strong> Clear visualization design, interactivity, iterative data exploration, task-oriented workflows.  </p></li>
</ul>

<blockquote>
  <p>“Barriers to actionability include poor tool design and lack of engagement with the data, while enablers include clear visualizations and the ability to interact with the data” (p. 6).  </p>
</blockquote>

<blockquote>
  <p>“Iterative engagement with the data through interactive visualizations helps refine mental models, which in turn supports actionable knowledge generation” (p. 7).</p>
</blockquote>

<h2>Relation to Existing Literature</h2>

<p>The paper builds on existing work in cognitive science and visualization, particularly in relation to how humans process and interact with data. It extends these theories by applying them to visual analytics systems and exploring how these systems support sense-making and knowledge generation.  </p>

<blockquote>
  <p>“This study extends existing cognitive theories by applying them to the context of visual analytics, showing how mental models evolve through interaction with interactive data visualizations” (p. 7).</p>
</blockquote>

<h2>Summary</h2>

<p>The paper explores the cognitive mechanisms behind sense-making and knowledge generation in visual analytics. It examines how analysts form and refine mental models through interaction with different types of visualization tools. The paper emphasizes the importance of clear, interactive visualizations in facilitating actionable insights and proposes a framework for understanding the dynamic and iterative nature of mental model formation in data exploration. The findings contribute to the broader understanding of how cognitive processes support data-driven decision-making in complex, interactive environments.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 – The paper offers significant insights into the cognitive aspects of visual analytics and how these impact actionable knowledge generation.  </p></li>
<li><p><strong>Operationalization Score:</strong> 80 – The paper outlines a conceptual framework but does not provide detailed operational steps for implementing actionability in practice.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Clear visual cues allow analysts to form coherent mental models, which are essential for actionable insights” (p. 5).  </p></li>
<li><p>“The context in which the data is explored plays a significant role in shaping the mental models and actionable insights” (p. 7).  </p></li>
<li><p>“Actionability can be evaluated through the effectiveness of the mental models in driving informed decisions” (p. 7).  </p></li>
<li><p>“Mental models evolve iteratively through interaction with visual systems, forming a cycle of understanding that drives decision-making” (p. 6).</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Liu, Z., &amp; Stasko, J.T. (2010). Mental Models, Visual Reasoning and Interaction in Information Visualization: A Top-down Perspective. IEEE Trans. Vis. Comput. Graph.  </p></li>
<li><p>Pirolli, P., &amp; Card, S. (2005). The Sensemaking Process and Leverage Points for Analyst Technology as Identified through Cognitive Task Analysis. International Conference on Intelligence Analysis.  </p></li>
<li><p>Mayr, E., Schreder, G., Smuc, M., &amp; Windhager, F. (2016). Measuring Mental Models of Information Visualizations. Proceedings of the BELIV Workshop.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: On Counterfactual Explanations under Predictive Multiplicity</p>

<p>Authors: Martin Pawelczyk, Klaus Broelemann, Gjergji Kasneci</p>

<p>DOI: N/A</p>

<p>Year: 2020</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Artificial Intelligence / Machine Learning</p>

<p>Subdomain/Topic: Explainable AI, Counterfactual Explanations, Predictive Multiplicity</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 82/100</p>

<p>Operationalization Score: 78/100</p>

<p>Actionable/Actionability Used in Paper: Yes – “actionable” used in connection with recommendations and recourse (e.g., “actionable recourse” p. 2; “distinct from actionability” p. 3)</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes – “distinct from actionability” (p. 3); need for recommendations individuals can act on (p. 1–2)</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: Yes – feasibility, plausibility (related), stability/invariance to model changes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes – formal definitions of Sparse and Data Support counterfactuals; cost bound framework</p>

<p>Operationalization Present: Yes – mathematical definitions, cost measures, experimental procedures</p>

<p>Primary Methodology: Conceptual + Quantitative</p>

<p>Study Context: Comparative analysis of counterfactual generation methods under predictive multiplicity</p>

<p>Geographic/Institutional Context: N/A</p>

<p>Target Users/Stakeholders: Individuals subject to automated decision-making; ML practitioners; policymakers</p>

<p>Primary Contribution Type: Theoretical framework + empirical evaluation</p>

<p>CL: Partial – clarity implied via sparsity but not as explicit dimension</p>

<p>CR: Yes – contextual relevance via data support</p>

<p>FE: Yes – feasibility as practical attainability</p>

<p>TI: Partial – timeliness as input choice (e.g., payment history features)</p>

<p>EX: Yes – explainability via formal definitions and method descriptions</p>

<p>GA: Partial – alignment to desired outcomes (achieving positive prediction)</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>On Counterfactual Explanations under Predictive Multiplicity</p>

<p><strong>Authors:</strong>  </p>

<p>Martin Pawelczyk, Klaus Broelemann, Gjergji Kasneci</p>

<p><strong>DOI:</strong>  </p>

<p>N/A</p>

<p><strong>Year:</strong>  </p>

<p>2020</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Artificial Intelligence / Machine Learning</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Explainable AI, Counterfactual Explanations, Predictive Multiplicity</p>

<p><strong>Contextual Background:</strong>  </p>

<p>This paper examines how the presence of multiple equally accurate predictive models (predictive multiplicity) affects counterfactual explanations, particularly their cost, stability, and robustness. It contrasts sparse (minimal change) and data support (distribution-grounded) approaches, both conceptually and empirically.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>N/A</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Individuals impacted by automated decisions, ML developers, policymakers</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual + Quantitative</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Theoretical framework and empirical evaluation</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper explores counterfactual explanations in the context of <em>predictive multiplicity</em>, where multiple equally accurate models may yield different decisions. It distinguishes between <strong>Sparse counterfactuals</strong> (minimal changes in norm) and <strong>Data Support counterfactuals</strong> (recommendations grounded in the data distribution). Through theoretical analysis, the authors provide bounds on the costs of counterfactuals under model changes, introducing metrics such as the <em>cost of negative surprise</em>. Empirical tests on real-world datasets (“Give Me Some Credit” and HELOC) show that while data-supported counterfactuals are costlier, they are more robust to changes in the predictive model. The paper concludes that sparsity is not always optimal when recommendations need to remain valid across different plausible models.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>Yes</strong> – Examples:</p>

<ul>
<li><p>“distinct from actionability (Ustun et al., 2019)” (p. 3)</p></li>
<li><p>“Towards realistic individual recourse and actionable explanations…” (p. 10, citing Joshi et al. 2019)</p></li>
<li><p>“actionable recourse in linear classification” (p. 10, citing Ustun et al. 2019)</p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>Yes</strong> – Quotes:</p>

<ul>
<li><p>“Distinct from actionability… They only demand that immutable inputs shall not be changed…” (p. 3)</p></li>
<li><p>“Recommendations that individuals can realistically translate into lived realities” (p. 7)</p></li>
<li><p>“It is crucial to provide counterfactual recommendations… which humans can rely on when working towards their goals” (p. 9)</p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly: Actionability is tied to producing counterfactual recommendations that individuals can feasibly implement, are grounded in real-world data distribution, and remain valid despite model changes.  </p>

<blockquote>
  <p>“Recommendations that end-users can realistically translate into lived realities” (p. 7)  </p>
</blockquote>

<blockquote>
  <p>“Ideally based on models that causally… relate inputs to targets to avoid the impact of predictive multiplicity” (p. 9)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Feasibility (Attainability)</strong>  </p>

<p> &gt; “…attainable… demand that immutable inputs shall not be changed…” (p. 3)  </p></li>
<li><p><strong>Plausibility/Data Support</strong>  </p>

<p> &gt; “…supported by the true data distribution…” (p. 3)  </p></li>
<li><p><strong>Stability/Invariance to Model Changes</strong>  </p>

<p> &gt; “…robust to predictive multiplicity… recommendations that are invariant to small… and large… model perturbations” (p. 8)  </p></li>
<li><p><strong>Semantic Coherence</strong>  </p>

<p> &gt; “…appear to make sense and seem consistent” (p. 11)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Sparse Counterfactuals, Data Support Counterfactuals</p></li>
<li><p><strong>Methods/Levers:</strong> Norm minimization (<code>p</code>-norm), density estimation via variational autoencoders, nearest-neighbor search in latent space</p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Define admissible counterfactual set (sparse or data-supported)  </p>

<p> 2. Optimize for minimal change or closeness to data distribution  </p>

<p> 3. Measure costs (percentile shift metrics) and robustness (transferability under model change)</p></li>
<li><p><strong>Data &amp; Measures:</strong> Two real-world credit datasets; cost metrics (<code>cost1</code>, <code>cost2</code>), transferability rate <code>T</code></p></li>
<li><p><strong>Implementation Context:</strong> Credit risk classification</p></li>
</ul>

<blockquote>
  <p>“Definition 2 essentially demands… pdata(x̃) &gt; 0… comes at a cost…” (p. 3)  </p>
</blockquote>

<blockquote>
  <p>“We use the method as suggested in Pawelczyk et al. (2020)… leveraging latent space… to search for counterfactual recommendations” (p. 7)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Partial – implicit via sparsity (clear minimal changes), not formalized</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – relevance ensured via data support  </p>

<p> &gt; “…supported by the true data distribution” (p. 3)</p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – immutable features respected, attainable suggestions  </p>

<p> &gt; “…realistically translate into lived realities” (p. 7)</p></li>
<li><p><strong>TI (Timeliness):</strong> Partial – payment history features as mutable inputs imply time-related considerations (p. 9)</p></li>
<li><p><strong>EX (Explainability):</strong> Yes – formal definitions, cost bounds, visual illustrations</p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial – recommendations aim at achieving desired classification outcome</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Stability/invariance to model changes (p. 8), semantic coherence (p. 11)</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Predictive Multiplicity (Breiman 2001; Marx et al. 2019)</p></li>
<li><p>Cost bounds for actionable recourse (Ustun et al. 2019)</p></li>
<li><p>Density-based plausibility (Laugel et al. 2019)</p></li>
<li><p>Variational Autoencoders for data distribution modeling</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Cost1: Total percentile shift (attainability measure)  </p></li>
<li><p>Cost2: Maximum percentile shift (difficulty of most challenging feature change)  </p></li>
<li><p>Transferability rate <code>T</code> across models (stability/invariance metric)  </p></li>
<li><p>Cost of Negative Surprise (change in cost after model switch)</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Predictive multiplicity; model instability; recommendations not grounded in real-world data; logical inconsistencies in sparse counterfactuals</p></li>
<li><p><strong>Enablers:</strong> Data support via density modeling; causal relationships; respecting immutability; semantic plausibility</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper builds on the actionable recourse literature (Ustun et al. 2019) but extends it to handle multiple plausible models. It integrates ideas from density-based plausibility (Laugel et al. 2019) and robustness to model changes, offering formal cost bounds not previously addressed in counterfactual explanation research.</p>

<hr />

<h2>Summary</h2>

<p>This paper addresses the gap in understanding how counterfactual explanations perform under predictive multiplicity—where multiple equally valid models exist. It contrasts sparse and data-supported counterfactuals, introducing formal cost relationships and upper bounds for recommendation robustness when switching models. Empirical work shows that while sparse counterfactuals are cheaper under a fixed model, they are less robust to model changes. Data-supported counterfactuals, though costlier, maintain validity across models and produce semantically coherent, realistic suggestions. The work implicitly treats actionability as the combination of feasibility, contextual relevance, and stability over time, operationalized through respect for immutable features, grounding in the data distribution, and resilience to predictive multiplicity. This challenges the default preference for minimal-change recommendations in consequential decision-making contexts.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 82/100 – Strong implicit engagement with actionability and operational criteria, though lacking an explicit formal definition.</p></li>
<li><p><strong>Operationalization Score:</strong> 78/100 – Clear methodology to produce and measure actionable-like recommendations; metrics directly tied to feasibility and robustness.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Distinct from actionability… They only demand that immutable inputs shall not be changed…” (p. 3)  </p></li>
<li><p>“Recommendations that end-users can realistically translate into lived realities” (p. 7)  </p></li>
<li><p>“Supported by the true data distribution” (p. 3)  </p></li>
<li><p>“Robust to predictive multiplicity… invariant to… model perturbations” (p. 8)  </p></li>
<li><p>“It is crucial to provide counterfactual recommendations… which humans can rely on when working towards their goals” (p. 9)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Ustun et al. (2019) – Actionable recourse in linear classification  </p></li>
<li><p>Joshi et al. (2019) – Realistic individual recourse and actionable explanations  </p></li>
<li><p>Karimi et al. (2020a) – Model-agnostic counterfactual explanations for consequential decisions</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Modelling and quantifying the behaviours of students in lecture capture environments  </p>

<p>Authors: Christopher Brooks, Graham Erickson, Jim Greer, Carl Gutwin  </p>

<p>DOI: 10.1016/j.compedu.2014.03.002  </p>

<p>Year: 2014  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Education Technology / Learning Analytics  </p>

<p>Subdomain/Topic: Lecture capture usage patterns, predictive modelling of student behaviour  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 80 – The paper uses the term “actionable” explicitly in the context of when model-based insights can trigger interventions and provides measurable, behaviour-based definitions.  </p>

<p>Operationalization Score: 75 – Presents a concrete modelling approach using machine learning (clustering) with explicit criteria for “actionability” in early-alert systems.  </p>

<p>Actionable/Actionability Used in Paper: Yes – “We introduce the term ‘actionable’ to denote when it would be reasonable for an early alert system to intervene and recommend a learner change their behaviour.” (p. 288)  </p>

<p>Authors Argue for Need for Actionability Without Defining It: No – The term is defined explicitly in context of interventions.  </p>

<p>Contains Definition of Actionability: Yes – See quote above.  </p>

<p>Contains Systematic Features/Dimensions: Yes – Actionability tied to confidence in predictive classification, temporal context (when in the semester), and intended intervention type.  </p>

<p>Contains Explainability: Partial – Clusters are statistically generated and explained descriptively, but no deep interpretability model is discussed.  </p>

<p>Contains Interpretability: Partial – Descriptions of learner clusters aid understanding, but interpretability in predictive modelling sense is limited.  </p>

<p>Contains Framework/Model: Yes – Abstract five-cluster usage model with predictive application.  </p>

<p>Operationalization Present: Yes – Weekly viewing behaviour patterns, clustering (k-means), model validation, and integration into early-alert triggers.  </p>

<p>Primary Methodology: Quantitative (unsupervised machine learning with correlation analysis)  </p>

<p>Study Context: Second-year undergraduate science courses using lecture capture  </p>

<p>Geographic/Institutional Context: Research-intensive university in Canada  </p>

<p>Target Users/Stakeholders: Educational researchers, instructional designers, instructors, early-alert system developers  </p>

<p>Primary Contribution Type: Behavioural usage model with predictive application  </p>

<p>CL: Yes – Viewing patterns clearly categorised into labelled clusters with behavioural descriptors.  </p>

<p>CR: Yes – Patterns linked to course timeline (midterms, finals) and applicable to instructional context.  </p>

<p>FE: Yes – Intervention feasibility linked to timing and predictive accuracy thresholds.  </p>

<p>TI: Yes – Actionability discussed in weekly terms, showing when predictions become reliable.  </p>

<p>EX: Partial – Explains clusters descriptively but not algorithmic reasoning in detail.  </p>

<p>GA: Yes – Interventions tied to improving student success outcomes.  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Modelling and quantifying the behaviours of students in lecture capture environments</p>

<p><strong>Authors:</strong>  </p>

<p>Christopher Brooks, Graham Erickson, Jim Greer, Carl Gutwin</p>

<p><strong>DOI:</strong>  </p>

<p>10.1016/j.compedu.2014.03.002</p>

<p><strong>Year:</strong>  </p>

<p>2014</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Education Technology / Learning Analytics</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Lecture capture usage patterns, predictive modelling of student behaviour</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper examines whether patterns of lecture capture usage—rather than lecture capture availability alone—correlate with student performance. Using unsupervised machine learning, the authors cluster viewing behaviours and develop a generalisable model for categorising learners, validating it across multiple cohorts and exploring its predictive use in early-alert interventions.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Research-intensive university in Canada</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Educational researchers, instructional designers, instructors, early-alert system developers</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative (unsupervised machine learning with correlation analysis)</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Behavioural usage model with predictive application</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The study investigates patterns of student engagement with lecture capture technology and their relationship to academic performance. Using detailed interaction logs from three cohorts of second-year science students, the authors applied k-means clustering to classify learners into five distinct behavioural groups: High Activity, Just-In-Time, Early, Deferred, and Minimal Activity. One group—High Activity—showed a consistent positive correlation with higher grades. The model was validated across cohorts and adapted to a related course. The paper also explores predictive modelling, introducing “actionable” moments when early-alert interventions could be made, based on the confidence of cluster membership predictions as the semester progresses. The results suggest that consistent weekly engagement is associated with better outcomes and that the developed model can inform targeted instructional support.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>Yes.  </p>

<blockquote>
  <p>“We introduce the term ‘actionable’ to denote when it would be reasonable for an early alert system to intervene and recommend a learner change their behaviour.” (p. 288)</p>
</blockquote>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No – The term is explicitly defined in context.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is defined in terms of the point in the semester when a student’s behaviour can be confidently classified into a usage pattern, allowing for meaningful intervention.  </p>

<blockquote>
  <p>“We introduce the term ‘actionable’ to denote when it would be reasonable for an early alert system to intervene and recommend a learner change their behaviour.” (p. 288)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Sufficient predictive confidence in behavioural classification</strong>  </p>

<p> &gt; “If there is sufficient confidence that a learner falls into one of the identified clusters as the semester progresses, then it is reasonable to take action…” (p. 288)</p></li>
<li><p><strong>Temporal relevance to intervention window</strong>  </p>

<p> &gt; “…depending on the instructional intervention being instigated, different values of how actionable the data is may be of interest.” (p. 288)</p></li>
<li><p><strong>Clear behavioural patterns linked to outcomes</strong>  </p>

<p> &gt; “By week eight it is possible to differentiate all of the clusters from one another.” (p. 288)</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Abstract five-cluster usage model for lecture capture behaviour.</p></li>
<li><p><strong>Methods/Levers:</strong> Weekly aggregation of viewership data, k-means clustering, error measurement, cross-cohort validation.</p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Log student interactions with lecture capture system.  </p>

<p> 2. Aggregate into binary weekly watch/no-watch data.  </p>

<p> 3. Apply k-means clustering (k=5) to identify behavioural patterns.  </p>

<p> 4. Create abstract model from initial cohort.  </p>

<p> 5. Validate on new cohorts and related courses.  </p>

<p> 6. Use model during semester to predict likely final cluster membership.  </p>

<p> 7. Define “actionable” weeks for potential intervention.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Minutes of video watched per week; academic week relative to midterm/final; error rates between cluster fits.</p></li>
<li><p><strong>Implementation Context:</strong> Large-enrollment, second-year science courses at a Canadian research university.  </p></li>
</ul>

<blockquote>
  <p>“We introduce the term ‘actionable’ to denote when it would be reasonable for an early alert system to intervene…” (p. 288)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – Distinctly labelled clusters with described behavioural patterns.  </p>

<p> &gt; “…categorize learners in a course into groups with behaviours corresponding to pedagogically meaningful patterns…” (p. 285)</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – Patterns tied to academic calendar events like midterms and finals.  </p>

<p> &gt; “Week 8 represents a calendar week that ends with a midterm examination.” (p. 285)</p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – Intervention timing linked to prediction accuracy milestones.  </p>

<p> &gt; “…by week eight it is possible to differentiate all of the clusters from one another.” (p. 288)</p></li>
<li><p><strong>TI (Timeliness):</strong> Yes – Weekly prediction tables identify earliest actionable points.  </p>

<p> &gt; “…depending on the instructional intervention… different values of how actionable the data is may be of interest.” (p. 288)</p></li>
<li><p><strong>EX (Explainability):</strong> Partial – Clusters explained descriptively; model mechanics not deeply interpretable.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – Aim is to improve student performance via targeted intervention.  </p>

<p> &gt; “…recommend a learner change their behaviour.” (p. 288)</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Machine learning-based behavioural modelling (unsupervised clustering)</p></li>
<li><p>Learning analytics for early-alert systems</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Week in semester when cluster membership can be confidently predicted</p></li>
<li><p>Prediction accuracy rates (true/false positives/negatives)</p></li>
<li><p>Error rates in model fit</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Early-semester ambiguity between clusters (p. 288)  </p>

<p> - Model misfit in cross-domain applications (p. 287)  </p>

<p> - Limited interpretability for small clusters</p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Large, detailed interaction datasets  </p>

<p> - Consistent weekly content availability  </p>

<p> - Cohort-level validation across years</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper contrasts with Leadbeater et al. (2013), noting that its statistically derived clusters differ from simple high/low usage categorisations and may better capture behaviours predictive of performance. It positions usage patterns—not technology presence—as the driver of learning benefits.</p>

<hr />

<h2>Summary</h2>

<p>This paper presents a data-driven model for classifying student lecture capture behaviours and linking them to academic performance. Using weekly viewing data, the authors identified five behavioural clusters and found that consistent weekly engagement (“High Activity”) correlates positively with grades. The model generalises across cohorts and a related course, with modest error increases. Importantly, the authors define “actionability” as the point in time when a learner’s behaviour can be confidently classified, enabling targeted interventions through early-alert systems. Operationalisation includes weekly monitoring, predictive modelling, and intervention planning based on temporal and confidence thresholds. While interpretability is partial, the work offers a clear, replicable framework for making behavioural learning analytics actionable, balancing predictive accuracy with pedagogical relevance.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 80 – Strong, explicit definition of actionability in context of early-alert interventions; measurable via predictive accuracy; directly linked to behaviour patterns and learning outcomes.  </p></li>
<li><p><strong>Operationalization Score:</strong> 75 – Detailed model-building process, validation steps, and intervention timing logic; partial explainability limits full operational clarity.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We introduce the term ‘actionable’ to denote when it would be reasonable for an early alert system to intervene and recommend a learner change their behaviour.” (p. 288)  </p></li>
<li><p>“By week eight it is possible to differentiate all of the clusters from one another.” (p. 288)  </p></li>
<li><p>“…categorize learners in a course into groups with behaviours corresponding to pedagogically meaningful patterns…” (p. 285)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li>Leadbeater, W., Shuttleworth, T., Couperthwaite, J., &amp; Nightingale, K. P. (2013) – Contrasted for differing operational definitions of usage/activity.</li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Health digital state and Smart EHR systems</p>

<p>Authors: Luca Dan Serbanati</p>

<p>DOI: https://doi.org/10.1016/j.imu.2020.100494</p>

<p>Year: 2020</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Health Informatics</p>

<p>Subdomain/Topic: Digital Health, Electronic Health Records (EHR), Decision Support Systems</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 92</p>

<p>Operationalization Score: 95</p>

<p>Actionable/Actionability Used in Paper: Yes — “assist healthcare professionals in making decisions using the HDS” (p. 1); “HDS… shapes the knowledge that underpins the decisions of healthcare professionals when diagnosing and establishing treatment” (p. 1); “proactively offering solutions, and helping them diagnose and decide on the right treatment” (p. 1)</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — “improve business processes in health and care systems through digitalization” (p. 4); “intelligent support for medical decisions” (p. 6)</p>

<p>Contains Definition of Actionability: No — but defines “health digital state” as a concept enabling actionable decision support</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes — Smart EHR conceptual model, VHR architecture, HDS generation algorithm</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual</p>

<p>Study Context: Health and care systems digital transformation</p>

<p>Geographic/Institutional Context: N/A (conceptual, references EU and national systems)</p>

<p>Target Users/Stakeholders: Healthcare professionals, health system designers, policymakers</p>

<p>Primary Contribution Type: Conceptual Framework and System Architecture</p>

<p>CL: Yes — “holistic picture of their health” (p. 2)</p>

<p>CR: Yes — “contextualize all these observations… according to a digitalized conceptual model of health” (p. 2)</p>

<p>FE: Yes — “propose better solutions for the diagnosis and treatment” (p. 4)</p>

<p>TI: Yes — “proactive dispatching of significant notifications” (p. 4)</p>

<p>EX: Yes — “highlighting the possible internal contradictions… proposing solutions for their elimination” (p. 11)</p>

<p>GA: Yes — “assist… in making decisions… addressing the patient’s concerns, fears… to improve health status” (p. 14)</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Health digital state and Smart EHR systems  </p>

<p><strong>Authors:</strong>  </p>

<p>Luca Dan Serbanati  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1016/j.imu.2020.100494  </p>

<p><strong>Year:</strong>  </p>

<p>2020  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Health Informatics  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Digital Health, Electronic Health Records (EHR), Decision Support Systems  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the need for a digitized representation of health — the “Health Digital State” (HDS) — and its integration into a Smart EHR infrastructure to support actionable decision-making in healthcare. It draws from conceptual modeling, EHR standards (HL7, CONTSYS), and IT/AI advancements to enable a holistic, contextual, and dynamic view of a patient’s health.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>No specific geographic study setting; concepts are positioned for use in EU and national health system contexts.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Healthcare professionals, EHR system architects, policymakers, public health planners.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework and system architecture  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper proposes the Health Digital State (HDS) — a digitized, holistic, and contextual representation of an individual’s health — as a foundational concept for digital transformation in health and care systems. It critiques the limitations of current EHR systems, which store fragmented health documents, and introduces the Smart EHR system, centered on the Virtual Health Record (VHR), to intelligently integrate structured and unstructured data from multiple sources. The Smart EHR is designed to provide healthcare professionals with a complete, context-aware, and actionable picture of patient health, facilitating improved diagnosis, treatment, and prevention. The work includes conceptual modeling (aligned with HL7 and CONTSYS standards), a layered system architecture, and an algorithm for generating the HDS. It envisions proactive decision support, interoperability, and integration across health domains, and emphasizes the role of AI and IT in supporting evidence-based, patient-centered care.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>Yes.  </p>

<ul>
<li><p>“assist healthcare professionals in making decisions using the HDS” (p. 1)  </p></li>
<li><p>“HDS… shapes the knowledge that underpins the decisions of healthcare professionals when diagnosing and establishing treatment” (p. 1)  </p></li>
<li><p>“proactively offering solutions, and helping them diagnose and decide on the right treatment” (p. 1)  </p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes.  </p>

<ul>
<li><p>“improve business processes in health and care systems through digitalization” (p. 4)  </p></li>
<li><p>“intelligent support for medical decisions” (p. 6)  </p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly understood as providing healthcare professionals with a digitally constructed, comprehensive, and context-aware health representation (HDS) that can directly inform diagnosis, treatment, and prevention decisions.  </p>

<blockquote>
  <p>“assist healthcare professionals in making decisions… addressing the patient’s concerns, fears… to improve health status” (p. 14)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Holistic and contextual health representation</strong>  </p>

<p> &gt; “contextualize all these observations… according to a digitalized conceptual model of health” (p. 2)  </p></li>
<li><p><strong>Evidence-based integration</strong>  </p>

<p> &gt; “digitized… from authoritative sources” (p. 22)  </p></li>
<li><p><strong>Proactive notification and support</strong>  </p>

<p> &gt; “proactive dispatching of significant notifications” (p. 4)  </p></li>
<li><p><strong>Conflict resolution and data cleaning</strong>  </p>

<p> &gt; “highlighting the possible internal contradictions… proposing solutions for their elimination” (p. 11)  </p></li>
<li><p><strong>Goal-oriented alignment</strong>  </p>

<p> &gt; “assist… in making decisions… addressing the patient’s concerns, fears… to improve health status” (p. 14)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Smart EHR System, Virtual Health Record (VHR), Health Digital State (HDS)  </p></li>
<li><p><strong>Methods/Levers:</strong> Conceptual modeling (HL7, CONTSYS), semantic networks, ontology-driven data structuring, decision support algorithms, HDS generation process  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Data extraction from structured/unstructured sources → semantic integration via VHR → creation and update of DIHSs → conflict resolution → aggregation into HDS → presentation to healthcare professional → decision support for diagnosis, care plan, prevention  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Quantifiable health parameters, structured clinical data, environmental and lifestyle data, standardized medical classifications (SNOMED, ICD, LOINC)  </p></li>
<li><p><strong>Implementation Context:</strong> National/regional EHR systems integrated with Smart EHR platform  </p></li>
</ul>

<blockquote>
  <p>“HDS… is the digitization of the concept of health, a holistic and customized image of the well-being of each individual” (p. 22)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — “holistic picture of their health” (p. 2)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — “contextualize all these observations… according to a digitalized conceptual model of health” (p. 2)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — “propose better solutions for the diagnosis and treatment” (p. 4)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — “proactive dispatching of significant notifications” (p. 4)  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — “highlighting the possible internal contradictions… proposing solutions for their elimination” (p. 11)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — “assist… in making decisions… addressing the patient’s concerns, fears… to improve health status” (p. 14)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Interoperability — “interoperable, holistic synthesis of all the available authoritative data” (p. 22)  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>HL7 and CONTSYS standards for health informatics  </p></li>
<li><p>Semantic networks for modeling relationships between health states  </p></li>
<li><p>Digital twin and avatar concepts in healthcare  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Completeness and non-redundancy of health data in HDS  </p></li>
<li><p>Resolution of conflicts in health data  </p></li>
<li><p>Coverage of health questionnaire slots with authoritative observations  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Fragmented and unstructured EHR data; varying specializations and subjective interpretations; lack of interoperable infrastructures  </p>

<p> &gt; “healthcare professionals… have different opinions… or the health of the individual has changed over time” (p. 14)  </p></li>
<li><p><strong>Enablers:</strong> Smart EHR’s semantic integration, proactive decision support, HDS as holistic health representation  </p>

<p> &gt; “assist healthcare professionals… by providing… a holistic image” (p. 11)  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds upon HL7, CONTSYS, MeSH, UMLS, and digital health ecosystem frameworks. Extends prior EHR conceptualizations by introducing the HDS as a directly actionable construct for healthcare decision-making.</p>

<hr />

<h2>Summary</h2>

<p>This paper presents the “Health Digital State” (HDS) as a novel digital equivalent of the health concept, designed to support actionable decision-making in healthcare. The HDS is generated through the Smart EHR system’s Virtual Health Record (VHR), which integrates structured and unstructured data from diverse sources, resolves conflicts, and organizes information into a holistic, context-aware representation. The authors emphasize that current EHRs fail to provide this comprehensive view, leading to fragmented decision-making. Their conceptual framework draws on HL7 and CONTSYS standards, semantic modeling, and digital twin concepts to define the Smart EHR architecture, VHR services, and an algorithm for generating HDS. Actionability emerges from the HDS’s clarity, contextual relevance, feasibility, timeliness, explainability, and goal alignment, enabling healthcare professionals to make informed, proactive decisions. The model aims to transform health systems toward patient-centered care, prevention, and integration across services, with potential applications in diagnosis, treatment planning, and population health management.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Strong conceptual definition of HDS as enabling actionable healthcare insights, with detailed dimensions and clear link to decision-making.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Provides explicit, step-by-step algorithm for generating HDS, integrated into a coherent system architecture with implementation guidance.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“HDS… shapes the knowledge that underpins the decisions of healthcare professionals when diagnosing and establishing treatment” (p. 1)  </p></li>
<li><p>“contextualize all these observations… according to a digitalized conceptual model of health” (p. 2)  </p></li>
<li><p>“highlighting the possible internal contradictions… proposing solutions for their elimination” (p. 11)  </p></li>
<li><p>“HDS… is the digitization of the concept of health, a holistic and customized image of the well-being of each individual” (p. 22)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>HL7 (Health Level Seven International) standards  </p></li>
<li><p>CONTSYS (Continuity of Care) ISO 13940:2016  </p></li>
<li><p>MeSH (Medical Subject Headings)  </p></li>
<li><p>UMLS (Unified Medical Language System)  </p></li>
<li><p>Digital twin concepts in healthcare (Bruynseels et al., 2018)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: From Data Mining to Knowledge Discovery in Databases  </p>

<p>Authors: Usama Fayyad, Gregory Piatetsky-Shapiro, Padhraic Smyth  </p>

<p>DOI: N/A  </p>

<p>Year: 1996  </p>

<p>Publication Type: Journal (AI Magazine)  </p>

<p>Discipline/Domain: Computer Science / Artificial Intelligence  </p>

<p>Subdomain/Topic: Knowledge Discovery in Databases (KDD), Data Mining  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 78 – The paper defines key concepts tied to usefulness and outlines explicit criteria like validity, novelty, usefulness, and understandability, but does not use the term “actionability.”  </p>

<p>Operationalization Score: 70 – Provides a detailed multistep process for achieving useful knowledge, including evaluation metrics, but not explicitly framed under “actionability.”  </p>

<p>Actionable/Actionability Used in Paper: No  </p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes – e.g., “lead to some benefit to the user or task” (p. 41); “can be interpreted as useful or interesting knowledge” (p. 40)  </p>

<p>Contains Definition of Actionability: No – Defines “useful knowledge” with similar traits.  </p>

<p>Contains Systematic Features/Dimensions: Yes – validity, novelty, usefulness, understandability.  </p>

<p>Contains Explainability: Partial – “understandable patterns” (p. 41), examples of interpretability trade-offs.  </p>

<p>Contains Interpretability: Yes – stresses importance of models being human-interpretable.  </p>

<p>Contains Framework/Model: Yes – KDD process model with steps and evaluation metrics.  </p>

<p>Operationalization Present: Yes – step-by-step KDD process description.  </p>

<p>Primary Methodology: Conceptual / Review  </p>

<p>Study Context: Cross-domain, examples from science and business applications.  </p>

<p>Geographic/Institutional Context: Various; authors from Microsoft Research, GTE Labs, University of California Irvine, Jet Propulsion Laboratory.  </p>

<p>Target Users/Stakeholders: Data scientists, AI researchers, domain experts in applied fields.  </p>

<p>Primary Contribution Type: Conceptual framework and process model for KDD.  </p>

<p>CL: Yes – “understandable patterns” (p. 41)  </p>

<p>CR: Yes – Focus on domain-specific utility and prior knowledge relevance (p. 49)  </p>

<p>FE: Partial – Implied in “lead to some benefit… possibly in dollars saved” (p. 41)  </p>

<p>TI: No – Timeliness not explicitly addressed  </p>

<p>EX: Partial – Focus on interpretability and visualization, but not as a formal dimension (p. 40, 50)  </p>

<p>GA: Yes – End-user goals guide process from the start (p. 42)  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>From Data Mining to Knowledge Discovery in Databases  </p>

<p><strong>Authors:</strong>  </p>

<p>Usama Fayyad, Gregory Piatetsky-Shapiro, Padhraic Smyth  </p>

<p><strong>DOI:</strong>  </p>

<p>N/A  </p>

<p><strong>Year:</strong>  </p>

<p>1996  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal (AI Magazine)  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Artificial Intelligence  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Knowledge Discovery in Databases (KDD), Data Mining  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>This seminal AI Magazine article synthesizes developments in knowledge discovery and data mining during the 1990s, framing KDD as a multistep process for deriving useful and understandable knowledge from large datasets. The authors integrate perspectives from AI, statistics, and database systems, outlining definitions, applications, methods, and research challenges.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Microsoft Research, GTE Laboratories, University of California Irvine, Jet Propulsion Laboratory.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Data scientists, AI researchers, and domain specialists in applied analytics.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual / Review  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework and process model  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper distinguishes between “data mining” and “knowledge discovery in databases” (KDD), positioning data mining as one step within the broader KDD process. It presents a formal definition of KDD as the process of identifying valid, novel, potentially useful, and understandable patterns in data, and outlines the nine steps of the KDD process—from understanding the domain to acting on discovered knowledge. The authors illustrate applications across science, business, and government, and detail methodological considerations including model representation, evaluation, and search. They also provide a taxonomy of data-mining methods, discuss integration with other systems, and outline technical and research challenges such as scalability, noise, overfitting, and interpretability.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No – The terms “actionable” or “actionability” do not appear. However, the paper emphasizes “usefulness” and “benefit to the user” as essential pattern qualities.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes:  </p>

<blockquote>
  <p>“We also want patterns to be… potentially useful, that is, lead to some benefit to the user or task.” (p. 41)  </p>
</blockquote>

<blockquote>
  <p>“KDD places a special emphasis on finding understandable patterns that can be interpreted as useful or interesting knowledge.” (p. 40)  </p>
</blockquote>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly, actionability is framed as the combination of validity, novelty, usefulness, and understandability in discovered patterns, where usefulness includes leading to measurable benefits for the user.</p>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Validity</strong>:  </p>

<p> &gt; “The discovered patterns should be valid on new data with some degree of certainty.” (p. 41)  </p></li>
<li><p><strong>Novelty</strong>:  </p>

<p> &gt; “Patterns to be novel… at least to the system and preferably to the user.” (p. 41)  </p></li>
<li><p><strong>Usefulness</strong>:  </p>

<p> &gt; “… lead to some benefit to the user or task.” (p. 41)  </p></li>
<li><p><strong>Understandability</strong>:  </p>

<p> &gt; “Finally, the patterns should be understandable, if not immediately then after some postprocessing.” (p. 41)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> KDD process model  </p></li>
<li><p><strong>Methods/Levers:</strong> Domain understanding, data selection, cleaning, reduction, transformation, data mining, interpretation, and action.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Nine-step iterative process (p. 42)  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Measures of certainty, utility, simplicity; interestingness functions.  </p></li>
<li><p><strong>Implementation Context:</strong> Broad applicability across business, science, and government.  </p></li>
</ul>

<blockquote>
  <p>“Ninth is acting on the discovered knowledge: using the knowledge directly, incorporating the knowledge into another system for further action, or simply documenting it…” (p. 42)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – “understandable patterns” (p. 41)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – importance of domain knowledge and relevant attributes (p. 49)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial – implied in “lead to some benefit… possibly in dollars saved” (p. 41)  </p></li>
<li><p><strong>TI (Timeliness):</strong> No – not explicitly addressed  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial – discussion of interpretability vs. complexity (p. 40, 50)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – domain goals shape KDD process from the start (p. 42)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Novelty, validity, simplicity  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Statistical modeling  </p></li>
<li><p>Machine learning  </p></li>
<li><p>Pattern recognition  </p></li>
<li><p>Database systems theory  </p></li>
<li><p>Interestingness functions as evaluation  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Prediction accuracy on new data  </p></li>
<li><p>Utility measures (e.g., cost savings)  </p></li>
<li><p>Simplicity measures (description length)  </p></li>
<li><p>Interestingness thresholds  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p><strong>Barriers:</strong>  </p>

<ul>
<li><p>High dimensionality (p. 49)  </p></li>
<li><p>Noise and missing data (p. 50)  </p></li>
<li><p>Overfitting (p. 49)  </p></li>
<li><p>Lack of domain knowledge (p. 49)  </p></li>
</ul>

<p><strong>Enablers:</strong>  </p>

<ul>
<li><p>Data cleaning and integration (p. 40)  </p></li>
<li><p>Incorporating prior knowledge (p. 49)  </p></li>
<li><p>Interactive and iterative process (p. 42)  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on machine learning, statistics, and database systems, unifying them under the KDD process framework. Cites prior work on interestingness, dependency modeling, and domain-specific applications.</p>

<hr />

<h2>Summary</h2>

<p>This paper formalizes the KDD process, distinguishing it from the narrower scope of data mining and defining it as a nontrivial process for identifying valid, novel, potentially useful, and understandable patterns in data. While it does not use the term “actionability,” it implicitly captures the concept by requiring discovered patterns to be useful and beneficial to the user. The authors present a nine-step iterative workflow, discuss multiple data-mining methods and their trade-offs, and emphasize evaluation criteria like validity, novelty, usefulness, and understandability. The framework’s emphasis on interpretability, contextual relevance, and alignment with user goals resonates strongly with modern definitions of actionability. However, timeliness as a dimension is missing, and feasibility is only implied. The operationalization is robust, providing concrete steps from domain understanding to acting on knowledge, making it a foundational reference for understanding how to produce insights that can be practically applied.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 78 – Clear mapping to actionability dimensions except for timeliness; no explicit definition but strong implicit conceptualization.  </p></li>
<li><p><strong>Operationalization Score:</strong> 70 – Detailed process and evaluation framework, but not explicitly connected to actionability.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“KDD is the nontrivial process of identifying valid, novel, potentially useful, and ultimately understandable patterns in data.” (p. 40)  </p></li>
<li><p>“Lead to some benefit to the user or task.” (p. 41)  </p></li>
<li><p>“Ninth is acting on the discovered knowledge…” (p. 42)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Silberschatz &amp; Tuzhilin (1995) – subjective measures of interestingness  </p></li>
<li><p>Piatetsky-Shapiro &amp; Matheus (1994) – interestingness of deviations  </p></li>
<li><p>Brachman &amp; Anand (1996) – human-centered KDD process</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Explanation in Artificial Intelligence: Insights from the Social Sciences  </p>

<p>Authors: Tim Miller  </p>

<p>DOI: arXiv:1706.07269v3  </p>

<p>Year: 2018  </p>

<p>Publication Type: Journal (Preprint)  </p>

<p>Discipline/Domain: Artificial Intelligence, Social Sciences  </p>

<p>Subdomain/Topic: Explainable AI (XAI), Human-Agent Interaction  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 85  </p>

<p>Contains Definition of Actionability: Yes (implicit — reframed as explainability in XAI, with actionable aspects derived from social science principles)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual Review  </p>

<p>Study Context: Application of social science theories of explanation to design and implementation of XAI systems  </p>

<p>Geographic/Institutional Context: University of Melbourne, Australia  </p>

<p>Target Users/Stakeholders: AI researchers, designers of explainable systems, HCI practitioners, cognitive scientists  </p>

<p>Primary Contribution Type: Theoretical synthesis and design implications for XAI  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Explanation in Artificial Intelligence: Insights from the Social Sciences  </p>

<p><strong>Authors:</strong>  </p>

<p>Tim Miller  </p>

<p><strong>DOI:</strong>  </p>

<p>arXiv:1706.07269v3  </p>

<p><strong>Year:</strong>  </p>

<p>2018  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal (Preprint)  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Artificial Intelligence, Social Sciences  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Explainable AI (XAI), Human-Agent Interaction  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper synthesizes findings from philosophy, cognitive psychology/science, and social psychology on how humans explain decisions and behaviors. It applies these to the design of explainable AI systems, focusing on everyday explanations, human-agent interaction, and the contextual, social, and cognitive biases that shape explanation effectiveness.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>School of Computing and Information Systems, University of Melbourne, Australia.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>AI researchers, system designers, HCI specialists, cognitive scientists, practitioners building explainable AI systems.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual Review  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Theoretical synthesis and design recommendations.  </p>

<h2>General Summary of the Paper</h2>

<p>This paper reviews over 250 works from social sciences to inform explainable AI (XAI) design, arguing that human explanation practices offer critical guidance for making AI outputs understandable and trustworthy. It emphasizes four major insights: explanations are contrastive, selectively biased, not primarily probabilistic, and inherently social. The work categorizes explanation as cognitive, product, and social processes, and reviews models of causality, attribution, and explanation selection/evaluation. It bridges these with XAI design needs, advocating explicit “models of self” for AI, contrastive and context-aware explanation generation, and interactive, conversational formats that align with user expectations and cognitive biases.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>In the XAI context, “actionability” is implicitly tied to providing explanations that enable users to trust, interpret, and effectively respond to AI decisions. Actionable explanations are those that are contextually relevant, cognitively accessible, socially attuned, and operationally aligned with user goals.  </p>

<blockquote>
  <p>“Explanations are not just the presentation of associations and causes… they are contextual” (p. 6)  </p>
</blockquote>

<blockquote>
  <p>“Explanations are social — they are a transfer of knowledge, presented as part of a conversation… relative to the explainer’s beliefs about the explainee’s beliefs” (p. 6)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Contrastive framing: answers “Why P rather than Q?”  </p></li>
<li><p>Selection of relevant causes over exhaustive causality  </p></li>
<li><p>Avoidance of purely statistical justification; preference for causal narratives  </p></li>
<li><p>Social alignment: tailoring to explainee’s beliefs, knowledge, and context  </p></li>
<li><p>Structuring at the right “level” of explanation (material, formal, efficient, final)  </p></li>
<li><p>Incorporation of abnormality, intentionality, and controllability as salience cues  </p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Contrastive Explanation, Model of Self, Overton’s Structure of Explanation, Malle’s Social Attribution Model, Hilton’s Conversational Model.  </p></li>
<li><p><strong>Methods/Levers:</strong> Identify fact–foil pairs; use abnormality detection; infer explainee’s knowledge state; apply cognitive biases in selection; design multi-level explanation models.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Determine explainee’s question and implicit foil  </p>

<p> 2. Identify minimal relevant causes based on contrastive differences  </p>

<p> 3. Filter through abnormality, intentionality, and goal alignment criteria  </p>

<p> 4. Present in conversational, iterative format, tailored to the explainee’s model  </p></li>
<li><p><strong>Data &amp; Measures:</strong> User knowledge models, causal chains, model abstractions, interaction logs.  </p></li>
<li><p><strong>Implementation Context:</strong> Human–agent interaction systems, decision-support tools, autonomous systems.  </p></li>
</ul>

<blockquote>
  <p>“An intelligent agent must be able to reason about its own causal model… alongside the decision-making mechanisms” (p. 22)  </p>
</blockquote>

<blockquote>
  <p>“Providing two complete explanations does not take advantage of contrastive questions” (p. 21)  </p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — “Explanations are not just causal chains… must be interpretable by lay-users” (p. 20)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — “They are contextual… explainee cares only about a small subset” (p. 6)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Ensuring explanations are within user’s cognitive capacity, via selection and abstraction.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Discussed in terms of interaction timing and explanation when needed.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Entire paper centers on making AI outputs explainable through social science insights.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Emphasis on aligning explanation with explainee’s goals and social purpose.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Abnormality, Intentionality, Functionality, Coherence, Simplicity.  </p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Aristotle’s Four Causes  </p></li>
<li><p>Halpern &amp; Pearl’s Structural Causal Models  </p></li>
<li><p>Malle’s Social Attribution Framework  </p></li>
<li><p>Hilton’s Conversational Model of Explanation  </p></li>
<li><p>Grice’s Maxims of Conversation  </p></li>
<li><p>Overton’s Structure of Scientific Explanation  </p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<p>No direct quantitative KPIs; proposes qualitative alignment metrics such as relevance, simplicity, coherence, and fit to explainee’s knowledge.</p>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Overemphasis on causal attribution over explanation; failure to infer foils; cognitive overload from exhaustive explanations; lack of social tailoring.  </p></li>
<li><p><strong>Enablers:</strong> Inferring foils; using cognitive biases constructively; interactive dialogue; models of self and other; multi-level causal modeling.  </p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions XAI as overly reliant on researcher intuition, contrasting with robust, experimentally validated social science models of explanation. Integrates philosophical, psychological, and conversational frameworks into a design-oriented synthesis.</p>

<h2>Summary</h2>

<p>Miller (2018) reframes explainability in AI as a human-agent interaction problem grounded in social science findings. Actionability, in this framing, means delivering explanations that users can comprehend, trust, and use to inform decisions, which requires contextual, contrastive, selective, and socially aware communication. The paper operationalizes these ideas via established theories (e.g., Malle’s, Hilton’s, Overton’s), proposing design steps like foil identification, abnormality detection, and conversational delivery. It advances XAI by bridging computational models with human cognitive and social processes, offering a structured path from philosophical foundations to practical implementation.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Rich, explicit linkage of social science principles to explanation as a basis for actionable AI outputs; strong conceptual grounding and comprehensive feature mapping.  </p></li>
<li><p><strong>Operationalization Score:</strong> 85 — Provides concrete design principles and procedural guidance, though lacks direct empirical evaluation of proposed XAI implementations.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Explanations are not just the presentation of associations and causes… they are contextual” (p. 6)  </p></li>
<li><p>“Explanations are social — they are a transfer of knowledge, presented as part of a conversation” (p. 6)  </p></li>
<li><p>“An intelligent agent must be able to reason about its own causal model… a model of self” (p. 22)  </p></li>
<li><p>“Providing two complete explanations does not take advantage of contrastive questions” (p. 21)  </p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Halpern &amp; Pearl (2005) on Structural Causal Models  </p></li>
<li><p>Malle (2004) on Social Attribution  </p></li>
<li><p>Hilton (1990) on Conversational Models  </p></li>
<li><p>Grice (1975) on Maxims of Conversation  </p></li>
<li><p>Overton (2012) on Structure of Explanation  </p></li>
<li><p>Lipton (1990) on Contrastive Explanation</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Explainable Matrix – Visualization for Global and Local Interpretability of Random Forest Classification Ensembles</p>

<p>Authors: Mario Popolin Neto, Fernando V. Paulovich</p>

<p>DOI: 10.1109/TVCG.2020.3030354</p>

<p>Year: 2021</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Computer Science / Machine Learning / Visualization</p>

<p>Subdomain/Topic: Explainable AI, Random Forest Interpretability, Visualization Techniques</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 82</p>

<p>Operationalization Score: 90</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — “aiming to improve users’ trust in the model” (p. 1428); “allowing the results to be used in practice” (p. 1433)</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes — ExMatrix method</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual + Empirical (method proposal, use cases, user study)</p>

<p>Study Context: Machine learning interpretability for Random Forests</p>

<p>Geographic/Institutional Context: Federal Institute of Sao Paulo (Brazil), University of Sao Paulo (Brazil), Dalhousie University (Canada)</p>

<p>Target Users/Stakeholders: Data scientists, ML engineers, decision-makers needing interpretable ML outputs</p>

<p>Primary Contribution Type: Visualization method for interpretability</p>

<p>CL: Yes — “removing unimportant information and reducing cluttering” (p. 1435)</p>

<p>CR: Yes — “focus on what is important regarding the overall model behavior” (p. 1431)</p>

<p>FE: Partial — indirectly via coverage and certainty measures (p. 1430–1431)</p>

<p>TI: No</p>

<p>EX: Yes — “supporting model overview and details on-demand” (p. 1427)</p>

<p>GA: Partial — aligning model explanations with user analytical tasks (p. 1430–1431)</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Explainable Matrix – Visualization for Global and Local Interpretability of Random Forest Classification Ensembles  </p>

<p><strong>Authors:</strong>  </p>

<p>Mario Popolin Neto, Fernando V. Paulovich  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1109/TVCG.2020.3030354  </p>

<p><strong>Year:</strong>  </p>

<p>2021  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Machine Learning / Visualization  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Explainable AI, Random Forest Interpretability, Visualization Techniques  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the challenge of interpreting complex ensemble models, particularly Random Forests, whose size and structure hinder conventional interpretability approaches. The authors propose a visualization method (ExMatrix) that transforms decision paths into compact, scalable, and interpretable logic-rule matrices, enabling both global model overviews and local instance-level explanations.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Federal Institute of Sao Paulo (Brazil), University of Sao Paulo (Brazil), Dalhousie University (Canada)  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Data scientists, ML engineers, decision-makers needing interpretable ML outputs  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual method design + use-case demonstration + user study  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Novel visualization framework for RF interpretability  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper introduces <strong>Explainable Matrix (ExMatrix)</strong>, a novel matrix-based visualization technique designed for the global and local interpretability of Random Forest classification models. ExMatrix represents decision paths as logic rules, with rows for rules, columns for features, and cells for predicates. It supports both <em>global explanations</em> (model overviews, feature–prediction relationships, rule certainty/coverage) and <em>local explanations</em> (rules applied to a specific instance, minimal changes to alter classification). The authors detail the method’s rule extraction process, visualization functions, and ordering/filtering strategies to manage scalability. Three local explanation modes are provided: showing used rules, and showing smallest changes. Use cases (breast cancer diagnostics, credit risk, contraceptive method choice) demonstrate practical utility, and a user study assesses interpretability effectiveness.  </p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No — The paper focuses on interpretability and explainability without using the terms “actionable” or “actionability.”  </p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes —  </p>

<blockquote>
  <p>“Aiming to improve users’ trust in the model” (p. 1428)  </p>
</blockquote>

<blockquote>
  <p>“Allowing the results to be used in practice” (p. 1433)  </p>
</blockquote>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicit — Actionability is treated as providing interpretable, trustworthy, and usable model explanations that inform decisions, without explicit definition.  </p>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Clarity of model reasoning</strong>  </p>

<p> &gt; “Removing unimportant information and reducing cluttering” (p. 1435)  </p></li>
<li><p><strong>Contextual relevance to user tasks</strong>  </p>

<p> &gt; “Focus on what is important regarding the overall model behavior” (p. 1431)  </p></li>
<li><p><strong>Explainability and interpretability</strong>  </p>

<p> &gt; “Supporting model overview and details on-demand” (p. 1427)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> ExMatrix  </p></li>
<li><p><strong>Methods/Levers:</strong> Vector rule extraction from decision trees, matrix visualization, ordering and filtering strategies, coverage and certainty metrics  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Extract decision paths from RF trees and convert into logic-rule vectors  </p>

<p> 2. Map rules (rows) and features (columns) into a matrix visualization  </p>

<p> 3. Use icons to depict predicate ranges, coverage, certainty, and feature importance  </p>

<p> 4. Enable ordering/filtering for global or local views  </p>

<p> 5. Support local instance analysis and counterfactual reasoning  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Coverage, certainty, feature importance (MDI), predicate intervals  </p></li>
<li><p><strong>Implementation Context:</strong> Applied to RF models in medical, financial, and public health datasets  </p></li>
</ul>

<blockquote>
  <p>“Supporting model overview and details on-demand” (p. 1427)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — “Removing unimportant information and reducing cluttering” (p. 1435)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — “Focus on what is important regarding the overall model behavior” (p. 1431)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — via coverage and certainty to gauge reliability (p. 1430–1431)  </p></li>
<li><p><strong>TI (Timeliness):</strong> No  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — “Supporting model overview and details on-demand” (p. 1427)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — aligning explanations with analytical tasks (p. 1430–1431)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> None explicitly as part of “actionability”  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Rule-based model interpretability  </p></li>
<li><p>Visualization theory (matrix-like metaphors, ordering/filtering principles)  </p></li>
<li><p>Surrogate modeling for black-box explainability  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>Indirect — coverage, certainty, feature importance (as proxies for relevance/reliability of rules)  </p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Scalability in visualizing all RF rules (p. 1435), complexity of certain views for non-experts (LE/SC mode, p. 1434)  </p></li>
<li><p><strong>Enablers:</strong> Filtering, ordering, compact matrix representation, icons for predicates (p. 1430–1431)  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The authors position ExMatrix against prior visualization approaches (node-link diagrams, Decision Tables, RuleMatrix), emphasizing improved scalability, compactness, and support for both global and local RF interpretability tasks.  </p>

<hr />

<h2>Summary</h2>

<p>This paper presents <strong>ExMatrix</strong>, a scalable visualization framework for interpreting Random Forest models by representing decision paths as logic-rule matrices. The approach enables both <em>global model analysis</em> and <em>local instance auditing</em>, addressing challenges in scalability, clarity, and usability that affect existing methods like node-link diagrams or textual decision tables. While not using the term “actionability” explicitly, the method aligns with actionable principles by emphasizing clarity, contextual relevance, and explainability, aiming to provide outputs that users can trust and apply in decision-making contexts. The framework’s operationalization is concrete — extracting rules, visualizing with matrices, and enabling interactive filtering and ordering — and demonstrated through real-world datasets. A user study shows promising interpretability gains, though advanced counterfactual views remain challenging for non-experts.  </p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 82 — Strong alignment with actionable principles via interpretability and practical usability, but lacks explicit “actionability” terminology or formal definition.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Detailed method with clear workflow, metrics, and tool implementation for producing interpretable, decision-supportive outputs.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Supporting model overview and details on-demand” (p. 1427)  </p></li>
<li><p>“Focus on what is important regarding the overall model behavior” (p. 1431)  </p></li>
<li><p>“Removing unimportant information and reducing cluttering” (p. 1435)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>RuleMatrix: Ming et al. (2019)  </p></li>
<li><p>iForest: Zhao et al. (2019)  </p></li>
<li><p>Surrogate Decision Trees: Di Castro &amp; Bertini (2019)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Explainable machine learning algorithms to identify predictors of intention to use family planning among women of reproductive-age in Ethiopia: Evidence from the Performance Monitoring and Accountability (PMA) 2021 survey data set  </p>

<p>Authors: Jibril Bashir Adem, Tewodros Desalegn Nebi, Agmasie Damtew Walle, Daniel Niguse Mamo, Sudi Jemal Wado, Ermias Bekele Enyew, Shimels Derso Kebede  </p>

<p>DOI: 10.1136/bmjph-2024-000962  </p>

<p>Year: 2025  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Public Health, Reproductive Health, Machine Learning  </p>

<p>Subdomain/Topic: Family Planning Intention Prediction, Explainable AI, SHAP Analysis  </p>

<p>Eligibility: Not Eligible  </p>

<p>Overall Relevance Score: 20 – While the study uses explainable AI and identifies predictors to inform interventions, it does not explicitly or implicitly discuss the concept of “actionability” as a definitional or conceptual construct.  </p>

<p>Operationalization Score: 40 – The paper operationalizes prediction of intention to use FP via ML workflows and SHAP analysis, but these are not linked to an explicit notion of creating “actionable” knowledge.  </p>

<p>Actionable/Actionability Used in Paper: No  </p>

<p>Authors Argue for Need for Actionability Without Defining It: No  </p>

<p>Contains Definition of Actionability: No  </p>

<p>Contains Systematic Features/Dimensions: No  </p>

<p>Contains Explainability: Yes – SHAP-based model interpretation is a core part of the methodology.  </p>

<p>Contains Interpretability: Yes – Model-agnostic SHAP feature importance used for interpretation.  </p>

<p>Contains Framework/Model: Yes – Workflow includes ML pipeline and SHAP explainability model.  </p>

<p>Operationalization Present: Yes – Data preprocessing, balancing, model selection, and interpretation steps clearly described.  </p>

<p>Primary Methodology: Quantitative (Machine Learning)  </p>

<p>Study Context: Family planning intention prediction among Ethiopian women of reproductive age  </p>

<p>Geographic/Institutional Context: Ethiopia, using nationally representative PMA 2021 survey data  </p>

<p>Target Users/Stakeholders: Ethiopian Ministry of Health, health policy makers, family planning programme implementers  </p>

<p>Primary Contribution Type: Predictive model and identification of key predictors for FP intention  </p>

<p>CL: No  </p>

<p>CR: No  </p>

<p>FE: No  </p>

<p>TI: No  </p>

<p>EX: Yes – SHAP-based explanation of predictors.  </p>

<p>GA: No  </p>

<p>Reason if Not Eligible: The paper does not conceptualize or define “actionability,” nor does it frame its findings explicitly in terms of actionable knowledge or actionable recommendations; instead, it focuses on prediction accuracy and interpretation of predictors.</p>

<!--META_END-->

<p><strong>Title:</strong> Explainable machine learning algorithms to identify predictors of intention to use family planning among women of reproductive-age in Ethiopia: Evidence from the Performance Monitoring and Accountability (PMA) 2021 survey data set  </p>

<p><strong>Authors:</strong> Jibril Bashir Adem, Tewodros Desalegn Nebi, Agmasie Damtew Walle, Daniel Niguse Mamo, Sudi Jemal Wado, Ermias Bekele Enyew, Shimels Derso Kebede  </p>

<p><strong>DOI:</strong> 10.1136/bmjph-2024-000962  </p>

<p><strong>Year:</strong> 2025  </p>

<p><strong>Publication Type:</strong> Journal  </p>

<p><strong>Discipline/Domain:</strong> Public Health, Reproductive Health, Machine Learning  </p>

<p><strong>Subdomain/Topic:</strong> Family Planning Intention Prediction, Explainable AI, SHAP Analysis  </p>

<p><strong>Contextual Background:</strong> The study addresses low utilization of family planning in Ethiopia, aiming to identify determinants of intention to use FP using nationally representative survey data and explainable ML methods.  </p>

<p><strong>Geographic/Institutional Context:</strong> Ethiopia, PMA 2021 dataset  </p>

<p><strong>Target Users/Stakeholders:</strong> Public health policymakers, FP programme designers, researchers in reproductive health  </p>

<p><strong>Primary Methodology:</strong> Quantitative (ML classifiers with SHAP interpretation)  </p>

<p><strong>Primary Contribution Type:</strong> Predictive analytics with model interpretability for FP intention</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This study uses the Ethiopian PMA 2021 survey to predict women’s intention to use family planning (FP) via eight machine learning classifiers, identifying the random forest model as most accurate (77% accuracy, 85% AUC). The researchers applied SHAP to determine the most influential predictors, including history of FP use, partner’s age, marital status, religion, pregnancy status, and unmet need for FP. The work aims to help policymakers and practitioners better target interventions by understanding which factors most influence FP intention. The ML pipeline included data cleaning, balancing with SMOTE, feature engineering, hyperparameter tuning, and interpretation using SHAP.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No – The study does not use the term “actionability,” “actionable insight,” “actionable recommendation,” or “actionable knowledge,” nor does it conceptualize the state of being actionable.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No – While the authors suggest their results can inform targeted interventions, they do not explicitly call for actionable outputs or frame their contribution in terms of actionability.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A – The operationalization described relates to ML prediction processes, not to making findings actionable.</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> No  </p></li>
<li><p><strong>FE (Feasibility):</strong> No  </p></li>
<li><p><strong>TI (Timeliness):</strong> No  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – “SHAP analysis provides a global or local interpretation and explanation of any ML model’s prediction.” (p.5)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> No  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<p>No theoretical framework for “actionability” is presented; ML methodology is grounded in SHAP interpretability literature.</p>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> N/A  </p></li>
<li><p><strong>Enablers:</strong> N/A</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The study situates itself in the context of prior work on determinants of FP intention and ML applications in public health, highlighting limitations of traditional regression models and the benefits of explainability via SHAP.</p>

<hr />

<h2>Summary</h2>

<p>This research applies explainable machine learning to predict intention to use family planning among Ethiopian women, identifying key sociodemographic and reproductive health predictors. Using the PMA 2021 dataset, the authors implemented eight ML algorithms and found the random forest model with SHAP interpretation to be most effective. While the results have clear policy implications, the study does not explicitly address or define “actionability” as a concept, nor does it present criteria or conditions for making findings actionable. Instead, it focuses on prediction accuracy and interpretability to inform targeted interventions in reproductive health. Therefore, while methodologically robust and relevant to policy, it falls outside the eligibility criteria for an “actionability” conceptual review.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 20 – Minimal conceptual linkage to actionability; results could be actionable in practice but are not framed as such.  </p></li>
<li><p><strong>Operationalization Score:</strong> 40 – Strong operationalization of ML workflow, but no operationalization of actionability.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“SHAP analysis provides a global or local interpretation and explanation of any ML model’s prediction.” (p.5)  </p></li>
<li><p>“Insights from this study can inform targeted interventions and policies to enhance the health and well-being of women in Ethiopia.” (Abstract, p.2)  </p></li>
<li><p>“The top predictors of intention to use FP were determined using model-agnostic SHAP global feature importance.” (p.7)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Evaluating the Quality of Machine Learning Explanations: A Survey on Methods and Metrics  </p>

<p>Authors: Jianlong Zhou, Amir H. Gandomi, Fang Chen, Andreas Holzinger  </p>

<p>DOI: https://doi.org/10.3390/electronics10050593  </p>

<p>Year: 2021  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Machine Learning / Explainable AI (XAI)  </p>

<p>Subdomain/Topic: Evaluation of ML explanations; metrics and methods for assessing explanation quality  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 85 – The paper provides a well-structured conceptualization of explainability, links it to measurable properties (clarity, parsimony, broadness, completeness, soundness), and frames evaluation in terms that align with actionability through interpretability and fidelity.  </p>

<p>Operationalization Score: 80 – Contains a taxonomy, metrics, and evaluation methodologies that can be adapted to operationalizing actionable explanations in practice.  </p>

<p>Actionable/Actionability Used in Paper: No – The paper does not use the term “actionable” but consistently addresses conditions and metrics that align with making explanations practically useful for decision-making.  </p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes – The need to “assess if explainability achieves the defined objective” and to “choose the most appropriate explanation for a specific task” (p. 8) implies actionability in practice without using the term.  </p>

<p>Contains Definition of Actionability: No – Defines explainability and its properties, not actionability per se.  </p>

<p>Contains Systematic Features/Dimensions: Yes – Clarity, parsimony, broadness, completeness, soundness.  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes – Taxonomy of explanation types; taxonomy of evaluation methods; mapping properties to metrics.  </p>

<p>Operationalization Present: Yes – Quantitative and qualitative metrics, evaluation workflows.  </p>

<p>Primary Methodology: Review  </p>

<p>Study Context: Survey of literature on evaluating ML explanations.  </p>

<p>Geographic/Institutional Context: Global literature; authors affiliated with Australia and Austria.  </p>

<p>Target Users/Stakeholders: Researchers, ML practitioners, application-domain experts in high-stakes domains.  </p>

<p>Primary Contribution Type: Conceptual framework + taxonomy + metrics for evaluation.  </p>

<p>CL: Yes – “Clarity implies that the explanation is unambiguous” (p. 3)  </p>

<p>CR: Partial – Context-dependence noted but not formally codified as a property.  </p>

<p>FE: Yes – Parsimony and simplicity operationalized; feasibility implied through model complexity metrics.  </p>

<p>TI: No – Timeliness not addressed.  </p>

<p>EX: Yes – Explainability defined and broken into interpretability and fidelity.  </p>

<p>GA: Partial – Goal alignment implied through “achieves the defined objective” (p. 8) but not a distinct property.  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Evaluating the Quality of Machine Learning Explanations: A Survey on Methods and Metrics</p>

<p><strong>Authors:</strong>  </p>

<p>Jianlong Zhou, Amir H. Gandomi, Fang Chen, Andreas Holzinger</p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.3390/electronics10050593</p>

<p><strong>Year:</strong>  </p>

<p>2021</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Machine Learning / Explainable AI (XAI)</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Evaluation of ML explanations; metrics and methods for assessing explanation quality</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the growing need to evaluate the quality of explanations provided by machine learning systems, especially in high-stakes domains. It reviews existing literature to identify properties of explainability, categorizes explanation approaches, and surveys metrics (both human-centred and objective) for evaluation.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Authored by researchers from the University of Technology Sydney (Australia) and Medical University of Graz (Austria).</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>ML researchers, explainability tool developers, domain experts in regulated sectors, policymakers.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Literature review and conceptual synthesis.</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework and taxonomy for evaluation of ML explanations; mapping of properties to metrics.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This survey systematically examines methods and metrics for evaluating machine learning explanations. It begins by defining explainability and its properties — clarity, parsimony, broadness (interpretability) and completeness, soundness (fidelity). It categorizes ML explanation types into model-based, attribution-based, and example-based, and reviews explanation delivery modes, including visualization techniques. The paper presents a taxonomy of evaluation approaches — application-grounded, human-grounded, and functionality-grounded — and details both subjective (trust, confidence) and objective (model complexity, sensitivity) metrics. Quantitative metrics are mapped to the identified properties of explainability, and gaps are highlighted, including the lack of metrics for certain properties and explanation types. The authors emphasize integrating human-centred and functionality-grounded evaluations to choose context-appropriate explanations, especially for high-stakes domains.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No – The paper does not use “actionable” explicitly.  </p>

<p>However:  </p>

<blockquote>
  <p>“To assess if explainability is achieved in an application… determining if the provided explainability achieves the defined objective” (p. 8)  </p>
</blockquote>

<blockquote>
  <p>“Suggest the most appropriate explanation from the comparison for a specific task” (p. 1)  </p>
</blockquote>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes – Implies the necessity for explanations that support real-world decision-making and task completion:  </p>

<blockquote>
  <p>“…find the most appropriate explanation for a specific ML solution in a given context on a given task for a given domain expert” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“…determine if the provided explainability achieves the defined objective” (p. 8)  </p>
</blockquote>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicit: Actionability is framed as the alignment between explanation properties (clarity, completeness, etc.) and the defined objectives of a task, enabling domain experts to make informed decisions.</p>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Clarity (unambiguous)</strong>  </p>

<p> &gt; “Clarity implies that the explanation is unambiguous” (p. 3)  </p></li>
<li><p><strong>Parsimony/Simplicity</strong>  </p>

<p> &gt; “…presented in a simple and compact form” (p. 3)  </p></li>
<li><p><strong>Broadness (generally applicable)</strong>  </p>

<p> &gt; “…describes how generally applicable is an explanation” (p. 3)  </p></li>
<li><p><strong>Completeness</strong>  </p>

<p> &gt; “…describes the entire dynamic of the ML model” (p. 3)  </p></li>
<li><p><strong>Soundness</strong>  </p>

<p> &gt; “…how correct and truthful the explanation is” (p. 3)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Taxonomy of evaluation approaches (application-grounded, human-grounded, functionality-grounded)  </p></li>
<li><p><strong>Methods/Levers:</strong> Human-centred subjective and objective metrics; functionality-grounded quantitative metrics  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify properties of explainability → map to metrics → apply appropriate evaluation type depending on context  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Model complexity measures, sensitivity analysis, trust/confidence questionnaires, mutual information, representativeness, diversity  </p></li>
<li><p><strong>Implementation Context:</strong> Suitable for both research and applied ML in high-stakes decision-making.  </p></li>
</ul>

<blockquote>
  <p>“Evaluation metrics… can guide the practitioner in the selection of the most appropriate explanation method for tasks” (p. 11)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – “Clarity implies that the explanation is unambiguous” (p. 3)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Partial – context noted as key to perceived quality (p. 2)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – Parsimony and simplicity linked to operational feasibility (p. 3, p. 11)  </p></li>
<li><p><strong>TI (Timeliness):</strong> No – Not addressed as a property.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – Defined explicitly and decomposed into interpretability and fidelity (p. 3)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial – “Achieves the defined objective” (p. 8)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Broadness, Completeness, Soundness.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Interpretability and fidelity framework (Markus et al. 2020)  </p></li>
<li><p>Taxonomy of evaluation methods (Doshi-Velez &amp; Kim, 2017)  </p></li>
<li><p>Properties derived from prior work (Gilpin et al., Lombrozo).</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Model size, runtime operation counts, interaction strength, main effect complexity  </p></li>
<li><p>Monotonicity, non-sensitivity, effective complexity, mutual information, selectivity, continuity  </p></li>
<li><p>Non-representativeness, diversity for example-based explanations  </p></li>
<li><p>Subjective trust/confidence scores; task performance measures.</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p><strong>Barriers:</strong>  </p>

<ul>
<li><p>Subjectivity of explanation quality (p. 2)  </p></li>
<li><p>Context dependence (p. 2)  </p></li>
<li><p>Lack of agreed criteria for human-centred evaluations (p. 14)  </p></li>
</ul>

<p><strong>Enablers:</strong>  </p>

<ul>
<li><p>Mapping properties to metrics (p. 11)  </p></li>
<li><p>Combining human-centred and functionality-grounded evaluations (p. 15)  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on prior surveys of explainability, extends by focusing on evaluation quality metrics and mapping to properties. References foundational explainability taxonomies and evaluation frameworks, integrates human-centred and quantitative approaches.</p>

<hr />

<h2>Summary</h2>

<p>Zhou et al. (2021) present the first survey dedicated to evaluating the quality of machine learning explanations. They define explainability through interpretability (clarity, parsimony, broadness) and fidelity (completeness, soundness) and review explanation types (model-based, attribution-based, example-based) alongside visualization approaches. The paper organizes evaluation into application-grounded, human-grounded, and functionality-grounded categories, detailing subjective (trust, confidence) and objective (model size, sensitivity, mutual information) metrics. While not using “actionable” explicitly, the paper implicitly addresses actionability as the selection and assessment of explanations that meet task objectives in context. Gaps include limited metrics for some properties (e.g., clarity, broadness) and for certain explanation types (e.g., example-based). The authors argue for integrating human and functionality-grounded evaluations to comprehensively assess explanation quality in real-world applications.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 – Strong conceptual mapping of explanation properties to evaluation metrics, indirectly aligning with actionability.  </p></li>
<li><p><strong>Operationalization Score:</strong> 80 – Provides concrete metrics and workflows, though not framed in explicit “actionable” terminology.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Clarity implies that the explanation is unambiguous” (p. 3)  </p></li>
<li><p>“Parsimony means that the explanation is presented in a simple and compact form” (p. 3)  </p></li>
<li><p>“Completeness implies that the explanation describes the entire dynamic of the ML model” (p. 3)  </p></li>
<li><p>“Soundness concerns how correct and truthful the explanation is” (p. 3)  </p></li>
<li><p>“To assess if explainability is achieved in an application… determining if the provided explainability achieves the defined objective” (p. 8)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Markus et al. (2020) – Properties of explainability  </p></li>
<li><p>Doshi-Velez &amp; Kim (2017) – Evaluation taxonomy  </p></li>
<li><p>Gilpin et al. (2018) – Interpretability and fidelity  </p></li>
<li><p>Lombrozo (2016) – Simplicity and breadth in explanations</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Decision Support Systems: The Next Decade  </p>

<p>Authors: Peter G.W. Keen  </p>

<p>DOI: n/a  </p>

<p>Year: 1987  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Information Systems / Management Science  </p>

<p>Subdomain/Topic: Decision Support Systems (DSS), Actionability in Decision Support  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 88  </p>

<p>Operationalization Score: 85  </p>

<p>Contains Definition of Actionability: Yes (implicit and explicit through decision support conceptualization)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (Extended Decision Support model)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual / Position Paper  </p>

<p>Study Context: DSS research and practice globally, with examples from business, technology, and management  </p>

<p>Geographic/Institutional Context: International; references to US, Europe, Asia; author from International Center for Information Technologies, USA  </p>

<p>Target Users/Stakeholders: Senior managers, DSS developers, information systems professionals, organizational decision makers  </p>

<p>Primary Contribution Type: Conceptual framework and agenda for DSS research and practice  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Decision Support Systems: The Next Decade  </p>

<p><strong>Authors:</strong>  </p>

<p>Peter G.W. Keen  </p>

<p><strong>DOI:</strong>  </p>

<p>n/a  </p>

<p><strong>Year:</strong>  </p>

<p>1987  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Information Systems / Management Science  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Decision Support Systems (DSS), Actionability in Decision Support  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the evolution and future direction of Decision Support Systems, framing DSS as both a technological and intellectual tool to enhance organizational decision-making. It reflects on ten years of DSS development and proposes an agenda for the next decade that emphasizes decisions that “really matter,” active support, and integration of emerging technologies such as expert systems, document-based systems, and telecommunications.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>International; examples drawn from US, Europe, Asia.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Senior managers, DSS builders, information systems professionals, organizational decision-makers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual / Position Paper  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework and research/practice agenda  </p>

<h2>General Summary of the Paper</h2>

<p>The article reviews the first decade of DSS, noting the shift from technology bottlenecks to an environment where technology is abundant, and the challenge is maximizing its strategic value. Keen critiques the lack of an agreed definition of DSS, highlighting the need for both “definitions for understanding” (broad, conceptual, innovative) and “definitions for action” (practical, organizationally relevant). He introduces the concept of <em>Extended Decision Support</em>—a more active, consultative approach aimed at decisions of organizational significance—contrasting it with Passive, Traditional, and Normative support models. The paper advocates rebalancing the “D” in DSS toward decision-focused research, incorporating multicriteria decision-making, and leveraging new tools like expert systems, document-based systems, and telecommunications. A detailed agenda for research, scholarship, and practice is provided.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as the capacity of DSS to provide decision support that improves the quality, creativity, and learning of decisions that “really matter” in organizations. This includes shifting from passive tool provision to active, consultative roles where DSS influences decision processes.  </p>

<blockquote>
  <p>“DSS is concerned with intellectual as well as computer-related technologies… We need to have a more ambitious view of decision making…” (p. 255)  </p>
</blockquote>

<blockquote>
  <p>“The agenda… is to apply intellectual and computer-related technologies to amplify creativity and learning in decisions that really matter.” (p. 256)  </p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Decision relevance: supports critical, high-impact organizational decisions.  </p></li>
<li><p>Integration of judgment with analytic tools.  </p></li>
<li><p>Contextual fit to user needs and organizational priorities.  </p></li>
<li><p>Ability to improve decision process quality, not just provide data.  </p></li>
<li><p>Leveraging appropriate technology for the decision context.  </p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Extended Decision Support (EDS)  </p></li>
<li><p><strong>Methods/Levers:</strong> Explicit targeting of significant decisions; blending analytic models with AI and document management; focus on organizational decision-making.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify decision areas of high value; build systems integrating analytic and technological tools; engage as consultants, not just system builders; apply iterative prototyping.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Use organizational data stores; integrate document-based info; apply multicriteria decision-making methods.  </p></li>
<li><p><strong>Implementation Context:</strong> Senior management planning, competitive/environmental scanning, organizational problem-solving.  </p></li>
</ul>

<blockquote>
  <p>“Extended support involves an explicit effort to influence and guide decision making… while respecting the primacy of judgement…” (p. 258)  </p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Systems must be understandable and usable to decision makers.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Support must align with “decisions that really matter.”  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Tools and approaches must be practical in organizational settings.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Focus on reducing “information float” and delivering alerts before issues escalate.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — EDS aims to make reasoning visible (e.g., semi-expert systems showing rule triggers).  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — Systems must align with primary business goals and user priorities.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong>  </p>

<p> - Level of support (Passive, Traditional, Extended, Normative)  </p>

<p> - Organizational integration (link with IS and data resources)  </p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Herbert Simon’s concepts of satisficing vs. optimization.  </p></li>
<li><p>Cognitive psychology and Carnegie School decision-making research.  </p></li>
<li><p>Management Science and multicriteria decision-making theories.  </p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Targeting high-value decisions.  </p></li>
<li><p>Reducing decision-making delays (“information float”).  </p></li>
<li><p>Integration of analytic and judgmental elements.  </p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of clear DSS definitions; overemphasis on technology over decision focus; “cherry-picking” easy applications; drift to passive support.  </p></li>
<li><p><strong>Enablers:</strong> Emerging AI tools; document-based DSS; telecommunications; strong linkages with IS and organizational data; hybrid professionals with both technical and domain expertise.  </p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Positions DSS as an evolution from Management Science and early decision-making theories, but critiques the field for losing decision focus. Advocates borrowing from organizational theory, political science, and MCDM to strengthen conceptual foundations.</p>

<h2>Summary</h2>

<p>Keen’s paper reframes DSS for its second decade, arguing for a more ambitious and decision-centered approach. Actionability here is about supporting critical organizational decisions, enhancing creativity and learning, and integrating judgment with technology. The proposed <em>Extended Decision Support</em> model moves beyond providing tools to actively guiding decisions, leveraging new technologies like AI, document-based systems, and telecommunications. Keen distinguishes between conceptual (“definition for understanding”) and practical (“definition for action”) views, urging researchers and practitioners to clarify their mission and target high-value decisions. This reconceptualization aims to ensure DSS remains a distinctive and impactful field rather than a commodity subset of end-user computing.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 — Strong conceptual treatment of actionability with explicit features and a detailed framework, though not framed using “actionability” terminology.  </p></li>
<li><p><strong>Operationalization Score:</strong> 85 — Provides concrete methods (EDS model, target market identification, technology integration), though implementation detail is more strategic than procedural.  </p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“DSS is concerned with intellectual as well as computer-related technologies…” (p. 255)  </p></li>
<li><p>“Apply intellectual and computer-related technologies to amplify creativity and learning in decisions that really matter.” (p. 256)  </p></li>
<li><p>“Extended support involves an explicit effort to influence and guide decision making…” (p. 258)  </p></li>
<li><p>“Reduce information ‘float’…” (p. 264)  </p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Keen &amp; Scott Morton (1978) <em>Decision Support Systems: An Organizational Perspective</em>  </p></li>
<li><p>Elam et al. (1986) <em>A Vision for DSS Research</em>  </p></li>
<li><p>Herbert Simon (1969) <em>Sciences of the Artificial</em>  </p></li>
<li><p>Sprague &amp; Carlson (1982) <em>Building Effective Decision Support Systems</em></p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Co-Designing a Real-Time Classroom Orchestration Tool to Support Teacher–AI Complementarity  </p>

<p>Authors: Kenneth Holstein, Bruce M. McLaren, Vincent Aleven  </p>

<p>DOI: http://dx.doi.org/10.18608/jla.2019.62.3  </p>

<p>Year: 2019  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Learning Analytics / Human–Computer Interaction  </p>

<p>Subdomain/Topic: Co-design of AI-enhanced classroom orchestration tools  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 88  </p>

<p>Operationalization Score: 95  </p>

<p>Contains Definition of Actionability: Yes (implicit and partial explicit)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (Replay Enactments prototyping method)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Mixed Methods (qualitative need-finding, iterative prototyping, in-lab simulation, classroom pilots, experimental evaluation)  </p>

<p>Study Context: K–12 AI-enhanced classrooms using Intelligent Tutoring Systems (ITS)  </p>

<p>Geographic/Institutional Context: US middle schools, Carnegie Mellon University-led research  </p>

<p>Target Users/Stakeholders: K–12 teachers, students, educational technologists  </p>

<p>Primary Contribution Type: Empirical case study and methodological framework  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Co-Designing a Real-Time Classroom Orchestration Tool to Support Teacher–AI Complementarity  </p>

<p><strong>Authors:</strong>  </p>

<p>Kenneth Holstein, Bruce M. McLaren, Vincent Aleven  </p>

<p><strong>DOI:</strong>  </p>

<p>http://dx.doi.org/10.18608/jla.2019.62.3  </p>

<p><strong>Year:</strong>  </p>

<p>2019  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Learning Analytics / Human–Computer Interaction  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Participatory design, AI in education, teacher orchestration tools  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The study addresses the challenge of designing AI-driven learning analytics (LA) tools that meaningfully involve non-technical stakeholders, specifically K–12 teachers, throughout the design process. It focuses on the development of <em>Lumilo</em>, a mixed-reality smart glasses system for real-time classroom orchestration in AI-enhanced classrooms.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Conducted in US middle schools in collaboration with Carnegie Mellon University.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Middle-school teachers, students, educational technologists.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed methods: generative design (interviews, card sorting, storytelling), iterative prototyping (low–high fidelity), Replay Enactments simulations, live classroom pilots, experimental evaluation.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical design case study and introduction of a novel prototyping method for data-driven algorithmic systems.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper presents the first end-to-end co-design case study of a complex learning analytics tool—<em>Lumilo</em>, a smart glasses system for K–12 teachers using AI tutoring systems. The authors integrate participatory design, iterative prototyping, and evaluation to ensure teacher needs drive system design. They introduce Replay Enactments (REs), a novel prototyping method combining authentic data, algorithms, and embodied role-play to simulate classroom contexts. Findings show that effective actionable analytics must enhance teacher awareness, respect autonomy, be context-sensitive, and link directly to instructional decisions. Classroom trials demonstrated <em>Lumilo</em>'s potential to equalize learning outcomes by reallocating teacher attention towards struggling students.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as analytics that:  </p>

<ul>
<li><p>Link directly to specific teacher decisions and interventions in real time.  </p></li>
<li><p>Provide timely, context-relevant, and interpretable insights that support in-the-moment decision-making.  </p></li>
<li><p>Enhance rather than replace teacher autonomy.  </p></li>
</ul>

<blockquote>
  <p>“Prompting teachers to reflect on what real-time decisions a particular information display might inform often led them to notice ways in which the display could be made more useful…” (p. 47)  </p>
</blockquote>

<blockquote>
  <p>Teachers distinguished between “seeing thought processes” and abstract mastery probabilities, noting the former was more <em>actionable</em> for immediate instructional rerouting (p. 31).  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Direct linkage between analytics and possible teacher interventions.  </p></li>
<li><p>Timeliness to act during a learning episode.  </p></li>
<li><p>Interpretability to justify and trust recommendations.  </p></li>
<li><p>Contextual relevance to the specific class, student, and task.  </p></li>
<li><p>Respect for teacher autonomy and flexibility in use.  </p></li>
<li><p>Grounding automated inferences in raw, concrete student artifacts.  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Replay Enactments (REs) for co-design and prototyping.  </p></li>
<li><p><strong>Methods/Levers:</strong> Generative need-finding (superpowers exercise, storytelling), iterative prototyping (lo–hi fidelity), simulation-based REs, classroom pilots.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify teacher needs → prototype low-fidelity displays → mid-fidelity HoloLens prototypes → RE simulations with authentic ITS data → classroom deployment and iteration.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> ITS logs, real-time detectors for misuse, struggle, performance, engagement; teacher movement and gaze tracking; qualitative feedback.  </p></li>
<li><p><strong>Implementation Context:</strong> US middle-school ITS classrooms.  </p></li>
</ul>

<blockquote>
  <p>“REs… enable earlier, nuanced observations of the interplay between human and machine judgments…” (p. 41)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – indicators visually simple with on-demand elaborations (p. 38).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – tailored to class-level, student-level needs (p. 33).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – designs respect teacher constraints, cognitive load (p. 33, p. 47).  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes – real-time analytics to intervene “in the moment” (p. 31, p. 47).  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – grounded in raw student artifacts to justify inferences (p. 39).  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – respect teacher goals, autonomy, instructional style (p. 35, p. 47).  </p></li>
<li><p><strong>Other Dimensions Named:</strong> Selective sharing, adaptability of thresholds, anonymity for help-seeking.  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Participatory/co-design principles from HCI.  </p></li>
<li><p>Human–machine function allocation literature.  </p></li>
<li><p>Open learner models and explainable AI in education.  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Accuracy and interpretability of student state detectors.  </p></li>
<li><p>Teacher time allocation toward students with greater need.  </p></li>
<li><p>Reduction in learning outcome gaps.  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Teacher overload; autonomy concerns; risk of distraction; privacy; lack of transparency in ITS logic.  </p></li>
<li><p><strong>Enablers:</strong> Wearable displays; context-sensitive analytics; selective visibility; raw data grounding; flexible customization.  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Extends prior LA co-design frameworks by demonstrating a full-cycle, stakeholder-driven design with a novel embodied simulation method. Bridges AI in education and HCI with a focus on actionable, real-time orchestration support.</p>

<hr />

<h2>Summary</h2>

<p>The authors detail a multi-year co-design process culminating in <em>Lumilo</em>, a wearable real-time analytics tool for K–12 teachers in AI-enhanced classrooms. They conceptualize actionability as timely, interpretable, and context-relevant information that directly informs instructional choices without undermining autonomy. The design process surfaced teacher priorities such as “seeing thought processes,” identifying unvoiced needs, and supporting discreet help requests. Operationalization centered on <em>Replay Enactments</em>—immersive, data-driven simulations enabling iterative refinement of analytics and interfaces before live deployment. Classroom results showed improved equity in teacher attention and student learning outcomes. The study offers methodological guidance for co-designing actionable LA systems.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 88 – Strong implicit and partial explicit conceptualization of actionability with detailed features; slightly less formal definitional clarity prevents a perfect score.  </p></li>
<li><p><strong>Operationalization Score:</strong> 95 – Comprehensive, multi-phase, and innovative operationalization with REs; rich linkage between needs, design, and classroom impact.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Such skill mastery estimates were less actionable… if teachers could follow students’ thought processes in real-time… this could provide opportunities… to ‘re-route’ students…” (p. 31)  </p></li>
<li><p>“Receiving more direct… feedback about the effects of their own teaching… could help them adjust their instruction on-the-spot…” (p. 43)  </p></li>
<li><p>“Ground automated inferences in ‘raw’ examples… Showing these example errors is crucial… in supporting teacher trust…” (p. 39)  </p></li>
<li><p>“Prompting teachers to reflect on what… might inform… often led them to notice ways… display could be made more useful…” (p. 47)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Bull &amp; Kay (2016) on grounding analytics in raw data.  </p></li>
<li><p>Martinez-Maldonado et al. (2016) LATUX workflow.  </p></li>
<li><p>Doshi-Velez &amp; Kim (2017) on interpretable ML.  </p></li>
<li><p>Aguilar (2018) on social comparison in analytics.  </p></li>
<li><p>Beck &amp; Gong (2013) on detecting “wheel-spinning.”</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Clinical Practice Guidelines: A Manual for Developing Evidence-Based Guidelines to Facilitate Performance Measurement and Quality Improvement  </p>

<p>Authors: Richard M. Rosenfeld, MD, MPH; Richard N. Shiffman, MD, MCIS  </p>

<p>DOI: 10.1016/j.otohns.2006.06.1277  </p>

<p>Year: 2006  </p>

<p>Publication Type: Journal Article (Special Contribution)  </p>

<p>Discipline/Domain: Medicine / Health Policy  </p>

<p>Subdomain/Topic: Clinical Practice Guideline Development  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 98  </p>

<p>Contains Definition of Actionability: Yes (explicit, as part of defining actionable guideline recommendations)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (COGS, AGREE, GLIA-based framework)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual / Methodological Guide  </p>

<p>Study Context: Guideline development in clinical medicine  </p>

<p>Geographic/Institutional Context: USA; American Academy of Otolaryngology–Head and Neck Surgery, Yale School of Medicine  </p>

<p>Target Users/Stakeholders: Clinicians, healthcare organizations, specialty societies, performance measurement developers  </p>

<p>Primary Contribution Type: Comprehensive, step-by-step manual for actionable guideline creation  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Clinical Practice Guidelines: A Manual for Developing Evidence-Based Guidelines to Facilitate Performance Measurement and Quality Improvement  </p>

<p><strong>Authors:</strong>  </p>

<p>Richard M. Rosenfeld, MD, MPH; Richard N. Shiffman, MD, MCIS  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1016/j.otohns.2006.06.1277  </p>

<p><strong>Year:</strong>  </p>

<p>2006  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article (Special Contribution)  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Medicine / Health Policy  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Clinical Practice Guideline Development  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The manual addresses how to systematically produce clinical practice guidelines that are implementable, measurable, and of high methodological quality. It emphasizes efficiency (12-month target), multidisciplinary collaboration, explicit action statements, and the link between recommendations and performance measurement.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>USA; American Academy of Otolaryngology–Head and Neck Surgery Foundation; Yale School of Medicine  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Clinicians, specialty societies, healthcare organizations, policymakers, and quality improvement bodies  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual / Methodological Guide  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Step-by-step framework for developing actionable, evidence-based clinical practice guidelines  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This manual provides a tested, pragmatic methodology for developing evidence-based clinical practice guidelines (CPGs) intended to facilitate both performance measurement and quality improvement. The authors integrate existing quality standards such as the AGREE instrument, the Conference on Guideline Standardization (COGS) checklist, and the GuideLine Implementability Appraisal (GLIA) tool into a comprehensive process. Key features include defining boldfaced, actionable recommendation statements, linking them explicitly to evidence profiles, and ensuring transparency about values and patient preferences. The manual details all phases—from topic selection and multidisciplinary team formation to literature review, statement drafting, evidence grading, external appraisal, and implementation planning—aimed at producing guidelines that are specific, measurable, and adaptable to performance metrics.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as the creation of <strong>specific, boldfaced key action statements</strong> that direct measurable clinical behaviors, linked to explicit conditions, target populations, and intended outcomes, with evidence-based strength ratings.  </p>

<blockquote>
  <p>“Guidelines should contain a series of key, boldfaced action statements that can be used to describe desired behavior, measure performance, and assess quality.” (p. S1)  </p>
</blockquote>

<blockquote>
  <p>“An ideal key, boldfaced statement describes… When, Who should do what, To whom, why, and how.” (p. S12)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Explicitly states conditions under which to act (decidability)  </p></li>
<li><p>Specifies precise, measurable clinician actions (executability)  </p></li>
<li><p>Links actions to evidence strength and harm–benefit balance  </p></li>
<li><p>Provides rationale, supporting evidence, and value judgments  </p></li>
<li><p>Identifies intended audience and settings  </p></li>
<li><p>Incorporates patient preferences where relevant  </p></li>
<li><p>Is feasible to implement in real-world workflows  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> AGREE instrument, COGS checklist, GLIA tool, AAP evidence grading system  </p></li>
<li><p><strong>Methods/Levers:</strong> Systematic literature search, multidisciplinary consensus, explicit evidence-to-recommendation linkage, use of performance-measure-ready key statements  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> 12-month plan including topic definition, team assembly, literature review, drafting, evidence grading, external appraisal, peer review, and implementation planning  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Evidence profiles (aggregate evidence quality, benefits, harms, costs, values, role of patient preferences, policy level)  </p></li>
<li><p><strong>Implementation Context:</strong> CPGs applicable across diverse clinical settings, designed to support performance measures and maintenance of certification  </p></li>
</ul>

<blockquote>
  <p>“Guideline implementers agree that statements are easiest to implement if parsed into statements of the form: if (conditions) then (actions).” (p. S12)  </p>
</blockquote>

<blockquote>
  <p>“Evidence profile… lists all decisions made by the group” (p. S21)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — explicit, unambiguous statements required (p. S2)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — tailored to defined populations, settings, and users (p. S8–S9)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — GLIA dimension includes “effect on process of care” (p. S23)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Yes — goal to produce within 12 months; timeliness affects impact (p. S1, S26–S27)  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — each action has supporting rationale, evidence, and values (p. S16–S21)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — recommendations linked to quality improvement and patient outcome goals (p. S1)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Decidability, executability, measurability, flexibility, novelty/innovation (GLIA, p. S23)  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Institute of Medicine’s definition of CPGs  </p></li>
<li><p>AGREE instrument for quality appraisal  </p></li>
<li><p>COGS checklist for standardized reporting  </p></li>
<li><p>AAP’s 3-step recommendation strength framework  </p></li>
<li><p>GLIA tool for implementability appraisal  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Presence of explicit “if–then” statements  </p></li>
<li><p>Evidence profile completeness (benefit–harm balance, evidence grade)  </p></li>
<li><p>Linkage to measurable outcomes for performance assessment  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p><strong>Barriers:</strong>  </p>

<ul>
<li><p>Clinician resistance to changing ingrained habits  </p></li>
<li><p>Procedural skills or equipment gaps (p. S23)  </p></li>
<li><p>Cost of recommended interventions (p. S23)  </p></li>
</ul>

<p><strong>Enablers:</strong>  </p>

<ul>
<li><p>Educational outreach and workshops  </p></li>
<li><p>Multidisciplinary buy-in from development stage  </p></li>
<li><p>Free public access to guidelines  </p></li>
<li><p>Algorithmic presentation for clarity (p. S21–S22)  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Positions itself as a synthesis and operationalization of prior work (IOM, AGREE, COGS, GLIA), moving from <strong>conceptual quality standards</strong> to a <strong>practical, reproducible process</strong> designed for producing measurable, implementable guidelines.</p>

<hr />

<h2>Summary</h2>

<p>Rosenfeld and Shiffman’s manual is a blueprint for creating <strong>actionable, performance-measure-ready clinical practice guidelines</strong>. Actionability is embedded in the use of boldfaced, condition-specific, measurable action statements linked to explicit evidence profiles. The manual specifies <strong>how</strong> to develop these statements through a structured, multidisciplinary process grounded in AGREE, COGS, GLIA, and AAP grading frameworks. Attributes such as clarity, contextual relevance, feasibility, timeliness, explainability, and goal alignment are explicitly tied to actionability. Operationalization is detailed step-by-step, from topic selection to implementation and updating, with strong emphasis on transparency, value declaration, and stakeholder engagement. This positions the manual as a high-value resource for both the <strong>conceptualization</strong> and <strong>practical execution</strong> of actionable guideline development.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Provides explicit, comprehensive conceptualization of actionability in CPGs, including definitions, attributes, and structured methods.  </p></li>
<li><p><strong>Operationalization Score:</strong> 98 — Offers full, replicable process for achieving actionability, including tools, templates, and measurable outputs.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Guidelines should contain a series of key, boldfaced action statements that can be used to describe desired behavior, measure performance, and assess quality.” (p. S1)  </p></li>
<li><p>“An ideal key, boldfaced statement describes… When, Who should do what, To whom, why, and how.” (p. S12)  </p></li>
<li><p>“Evidence profile… lists all decisions made by the group.” (p. S21)  </p></li>
<li><p>“Guideline implementers agree that statements are easiest to implement if parsed into statements of the form: if (conditions) then (actions).” (p. S12)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Field MJ, Lohr KN (1990) — IOM definition of CPGs  </p></li>
<li><p>AGREE Collaboration (2003) — AGREE Instrument  </p></li>
<li><p>Shiffman et al. (2003) — COGS checklist  </p></li>
<li><p>AAP Steering Committee (2004) — Recommendation classification framework  </p></li>
<li><p>Shiffman et al. (2005) — GLIA instrument</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Seeking Truth and Actionable Knowledge: How the Scientific Method Inhibits Both</p>

<p>Authors: Chris Argyris</p>

<p>DOI: n/a</p>

<p>Year: n/a</p>

<p>Publication Type: Journal Article</p>

<p>Discipline/Domain: Organizational Studies / Social Science Methodology</p>

<p>Subdomain/Topic: Actionable Knowledge; Organizational Defensive Routines; Scientific Method Critique</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 92</p>

<p>Operationalization Score: 85</p>

<p>Contains Definition of Actionability: Yes (implicit, conceptualized as knowledge enabling effective intervention and change in organizational contexts)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Partial</p>

<p>Contains Framework/Model: Yes (Model I, Model II, 0–1 Learning System)</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual with empirical illustrations</p>

<p>Study Context: Organizational settings, primarily corporate and institutional</p>

<p>Geographic/Institutional Context: U.S.-based, Harvard University</p>

<p>Target Users/Stakeholders: Social scientists, organizational leaders, change agents</p>

<p>Primary Contribution Type: Theoretical framework and methodological critique</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Partial</p>

<p>EX: Yes</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: n/a</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p><em>Seeking Truth and Actionable Knowledge: How the Scientific Method Inhibits Both</em></p>

<p><strong>Authors:</strong>  </p>

<p>Chris Argyris</p>

<p><strong>DOI:</strong>  </p>

<p>n/a</p>

<p><strong>Year:</strong>  </p>

<p>n/a</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Organizational Studies / Social Science Methodology</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Actionable Knowledge; Organizational Defensive Routines; Scientific Method Critique</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses how conventional scientific research methods can unintentionally inhibit the production of actionable knowledge in social science, particularly in contexts involving organizational defensive routines. It critiques “Model I” theories-in-use and limited learning systems, arguing for a shift toward methods and theories that facilitate double-loop learning and effective intervention.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>U.S., Harvard University</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Social scientists, organizational leaders, consultants, change agents</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual analysis with empirical illustrations from organizational research</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Theoretical framework and methodological critique</p>

<h2>General Summary of the Paper</h2>

<p>Argyris critiques the standard application of the scientific method in social sciences, arguing that it often reinforces defensive routines within organizations, limiting both truth-seeking and the generation of actionable knowledge. Through the concepts of “Model I” and “0–1 learning systems,” he shows how prevailing research practices mirror the very defensive behaviors they aim to study, especially when dealing with threatening or embarrassing issues. He calls for the creation of normative models of “rare universes” where defensive routines are minimized, coupled with robust intervention and instructional theories. This approach would enable researchers to produce knowledge that is not only valid but also usable by practitioners in real-world settings.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>Actionable knowledge is framed as information that enables effective change in systems characterized by defensive routines. It must be valid, disconfirmable, and usable under everyday conditions.  </p>

<blockquote>
  <p>“In order to provide a comprehensive description… we must produce propositions about what happens when we try to change them” (p. 12)  </p>
</blockquote>

<blockquote>
  <p>“Researchers should focus on making their normative theories as comprehensive and as empirically valid as possible… and study the processes by which individuals can use the theories in everyday life” (p. 18)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Explicit recognition and surfacing of undiscussable issues</p></li>
<li><p>Valid, disconfirmable knowledge</p></li>
<li><p>Normative models enabling rare but desirable organizational states</p></li>
<li><p>Practical usability under real-time conditions</p></li>
<li><p>Alignment between espoused theories and theories-in-use</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Model I, Model II, 0–1 Learning Systems</p></li>
<li><p><strong>Methods/Levers:</strong> Double-loop learning; theory-of-intervention design; theory-of-instruction development</p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Diagnose defensive routines → Create normative models → Develop intervention &amp; instructional strategies → Implement in real organizational contexts → Provide disconfirmable evidence</p></li>
<li><p><strong>Data &amp; Measures:</strong> Observable behavioral data (conversation transcripts), theory-in-use analysis</p></li>
<li><p><strong>Implementation Context:</strong> Organizational change efforts where defensive routines are prevalent  </p></li>
</ul>

<blockquote>
  <p>“More time and effort should be spent on learning how to produce normative models of rare universes… and study the processes by which individuals can use the theories in everyday life” (p. 18)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – Must make tacit theories explicit and testable (p. 18)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – Models must work in real organizational contexts (p. 18)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – Must be usable under everyday conditions (p. 19–20)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial – Emphasis on real-time usability but not extensively discussed as “timeliness”  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – Provide rationale and make embedded values explicit (p. 18)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – Designed to improve organizational learning and reduce defensive routines  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Disconfirmability; empirical validity under natural conditions</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Organizational Learning Theory (Argyris &amp; Schön, 1974, 1978)  </p></li>
<li><p>Model I / Model II theories-in-use  </p></li>
<li><p>Double-loop learning  </p></li>
<li><p>Defensive routines theory</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Reduction in organizational defensive routines</p></li>
<li><p>Ability to discuss previously undiscussable issues</p></li>
<li><p>Observable changes in theory-in-use</p></li>
<li><p>Successful use of interventions in real-time situations</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Defensive reasoning; organizational culture; lack of intervention skills; research methods reinforcing defensive routines  </p></li>
<li><p><strong>Enablers:</strong> Normative models; explicit theories-in-use; real-time practice; creation of safe contexts for learning</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Argyris positions his critique against traditional scientific method prescriptions (Campbell &amp; Stanley) and psychological theories (learning theory, mass communication research), showing how these often presuppose and perpetuate Model I conditions, limiting the scope of actionable insights.</p>

<h2>Summary</h2>

<p>Argyris’ paper argues that prevailing social science research practices inadvertently reinforce the very defensive patterns they aim to study, limiting both truth-seeking and actionable knowledge. Actionability, in his view, requires producing normative models of alternative organizational realities, grounded in disconfirmable evidence and usable under everyday conditions. This entails shifting focus from abstract generalizations to theory-in-use analysis, developing intervention and instructional frameworks, and openly addressing embedded values and assumptions. The paper’s distinctive contribution is its integration of organizational learning theory, methodological critique, and operational guidance for producing knowledge that organizations can genuinely use to change entrenched behaviors.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 92 — Strong implicit conceptualization of actionability with systematic features and explicit links to organizational learning theory.</p></li>
<li><p><strong>Operationalization Score:</strong> 85 — Provides concrete frameworks (Model I/II), methods, and steps, though practical examples of large-scale implementation are limited.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[Researchers should] study the processes by which individuals can use the theories in everyday life” (p. 18)  </p></li>
<li><p>“More time and effort should be spent on learning how to produce normative models of rare universes…” (p. 18)  </p></li>
<li><p>“It is not possible for human beings to change their theory-in-use because they wish to do so… requires new skills and new values” (p. 19)  </p></li>
<li><p>“In order for human beings to use propositions, they must be producible under everyday life conditions” (p. 19–20)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Argyris &amp; Schön, <em>Theory in Practice</em> (1974)  </p></li>
<li><p>Argyris &amp; Schön, <em>Organizational Learning</em> (1978)  </p></li>
<li><p>Argyris, <em>Reasoning, Learning and Action</em> (1982)  </p></li>
<li><p>Campbell &amp; Stanley, <em>Experimental and Quasi-experimental Design for Research</em> (1963)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: A Survey of Algorithmic Recourse: Contrastive Explanations and Consequential Recommendations  </p>

<p>Authors: Amir-Hossein Karimi, Gilles Barthe, Bernhard Schölkopf, Isabel Valera  </p>

<p>DOI: 10.1145/3442188.3445899  </p>

<p>Year: 2021  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Computer Science / Machine Learning  </p>

<p>Subdomain/Topic: Algorithmic Recourse, Explainable AI, Causal Inference  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual + Review  </p>

<p>Study Context: Automated decision-making in consequential domains (finance, justice, healthcare, hiring)  </p>

<p>Geographic/Institutional Context: Not location-specific; examples from EU GDPR, US legal contexts  </p>

<p>Target Users/Stakeholders: Affected individuals, ML practitioners, legal scholars, researchers  </p>

<p>Primary Contribution Type: Conceptual framework + literature survey  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>A Survey of Algorithmic Recourse: Contrastive Explanations and Consequential Recommendations  </p>

<p><strong>Authors:</strong>  </p>

<p>Amir-Hossein Karimi, Gilles Barthe, Bernhard Schölkopf, Isabel Valera  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1145/3442188.3445899  </p>

<p><strong>Year:</strong>  </p>

<p>2021  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Machine Learning  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Algorithmic Recourse, Explainable AI, Causal Inference  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper reviews and unifies definitions, formulations, and solutions for algorithmic recourse in settings where automated decisions significantly impact individuals’ lives. It clarifies distinctions between contrastive explanations and consequential recommendations, framing them within causal reasoning. It situates recourse alongside ethical ML concerns (fairness, robustness, privacy, security) and identifies open research directions.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Not geographically restricted; draws on EU GDPR and US legal notions.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Individuals affected by automated decisions, ML practitioners, policymakers, legal scholars.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual synthesis and literature review.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework + systematic survey of technical literature.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper consolidates the rapidly growing literature on algorithmic recourse — the provision of explanations and recommendations enabling individuals to change unfavorable decisions from automated systems. It distinguishes between <strong>contrastive explanations</strong> (“Why outcome P rather than Q?”) and <strong>consequential recommendations</strong> (“What actions should I take to achieve Q?”), grounding both in causal inference theory. The authors present unified definitions, formulate the problem as constrained optimization, and categorize constraints such as actionability, plausibility, diversity, and sparsity. They survey over 50 recourse algorithms, analyzing properties like optimality, coverage, and runtime. The paper also explores how recourse interacts with fairness, robustness, security, and privacy, and outlines future research directions beyond deterministic, supervised, and individualized contexts.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>The authors define algorithmic recourse as enabling affected individuals to <strong>understand</strong> and <strong>act</strong> to alleviate an unfavorable outcome, exercising “temporally-extended agency”:contentReference[oaicite:0]{index=0}. Actionability in this context involves not only knowing why a decision occurred but also receiving feasible, effective recommendations to change it.  </p>

<blockquote>
  <p>“An actionable set of changes a person can undertake in order to improve their outcome” (p. n/a)  </p>
</blockquote>

<blockquote>
  <p>“Recourse is offered when the individual is given explanations…and offered recommendations on how to obtain [the desired outcome] in the future” (p. n/a)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Comprehensibility (clear link between features and outcome)  </p></li>
<li><p>Feasibility of interventions (actions possible for the individual)  </p></li>
<li><p>Plausibility (recommendations correspond to realistic states)  </p></li>
<li><p>Causal validity (recommendations derived from interventions in a structural causal model, not just feature manipulations)  </p></li>
<li><p>Alignment with individual goals and constraints  </p></li>
<li><p>Efficiency (minimal cost/effort to achieve the outcome)</p></li>
</ul>

<hr />

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Contrastive explanations vs. consequential recommendations  </p></li>
<li><p><strong>Methods/Levers:</strong> Constrained optimization (distance metrics for explanations; cost functions for recommendations)  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Identify current decision outcome and features  </p>

<p> 2. For explanations: find minimal changes in feature space leading to a different outcome (Eq. 1)  </p>

<p> 3. For recommendations: identify feasible actions within a causal model that lead to a favorable outcome with minimal cost (Eq. 2)  </p>

<p> 4. Apply plausibility, actionability, diversity, and sparsity constraints  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Dissimilarity metrics (e.g., MAD-weighted Manhattan, mixed ℓp norms), cost measures (percentile shifts, ℓp norms)  </p></li>
<li><p><strong>Implementation Context:</strong> Applied to tabular, image, and text data; models include tree-based, kernel-based, differentiable, and others.  </p></li>
</ul>

<blockquote>
  <p>“Minimal consequential recommendations…result in a contrastive explanation when acted upon” (p. n/a)  </p>
</blockquote>

<blockquote>
  <p>“Offering nearest contrastive explanations that are not attainable through minimal effort is of secondary importance” (p. n/a)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Explanations should reveal causal relationships between features and outcome.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Recommendations must account for individual-specific constraints and context.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Only actionable interventions (do-operations) feasible for the individual.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Time-sensitive nature acknowledged (stationarity assumption), but not deeply operationalized.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Transparency in how recommendations are derived.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — Recommendations should align with individual’s goals but often implicit.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Plausibility, diversity, sparsity, robustness, fairness.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Structural Causal Models (Pearl)  </p></li>
<li><p>Counterfactual reasoning in philosophy of science (Lewis, Lipton)  </p></li>
<li><p>Explainable AI literature  </p></li>
<li><p>Ethical ML frameworks (fairness, accountability, GDPR compliance)</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Distance measures (MAD-weighted Manhattan, ℓp norms)  </p></li>
<li><p>Cost measures (effort, percentile shifts)  </p></li>
<li><p>Feasibility constraints satisfaction rate  </p></li>
<li><p>Plausibility constraint adherence  </p></li>
<li><p>Optimality, coverage, runtime</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Incomplete causal knowledge, infeasible recommendations, reliance on manipulable but implausible features, security/privacy risks, non-robustness to model shifts.  </p></li>
<li><p><strong>Enablers:</strong> Accurate causal models, open-source implementations, user interfaces for non-technical stakeholders, diversity in recourse options.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper integrates insights from explainable AI, causal inference, and optimization, positioning algorithmic recourse as distinct from related fields like adversarial perturbations or actionable knowledge discovery by emphasizing stakeholder trust, plausibility, and feasibility.</p>

<hr />

<h2>Summary</h2>

<p>This survey formalizes and unifies the concept of algorithmic recourse, distinguishing between contrastive explanations and consequential recommendations and embedding both in a causal inference framework. Actionability is conceptualized as the combination of comprehensible reasoning, feasible interventions, and realistic outcomes, tailored to an individual’s context. The authors provide operational formulations, catalog a broad range of algorithms, and detail constraints that ensure real-world applicability. They argue for prioritizing minimal consequential recommendations over nearest contrastive explanations and connect recourse to ethical ML considerations like fairness, robustness, and privacy. Future research directions challenge current assumptions of determinism, supervision, and individuality, calling for richer, more realistic recourse systems.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Clear, explicit conceptualization of actionability, systematic identification of its features, and deep integration with related ethical ML considerations.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Provides detailed formulations, metrics, and algorithmic approaches to achieve actionability, though practical implementation still depends on strong causal assumptions.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[Recourse is] an actionable set of changes a person can undertake in order to improve their outcome” (p. n/a)  </p></li>
<li><p>“Recourse is offered when the individual is given explanations…and offered recommendations” (p. n/a)  </p></li>
<li><p>“Minimal consequential recommendations…result in a contrastive explanation when acted upon” (p. n/a)  </p></li>
<li><p>“Offering nearest contrastive explanations that are not attainable through minimal effort is of secondary importance” (p. n/a)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Wachter et al. (2017) — Counterfactual explanations and GDPR compliance  </p></li>
<li><p>Karimi et al. (2020) — Algorithmic recourse from counterfactuals to interventions  </p></li>
<li><p>Ustun et al. (2019) — Actionable recourse in linear classification  </p></li>
<li><p>Miller (2019) — Contrastive explanation in AI  </p></li>
<li><p>Pearl (2000) — Causality: Models, Reasoning, and Inference</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: A Modified LIME and Its Application to Explain Service Supply Chain Forecasting</p>

<p>Authors: Haisheng Li, Wei Fan, Sheng Shi, Qiang Chou</p>

<p>DOI: 10.1007/978-3-030-32236-6_58</p>

<p>Year: 2019</p>

<p>Publication Type: Conference (Lecture Notes in Computer Science)</p>

<p>Discipline/Domain: Computer Science / Artificial Intelligence</p>

<p>Subdomain/Topic: Explainable Artificial Intelligence, Model-agnostic Methods, Service Supply Chain Forecasting</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 35 — The paper focuses on explainability (fidelity, interpretability) but does not explicitly or implicitly link it to “actionability” or being “actionable” in the sense of enabling concrete actions or decisions.</p>

<p>Operationalization Score: 70 — Provides a concrete operational approach (tree-LIME) and fidelity metric (MAE) for regression explanations.</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes (tree-LIME)</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Quantitative (algorithm development and experimental evaluation)</p>

<p>Study Context: Forecasting usage of computer repair parts in a service supply chain</p>

<p>Geographic/Institutional Context: Lenovo Research, Beijing, China</p>

<p>Target Users/Stakeholders: Service supply chain planners, machine learning practitioners</p>

<p>Primary Contribution Type: Methodological (modified explanation algorithm)</p>

<p>CL: No</p>

<p>CR: No</p>

<p>FE: No</p>

<p>TI: No</p>

<p>EX: Yes — focus on explanation fidelity and interpretability</p>

<p>GA: No</p>

<p>Reason if Not Eligible: The study is entirely about model explainability and fidelity in ML forecasting; there is no conceptualization of actionability or link between explanation and actionable decision-making.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>A Modified LIME and Its Application to Explain Service Supply Chain Forecasting</p>

<p><strong>Authors:</strong>  </p>

<p>Haisheng Li, Wei Fan, Sheng Shi, Qiang Chou</p>

<p><strong>DOI:</strong>  </p>

<p>10.1007/978-3-030-32236-6_58</p>

<p><strong>Year:</strong>  </p>

<p>2019</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference (Lecture Notes in Computer Science)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Artificial Intelligence</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Explainable Artificial Intelligence, Model-agnostic Methods, Service Supply Chain Forecasting</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper proposes a modification to the Local Interpretable Model-Agnostic Explanations (LIME) framework to improve local fidelity and interpretability in regression problems by using decision tree regression instead of sparse linear models. This “tree-LIME” is applied to explain forecasts in a real-world service supply chain scenario. The focus is on improving fidelity and providing more interpretable representations, not on actionability.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Lenovo Research, Beijing, China</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Service supply chain planners, ML practitioners</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative — algorithm modification and empirical evaluation</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Methodological</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The study addresses the limitations of LIME in explaining regression models by replacing its local linear approximations with decision tree regression, creating “tree-LIME.” This modification aims to improve the fidelity of explanations and make them more intuitive by providing tree-based representations. The fidelity for regression explanations is formally defined using Mean Absolute Error (MAE) between the explainer’s predictions and the original model’s outputs. The approach is applied to a real-world service supply chain forecasting problem involving predicting weekly usage of computer repair parts. Experiments compare tree-LIME to original LIME on a dataset of over 270,000 training samples, showing improved fidelity and concise decision rule explanations. The authors also explore the impact of tree depth on the trade-off between interpretability and fidelity.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No — The paper does not use the terms “actionability” or “actionable” in connection with its results, insights, or recommendations.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No — There is no argument for actionability or need for actionable results.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> No</p></li>
<li><p><strong>FE (Feasibility):</strong> No</p></li>
<li><p><strong>TI (Timeliness):</strong> No</p></li>
<li><p><strong>EX (Explainability):</strong> Yes — The entire study focuses on improving explanation fidelity and interpretability.</p>

<p> &gt; “The approach also works well when applied to service supply chain forecasting” (p. 2)  </p>

<p> &gt; “Tree-LIME’s fidelity is better than LIME… tree representation for explanation is transparent and concise” (p. 6)</p></li>
<li><p><strong>GA (Goal Alignment):</strong> No</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> None related to actionability.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Model-agnostic interpretability (LIME)</p></li>
<li><p>Decision tree regression (CART)</p></li>
<li><p>Fidelity metrics for regression (MAE)</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p>N/A</p>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper situates itself in the explainable AI literature, contrasting model-agnostic and model-specific methods, and builds on prior work on LIME by Ribeiro et al. It contributes by defining a fidelity metric for regression problems and by proposing a nonlinear local explainer to improve interpretability without sacrificing fidelity.</p>

<hr />

<h2>Summary</h2>

<p>This paper focuses on enhancing the interpretability and fidelity of explanations for black-box regression models in service supply chain forecasting by modifying the LIME framework to use decision tree regression (tree-LIME) instead of linear models. The authors define fidelity for regression using MAE and show experimentally that tree-LIME achieves higher fidelity and produces more concise decision rule explanations than original LIME when applied to a complex real-world dataset. They explore the trade-off between fidelity and interpretability via tree depth and conclude that depths of 4–5 offer a good balance. While the work provides a valuable methodological contribution to explainable AI, it does not address actionability — neither explicitly nor implicitly — and focuses solely on the quality of explanations rather than their capacity to inform or drive decisions.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 35 — Strong on explainability, but no link to actionability or decision-oriented features.</p></li>
<li><p><strong>Operationalization Score:</strong> 70 — Clear operational methodology for improved explanation fidelity; not linked to actionability.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Tree-LIME… can effectively locally approximate the original model to be explained with the tree interpretable representation.” (p. 3)  </p></li>
<li><p>“For regression problem, the mean absolute error (MAE) … as the fidelity measure.” (p. 4)  </p></li>
<li><p>“Tree-LIME’s fidelity is better than LIME… tree representation for explanation is transparent and concise.” (p. 6)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Towards Understanding the Role of the Human in Event Log Extraction</p>

<p>Authors: Vinicius Stein Dani; Henrik Leopold; Jan Martijn E. M. van der Werf; Xixi Lu; Iris Beerepoot; Jelmer J. Koorn; Hajo A. Reijers</p>

<p>DOI: N/A</p>

<p>Year: 2022</p>

<p>Publication Type: Conference (assumed)</p>

<p>Discipline/Domain: Process Mining / Information Systems</p>

<p>Subdomain/Topic: Event log extraction; human-in-the-loop; taxonomy of manual tasks</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 20</p>

<p>Operationalization Score: 10</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes (taxonomy of manual tasks)</p>

<p>Operationalization Present: No</p>

<p>Primary Methodology: Mixed Methods (Structured literature review + qualitative coding)</p>

<p>Study Context: Process mining case studies (2000–2020) informing a taxonomy of human tasks in event log extraction</p>

<p>Geographic/Institutional Context: Utrecht University (NL) and Kühne Logistics University (DE); application contexts span multiple domains from reviewed case studies</p>

<p>Target Users/Stakeholders: Process analysts; data engineers; domain experts; researchers developing extraction/automation methods</p>

<p>Primary Contribution Type: Taxonomy and methodological reflection</p>

<p>CL: No</p>

<p>CR: No</p>

<p>FE: No</p>

<p>TI: No</p>

<p>EX: No</p>

<p>GA: No</p>

<p>Reason if Not Eligible: The paper does not use or define “actionable/actionability,” nor does it articulate properties/criteria that make outputs actionable; it focuses on cataloging human tasks during event log extraction and implications for automation/guidance.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Towards Understanding the Role of the Human in Event Log Extraction</p>

<p><strong>Authors:</strong>  </p>

<p>Vinicius Stein Dani; Henrik Leopold; Jan Martijn E. M. van der Werf; Xixi Lu; Iris Beerepoot; Jelmer J. Koorn; Hajo A. Reijers</p>

<p><strong>DOI:</strong>  </p>

<p>N/A</p>

<p><strong>Year:</strong>  </p>

<p>2022</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference (assumed)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Process Mining / Information Systems</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Event log extraction; human-in-the-loop; taxonomy of manual tasks</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper observes that process mining’s application is often hindered by substantial human preparation effort—especially to obtain and transform data into an event log—prompting a study to precisely characterize manual activities in extraction via literature review and qualitative coding. :contentReference[oaicite:0]{index=0}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Authored by researchers from Utrecht University (NL) and Kühne Logistics University (DE); evidence base is cross-domain case studies. :contentReference[oaicite:1]{index=1}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process analysts, data engineers, domain experts, method/tool developers. :contentReference[oaicite:2]{index=2}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Structured literature review (Scopus case studies) + qualitative coding to derive a taxonomy. :contentReference[oaicite:3]{index=3}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Taxonomy of manual tasks in event log extraction and discussion of implications for automation and guidance. :contentReference[oaicite:4]{index=4}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors investigate how humans are involved in extracting event logs for process mining. They conduct a structured literature review (initial 191 papers; 46 analyzed for manual tasks) and apply qualitative coding to derive a taxonomy of human tasks. The taxonomy comprises five categories: context/scope definition, data source assessment, attribute selection, data source extraction, and event log assessment. The paper argues this overview can guide future automation efforts and provide practical guidance (e.g., checklists) for manual steps. It also acknowledges limitations related to literature scope and reporting gaps. :contentReference[oaicite:5]{index=5}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No. The terms “actionable/actionability” are not used nor are equivalent criteria linked explicitly to “being actionable.” The focus is on cataloging human tasks and implications for automation/guidance. :contentReference[oaicite:6]{index=6}</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No. The authors argue for precision in understanding human tasks to enable automation and guidance, not for “actionability” of outputs. :contentReference[oaicite:7]{index=7}</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> No</p></li>
<li><p><strong>FE (Feasibility):</strong> No</p></li>
<li><p><strong>TI (Timeliness):</strong> No</p></li>
<li><p><strong>EX (Explainability):</strong> No</p></li>
<li><p><strong>GA (Goal Alignment):</strong> No</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<p>Process mining methodology background (e.g., PM2), literature-driven taxonomy development via qualitative coding. :contentReference[oaicite:8]{index=8}</p>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p>N/A</p>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper synthesizes case-study evidence to map recurring manual tasks across the extraction pipeline, noting that existing techniques often tackle isolated technical aspects without clarifying the human role; it positions the taxonomy as groundwork for more holistic automation and structured guidance. :contentReference[oaicite:9]{index=9}</p>

<hr />

<h2>Summary</h2>

<p>This paper catalogs the human work necessary to transform heterogeneous operational data into process-centric event logs for process mining. Drawing on a structured literature review and qualitative coding of 46 case-study papers, the authors propose a five-part taxonomy: (1) context &amp; scope definition; (2) data source assessment (including defining sources, reverse-engineering meta models, data quality auditing, locating missing data); (3) attribute selection (e.g., defining events/activity names, event types, timestamp characteristics, case notion, and mappings); (4) data source extraction (e.g., defining collectors, aggregations, transformations, filtering, anonymization, scoping); and (5) event log assessment (exploration, noise analysis, problem identification). The paper emphasizes that not all manual steps can be automated, but many can be better supported, and that the taxonomy can guide future tooling and methodologies. A figure on p. 5 visually summarizes the taxonomy and frequencies across the literature, while an example log (Table 1, p. 2) grounds the discussion. :contentReference[oaicite:10]{index=10}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 20 — Useful context for process mining execution but provides no definition, criteria, or conceptualization of “actionability”; therefore, limited relevance to actionability-specific research.</p></li>
<li><p><strong>Operationalization Score:</strong> 10 — Offers a taxonomy (framework) of tasks and implications for automation/guidance, but no operational guidance on achieving or assessing <em>actionability</em> per se.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Therefore, the research question of this paper is ‘What are the specific manual tasks that humans perform in the context of event log extraction?’” (p. 3). :contentReference[oaicite:11]{index=11}  </p></li>
<li><p>“A visual representation of our taxonomy is shown in Figure 1. It consists of five categories…” (p. 5). :contentReference[oaicite:12]{index=12}  </p></li>
<li><p>“The extraction of event logs comes with substantial human effort. In this paper, we set out to develop a precise understanding of which manual tasks humans perform…” (p. 10). :contentReference[oaicite:13]{index=13}  </p></li>
<li><p>“Our taxonomy… can also serve as input for future automation efforts and for methodological process mining support.” (p. 10). :contentReference[oaicite:14]{index=14}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A — The paper does not cite or develop an explicit “actionability” construct; references are about event log extraction, process mining methods, and case studies. :contentReference[oaicite:15]{index=15}</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: On the Trade-offs between Adversarial Robustness and Actionable Explanations  </p>

<p>Authors: Satyapriya Krishna, Chirag Agarwal, Himabindu Lakkaraju  </p>

<p>DOI: 10.3390/analytics1020008  </p>

<p>Year: 2024  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Machine Learning, Explainable AI  </p>

<p>Subdomain/Topic: Adversarial Robustness, Counterfactual Explanations  </p>

<p>Eligibility: Yes  </p>

<p>Overall Relevance Score: 90  </p>

<p>Operationalization Score: 85  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Theoretical and Empirical Analysis  </p>

<p>Study Context: Adversarial Robustness vs. Actionable Explanations in Machine Learning  </p>

<p>Geographic/Institutional Context: Harvard University  </p>

<p>Target Users/Stakeholders: AI Researchers, ML Practitioners, Data Scientists  </p>

<p>Primary Contribution Type: Theoretical Analysis, Empirical Evaluation  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Yes  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: n/a  </p>

<!--META_END-->

<p><strong>Title:</strong> On the Trade-offs between Adversarial Robustness and Actionable Explanations  </p>

<p><strong>Authors:</strong> Satyapriya Krishna, Chirag Agarwal, Himabindu Lakkaraju  </p>

<p><strong>DOI:</strong> 10.3390/analytics1020008  </p>

<p><strong>Year:</strong> 2024  </p>

<p><strong>Publication Type:</strong> Journal  </p>

<p><strong>Discipline/Domain:</strong> Machine Learning, Explainable AI  </p>

<p><strong>Subdomain/Topic:</strong> Adversarial Robustness, Counterfactual Explanations  </p>

<p><strong>Contextual Background:</strong> The paper explores the trade-offs between two important characteristics of machine learning models: adversarial robustness and the ability to provide actionable explanations. The authors examine how adversarially robust models affect the cost (ease of implementation) and validity (probability of success) of counterfactual explanations, which are typically used for generating actionable recourses. The study theoretically and empirically investigates these trade-offs using real-world datasets and compares state-of-the-art algorithms for adversarially robust and non-robust models.  </p>

<p><strong>Geographic/Institutional Context:</strong> Harvard University  </p>

<p><strong>Target Users/Stakeholders:</strong> AI researchers, machine learning practitioners, stakeholders in high-stakes decision-making applications  </p>

<p><strong>Primary Methodology:</strong> Theoretical bounds, empirical analysis on real-world datasets  </p>

<p><strong>Primary Contribution Type:</strong> Theoretical framework, empirical study  </p>

<h2>General Summary of the Paper</h2>

<p>This paper examines the relationship between adversarial robustness and the generation of actionable recourses in machine learning models. Adversarially robust models are trained to resist small perturbations in input data, which improves model reliability but may affect the feasibility and validity of the recourses (counterfactual explanations) provided to affected individuals. The authors present both theoretical and empirical analyses to investigate how the degree of adversarial robustness impacts the cost and validity of recourses, demonstrating that stronger robustness typically leads to higher recourse costs and reduced validity. The paper highlights the inherent trade-offs between model robustness and the practical utility of actionable explanations.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<p>Reason if Not Eligible: n/a  </p>

<h2>How Actionability is Understood</h2>

<p>In this context, actionability is understood as the ability to provide actionable recourses (counterfactual explanations) to individuals who are impacted by model predictions. These recourses suggest the minimal changes that an individual should make to their input data to change the model’s outcome. The paper emphasizes that for recourses to be actionable, they need to be both feasible (i.e., easy to implement) and valid (i.e., likely to result in the desired outcome).  </p>

<blockquote>
  <p>“Actionable explanations are those that provide individuals with practical, implementable changes to their data to achieve a positive model prediction” (p. 4).  </p>
</blockquote>

<blockquote>
  <p>“The ability to generate valid and feasible recourses is a key aspect of actionability in machine learning models” (p. 6).</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<p>For counterfactual explanations to be actionable, they must meet two key criteria:</p>

<ol>
<li><p><strong>Feasibility (Cost):</strong> The cost of implementing the changes suggested by the explanation should be minimal, meaning that the required changes to the data are small and easy to apply.  </p></li>
<li><p><strong>Validity:</strong> The recourse should have a high probability of achieving the desired model outcome, ensuring that the changes will indeed result in a positive decision.  </p></li>
</ol>

<blockquote>
  <p>“Actionability is achieved when the cost of implementing the changes is low, and the probability of achieving the desired outcome is high” (p. 5).  </p>
</blockquote>

<blockquote>
  <p>“The balance between the cost of recourses and their validity is a crucial factor in determining actionability” (p. 5).</p>
</blockquote>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<p>Actionability is operationalized by evaluating the <strong>cost</strong> and <strong>validity</strong> of counterfactual explanations generated by adversarially robust and non-robust models. The paper examines these aspects both theoretically (using bounds on cost and validity) and empirically (using real-world datasets).  </p>

<ul>
<li><p><strong>Cost:</strong> Measured by the L2-norm distance between the original and counterfactual instances.  </p></li>
<li><p><strong>Validity:</strong> Measured by the probability that the counterfactual leads to the desired outcome (e.g., a positive loan approval prediction).  </p></li>
</ul>

<blockquote>
  <p>“We measure the cost of recourse as the L2 distance between the factual instance and the generated counterfactual” (p. 7).  </p>
</blockquote>

<blockquote>
  <p>“The validity of recourses is evaluated by computing the probability of achieving the desired model outcome” (p. 7).</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes – Clarity of the changes needed is inherent in the definition of actionable recourses, as they must specify the minimal changes required.  </p>

<p> &gt; “Clear explanations are necessary for actionability, as individuals need to know exactly what changes to make to their data” (p. 6).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes – The recourses must be relevant to the individual's context, meaning they should lead to a valid outcome for the individual’s situation.  </p>

<p> &gt; “Contextual relevance is key to actionability, as the changes suggested must result in a valid decision for the individual” (p. 6).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes – Feasibility is central to actionability, ensuring that the changes are easy for the affected individual to implement.  </p>

<p> &gt; “Feasible recourses are those that are realistic and easy to implement within the constraints of the individual’s context” (p. 5).  </p></li>
<li><p><strong>TI (Timeliness):</strong> No – Timeliness is not specifically addressed in the paper, but it may be an implicit factor in the validity and cost of the recourses.  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes – Actionable explanations must be understandable, so the individual knows how to act on the advice.  </p>

<p> &gt; “Explainability is essential for actionability, as users must understand the suggested changes to effectively implement them” (p. 6).  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes – The recourses should align with the individual's goal, ensuring that the suggested changes move them toward achieving the desired outcome.  </p>

<p> &gt; “Goal alignment is a key aspect of actionable explanations, as the recourses must help individuals reach their desired outcome” (p. 5).</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<p>The paper builds on existing theories in machine learning interpretability, particularly the work on counterfactual explanations and adversarial robustness. The authors extend these ideas by analyzing how adversarially robust models impact the quality of recourses generated by state-of-the-art algorithms.  </p>

<blockquote>
  <p>“This paper extends the existing literature on adversarial robustness and counterfactual explanations by analyzing the trade-offs between these two important properties” (p. 4).</p>
</blockquote>

<h2>Indicators or Metrics for Actionability</h2>

<p>The primary metrics used to measure actionability are <strong>cost</strong> (measured as the L2-norm distance between the factual and counterfactual instances) and <strong>validity</strong> (measured by the probability that the counterfactual will lead to the desired outcome).  </p>

<blockquote>
  <p>“We use the L2-norm to quantify the cost of recourses and measure validity by evaluating the probability of achieving the target model outcome” (p. 7).</p>
</blockquote>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Adversarial robustness introduces challenges, such as increased cost and reduced validity of recourses, which can hinder actionability.  </p></li>
<li><p><strong>Enablers:</strong> Non-robust models, which provide lower-cost and higher-validity recourses, enable more effective actionability.  </p></li>
</ul>

<blockquote>
  <p>“The increased cost and decreased validity of recourses in adversarially robust models create a significant barrier to actionability” (p. 8).  </p>
</blockquote>

<blockquote>
  <p>“Non-robust models provide lower-cost and higher-validity recourses, facilitating more actionable explanations” (p. 8).</p>
</blockquote>

<h2>Relation to Existing Literature</h2>

<p>The paper fills a gap in the existing literature by explicitly examining the trade-offs between adversarial robustness and actionability, an area that has received little attention in previous work.  </p>

<blockquote>
  <p>“Our work is one of the first to examine the trade-offs between adversarial robustness and actionable explanations, a gap that existing literature has not adequately addressed” (p. 4).</p>
</blockquote>

<h2>Summary</h2>

<p>This paper investigates the trade-offs between adversarial robustness and actionable explanations in machine learning models. It provides both theoretical and empirical analyses, demonstrating that adversarially robust models tend to increase the cost and decrease the validity of algorithmic recourses, making them less actionable. The findings highlight the inherent challenges of balancing model robustness with the need for reliable and feasible recourses, and suggest that adversarial robustness can complicate the provision of actionable insights.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 – The paper addresses an important and underexplored area in machine learning, offering valuable insights into the trade-offs between model robustness and explainability.  </p></li>
<li><p><strong>Operationalization Score:</strong> 85 – The paper presents a clear framework for evaluating the cost and validity of recourses but could benefit from more detailed guidance for practitioners on how to implement these findings.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Feasible recourses are those that are realistic and easy to implement within the constraints of the individual’s context” (p. 5).  </p></li>
<li><p>“Actionability is achieved when the cost of implementing the changes is low, and the probability of achieving the desired outcome is high” (p. 5).  </p></li>
<li><p>“The increased cost and decreased validity of recourses in adversarially robust models create a significant barrier to actionability” (p. 8).  </p></li>
<li><p>“Our work is one of the first to examine the trade-offs between adversarial robustness and actionable explanations” (p. 4).</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Wachter, S., Mittelstadt, B., &amp; Russell, C. (2018). Counterfactual explanations without opening the black box: Automated decisions and the GDPR.  </p></li>
<li><p>Ustun, B., Spangher, A., &amp; Liu, Y. (2019). Actionable recourse in linear classification.  </p></li>
<li><p>Pawelczyk, M., Broelemann, K., &amp; Kasneci, G. (2020). Learning model-agnostic counterfactual explanations for tabular data.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: FACE: Feasible and Actionable Counterfactual Explanations</p>

<p>Authors: Rafael Poyiadzi, Kacper Sokol, Raul Santos-Rodriguez, Tijl De Bie, Peter Flach</p>

<p>DOI: https://doi.org/10.1145/3375627.3375850</p>

<p>Year: 2020</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Artificial Intelligence / Machine Learning</p>

<p>Subdomain/Topic: Explainable AI (XAI), Counterfactual Explanations</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 90</p>

<p>Operationalization Score: 95</p>

<p>Contains Definition of Actionability: Yes (implicit and explicit via feasibility + actionable path requirements)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Yes</p>

<p>Contains Interpretability: Yes</p>

<p>Contains Framework/Model: Yes (FACE algorithm)</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Conceptual + Algorithmic with Empirical Demonstration</p>

<p>Study Context: Algorithmic explainability for decision-making systems</p>

<p>Geographic/Institutional Context: University of Bristol, University of Ghent</p>

<p>Target Users/Stakeholders: Individuals receiving automated decisions (e.g., loan applicants), AI practitioners, policy/regulation compliance</p>

<p>Primary Contribution Type: Conceptual framework + Algorithm</p>

<p>CL: Yes — clarity of feasible, coherent, and interpretable path is essential for actionability.</p>

<p>CR: Yes — contextual relevance to real-world feasibility emphasized.</p>

<p>FE: Yes — feasibility explicitly required for actionability.</p>

<p>TI: Partial — timeliness is not central, but feasibility implicitly assumes achievable change within realistic time.</p>

<p>EX: Yes — explainability as part of model-agnostic, understandable paths.</p>

<p>GA: Yes — goal alignment with desired class/outcome is fundamental.</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>FACE: Feasible and Actionable Counterfactual Explanations  </p>

<p><strong>Authors:</strong>  </p>

<p>Rafael Poyiadzi, Kacper Sokol, Raul Santos-Rodriguez, Tijl De Bie, Peter Flach  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1145/3375627.3375850  </p>

<p><strong>Year:</strong>  </p>

<p>2020  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Artificial Intelligence / Machine Learning  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Explainable AI, Counterfactual Explanations  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses limitations in existing counterfactual explanation methods in machine learning, specifically focusing on producing counterfactuals that are not only close in feature space but also <em>feasible</em> and <em>actionable</em>. It is designed for practical decision-making contexts, such as loan approvals, where advice must be realistic and aligned with the user’s circumstances.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of Bristol, University of Ghent  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Loan applicants, individuals affected by automated decision systems, explainability tool developers, regulators.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual + Algorithmic with empirical demonstration on synthetic and MNIST datasets.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Novel algorithm (FACE) + conceptual reframing of counterfactual actionability.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper critiques the dominant “closest possible world” approach to counterfactual explanations, highlighting that such counterfactuals may reside in low-density, unrealistic regions of the data space and lack feasible paths for the individual to achieve the desired state. The authors introduce <em>FACE</em> — Feasible and Actionable Counterfactual Explanations — which generate counterfactuals coherent with the data distribution and connected via high-density, feasible paths to the original instance. FACE uses density-weighted shortest paths in a graph constructed from the data to identify achievable transitions. Demonstrations on synthetic datasets and MNIST illustrate the approach. FACE improves actionability by incorporating feasibility constraints, domain knowledge, and classifier confidence thresholds.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>The paper defines actionability in terms of producing counterfactuals that are:</p>

<ul>
<li><p>Situated in high-density regions of the feature space.</p></li>
<li><p>Connected to the original data point by a feasible, realistic transformation path.</p></li>
</ul>

<blockquote>
  <p>“We identify two essential properties of counterfactual explanations: feasibility and actionability” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“…providing actionable and feasible paths to transform a selected instance into one that meets a certain goal” (p. 1)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Feasibility of the counterfactual state (achievable in real life).</p></li>
<li><p>High-density region representation (coherence with data distribution).</p></li>
<li><p>Existence of a feasible path with short length and high density.</p></li>
<li><p>Avoidance of unrealistic or offensive prescriptions (e.g., changing immutable attributes).</p></li>
<li><p>Alignment with desired class outcome and real-world constraints.</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> FACE (Feasible and Actionable Counterfactual Explanations)</p></li>
<li><p><strong>Methods/Levers:</strong> Density-weighted shortest path search over a graph of data points.</p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Construct a graph using KDE, k-NN, or ε-graph based on dataset.  </p>

<p> 2. Apply prediction confidence and density thresholds.  </p>

<p> 3. Remove infeasible transitions using domain constraints (immutable/conditionally mutable features).  </p>

<p> 4. Run Dijkstra’s algorithm to find shortest high-density path to a target class instance.</p></li>
<li><p><strong>Data &amp; Measures:</strong> Density estimates (KDE), classifier confidence scores, distance metrics.</p></li>
<li><p><strong>Implementation Context:</strong> Model-agnostic, applicable to tabular or image data.</p></li>
</ul>

<blockquote>
  <p>“Our approach… generates counterfactuals that are coherent with the underlying data distribution and supported by ‘feasible paths’ of change” (p. 1)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL:</strong> Yes — counterfactuals must be interpretable and coherent with the data.</p></li>
<li><p><strong>CR:</strong> Yes — paths must be relevant to real-world conditions and domain constraints.</p></li>
<li><p><strong>FE:</strong> Yes — feasibility is explicitly central.</p></li>
<li><p><strong>TI:</strong> Partial — implicitly considered via feasible steps achievable over time.</p></li>
<li><p><strong>EX:</strong> Yes — explanations are model-agnostic and understandable.</p></li>
<li><p><strong>GA:</strong> Yes — targets aligned with desired outcome class.</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> High-density path requirement.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Counterfactual and contrastive explanations literature (Wachter et al., 2017).</p></li>
<li><p>Graph-theoretic shortest paths (Dijkstra’s algorithm).</p></li>
<li><p>Kernel density estimation for distribution-aware distances.</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Density thresholds.</p></li>
<li><p>Prediction confidence thresholds.</p></li>
<li><p>Path length in density-weighted space.</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Low-density/unrealistic counterfactuals; immutable features; classifier uncertainty in sparse regions.</p></li>
<li><p><strong>Enablers:</strong> Density-weighted feasible paths; domain knowledge constraints; customizable cost functions.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>FACE is compared against Wachter et al. (2017), Ustun et al. (2019), Russell (2019), and Waa et al. (2018), surpassing them in combining model-agnostic applicability, discrete feature handling, and explicit feasibility/actionability requirements.</p>

<hr />

<h2>Summary</h2>

<p>The authors introduce FACE, a method for generating counterfactual explanations that are feasible and actionable, addressing gaps in the current “closest possible world” paradigm. FACE ensures counterfactuals are located in high-density regions and connected to the original instance through realistic transformation paths. This is operationalized using density-weighted shortest path algorithms with feasibility constraints. The method is model-agnostic, supports discrete features, incorporates domain restrictions, and produces explanations coherent with the data distribution. Demonstrations show FACE avoids impractical or misleading counterfactuals, offering more trustworthy and implementable recommendations.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 90 — Strong and explicit conceptualization of actionability in counterfactual explanations; well-integrated into methodological proposal.</p></li>
<li><p><strong>Operationalization Score:</strong> 95 — Detailed algorithmic approach, with parameters, constraints, and examples, fully linked to achieving actionability.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“We identify two essential properties of counterfactual explanations: feasibility and actionability” (p. 2)</p></li>
<li><p>“Providing actionable and feasible paths to transform a selected instance into one that meets a certain goal” (p. 1)</p></li>
<li><p>“Feasibility of the counterfactual data point, continuity and feasibility of the path linking it with the data point being explained, and high density along this path” (p. 3)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Wachter, Mittelstadt, &amp; Russell (2017) — Counterfactual Explanations framework.</p></li>
<li><p>Ustun, Spangher, &amp; Liu (2019) — Actionable recourse.</p></li>
<li><p>Russell (2019) — Diverse coherent explanations.</p></li>
<li><p>Waa et al. (2018) — Local foil trees for contrastive explanations.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Evaluating the understandability and actionability of online CKD educational materials</p>

<p>Authors: Emi Furukawa, Tsuyoshi Okuhara, Hiroko Okada, Yuriko Nishiie, Takahiro Kiuchi</p>

<p>DOI: https://doi.org/10.1007/s10157-023-02401-6</p>

<p>Year: 2024</p>

<p>Publication Type: Journal</p>

<p>Discipline/Domain: Health Communication / Nephrology</p>

<p>Subdomain/Topic: Chronic Kidney Disease (CKD) patient education, online health information evaluation</p>

<p>Eligibility: Eligible</p>

<p>Overall Relevance Score: 85</p>

<p>Operationalization Score: 80</p>

<p>Contains Definition of Actionability: Yes (implicit via PEMAT framework and study framing)</p>

<p>Contains Systematic Features/Dimensions: Yes</p>

<p>Contains Explainability: Partial</p>

<p>Contains Interpretability: Yes (via understandability dimension)</p>

<p>Contains Framework/Model: Yes (Japanese version of PEMAT-P)</p>

<p>Operationalization Present: Yes</p>

<p>Primary Methodology: Quantitative content analysis</p>

<p>Study Context: Evaluation of Japanese-language online CKD educational webpages</p>

<p>Geographic/Institutional Context: Japan; The University of Tokyo</p>

<p>Target Users/Stakeholders: CKD patients, their families, general public</p>

<p>Primary Contribution Type: Empirical evaluation and methodological application</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: No</p>

<p>EX: Partial</p>

<p>GA: Partial</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Evaluating the understandability and actionability of online CKD educational materials  </p>

<p><strong>Authors:</strong>  </p>

<p>Emi Furukawa, Tsuyoshi Okuhara, Hiroko Okada, Yuriko Nishiie, Takahiro Kiuchi  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1007/s10157-023-02401-6  </p>

<p><strong>Year:</strong>  </p>

<p>2024  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Health Communication / Nephrology  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Chronic Kidney Disease (CKD) patient education, online health information evaluation  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>CKD is prevalent yet under-recognized in Japan, with low public awareness and limited health literacy. Online resources are a key channel for patient education but may lack clarity and practical guidance to support behavior change.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Japan; conducted by The University of Tokyo  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>CKD patients, their families, general public  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative content analysis of Japanese-language CKD webpages using PEMAT-P, GQS, and jReadability  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical evaluation of online educational material quality and actionability  </p>

<h2>General Summary of the Paper</h2>

<p>This study systematically evaluated 186 Japanese-language online educational materials on chronic kidney disease (CKD) for their understandability and actionability using the Japanese version of the Patient Education Materials Assessment Tool for Printed Materials (PEMAT-P). The analysis also considered content quality (GQS) and readability (jReadability). The results revealed low average scores for understandability (61.5%) and especially actionability (38.7%), with lifestyle modification pages outperforming those on symptoms or treatment. Materials from for-profit companies tended to be more understandable and visually supportive than those from medical or academic institutions. The authors recommend adopting plain language, defining medical terms, and using clear visual aids and actionable tools to improve patient engagement and health behaviors.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<h2>How Actionability is Understood</h2>

<p>Actionability is framed through the PEMAT definition: materials are actionable if they clearly identify actions the user can take, break them into explicit steps, use direct address, provide tangible tools, and employ visual aids to facilitate action.  </p>

<blockquote>
  <p>“PEMAT systematically examines how the required action points are presented” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“The material clearly identifies at least one action the user can take… breaks down any action into explicit steps… provides tangible tools” (Table 2, p. 5)  </p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Clearly stated, specific actions for the user  </p></li>
<li><p>Directly addressing the user when describing actions  </p></li>
<li><p>Breaking actions into explicit, manageable steps  </p></li>
<li><p>Providing tangible tools (e.g., checklists, planners)  </p></li>
<li><p>Using visual aids to make it easier to act on instructions  </p></li>
<li><p>Explaining how to use visual elements to support actions  </p></li>
</ul>

<h2><strong>How Actionability is Achieved / Operationalized</strong></h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Japanese version of PEMAT-P  </p></li>
<li><p><strong>Methods/Levers:</strong> Binary-item assessment of 7 actionability criteria (agree/disagree)  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify CKD webpages → classify by topic/source/audience → score using PEMAT-P actionability items → analyze by ANOVA and post-hoc tests  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Actionability percentage score (threshold 70% for acceptable)  </p></li>
<li><p><strong>Implementation Context:</strong> Japanese-language CKD patient educational webpages  </p></li>
</ul>

<blockquote>
  <p>“We calculated the PEMAT-P scores… multiplying the result by 100 to obtain a percentage… set the threshold of 70% to be considered… actionable” (p. 3)  </p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — “Many had difficulty using only common, everyday language and did not explain medical terms” (p. 3)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — lifestyle modification materials were more relevant and actionable than disease overview (p. 4)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — tangible tools/checklists suggested for feasibility (p. 6)  </p></li>
<li><p><strong>TI (Timeliness):</strong> No explicit link found  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — some use of captions, but many visual aids unclear (p. 5)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — lifestyle recommendations aligned with health goals (p. 4)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Use of plain language, structured layout, visual reinforcement, and defined terms  </p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>PEMAT framework (AHRQ)  </p></li>
<li><p>National Action Plan on Health Literacy (U.S. HHS)  </p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>PEMAT-P actionability score (% of applicable items marked “agree”)  </p></li>
<li><p>Threshold ≥70% considered actionable  </p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Excessive medical jargon; lack of visual aids for actions; absence of tangible tools; unclear illustrations; missing summaries  </p></li>
<li><p><strong>Enablers:</strong> Use of plain language; clear, patient-centered visuals; structured actionable steps; commercial company design practices  </p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Findings align with prior studies showing lower actionability than understandability, and the need for better visual design and plain language. Contrasts with English-language materials where public institutions often perform better.  </p>

<h2>Summary</h2>

<p>The paper offers a robust, operationalized view of actionability grounded in the PEMAT framework, applied to CKD patient education materials in Japan. Actionability hinges on clear, user-directed, and stepwise guidance supplemented by tangible tools and visual aids. The study shows that most current materials fall short, particularly those from medical and academic institutions, while commercial entities fare better in design and clarity. Recommendations include adopting plain language, defining technical terms, improving visual supports, and integrating practical tools to enhance patient engagement and self-management. This makes the paper valuable both for conceptual understanding and for methodological replication in evaluating other health topics.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 — Strong conceptual framing via PEMAT and clear link between attributes and actionability, though no novel theoretical definition beyond operational tool.  </p></li>
<li><p><strong>Operationalization Score:</strong> 80 — Fully operationalized through PEMAT-P items and scoring; provides detailed criteria and thresholds, but lacks qualitative exploration of patient-perceived actionability.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“PEMAT systematically examines how the required action points are presented” (p. 2)  </p></li>
<li><p>“The material clearly identifies at least one action the user can take” (Table 2, p. 5)  </p></li>
<li><p>“Lacked clear and concise charts and illustrations to encourage action” (p. 1)  </p></li>
<li><p>“Webpages… lacked visual aids to encourage the audience to take action” (p. 3)  </p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Shoemaker SJ et al. (2014) — Development of PEMAT (Patient Educ Couns)  </p></li>
<li><p>National Action Plan to Improve Health Literacy (U.S. HHS, 2010)  </p></li>
<li><p>Morony S et al. (2017) — CKD lifestyle info and actionability analysis</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Directive Explanations for Actionable Explainability in Machine Learning Applications  </p>

<p>Authors: Ronal Singh, Tim Miller, Henrietta Lyons, Liz Sonenberg, Eduardo Velloso, Frank Vetere, Piers Howe, Paul Dourish  </p>

<p>DOI: 10.1145/3579363  </p>

<p>Year: 2023  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Human-Computer Interaction / Artificial Intelligence  </p>

<p>Subdomain/Topic: Explainable AI (XAI), Counterfactual Explanations, Actionable Recourse  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (explicitly defines “directive explanations” as a form of actionable explanation)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (MDP-based model)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Mixed Methods (Quantitative + Qualitative user studies, conceptual modeling)  </p>

<p>Study Context: Credit scoring and employee satisfaction prediction systems  </p>

<p>Geographic/Institutional Context: United States participants, University of Melbourne research team  </p>

<p>Target Users/Stakeholders: Loan officers, HR officers, decision recipients (customers, employees)  </p>

<p>Primary Contribution Type: Conceptual model + empirical evaluation  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong> Directive Explanations for Actionable Explainability in Machine Learning Applications  </p>

<p><strong>Authors:</strong> Ronal Singh, Tim Miller, Henrietta Lyons, Liz Sonenberg, Eduardo Velloso, Frank Vetere, Piers Howe, Paul Dourish  </p>

<p><strong>DOI:</strong> 10.1145/3579363  </p>

<p><strong>Year:</strong> 2023  </p>

<p><strong>Publication Type:</strong> Journal  </p>

<p><strong>Discipline/Domain:</strong> Human-Computer Interaction / Artificial Intelligence  </p>

<p><strong>Subdomain/Topic:</strong> Explainable AI, Counterfactuals, Actionable Recourse  </p>

<p><strong>Contextual Background:</strong> The paper addresses the gap between counterfactual explanations (which state how inputs must differ for a different outcome) and actionable explanations (which tell recipients what actions to take). It proposes “directive explanations” that specify concrete or generic actions to achieve a desired outcome, formalizing them via Markov Decision Processes.  </p>

<p><strong>Geographic/Institutional Context:</strong> Conducted by University of Melbourne with US-based MTurk participants.  </p>

<p><strong>Target Users/Stakeholders:</strong> Decision recipients, intermediary decision communicators, designers of ML-based decision systems.  </p>

<p><strong>Primary Methodology:</strong> Mixed Methods (Quantitative + Qualitative studies + conceptual modeling)  </p>

<p><strong>Primary Contribution Type:</strong> Conceptual model (MDP framework) + empirical evaluation.</p>

<h2>General Summary of the Paper</h2>

<p>The authors propose <strong>directive explanations</strong> as a way to make AI explanations more actionable by explicitly providing sequences of actions that lead from the current state to a desired counterfactual outcome. They define two types—<strong>directive-specific</strong> (concrete actions) and <strong>directive-generic</strong> (action categories)—and formalize generation using an MDP framework. Two user studies in credit scoring and employee satisfaction domains compare directive explanations with non-directive counterfactuals, showing a clear preference for directive forms. Thematic analysis reveals that preferences are shaped by feasibility, social sensitivity, and autonomy. The authors conclude that actionability is context- and user-dependent, advocating a human-centered, context-specific approach.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionability is framed as enabling <strong>recourse</strong>—guiding individuals not just on what feature values would yield a different outcome, but on <strong>what specific or generic actions they can take</strong> to reach that state.  </p>

<blockquote>
  <p>“A directive explanation … offers specific actions an individual could take to achieve their desired outcome.” (p. 1)  </p>
</blockquote>

<blockquote>
  <p>“Counterfactual explanations should be directive in that they should include suggestions or recommendations of the action(s) the individual could perform…” (p. 2)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Ties counterfactuals to <strong>mutable and feasible actions</strong>.</p></li>
<li><p>Specifies <strong>sequences</strong> of dependent actions, not just one-step changes.</p></li>
<li><p>Accounts for <strong>action costs</strong> and individual feasibility.</p></li>
<li><p>Provides either <strong>specific actionable steps</strong> or <strong>generic guidance</strong> to preserve autonomy.</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> MDP-based directive explanation generation model.  </p></li>
<li><p><strong>Methods/Levers:</strong> Use of Monte Carlo Tree Search to find policies transitioning from factual to counterfactual states.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong></p>

<p> 1. Generate counterfactual states using existing algorithms (e.g., Russell 2019).</p>

<p> 2. Define mutable features and possible actions.</p>

<p> 3. Model state transitions and action costs in MDP.</p>

<p> 4. Search for optimal policy (action sequence) to reach counterfactual.</p>

<p> 5. Post-process for directive-generic explanations by grouping actions.</p></li>
<li><p><strong>Data &amp; Measures:</strong> Credit scoring and employee satisfaction datasets; user preference rankings; thematic coding of qualitative justifications.</p></li>
<li><p><strong>Implementation Context:</strong> Simulated loan officer and HR officer decision communication.</p></li>
</ul>

<blockquote>
  <p>“Actions from πi must lead from x to ci… model must capture different ways to achieve specific outcomes… account for action costs…” (p. 6)  </p>
</blockquote>

<blockquote>
  <p>“Policy πi is the source of the directives in the directive explanations.” (p. 6–7)</p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — explicit link between action and outcome. “Provides clear actions… so the customer will know what to do next.” (p. 16)</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — tailored to recipient’s situation and domain. (p. 16–17)</p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — consideration of whether directives are realistic and achievable. (p. 17)</p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — relevance discussed when outcomes are imminent, but not formalized as a dimension.</p></li>
<li><p><strong>EX (Explainability):</strong> Yes — explanations remain interpretable, showing causal pathways.</p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — directives are aligned with recipient’s desired outcome.</p></li>
<li><p><strong>Other Dimensions:</strong> Autonomy (directive-generic explanations preserve choice), Social Acceptability (avoid condescending or overly personal directives).</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Counterfactual explanations literature (Wachter et al. 2017)</p></li>
<li><p>Algorithmic recourse and causal modeling (Karimi et al. 2021)</p></li>
<li><p>Markov Decision Processes and planning theory (Puterman 2014, Geffner &amp; Bonet 2013)</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>User preference ranking between explanation types.</p></li>
<li><p>Qualitative themes on perceived usefulness, feasibility, autonomy.</p></li>
<li><p>Domain-specific acceptance patterns.</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Social sensitivity of directives, infeasibility of actions, lack of user autonomy, condescending tone.</p></li>
<li><p><strong>Enablers:</strong> Clear linkage between actions and outcomes, multiple feasible options, domain familiarity, personalization.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Builds on counterfactual explanations but addresses lack of explicit action guidance. Extends recourse work by modeling multi-step action sequences and accounting for costs, aligning with causal model-based proposals.</p>

<h2>Summary</h2>

<p>This paper advances the concept of <strong>actionable explainability</strong> by formalizing “directive explanations” that move beyond stating hypothetical changes to prescribing concrete or generic actions. It operationalizes this through an MDP model that sequences feasible, cost-sensitive actions from the factual to the counterfactual state. Two empirical studies demonstrate that users prefer directive explanations, especially in unfavorable decision contexts, though preferences depend on domain, feasibility, and social considerations. The work contributes both a theoretical framework for actionable recourse and empirical evidence supporting directive over non-directive counterfactuals, while emphasizing the need for human-centered and context-specific tailoring.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Explicitly defines actionability, ties it to recourse, offers detailed conceptual and empirical analysis with multiple dimensions.</p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Provides a full computational method (MDP model) and empirical validation; could improve by integrating cost/feasibility personalization into generation.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[A] directive explanation … offers specific actions an individual could take to achieve their desired outcome.” (p. 1)</p></li>
<li><p>“Counterfactual explanations should be directive in that they should include suggestions or recommendations of the action(s) the individual could perform…” (p. 2)</p></li>
<li><p>“Actions from πi must lead from x to ci… model must capture different ways to achieve specific outcomes… account for action costs…” (p. 6)</p></li>
<li><p>“Provides clear actions… so the customer will know what to do next.” (p. 16)</p></li>
<li><p>“I picked [directive-generic] based on how feasible I thought each strategy would be.” (p. 17)</p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Wachter et al. 2017 (counterfactual explanations)</p></li>
<li><p>Karimi et al. 2021 (algorithmic recourse via causal models)</p></li>
<li><p>Tsirtsis et al. 2021 (sequential decision-making counterfactuals)</p></li>
<li><p>Russell 2019 (diverse counterfactual generation)</p></li>
<li><p>Puterman 2014; Geffner &amp; Bonet 2013 (MDP and planning frameworks)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Evaluating Online and Offline Health Information With the Patient Education Materials Assessment Tool: Protocol for a Systematic Review  </p>

<p>Authors: Emi Furukawa, Tsuyoshi Okuhara, Mingxin Liu, Hiroko Okada, Takahiro Kiuchi  </p>

<p>DOI: 10.2196/63489  </p>

<p>Year: 2025  </p>

<p>Publication Type: Journal Article (Protocol)  </p>

<p>Discipline/Domain: Health Communication / Health Literacy  </p>

<p>Subdomain/Topic: Patient Education Materials Evaluation  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 85  </p>

<p>Operationalization Score: 70  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: No  </p>

<p>Contains Interpretability: No  </p>

<p>Contains Framework/Model: Yes  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Systematic Review Protocol (Conceptual/Methodological)  </p>

<p>Study Context: Systematic review of studies evaluating patient education materials using the PEMAT  </p>

<p>Geographic/Institutional Context: International; led by The University of Tokyo, Japan  </p>

<p>Target Users/Stakeholders: Health communication researchers, patient educators, health institutions, policy-makers  </p>

<p>Primary Contribution Type: Methodological framework for systematic review  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: No  </p>

<p>EX: No  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Evaluating Online and Offline Health Information With the Patient Education Materials Assessment Tool: Protocol for a Systematic Review  </p>

<p><strong>Authors:</strong>  </p>

<p>Emi Furukawa, Tsuyoshi Okuhara, Mingxin Liu, Hiroko Okada, Takahiro Kiuchi  </p>

<p><strong>DOI:</strong>  </p>

<p>10.2196/63489  </p>

<p><strong>Year:</strong>  </p>

<p>2025  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article (Protocol)  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Health Communication / Health Literacy  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Patient Education Materials Evaluation  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper presents a protocol for a systematic review of studies using the Patient Education Materials Assessment Tool (PEMAT) to evaluate the understandability and actionability of health information materials across different formats, contexts, and languages.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>International scope; coordinated by The University of Tokyo Hospital and Graduate School of Medicine.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Health communication researchers, patient education specialists, health literacy advocates, public health institutions.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual and methodological protocol for systematic review.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Methodological framework and synthesis approach.  </p>

<h2>General Summary of the Paper</h2>

<p>This protocol outlines a systematic review plan to analyze how the PEMAT has been used to evaluate the understandability and actionability of patient education materials in various health contexts. It defines clear inclusion and exclusion criteria, search strategies across five major databases, and detailed plans for data extraction and synthesis. The review aims to map evaluated domains, assess average quality levels, and identify research and practice gaps for improving health materials. It also plans subgroup analyses by material type, clinical field, and source type. By integrating and comparing PEMAT-based evaluations globally, the authors expect to provide actionable recommendations for developing more understandable and actionable patient education resources.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionability is defined by PEMAT as “the likelihood that the reader or viewer will know how to act on the information presented in the material” (p. 2). The review treats actionability as a measurable, comparable quality dimension that determines whether materials can guide patients and the public toward specific health behaviors.  </p>

<blockquote>
  <p>“Actionability refers to the likelihood that the reader or viewer will know how to act on the information presented in the material.” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“Understanding the material alone is insufficient; a separate evaluation is necessary to determine whether audience can translate the material’s content into actionable behavior.” (p. 2)</p>
</blockquote>

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Clear, specific instructions for action.  </p></li>
<li><p>Concrete steps enabling readers to perform recommended behaviors.  </p></li>
<li><p>Contextual relevance to target users.  </p></li>
<li><p>Structured presentation that facilitates translation from information to behavior.</p></li>
</ul>

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Patient Education Materials Assessment Tool (PEMAT)  </p></li>
<li><p><strong>Methods/Levers:</strong> Application of PEMAT-P (print) and PEMAT-A/V (audiovisual) formats, scoring actionability and understandability separately.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Literature search → screening → data extraction of PEMAT scores → subgroup analysis by material type, clinical field, source.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> PEMAT’s actionability items (20–26 for print, 20–22 &amp; 25 for audiovisual), scored as percentages.  </p></li>
<li><p><strong>Implementation Context:</strong> Applied in diverse cultural and linguistic contexts for cross-study comparison.  </p></li>
</ul>

<blockquote>
  <p>“On the practical side, the PEMAT visualizes the challenges of materials to find the most understandable and actionable materials among the many available.” (p. 2)  </p>
</blockquote>

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Clear presentation and understandable content are necessary precursors to action.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Materials must match the needs and settings of the intended audience.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — Materials must present actions the audience can realistically perform.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No — Not explicitly linked to actionability.  </p></li>
<li><p><strong>EX (Explainability):</strong> No — Not explicitly tied to actionability.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — Alignment with intended health behavior is implied but not systematically stated.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Understandability as a prerequisite; cultural and linguistic adaptability.</p></li>
</ul>

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Health literacy theory.  </p></li>
<li><p>Garner et al.’s three-step model of audience interaction with materials (reading, understanding, responding).  </p></li>
<li><p>Organizational health literacy frameworks (Healthy People 2030).</p></li>
</ul>

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>PEMAT actionability score (0–100%).  </p></li>
<li><p>Item-level scoring on explicit action guidance and steps.</p></li>
</ul>

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Lack of patient perspective in PEMAT scoring; heterogeneity in methods across studies; exclusion of non-English literature.  </p></li>
<li><p><strong>Enablers:</strong> Standardized, validated PEMAT tool; availability in multiple languages; ability to compare across contexts.</p></li>
</ul>

<h2>Relation to Existing Literature</h2>

<p>Builds on prior scoping reviews of health material quality assessment but is the first systematic synthesis of PEMAT-based evaluations.</p>

<h2>Summary</h2>

<p>This protocol establishes a systematic approach for synthesizing global evidence on the understandability and actionability of patient education materials, as assessed by PEMAT. It conceptualizes actionability as the material’s capacity to guide audiences toward specific health actions and positions clarity, contextual relevance, and feasibility as essential attributes. By collecting and comparing PEMAT scores across contexts and formats, the review will generate insights into areas where materials succeed or fall short in supporting behavior change. It will also identify priority areas for improvement in health communication practices.</p>

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 — Strong, explicit conceptualization of actionability and its components within PEMAT; multiple dimensions tied to actionability.  </p></li>
<li><p><strong>Operationalization Score:</strong> 70 — Provides a clear methodological framework for assessing actionability via PEMAT, but as a protocol, lacks empirical application results.</p></li>
</ul>

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Actionability refers to the likelihood that the reader or viewer will know how to act on the information presented in the material.” (p. 2)  </p></li>
<li><p>“Understanding the material alone is insufficient; a separate evaluation is necessary to determine whether audience can translate the material’s content into actionable behavior.” (p. 2)  </p></li>
<li><p>“On the practical side, the PEMAT visualizes the challenges of materials to find the most understandable and actionable materials among the many available.” (p. 2)  </p></li>
</ul>

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Shoemaker et al., 2014 — Original PEMAT development.  </p></li>
<li><p>Garner et al., 2012 — Framework for evaluating patient information leaflets.  </p></li>
<li><p>CDC Clear Communication Index.</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Counterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR  </p>

<p>Authors: Sandra Wachter, Brent Mittelstadt, Chris Russell  </p>

<p>DOI: 10.2139/ssrn.3063289  </p>

<p>Year: 2018  </p>

<p>Publication Type: Journal Article  </p>

<p>Discipline/Domain: Law &amp; Technology  </p>

<p>Subdomain/Topic: Algorithmic Decision-Making, Data Protection, Explainable AI  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes (implicit, in terms of what makes explanations actionable for data subjects)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Yes  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (Counterfactual Explanation framework)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual + Technical Demonstration  </p>

<p>Study Context: Automated decision-making under GDPR constraints  </p>

<p>Geographic/Institutional Context: European Union, GDPR context  </p>

<p>Target Users/Stakeholders: Data subjects, policymakers, data controllers, AI developers  </p>

<p>Primary Contribution Type: Conceptual framework + technical method proposal  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Partial  </p>

<p>TI: Partial  </p>

<p>EX: Yes  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Counterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR  </p>

<p><strong>Authors:</strong>  </p>

<p>Sandra Wachter, Brent Mittelstadt, Chris Russell  </p>

<p><strong>DOI:</strong>  </p>

<p>10.2139/ssrn.3063289  </p>

<p><strong>Year:</strong>  </p>

<p>2018  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal Article  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Law &amp; Technology  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Algorithmic Decision-Making, Data Protection, Explainable AI  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the problem of explaining complex algorithmic decisions under the GDPR without revealing proprietary or technical details of the models. It proposes counterfactual explanations as an alternative that focuses on actionable changes to input variables to achieve desired outcomes, aligning with transparency and accountability goals while bypassing technical and legal barriers to “opening the black box.”  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>European Union, GDPR regulatory environment.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Data subjects, policymakers, regulators, AI system designers, data controllers.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual analysis with technical implementation examples.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Proposal and justification of a new explanation method (counterfactual explanations) with legal, philosophical, and technical grounding.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors critique the GDPR’s limited and ambiguous provisions on explaining automated decisions, noting that they do not mandate disclosure of algorithms’ internal logic. They propose <em>counterfactual explanations</em>—“if-then” statements showing minimal changes to input variables that would alter a decision—as a practical, legally compatible way to inform, empower, and guide data subjects. This approach avoids revealing trade secrets or requiring technical interpretability, but still supports understanding, contesting, and influencing future decisions. They situate counterfactuals in philosophical discussions of knowledge and causality, review related work in AI, and present methods for generating them, illustrated with LSAT and Pima Diabetes datasets. They evaluate their legal compatibility with GDPR’s transparency, notification, and access provisions, and conclude that unconditional counterfactual explanations could balance transparency, accountability, and practical feasibility.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is framed in terms of explanations that enable the <em>data subject to act</em>—to understand a decision, contest it, or modify future outcomes—without needing to understand the internal model logic.  </p>

<blockquote>
  <p>“Looking at explanations as a means to help a data subject act rather than merely understand…” (p. 843)  </p>
</blockquote>

<blockquote>
  <p>“An explanation… does not necessarily hinge on… understanding how algorithmic systems function.” (p. 843)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Provides clear, minimal, relevant changes to variables that would alter the decision.  </p></li>
<li><p>Expressed in terms directly relevant to the individual’s circumstances.  </p></li>
<li><p>Supports specific goals: understanding, contesting, or changing outcomes.  </p></li>
<li><p>Avoids unnecessary technical or internal model details.  </p></li>
<li><p>Must be intelligible, concise, and accessible to non-experts.  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Counterfactual Explanations.  </p></li>
<li><p><strong>Methods/Levers:</strong> Optimization to find minimally different “possible worlds” producing a different decision outcome; distance metrics (e.g., weighted L1 norm).  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Fix model parameters after training.  </p>

<p> 2. Search for an alternative input vector close to the original.  </p>

<p> 3. Ensure minimal and realistic changes (sparse changes).  </p>

<p> 4. Output human-readable “if-then” statements.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> LSAT and Pima Diabetes datasets; performance measured by plausibility and sparsity of changes.  </p></li>
<li><p><strong>Implementation Context:</strong> Applicable across domains where individual-level decisions are made.  </p></li>
</ul>

<blockquote>
  <p>“Unconditional counterfactual explanations should be given for positive and negative automated decisions…” (p. 844)  </p>
</blockquote>

<blockquote>
  <p>“If your LSAT was 34.0, you would have an average predicted score (0).” (p. 858)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — Must be “concise, transparent, intelligible” (p. 871).  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — Tailored to the individual’s data and decision context (p. 843–844).  </p></li>
<li><p><strong>FE (Feasibility):</strong> Partial — Mutability and practicality of changes considered but not guaranteed (p. 845).  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — Can be given post-decision; real-time use possible but not core focus (p. 882).  </p></li>
<li><p><strong>EX (Explainability):</strong> Yes — Provides rationale via dependency on external facts (p. 845).  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — Aims to support user goals (understand, contest, alter), but no explicit goal-matching process.  </p></li>
<li><p><strong>Other Dimensions:</strong> Legal compatibility; minimal intrusion on rights of others.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Analytic philosophy of knowledge (“justified true belief,” counterfactual reasoning).  </p></li>
<li><p>Possible worlds semantics (David Lewis).  </p></li>
<li><p>Causal reasoning in fairness (Pearl).  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Minimal number of changed variables (sparsity).  </p></li>
<li><p>Plausibility of changes (within realistic ranges).  </p></li>
<li><p>Relevance to individual’s mutable characteristics.</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> GDPR’s limited scope for explanations; possible unchangeable variables; cost of computation; dynamic models.  </p></li>
<li><p><strong>Enablers:</strong> Model-agnostic applicability; computational efficiency; legal compatibility; minimal trade secret exposure.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Contrasts with ML interpretability work focusing on internal logic; aligns with fairness literature using counterfactuals but for outcome change rather than fairness testing. Bridges law, philosophy, and AI explainability research.</p>

<hr />

<h2>Summary</h2>

<p>The paper redefines “actionability” for explanations of automated decisions under GDPR as enabling the data subject to understand, contest, or alter outcomes without requiring insight into a system’s internal workings. <em>Counterfactual explanations</em> operationalize this by showing minimal, plausible input changes that would have led to a different result, delivered in human-readable terms. This approach is legally compatible, computationally feasible, and preserves trade secrets and privacy. It is demonstrated through technical examples and evaluated against GDPR provisions, revealing that while the regulation does not mandate such explanations, they could serve as a practical, user-centered transparency mechanism. The authors advocate unconditional provision of counterfactuals to all affected individuals.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 95 — Strong, explicit linkage between explanation design and enabling user action; detailed conceptual and operational guidance.  </p></li>
<li><p><strong>Operationalization Score:</strong> 90 — Clear technical method with worked examples; some limitations on feasibility and mutability consideration.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“An explanation… does not necessarily hinge on… understanding how algorithmic systems function.” (p. 843)  </p></li>
<li><p>“Unconditional counterfactual explanations should be given for positive and negative automated decisions…” (p. 844)  </p></li>
<li><p>“If your LSAT was 34.0, you would have an average predicted score (0).” (p. 858)  </p></li>
<li><p>“Concise, transparent, intelligible and easily accessible form.” (p. 871)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Lewis, <em>Counterfactuals</em> (1973)  </p></li>
<li><p>Pearl, <em>Causation</em> (2000)  </p></li>
<li><p>Kusner et al., “Counterfactual Fairness” (2018)  </p></li>
<li><p>Citron &amp; Pasquale, on hypothetical alterations in credit scoring (2014)</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Assessing the understandability and actionability of online resources for patients undergoing hemodialysis  </p>

<p>Authors: Emi Furukawa, Tsuyoshi Okuhara, Hiroko Okada, Yumiko Fujitomo, Takahiro Kiuchi  </p>

<p>DOI: https://doi.org/10.1111/1744-9987.14221  </p>

<p>Year: 2025  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Health Communication / Nephrology  </p>

<p>Subdomain/Topic: Patient education, online health resources, health literacy assessment  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 78  </p>

<p>Operationalization Score: 85  </p>

<p>Contains Definition of Actionability: Yes (via PEMAT-P framework)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: Partial  </p>

<p>Contains Framework/Model: Yes (PEMAT-P)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Quantitative / Cross-sectional evaluation study  </p>

<p>Study Context: Evaluation of Japanese-language online patient education materials on hemodialysis using PEMAT-P, GQS, and jReadability  </p>

<p>Geographic/Institutional Context: Japan (University of Tokyo Hospital, Graduate School of Medicine)  </p>

<p>Target Users/Stakeholders: Patients undergoing hemodialysis, healthcare providers, patient education material developers  </p>

<p>Primary Contribution Type: Empirical assessment and guidance for material improvement  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: No  </p>

<p>EX: Partial  </p>

<p>GA: Partial  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Assessing the understandability and actionability of online resources for patients undergoing hemodialysis  </p>

<p><strong>Authors:</strong>  </p>

<p>Emi Furukawa, Tsuyoshi Okuhara, Hiroko Okada, Yumiko Fujitomo, Takahiro Kiuchi  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1111/1744-9987.14221  </p>

<p><strong>Year:</strong>  </p>

<p>2025  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Health Communication / Nephrology  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Patient education, online health resources, health literacy assessment  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The study evaluates whether Japanese-language online materials for patients on hemodialysis are understandable and actionable enough to support health behavior change. It addresses issues in patient education content given the high prevalence and self-management demands of HD in Japan.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Japan; University of Tokyo Hospital; Graduate School of Medicine, University of Tokyo.</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Patients undergoing hemodialysis, their families, healthcare providers, and material developers.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative cross-sectional content evaluation.</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Empirical assessment with actionable recommendations for improving educational resources.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This cross-sectional study assessed 194 Japanese-language online educational materials for patients undergoing hemodialysis (HD), focusing on understandability and actionability using the Japanese version of the Patient Education Materials Assessment Tool (PEMAT-P). Materials were also evaluated for quality (Global Quality Score, GQS) and readability (jReadability). The median understandability score was 66.7%, with only 38.7% meeting the ≥70% threshold; median actionability was 33.3%, with just 16.5% meeting the threshold. Common shortcomings included lack of plain language, absence of summaries, poor titling of visual aids, and limited use of tools that support concrete actions. Self-management materials scored significantly higher in actionability and readability compared to other content categories. For-profit company-produced materials tended to be more understandable and readable. The study concludes that many HD-related online resources are not presented in ways that enable patients to effectively use them for self-care.</p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<hr />

<h2>How Actionability is Understood</h2>

<p>The paper adopts the PEMAT-P definition: actionability refers to how well materials enable patients to identify what to do based on the information, and to take concrete steps toward action.</p>

<blockquote>
  <p>“Actionability… evaluates how well patients can identify what they need to do based on the information presented.” (p. 203)  </p>
</blockquote>

<blockquote>
  <p>“Scores below 70% indicated poor… actionability, whereas scores of 70% or higher were considered… actionable.” (p. 203)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p>Clearly identifies at least one specific action a user can take.  </p></li>
<li><p>Addresses the user directly in describing actions.  </p></li>
<li><p>Breaks down actions into explicit steps.  </p></li>
<li><p>Provides tangible tools (e.g., checklists, planners) to facilitate the action.  </p></li>
<li><p>Uses visual aids to make instructions easier to follow.  </p></li>
<li><p>Explains how to interpret charts, graphs, or tables for taking action.  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Japanese version of PEMAT-P (Patient Education Materials Assessment Tool for Printed Materials).  </p></li>
<li><p><strong>Methods/Levers:</strong> Binary scoring (agree/disagree) across seven actionability items; 70% threshold for acceptable actionability.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong> Identify actions, address user directly, break down steps, provide tools, explain visual aids, and ensure ease of acting upon instructions.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> PEMAT-P scores; Kruskal–Wallis test for group differences; inter-rater reliability via Gwet’s AC1.  </p></li>
<li><p><strong>Implementation Context:</strong> Applied to Japanese online HD materials from diverse sources and content areas.</p></li>
</ul>

<blockquote>
  <p>“More than half of the materials satisfied Item 19… However, &lt;30%… met Item 21… Item 22… Item 24… and Item 25.” (p. 204)  </p>
</blockquote>

<blockquote>
  <p>“Self-management materials tended to offer more detailed instructions and utilized visual aids to facilitate readers in taking action…” (p. 206)</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — linked via plain language and absence of distracting information.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — self-management content most relevant and actionable.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — inclusion of tangible tools and breakdown of steps supports feasibility.  </p></li>
<li><p><strong>TI (Timeliness):</strong> No explicit link found.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — explanation of how to use visual aids was rare (&lt;10%).  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Partial — some materials align with patient self-care goals (e.g., self-management), but not universal.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Use of visual aids, chunking information, providing summaries.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>PEMAT-P framework for defining and measuring understandability and actionability.  </p></li>
<li><p>Health literacy principles, including plain language and visual aid effectiveness.  </p></li>
<li><p>Prior literature on patient education in CKD and HD contexts.</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>PEMAT-P actionability subscore (% of items rated “agree” out of applicable items).  </p></li>
<li><p>≥70% threshold for actionable materials.</p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Lack of summaries.  </p>

<p> - Inadequate titling/captioning of visual aids.  </p>

<p> - Minimal use of tangible tools for action.  </p>

<p> - Complex syntax and medical jargon.  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Direct address to the user.  </p>

<p> - Clear identification of actions.  </p>

<p> - Detailed step-by-step instructions in self-management materials.  </p>

<p> - Effective visual aids used by for-profit company materials.</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The authors note similar deficiencies in English-language HD and CKD materials internationally, such as low readability and lack of action-oriented tools, suggesting a common challenge in health communication regardless of language or country.</p>

<hr />

<h2>Summary</h2>

<p>This study provides a quantitative assessment of the understandability and actionability of Japanese online educational materials for patients undergoing hemodialysis using the PEMAT-P framework. It finds that most materials fail to meet the actionability threshold, with common deficits including lack of plain language, absence of summaries, and minimal use of tangible action tools. Self-management materials stood out for higher actionability and readability, largely due to explicit action steps and supportive visual aids. For-profit companies tended to produce more understandable and readable content. The findings offer clear operational guidance — rooted in an established framework — for improving patient education materials so they can effectively bridge the gap between information provision and patient self-management.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 78 — Strong definition via PEMAT-P, clear articulation of features tied to actionability, though timeliness and full goal alignment not fully addressed.  </p></li>
<li><p><strong>Operationalization Score:</strong> 85 — Detailed use of PEMAT-P with actionable criteria, scoring method, and applied analysis to identify gaps and improvement strategies.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Actionability… evaluates how well patients can identify what they need to do based on the information presented.” (p. 203)  </p></li>
<li><p>“More than half… satisfied Item 19… &lt;30% met Item 21… Item 22… Item 24… and Item 25.” (p. 204)  </p></li>
<li><p>“Self-management materials… offered more detailed instructions and utilized visual aids… distinguishing them from materials on other topics.” (p. 206)  </p></li>
<li><p>“Development and dissemination of quality materials… can minimize the gap between patient education and health behavior practices.” (p. 208)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Shoemaker SJ et al. (2014) — development of PEMAT.  </p></li>
<li><p>Furukawa E et al. (2022) — Japanese version of PEMAT validation.  </p></li>
<li><p>Studies on readability and quality of CKD/HD patient education (e.g., Bresler et al., 2021; Tuot et al., 2013).  </p></li>
<li><p>Federal Plain Language Guidelines (2011).</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Predictive monitoring of business processes: a survey</p>

<p>Authors: Alfonso E. Márquez‑Chamorro; Manuel Resinas; Antonio Ruiz‑Cortés</p>

<p>DOI: 10.1109/TSC.2017.2772256</p>

<p>Year: 2017</p>

<p>Publication Type: Journal (IEEE Transactions on Services Computing)</p>

<p>Discipline/Domain: Business Process Management; Process Mining</p>

<p>Subdomain/Topic: Predictive process monitoring (time, risk, SLA, next-event, indicators)</p>

<p>Eligibility: Eligible (Implicit treatment of actionability tied to proactive/corrective action and recommendations)</p>

<p>Overall Relevance Score: 78</p>

<p>Operationalization Score: 52</p>

<p>Actionable/Actionability Used in Paper: Yes — “Predictive monitoring … aims to provide timely information that enable proactive and corrective actions to improve process performance and mitigate risks.” (p. 2):contentReference[oaicite:0]{index=0}; “little attention has been given to providing recommendations … so that they can determine the best way to act upon.” (pp. 16–17):contentReference[oaicite:1]{index=1}:contentReference[oaicite:2]{index=2}</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — “provide timely information that enable proactive and corrective actions” (p. 2):contentReference[oaicite:3]{index=3}; “providing recommendations and explaining the prediction values … so that they can determine the best way to act upon” (pp. 16–17):contentReference[oaicite:4]{index=4}:contentReference[oaicite:5]{index=5}</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: Yes (implicit: timeliness, interpretability/clarity, domain relevance, feasibility)</p>

<p>Contains Explainability: Partial (emphasized as needed for actionability):contentReference[oaicite:6]{index=6}:contentReference[oaicite:7]{index=7}</p>

<p>Contains Interpretability: Yes (explicitly discussed as requirement/challenge):contentReference[oaicite:8]{index=8}:contentReference[oaicite:9]{index=9}</p>

<p>Contains Framework/Model: Yes (two-stage methodology; taxonomies; tables):contentReference[oaicite:10]{index=10}:contentReference[oaicite:11]{index=11}</p>

<p>Operationalization Present: Yes (general methodology; checkpoints; integration recommendations; but limited direct “how-to” for actionability):contentReference[oaicite:12]{index=12}:contentReference[oaicite:13]{index=13}:contentReference[oaicite:14]{index=14}</p>

<p>Primary Methodology: Review</p>

<p>Study Context: Survey of predictive monitoring techniques for business processes, 2010–2017</p>

<p>Geographic/Institutional Context: N/A (multi-dataset, multi-domain survey)</p>

<p>Target Users/Stakeholders: BPM researchers; practitioners building predictive monitoring systems</p>

<p>Primary Contribution Type: Systematic survey, classification, and identification of challenges and research agenda</p>

<p>CL: Partial</p>

<p>CR: Yes</p>

<p>FE: Partial</p>

<p>TI: Yes</p>

<p>EX: Partial</p>

<p>GA: Partial</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Predictive monitoring of business processes: a survey</p>

<p><strong>Authors:</strong>  </p>

<p>Alfonso E. Márquez‑Chamorro; Manuel Resinas; Antonio Ruiz‑Cortés</p>

<p><strong>DOI:</strong>  </p>

<p>10.1109/TSC.2017.2772256</p>

<p><strong>Year:</strong>  </p>

<p>2017</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal (IEEE Transactions on Services Computing)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Business Process Management; Process Mining</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Predictive process monitoring (runtime prediction of time, risk, SLA, next-event, and indicators)</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper surveys 39 approaches to predictive monitoring in BPM, detailing inputs (event logs, models, context), encodings, modeling (process‑aware vs non‑process‑aware), prediction targets, and evaluation. It also outlines a general two‑stage methodology (learning &amp; runtime prediction) and open challenges. [Assumption: framed for readers familiar with process mining foundations.]:contentReference[oaicite:15]{index=15}:contentReference[oaicite:16]{index=16}</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>N/A (broad, cross‑domain survey; includes public BPIC datasets and industrial cases):contentReference[oaicite:17]{index=17}</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Researchers and practitioners designing predictive monitoring systems in BPM:contentReference[oaicite:18]{index=18}:contentReference[oaicite:19]{index=19}</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Review / Survey (methodological synthesis and taxonomy):contentReference[oaicite:20]{index=20}</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Domain overview; taxonomy; methodological framework; challenges and agenda:contentReference[oaicite:21]{index=21}:contentReference[oaicite:22]{index=22}</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The authors review predictive monitoring methods for business processes that forecast runtime outcomes such as remaining time, risk/SLA violations, next events, and indicator values using event logs and, optionally, discovered process models. They summarize a two‑stage methodology: offline learning (encoding logs, building and evaluating models) and online prediction for ongoing cases. Techniques are categorized by process‑awareness (explicit model vs. data‑driven), problem type (classification vs. regression), inputs, and targets, with comparative tables of datasets and measures. The paper highlights evaluation gaps, the need for shared benchmarks, and practical challenges, including interpretability, recommendations, and system integration.:contentReference[oaicite:23]{index=23}:contentReference[oaicite:24]{index=24}</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>Yes. Verbatim and tied to acting on results:  </p>

<ul>
<li><p>“Predictive monitoring of BPs … aims to provide timely information that enable <strong>proactive and corrective actions</strong> to improve process performance and mitigate risks.” (p. 2):contentReference[oaicite:25]{index=25}  </p></li>
<li><p>“Most proposals are focused on improving the accuracy of predictions, but <strong>little attention has been given to providing recommendations and explaining the prediction values to the users so that they can determine the best way to act upon</strong>.” (pp. 16–17):contentReference[oaicite:26]{index=26}:contentReference[oaicite:27]{index=27}</p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>Yes.  </p>

<ul>
<li><p>“Provide timely information that enable proactive and corrective actions …” (p. 2):contentReference[oaicite:28]{index=28}  </p></li>
<li><p>Emphasis on recommendations/explanations enabling users “to determine the best way to act upon” predictions (pp. 16–17).:contentReference[oaicite:29]{index=29}:contentReference[oaicite:30]{index=30}</p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly: information is actionable when it is <strong>timely</strong>, <strong>interpretable/explainable</strong>, and accompanied by <strong>recommendations</strong> that guide decisions in context.  </p>

<blockquote>
  <p>“Provide timely information that enable proactive and corrective actions …” (p. 2):contentReference[oaicite:31]{index=31}  </p>
</blockquote>

<blockquote>
  <p>“Providing recommendations and explaining the prediction values … so that they can determine the best way to act upon.” (pp. 16–17):contentReference[oaicite:32]{index=32}:contentReference[oaicite:33]{index=33}</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Timeliness of information (runtime, proactive):</strong>  </p>

<p> &gt; “Predictive monitoring … at real‑time during the execution …” (p. 3):contentReference[oaicite:34]{index=34}  </p>

<p> &gt; “Provide timely information … enable proactive and corrective actions …” (p. 2):contentReference[oaicite:35]{index=35}</p></li>
<li><p><strong>Interpretability/Clarity of models and outputs:</strong>  </p>

<p> &gt; “The interpretability of the model … has not been a main concern… Only a few proposals have explicitly mentioned the interpretability …” (p. 14):contentReference[oaicite:36]{index=36}</p></li>
<li><p><strong>Recommendations that guide action:</strong>  </p>

<p> &gt; “Little attention has been given to providing recommendations … so that they can determine the best way to act upon.” (pp. 16–17):contentReference[oaicite:37]{index=37}:contentReference[oaicite:38]{index=38}  </p>

<p> &gt; “A recommendation system … identifies the best assignment of resources … based on the generated risk predictions.” (p. 17):contentReference[oaicite:39]{index=39}</p></li>
<li><p><strong>Domain relevance and feasibility of actions:</strong>  </p>

<p> &gt; “Recommendations presented to the user must make sense in the domain … domain knowledge have to be included to identify all potential recommendations.” (p. 17):contentReference[oaicite:40]{index=40}</p></li>
<li><p><strong>Integration into operational systems (to act):</strong>  </p>

<p> &gt; “Integration of predictive monitoring techniques with BPMS … frameworks … prototypes …” (p. 17):contentReference[oaicite:41]{index=41}</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> General predictive monitoring methodology (learning + runtime phases); integration prototypes (e.g., Nirdizati; XES‑Tensorflow; Camunda integration).:contentReference[oaicite:42]{index=42}:contentReference[oaicite:43]{index=43}  </p></li>
<li><p><strong>Methods/Levers:</strong> Feature engineering/encoding; checkpoint selection; model interpretability; recommendation mechanisms; domain knowledge inclusion.:contentReference[oaicite:44]{index=44}:contentReference[oaicite:45]{index=45}:contentReference[oaicite:46]{index=46}  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1) Offline learning from event logs (encode features; build/evaluate models).  </p>

<p> 2) Online application to ongoing cases at <strong>checkpoints</strong> for timely alerts.  </p>

<p> 3) Present interpretable outputs and <strong>recommendations</strong>; integrate with BPMS to trigger actions. (Figure 2; discussion):contentReference[oaicite:47]{index=47}  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Event logs (+ optional process models and contextual attributes); evaluation via RMSE/MAE for regression, Accuracy/Precision/AUC for classification.:contentReference[oaicite:48]{index=48}  </p></li>
<li><p><strong>Implementation Context:</strong> BPM/Process Mining toolchains; emphasis on real‑time monitoring and system integration (e.g., ProM plugins, BPMS).:contentReference[oaicite:49]{index=49}:contentReference[oaicite:50]{index=50}  </p></li>
</ul>

<blockquote>
  <p>“Stage 2 … at run‑time … predictive model … determine the value …” (p. 3):contentReference[oaicite:51]{index=51}  </p>
</blockquote>

<blockquote>
  <p>“Recommendations … decision support … integration with BPMS.” (p. 17):contentReference[oaicite:52]{index=52}</p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<p><em>(Marked “Yes/Partial” when explicitly tied to making outputs actionable.)</em></p>

<ul>
<li><p><strong>CL (Clarity):</strong> <strong>Partial</strong> — Need for interpretability and explanation to act.  </p>

<p> &gt; “Providing recommendations and <strong>explaining the prediction values</strong> … to determine the best way to act upon.” (pp. 16–17):contentReference[oaicite:53]{index=53}:contentReference[oaicite:54]{index=54}</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> <strong>Yes</strong> — Actions must make domain sense; include domain knowledge.  </p>

<p> &gt; “Recommendations … <strong>must make sense in the domain</strong> … include domain knowledge.” (p. 17):contentReference[oaicite:55]{index=55}</p></li>
<li><p><strong>FE (Feasibility):</strong> <strong>Partial</strong> — Emphasis on recommendations that are implementable within BPMS and resource assignment.  </p>

<p> &gt; “Recommendation system … <strong>best assignment of resources</strong> … integrated in YAWL.” (p. 17):contentReference[oaicite:56]{index=56}</p></li>
<li><p><strong>TI (Timeliness):</strong> <strong>Yes</strong> — Real‑time/at‑runtime checkpoints for proactive action.  </p>

<p> &gt; “Carried out at real‑time … prediction is made at a <strong>checkpoint</strong> …” (p. 3):contentReference[oaicite:57]{index=57}</p></li>
<li><p><strong>EX (Explainability):</strong> <strong>Partial</strong> — Stressed as missing and needed for actionability.  </p>

<p> &gt; “Little attention … to <strong>providing recommendations and explaining</strong> the prediction values …” (pp. 16–17):contentReference[oaicite:58]{index=58}:contentReference[oaicite:59]{index=59}</p></li>
<li><p><strong>GA (Goal Alignment):</strong> <strong>Partial</strong> — Framed around improving performance, mitigating risks, meeting SLAs.  </p>

<p> &gt; “Improve process performance and mitigate risks.” (p. 2):contentReference[oaicite:60]{index=60}  </p></li>
</ul>

<p><strong>Other Dimensions Named by Authors:</strong> Integration with operations/BPMS as enabler (practical applicability).:contentReference[oaicite:61]{index=61}</p>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Process mining perspectives (control‑flow, data, time, resource) as input to prediction and decision support.:contentReference[oaicite:62]{index=62}  </p></li>
<li><p>Distinction between process‑aware vs. non‑process‑aware methods (conceptual categorization).:contentReference[oaicite:63]{index=63}:contentReference[oaicite:64]{index=64}</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>No explicit “actionability” KPI. Related evaluation metrics focus on prediction quality (RMSE/MAE, Accuracy/Precision/AUC) rather than usefulness of actions; authors suggest A/B testing for recommendation usefulness.:contentReference[oaicite:65]{index=65}:contentReference[oaicite:66]{index=66}</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Lack of interpretability/explanations and recommendations (pp. 16–17):contentReference[oaicite:67]{index=67}:contentReference[oaicite:68]{index=68}  </p>

<p> - Limited software/dataset availability hindering comparison and adoption (p. 15):contentReference[oaicite:69]{index=69}  </p>

<p> - Model complexity with many categorical variables (p. 14):contentReference[oaicite:70]{index=70}  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Runtime checkpoints and timely monitoring (p. 3):contentReference[oaicite:71]{index=71}  </p>

<p> - Integration with BPMS and recommendation systems (p. 17):contentReference[oaicite:72]{index=72}  </p>

<p> - Domain knowledge inclusion in recommendations (p. 17):contentReference[oaicite:73]{index=73}</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The survey situates predictive monitoring relative to deviance mining and software failure prediction, clarifying differences in timing and inputs. It compiles methods across machine learning, statistical models, and process‑aware techniques, and points to public benchmarks (BPIC) while noting evaluation gaps. It also traces pre‑2010 precursors in business process intelligence.:contentReference[oaicite:74]{index=74}:contentReference[oaicite:75]{index=75}</p>

<hr />

<h2>Summary</h2>

<p>This survey synthesizes the landscape of predictive monitoring for business processes, proposing a general two‑stage methodology (offline learning; online prediction at checkpoints) and organizing 39 methods by process‑awareness, learning approach, inputs, and targets (remaining time, risk/SLA, next event, indicators). Although the paper focuses on predictive accuracy and taxonomy, it repeatedly frames the purpose as enabling <strong>proactive, corrective action</strong> during execution. The authors argue that <strong>actionability</strong> depends on timely predictions, <strong>interpretability/explanation</strong>, <strong>domain‑sensible recommendations</strong>, and <strong>operational integration</strong> into BPMS. They highlight gaps—limited comparative evaluations, scarce software, and insufficient focus on recommendations and explanation—and propose future directions: feature engineering with domain knowledge, strategies for checkpoint selection and model updating, and <strong>A/B testing</strong> of recommendations. In short, the paper provides a strong conceptual basis for turning predictive insights into actions, even though it stops short of prescribing a full, standardized operational playbook for actionability.:contentReference[oaicite:76]{index=76}:contentReference[oaicite:77]{index=77}</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 78 — Strong, explicit linkage between predictions and <strong>acting</strong> (proactive/corrective), plus clear articulation of what’s missing (interpretability, recommendations). No formal definition of “actionability,” but substantial conceptual grounding.:contentReference[oaicite:78]{index=78}:contentReference[oaicite:79]{index=79}</p></li>
<li><p><strong>Operationalization Score:</strong> 52 — Provides a general methodology and identifies levers (checkpoints, explanations, recommendations, integration), but limited step‑by‑step procedures to reliably <strong>produce actionable outputs</strong> across contexts.:contentReference[oaicite:80]{index=80}:contentReference[oaicite:81]{index=81}</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“Predictive monitoring … <strong>provide timely information that enable proactive and corrective actions</strong> …” (p. 2):contentReference[oaicite:82]{index=82}  </p></li>
<li><p>“<strong>Interpretability</strong> of the model … only a few proposals …” (p. 14):contentReference[oaicite:83]{index=83}  </p></li>
<li><p>“Little attention has been given to <strong>providing recommendations and explaining</strong> the prediction values … <strong>to determine the best way to act upon</strong>.” (pp. 16–17):contentReference[oaicite:84]{index=84}:contentReference[oaicite:85]{index=85}  </p></li>
<li><p>“Recommendations … <strong>must make sense in the domain</strong>, … include domain knowledge.” (p. 17):contentReference[oaicite:86]{index=86}</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Maggi et al. (2014) — predictive monitoring with <strong>recommendations</strong> to maximize constraint satisfaction (cited within survey).:contentReference[oaicite:87]{index=87}:contentReference[oaicite:88]{index=88}  </p></li>
<li><p>Conforti et al. (2015) — <strong>recommendation system</strong> for risk‑aware resource assignment integrated with YAWL.:contentReference[oaicite:89]{index=89}:contentReference[oaicite:90]{index=90}  </p></li>
<li><p>Integration prototypes and frameworks (e.g., Nirdizati; Camunda integration) as enablers of actionable deployment.:contentReference[oaicite:91]{index=91}</p></li>
</ul>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Where Did I Misbehave? Diagnostic Information in Compliance Checking</p>

<p>Authors: Elham Ramezani; Dirk Fahland; Wil van der Aalst</p>

<p>DOI: 10.1007/978-3-642-32885-5_21</p>

<p>Year: 2012</p>

<p>Publication Type: Conference (Lecture Notes in Computer Science)</p>

<p>Discipline/Domain: Business Process Management; Process Mining</p>

<p>Subdomain/Topic: Backward compliance checking; Petri net patterns; Optimal alignments; Diagnostic conformance analysis</p>

<p>Eligibility: Eligible (implicitly and substantively addresses the state of being actionable via “diagnostic information,” localization of deviations, quantified conformance, and ProM-supported workflows)</p>

<p>Overall Relevance Score: 68</p>

<p>Operationalization Score: 82</p>

<p>Actionable/Actionability Used in Paper: No explicit use of “actionable/‑ity”; yes to strong implicit framing with “diagnostic information,” “root cause,” “improve compliance.” E.g., “intuitive diagnostics explaining deviations at the level of alignments.” (Abstract, p. 2)【p.2】</p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — e.g., “compliance improvement: modify the processes and systems based on the diagnostic information in order to improve compliance.” (p. 3)【p.3】</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: Yes — six‑dimension compliance rule framework (control‑flow, data, organizational; timed/untimed; single case/entire log; model vs. observation). (Fig. 1, p. 6)【p.6】</p>

<p>Contains Explainability: Yes — alignment-based diagnostics highlighting exact deviation positions. (pp. 5–6, 13–14)【p.5】【p.6】【p.13】【p.14】</p>

<p>Contains Interpretability: Yes — rule categories (Table 1) and Petri-net pattern diagrams (Figs. 2–5, 7, 10) provide interpretable constraints and visual diagnostics. (pp. 7–11, 12, 14)【p.7】【p.8】【p.9】【p.10】【p.11】【p.12】【p.14】</p>

<p>Contains Framework/Model: Yes — repository of 50 control-flow rules in 15 categories; Petri-net pattern formalizations; alignment method. (pp. 7–11)【p.7】【p.8】【p.9】【p.10】【p.11】</p>

<p>Operationalization Present: Yes — end-to-end procedure in ProM: select rule, parameterize mapping, compute optimal alignment, inspect deviations. (pp. 13–14)【p.13】【p.14】</p>

<p>Primary Methodology: Conceptual + Method/Tool with Case Study (real-life event log)</p>

<p>Study Context: Hospital financial process event log, 150k+ events, ~700 activities, 1,150 cases (2005–2008)</p>

<p>Geographic/Institutional Context: Large Dutch hospital; Eindhoven University of Technology</p>

<p>Target Users/Stakeholders: Compliance officers; auditors; BPM analysts; process owners</p>

<p>Primary Contribution Type: Method + Framework + Tooling (ProM plug-ins)</p>

<p>CL: Yes</p>

<p>CR: Yes</p>

<p>FE: Yes</p>

<p>TI: Partial</p>

<p>EX: Yes</p>

<p>GA: Yes</p>

<p>Reason if Not Eligible: N/A</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Where Did I Misbehave? Diagnostic Information in Compliance Checking</p>

<p><strong>Authors:</strong>  </p>

<p>Elham Ramezani; Dirk Fahland; Wil van der Aalst</p>

<p><strong>DOI:</strong>  </p>

<p>10.1007/978-3-642-32885-5_21</p>

<p><strong>Year:</strong>  </p>

<p>2012</p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference (Lecture Notes in Computer Science)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Business Process Management; Process Mining</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Backward compliance checking; Petri net patterns; Optimal alignments; Diagnostic conformance analysis</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses backward (a posteriori) compliance checking using event logs, motivated by regulatory pressures (e.g., SOX) and availability of detailed event data. It proposes Petri‑net patterns for 50 rule types and uses cost‑optimal alignments to quantify conformance and localize deviations. <em>Assumption:</em> In the actionability screen, “diagnostic information” leading to process changes is treated as an implicit actionability construct. (Abstract, pp. 2–3; Sections 1, 3–4)【p.2】【p.3】【p.5】【p.7】</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Large Dutch hospital case study; Eindhoven University of Technology (authors). (pp. 12–14)【p.12】【p.13】【p.14】</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Compliance officers, internal/external auditors, BPM analysts, process owners.</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual method + tooling + real-life case study.</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Framework of compliance rules + Petri‑net pattern operationalization + alignment-based diagnostics + ProM implementation.</p>

<hr />

<h2>General Summary o</h2>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Outlier Detection Techniques for Process Mining Applications</p>

<p>Authors: Lucantonio Ghionna, Gianluigi Greco, Antonella Guzzo, Luigi Pontieri</p>

<p>DOI: 10.1007/978-3-540-68123-6_17</p>

<p>Year: 2008</p>

<p>Publication Type: Conference</p>

<p>Discipline/Domain: Computer Science / Process Mining</p>

<p>Subdomain/Topic: Outlier detection, anomaly detection, process mining</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 15</p>

<p>Operationalization Score: 0</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: No</p>

<p>Contains Framework/Model: Yes</p>

<p>Operationalization Present: No</p>

<p>Primary Methodology: Conceptual with experimental validation</p>

<p>Study Context: Development of a specialized outlier detection approach for process logs</p>

<p>Geographic/Institutional Context: University of Calabria (Italy); Italian National Research Council</p>

<p>Target Users/Stakeholders: Process analysts, researchers in process mining</p>

<p>Primary Contribution Type: New methodology for outlier detection in process mining</p>

<p>CL: No</p>

<p>CR: No</p>

<p>FE: No</p>

<p>TI: No</p>

<p>EX: No</p>

<p>GA: No</p>

<p>Reason if Not Eligible: The paper does not discuss actionability, actionable insights, or conditions for being actionable; focus is entirely on algorithmic outlier detection in process logs.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Outlier Detection Techniques for Process Mining Applications  </p>

<p><strong>Authors:</strong>  </p>

<p>Lucantonio Ghionna, Gianluigi Greco, Antonella Guzzo, Luigi Pontieri  </p>

<p><strong>DOI:</strong>  </p>

<p>10.1007/978-3-540-68123-6_17  </p>

<p><strong>Year:</strong>  </p>

<p>2008  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Process Mining  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Outlier detection, anomaly detection, process mining  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses limitations of classical outlier detection when applied to process mining, where anomalies may result from deviations from common trace patterns or from expected process models, especially in concurrent process contexts. It proposes a two-step methodology integrating frequent pattern mining of “structural patterns” with cluster-based anomaly detection.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of Calabria, Italy; ICAR-CNR  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Researchers and practitioners in process mining, process analysts  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual and algorithmic approach with simulated experimental evaluation  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Methodology and prototype system for detecting anomalous process traces  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper proposes a specialized outlier detection approach for process mining applications, recognizing that standard methods can produce false positives or false negatives when concurrency and process model compliance are involved. The method first identifies “structural patterns” (S-patterns) representing frequent parallelism, branching, and synchronization constructs in process execution logs. It then uses a cluster-based detection procedure, grouping both traces and patterns through co-clustering to detect deviations from the dominant behaviors. The proposed algorithm, <em>TraceOutlierMining</em>, is implemented in a Java prototype and tested on synthetic logs to evaluate accuracy, scalability, and parameter sensitivity. Results demonstrate reduced false positives/negatives and scalability to large datasets. The work concludes by suggesting extensions for explanation generation and automated parameter tuning.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No — The paper does not reference actionability, actionable insights, recommendations, or knowledge.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No — The authors do not discuss the need for actionable results.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> No</p></li>
<li><p><strong>FE (Feasibility):</strong> No</p></li>
<li><p><strong>TI (Timeliness):</strong> No</p></li>
<li><p><strong>EX (Explainability):</strong> No</p></li>
<li><p><strong>GA (Goal Alignment):</strong> No</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Pattern mining in process logs  </p></li>
<li><p>Clustering-based anomaly detection  </p></li>
<li><p>Co-clustering techniques (Markov Cluster Algorithm)</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> N/A  </p></li>
<li><p><strong>Enablers:</strong> N/A</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper builds on prior work in process mining, frequent pattern mining, and clustering-based anomaly detection, addressing gaps where existing sequential outlier detection methods fail in concurrent process contexts. It extends work on noisy log handling by integrating concurrency-sensitive structural pattern detection.</p>

<hr />

<h2>Summary</h2>

<p>This study addresses the challenge of detecting anomalies in process mining logs, where concurrent processes and deviations from typical execution patterns complicate detection. The proposed <em>TraceOutlierMining</em> algorithm first extracts frequent structural patterns, which capture concurrency constructs like forks and joins, and then applies co-clustering to group related patterns and traces. Outliers are identified as traces that either do not belong to any significant cluster or are in clusters smaller than a defined fraction of the average size. The methodology is designed to reduce false positives and false negatives common in standard sequence-based detection methods. Evaluations with synthetic datasets demonstrate high accuracy for modest outlier rates (&lt;9%), parameter sensitivity, and linear scalability with log size. While focused on algorithmic anomaly detection rather than actionable insight generation, the paper lays groundwork for future integration with explanation techniques.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 15 — The paper is methodologically strong but unrelated to the concept of actionability as defined for this review.</p></li>
<li><p><strong>Operationalization Score:</strong> 0 — No operationalization of actionability; only operationalizes outlier detection.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“...an approach for singling out anomalous evolutions within a set of process traces, which takes into account both statistical properties of the log and the constraints associated with the process model.” (p. 2)  </p></li>
<li><p>“Outliers are found by a two-steps approach: First, we mine the patterns of executions... Second, we use an outlier detection approach which is cluster-based...” (p. 4)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Algorithms for Anomaly Detection of Traces in Logs of Process Aware Information Systems</p>

<p>Authors: Fábio Bezerra, Jacques Wainer</p>

<p>DOI: N/A</p>

<p>Year: 2013</p>

<p>Publication Type: Journal (Elsevier Preprint)</p>

<p>Discipline/Domain: Computer Science / Information Systems</p>

<p>Subdomain/Topic: Process Mining, Anomaly Detection</p>

<p>Eligibility: Not Eligible</p>

<p>Overall Relevance Score: 20</p>

<p>Operationalization Score: 40</p>

<p>Actionable/Actionability Used in Paper: No</p>

<p>Authors Argue for Need for Actionability Without Defining It: No</p>

<p>Contains Definition of Actionability: No</p>

<p>Contains Systematic Features/Dimensions: No</p>

<p>Contains Explainability: No</p>

<p>Contains Interpretability: Partial (related to model “make sense” appropriateness, but not tied to actionability)</p>

<p>Contains Framework/Model: Yes (Algorithms for anomaly detection: Threshold, Iterative, Sampling)</p>

<p>Operationalization Present: Yes (Detailed algorithmic steps for anomaly detection)</p>

<p>Primary Methodology: Quantitative (algorithm design and evaluation with synthetic and real logs)</p>

<p>Study Context: Anomaly detection in control-flow perspective of process-aware information systems</p>

<p>Geographic/Institutional Context: Brazil (UFRA, UNICAMP)</p>

<p>Target Users/Stakeholders: Process auditors, fraud detection analysts, process mining researchers</p>

<p>Primary Contribution Type: Algorithmic framework for anomaly detection</p>

<p>CL: No</p>

<p>CR: No</p>

<p>FE: No</p>

<p>TI: No</p>

<p>EX: No</p>

<p>GA: No</p>

<p>Reason if Not Eligible: The paper does not address actionability, actionable insights, or actionable knowledge. Focus is solely on anomaly detection in process logs without conceptualizing or defining what makes outputs actionable.</p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Algorithms for Anomaly Detection of Traces in Logs of Process Aware Information Systems</p>

<p><strong>Authors:</strong>  </p>

<p>Fábio Bezerra, Jacques Wainer</p>

<p><strong>DOI:</strong>  </p>

<p>N/A</p>

<p><strong>Year:</strong>  </p>

<p>2013</p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal (Elsevier Preprint)</p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Computer Science / Information Systems</p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Process Mining, Anomaly Detection</p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper presents and evaluates algorithms for detecting anomalies in process-aware information systems based on the control-flow perspective of process logs. It focuses on flexible and ad-hoc workflows where process execution is not predefined, leading to a higher risk of errors or fraud.</p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Brazil (UFRA, UNICAMP)</p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Process auditors, fraud detection specialists, process mining researchers</p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Quantitative (algorithm development, synthetic log simulation, and empirical evaluation)</p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Algorithmic framework and comparative performance evaluation</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>This paper proposes and evaluates three algorithms—Threshold, Iterative, and Sampling—for detecting anomalies in process-aware information system logs, focusing on the control-flow perspective. It also compares them against a baseline Naive algorithm. The methods rely on mining process models from logs and measuring conformance of traces to these models, assuming anomalies are infrequent and deviate structurally from normal execution paths. The authors evaluate performance using 360 synthetic logs and one real-life case from a Dutch municipality. The sampling algorithm consistently outperforms or matches the naive approach in F-measures and reduces false positives, offering a practical method for anomaly detection without requiring prior knowledge of a “normal” log.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p>No — the paper does not use the terms “actionable,” “actionability,” or related concepts.</p>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p>No — the focus is solely on anomaly detection effectiveness, not on the applicability or usability of results in decision-making.</p>

<hr />

<h2>How Actionability is Understood</h2>

<p>N/A</p>

<hr />

<h2>What Makes Something Actionable</h2>

<p>N/A</p>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<p>N/A</p>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> No</p></li>
<li><p><strong>CR (Contextual Relevance):</strong> No</p></li>
<li><p><strong>FE (Feasibility):</strong> No</p></li>
<li><p><strong>TI (Timeliness):</strong> No</p></li>
<li><p><strong>EX (Explainability):</strong> No</p></li>
<li><p><strong>GA (Goal Alignment):</strong> No</p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> N/A</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Process mining (precise vs. noisy mining approaches)</p></li>
<li><p>Conformance checking</p></li>
<li><p>Appropriateness measures (behavioral and structural)</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<p>N/A</p>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<p>N/A — barriers discussed are related to anomaly detection performance, not to actionability.</p>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The work situates itself within anomaly detection and process mining literature, contrasting with methods that require a known “normal” log or predefined policies. It references conformance checking, process model appropriateness, and structural/behavioral metrics.</p>

<hr />

<h2>Summary</h2>

<p>The paper addresses the detection of anomalous traces in logs from process-aware information systems, focusing exclusively on the control-flow perspective. It introduces three algorithms—Threshold, Iterative, and Sampling—and compares them with a naive baseline. The sampling algorithm with a 70% sample size and heuristic miner achieved the highest F-measures in detecting anomalies in synthetic datasets and was also effective on a real-life log from a Dutch municipality. While detailed in its operationalization of anomaly detection, the study does not address actionability, nor does it discuss how its outputs can directly inform decisions or actions. Instead, it contributes an efficient, parameter-tested methodology for identifying suspicious process executions, potentially as a pre-screening tool for further human-led investigation.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 20 — Only tangentially relevant to actionability; no conceptual or definitional contribution.</p></li>
<li><p><strong>Operationalization Score:</strong> 40 — Strong operationalization of anomaly detection, but unrelated to operationalizing actionability.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“The algorithms discussed in this paper must be used as a first automated step towards a more comprehensive security auditing practice…” (p. 3)</p></li>
<li><p>“We have no formal definition of an anomalous trace, but we have some intuitions that guided the development of the algorithms…” (p. 3)</p></li>
<li><p>“The sampling algorithm proved to be the most effective solution.” (Abstract)</p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<p>N/A</p>

<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Addressing the Contemporary Challenges of Business Process Compliance: The Case for Process Mining in the Banking Industry  </p>

<p>Authors: Nigel Adams, Adriano Augusto, Michael Davern, Marcello La Rosa  </p>

<p>DOI: https://doi.org/10.1007/s12599-025-00929-3  </p>

<p>Year: 2025  </p>

<p>Publication Type: Journal  </p>

<p>Discipline/Domain: Business Process Management / Information Systems  </p>

<p>Subdomain/Topic: Business Process Compliance (BPC), Process Mining, Banking Industry, Conformance Checking  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 85 — Strong conceptual contribution on operationalizing compliance monitoring via process mining, explicit discussion of producing “actionable process knowledge.”  </p>

<p>Operationalization Score: 80 — Detailed mapping of process mining software features to compliance challenges, including explicit operational pathways and limitations.  </p>

<p>Actionable/Actionability Used in Paper: Yes — “to facilitate business process management activities by extracting actionable process knowledge” (p. 4); “recommend a course of action during process execution to achieve a certain outcome” (p. 5).  </p>

<p>Authors Argue for Need for Actionability Without Defining It: Yes — “proactive monitoring… aims to recommend a course of action… to achieve a certain outcome” (p. 5); “recommend options to simplify the business process environment” (p. 19).  </p>

<p>Contains Definition of Actionability: No explicit formal definition; implicitly framed as producing insights or recommendations that can be operationally applied to improve compliance and process outcomes.  </p>

<p>Contains Systematic Features/Dimensions: Yes — Multiple conditions for compliance to be “actionable,” e.g., clarity, completeness of data, integration with operational processes.  </p>

<p>Contains Explainability: Partial — Discusses root cause analysis, intelligible feedback, visualization for understanding compliance breaches.  </p>

<p>Contains Interpretability: Partial — Focus on interpretability of compliance rules, transparency in process model checking.  </p>

<p>Contains Framework/Model: Yes — Consolidated list of 41 BPC Challenges (BPCCs) mapped to process mining features; conceptual map of compliance management lifecycle vs. process mining capabilities.  </p>

<p>Operationalization Present: Yes — Detailed mapping of process mining software features to specific BPC challenges with example workflows and workaround strategies.  </p>

<p>Primary Methodology: Mixed Methods (systematic literature review + qualitative industry analysis + feature mapping)  </p>

<p>Study Context: Australian Banking Industry (2017–2022 regulatory breach cases)  </p>

<p>Geographic/Institutional Context: Australia; major Australian banks; regulators (APRA, ASIC, AUSTRAC); consulting firms (KPMG, Accenture, McKinsey, Deloitte).  </p>

<p>Target Users/Stakeholders: Compliance officers, process mining practitioners, software vendors, regulators, banking executives.  </p>

<p>Primary Contribution Type: Conceptual framework and operational mapping of process mining to compliance challenges.  </p>

<p>CL: Yes — “clear statement of a compliance requirement… compliance rule templates… formalize the requirement in a standard and consistent way” (p. 16).  </p>

<p>CR: Yes — “compliance rules… aligned to the organizational hierarchy… to the business process environment” (p. 19).  </p>

<p>FE: Yes — “workarounds to address… difficulties in implementing rules” (p. 16); feasibility linked to technical integration and operational maturity.  </p>

<p>TI: Partial — Timeliness in alerts and detecting requirements changes noted as critical gaps.  </p>

<p>EX: Partial — “root cause analysis… intelligible user feedback… process animation to help visualize” (p. 20).  </p>

<p>GA: Yes — “recommend options to simplify… reconcile conflicting objectives” (p. 19).  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Addressing the Contemporary Challenges of Business Process Compliance: The Case for Process Mining in the Banking Industry  </p>

<p><strong>Authors:</strong>  </p>

<p>Nigel Adams, Adriano Augusto, Michael Davern, Marcello La Rosa  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1007/s12599-025-00929-3  </p>

<p><strong>Year:</strong>  </p>

<p>2025  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Journal  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Business Process Management / Information Systems  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Business Process Compliance, Process Mining, Banking Industry, Conformance Checking  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses the persistent challenges in business process compliance (BPC) by contrasting research and industry perspectives, particularly in the Australian banking sector following significant compliance breaches. It investigates how process mining can operationally address these challenges by mapping software capabilities to specific BPC problems.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>Australia; major banks; regulatory bodies APRA, ASIC, AUSTRAC; consulting firms KPMG, Accenture, McKinsey, Deloitte.  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Compliance officers, process mining practitioners, software vendors, regulators, banking executives.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Mixed Methods (systematic literature review, qualitative analysis of regulatory and consultancy reports, mapping to technical features).  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>Conceptual framework and operational mapping of process mining to BPC challenges.  </p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The study explores how commercial process mining solutions can bridge the gap between research-identified and industry-experienced challenges in business process compliance (BPC). Using the Australian banking industry as a case, it consolidates 41 unique BPC challenges (BPCCs) from literature, regulatory reports, practitioner interviews, and consultancy insights. It then identifies 63 process mining software features across five leading vendors and maps them to these BPCCs, assessing which are satisfied, unsatisfied, or enabled. The analysis reveals substantial overlap in identified challenges but divergence in priorities: research focuses on formalizing and verifying compliance at design/run time, while industry emphasizes operational and organizational constraints. Workarounds are proposed for unsatisfied BPCCs, leveraging organizational risk/control registers and event logs. The paper concludes with implications for researchers, practitioners, vendors, and regulators, advocating for integrated, user-friendly BPC modules.</p>

<hr />

<h2>Actionable/Actionability Used in Paper</h2>

<p><strong>Yes</strong>  </p>

<ul>
<li><p>“to facilitate business process management activities by extracting actionable process knowledge” (p. 4)  </p></li>
<li><p>“prescriptive monitoring aims to recommend a course of action during process execution to achieve a certain outcome” (p. 5)  </p></li>
</ul>

<hr />

<h2>Authors Argue for a Need for Actionability Without Defining It</h2>

<p><strong>Yes</strong>  </p>

<ul>
<li><p>“recommend options to simplify the business process environment” (p. 19)  </p></li>
<li><p>“recommendations based on reconciling conflicting objectives” (p. 19)  </p></li>
</ul>

<hr />

<h2>How Actionability is Understood</h2>

<p>Implicitly framed as generating operationally relevant knowledge, recommendations, or rule-based checks that can be applied to improve compliance, prevent violations, and optimize process execution.  </p>

<blockquote>
  <p>“Prescriptive monitoring aims to recommend a course of action during process execution to achieve a certain outcome” (p. 5)</p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Operational Relevance</strong>  </p>

<p> &gt; “recommend a course of action during process execution to achieve a certain outcome” (p. 5)  </p></li>
<li><p><strong>Clarity of Requirements</strong>  </p>

<p> &gt; “clear statement of a compliance requirement… compliance rule templates… formalize the requirement in a standard and consistent way” (p. 16)  </p></li>
<li><p><strong>Organizational Integration</strong>  </p>

<p> &gt; “recommend options to simplify the business process environment” (p. 19)  </p></li>
<li><p><strong>Goal Alignment</strong>  </p>

<p> &gt; “recommendations based on reconciling conflicting objectives” (p. 19)  </p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> BPCC–Feature Mapping; Compliance Management Lifecycle integrated with Process Mining  </p></li>
<li><p><strong>Methods/Levers:</strong> Extraction of compliance requirements from risk/control registers; instantiation into rule templates; event log-based compliance checking; root cause analysis.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Compile compliance requirements from a unified risk/obligations/control register.  </p>

<p> 2. Formalize rules via compliance rule templates.  </p>

<p> 3. Apply to event logs for design-time, run-time, and post-execution compliance checking.  </p>

<p> 4. Use visualization and analytics to detect violations, root causes, and process improvement opportunities.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Event logs, process models, compliance rules, violation metrics (frequency, duration, resource usage).  </p></li>
<li><p><strong>Implementation Context:</strong> Australian banking sector compliance with AML/CTF and other regulations.  </p></li>
</ul>

<blockquote>
  <p>“taking an organization’s ROCR as the compliance requirements’ source, and using event logs for design-time and run-time compliance checking” (p. 22)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — “clear statement of a compliance requirement… formalize… in a standard and consistent way” (p. 16)  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — “aligned to the organizational hierarchy… to the business process environment” (p. 19)  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — “workarounds to address… difficulties in implementing rules” (p. 16)  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — timeliness in alerts and detecting requirements changes noted as critical gaps.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — “root cause analysis… intelligible user feedback… process animation to help visualize” (p. 20)  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — “recommendations based on reconciling conflicting objectives” (p. 19)  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Integration with operational processes; scalability; user support.  </p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Compliance Management Lifecycle (Governatori &amp; Sadiq, 2009)  </p></li>
<li><p>Business Process Management Lifecycle (Dumas et al., 2018)  </p></li>
<li><p>BPCC classification framework (derived from literature + industry)  </p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Violation frequency and severity  </p></li>
<li><p>Time-to-detection and remediation  </p></li>
<li><p>Compliance metrics (timeliness, completeness, control effectiveness)  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong> Complex/ambiguous requirements; fragmented processes/data; technical integration challenges; organizational culture.  </p></li>
<li><p><strong>Enablers:</strong> Unified control registers; compliance rule templates; event log-based monitoring; root cause analysis tools.  </p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>Builds on systematic reviews of BPC and process mining; extends prior work by integrating industry regulatory insights; addresses limitations in current compliance checking approaches (design-time, run-time, audit).  </p>

<hr />

<h2>Summary</h2>

<p>This paper provides a detailed, dual-perspective analysis of business process compliance challenges in the banking sector, synthesizing research literature and industry/regulatory findings into a consolidated taxonomy of 41 challenges (BPCCs). It maps these to the features of leading process mining tools, evaluating which challenges are satisfied, unsatisfied, or enabled. Actionability is framed implicitly as the generation of operationally relevant, clear, and goal-aligned recommendations that can improve compliance outcomes. Operationalization is achieved through a structured workflow using unified compliance registers, rule formalization, and event log analysis for various lifecycle phases. While process mining can address most BPCCs, gaps remain in requirement elicitation, interpretation, rationalization, change detection, and design-time checking. The authors propose a paradigm shift toward an integrated, user-friendly compliance module leveraging existing features and standardized processes. The findings have significant implications for researchers (aligning with industry needs), practitioners (improving process maturity), vendors (consolidating into BPC modules), and regulators (streamlining compliance requirements).</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 — Strong alignment with actionability in the sense of generating operationally relevant recommendations; lacks a formal definition but provides clear operational pathways.  </p></li>
<li><p><strong>Operationalization Score:</strong> 80 — Concrete feature–challenge mapping and workflow descriptions; some gaps in automation of requirement management.  </p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“to facilitate business process management activities by extracting actionable process knowledge” (p. 4)  </p></li>
<li><p>“Prescriptive monitoring aims to recommend a course of action during process execution to achieve a certain outcome” (p. 5)  </p></li>
<li><p>“clear statement of a compliance requirement… compliance rule templates… formalize the requirement in a standard and consistent way” (p. 16)  </p></li>
<li><p>“recommend options to simplify the business process environment” (p. 19)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Dumas et al. (2018) — Fundamentals of Business Process Management (actionable process knowledge).  </p></li>
<li><p>van der Aalst (2016) — Process Mining: Data Science in Action (prescriptive monitoring for action outcomes).  </p></li>
<li><p>Maggi et al. (2011) — Monitoring Business Constraints with LTL (recommendations during execution).</p></li>
</ul>
