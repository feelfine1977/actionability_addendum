<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Metrics for What, Metrics for Whom: Assessing Actionability of Bias Evaluation Metrics in NLP  </p>

<p>Authors: Pieter Delobelle, Giuseppe Attanasio, Debora Nozza, Su Lin Blodgett, Zeerak Talat  </p>

<p>DOI: 10.18653/v1/2024.emnlp-main.1315  </p>

<p>Year: 2024  </p>

<p>Publication Type: Journal/Conference Proceedings (EMNLP 2024)  </p>

<p>Discipline/Domain: Natural Language Processing, AI Ethics  </p>

<p>Subdomain/Topic: Bias evaluation metrics, actionability assessment  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 95  </p>

<p>Operationalization Score: 90  </p>

<p>Contains Definition of Actionability: Yes  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial  </p>

<p>Contains Interpretability: Yes  </p>

<p>Contains Framework/Model: Yes (desiderata-based framework)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Review and Conceptual Framework + Qualitative Analysis  </p>

<p>Study Context: NLP bias measures  </p>

<p>Geographic/Institutional Context: International (Authors from KU Leuven, Instituto de Telecomunicações Lisbon, Bocconi, Microsoft Research, MBZUAI)  </p>

<p>Target Users/Stakeholders: NLP researchers, metric developers, practitioners, policymakers, regulators  </p>

<p>Primary Contribution Type: Conceptual framework + systematic literature review  </p>

<p>CL: Yes  </p>

<p>CR: Yes  </p>

<p>FE: Yes  </p>

<p>TI: Partial  </p>

<p>EX: Partial  </p>

<p>GA: Yes  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong> Metrics for What, Metrics for Whom: Assessing Actionability of Bias Evaluation Metrics in NLP  </p>

<p><strong>Authors:</strong> Pieter Delobelle, Giuseppe Attanasio, Debora Nozza, Su Lin Blodgett, Zeerak Talat  </p>

<p><strong>DOI:</strong> 10.18653/v1/2024.emnlp-main.1315  </p>

<p><strong>Year:</strong> 2024  </p>

<p><strong>Publication Type:</strong> Conference Proceedings (EMNLP 2024)  </p>

<p><strong>Discipline/Domain:</strong> Natural Language Processing, Responsible AI  </p>

<p><strong>Subdomain/Topic:</strong> Bias evaluation metrics, actionability, metric design  </p>

<p><strong>Contextual Background:</strong> The paper situates itself in the context of growing use of bias measures in NLP and the need to assess their practical utility (“actionability”). It introduces a conceptual framework with desiderata for making bias metrics actionable.  </p>

<p><strong>Geographic/Institutional Context:</strong> Belgium, Portugal, Italy, Canada, UAE  </p>

<p><strong>Target Users/Stakeholders:</strong> NLP researchers, fairness auditors, AI developers, policymakers, regulators, and potentially impacted communities.  </p>

<p><strong>Primary Methodology:</strong> Conceptual framework + systematic literature review (146 papers)  </p>

<p><strong>Primary Contribution Type:</strong> Definition and framework for “actionability” of bias measures + review-based evidence.</p>

<h2>General Summary of the Paper</h2>

<p>The authors define <em>actionability</em> in bias measures as the degree to which a measure’s results enable informed decision-making or intervention. They propose a set of desiderata (motivation, underlying bias construct, interval/ideal result, intended use, and reliability) drawn from responsible NLP, measurement modeling, and AI auditing literature. They apply these criteria in a systematic review of 146 NLP papers proposing bias measures, revealing widespread under-specification in intended use, theoretical constructs, and reliability assessment. The findings show that such omissions hinder the practical uptake of bias metrics in addressing harms. Recommendations include clear articulation of motivations, linking results to impacts, ensuring reliability assessment, and considering the actions afforded to different stakeholders.</p>

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong></p>

<h2>How Actionability is Understood</h2>

<p>Actionability is “the degree to which a measure’s results enable decision-making or intervention” — results should help identify who is impacted, the scale and source of bias, and guide potential mitigations, safeguards, redesign, or policy changes. It is related to but distinct from validity, interpretability, transparency, and accountability, focusing on enabling meaningful interventions.</p>

<blockquote>
  <p>“Actionability refers to the degree to which a measure’s results enable decision-making or intervention…” (p. 2)  </p>
</blockquote>

<blockquote>
  <p>“…results from actionable bias measures should facilitate informed actions with respect to th</p>
</blockquote>
