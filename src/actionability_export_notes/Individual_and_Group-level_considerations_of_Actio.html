<h1>Paper Summary</h1>

<!--META_START-->

<p>Title: Individual and Group-level considerations of Actionable Recourse  </p>

<p>Authors: Jayanth Yetukuri, Yang Liu  </p>

<p>DOI: https://doi.org/10.1145/3600211.3604758  </p>

<p>Year: 2023  </p>

<p>Publication Type: Conference  </p>

<p>Discipline/Domain: Artificial Intelligence / Human-Centered Computing  </p>

<p>Subdomain/Topic: Actionable Recourse, Fairness in Machine Learning, User Preferences, Plausibility  </p>

<p>Eligibility: Eligible  </p>

<p>Overall Relevance Score: 85  </p>

<p>Operationalization Score: 78  </p>

<p>Contains Definition of Actionability: Yes (explicitly in context of recourse viability)  </p>

<p>Contains Systematic Features/Dimensions: Yes  </p>

<p>Contains Explainability: Partial (linked to transparency and trust)  </p>

<p>Contains Interpretability: Partial (discussed via counterfactual explanation methods)  </p>

<p>Contains Framework/Model: Yes (proposed optimization approach incorporating preferences and plausibility)  </p>

<p>Operationalization Present: Yes  </p>

<p>Primary Methodology: Conceptual + Quantitative Experiments  </p>

<p>Study Context: Machine learning decision systems in lending, insurance, hiring  </p>

<p>Geographic/Institutional Context: University of California, Santa Cruz; USA  </p>

<p>Target Users/Stakeholders: Negatively impacted individuals seeking recourse; developers of ML decision systems  </p>

<p>Primary Contribution Type: Conceptual framework + algorithmic method proposal with empirical demonstration  </p>

<p>CL: Yes — “Such a transparent mechanism also builds trust in decision-making by enabling adversely affected individuals to maneuver the recourse generation process.” (p. n/a)  </p>

<p>CR: Yes — “Plausibility draws strong signals from group-level population information, which must be considered…” (p. n/a)  </p>

<p>FE: Yes — “Considering that she belongs to the sub-population of denied single parent, the recourse may not be actionable…” (p. n/a)  </p>

<p>TI: Partial — Timeliness is not explicitly discussed as a feature of actionability.  </p>

<p>EX: Partial — Linked to transparency and trust but not fully unpacked.  </p>

<p>GA: Yes — “Identify specific, actionable steps in agreement with the approved single parent sub-population…” (p. n/a)  </p>

<p>Reason if Not Eligible: N/A  </p>

<!--META_END-->

<p><strong>Title:</strong>  </p>

<p>Individual and Group-level considerations of Actionable Recourse  </p>

<p><strong>Authors:</strong>  </p>

<p>Jayanth Yetukuri, Yang Liu  </p>

<p><strong>DOI:</strong>  </p>

<p>https://doi.org/10.1145/3600211.3604758  </p>

<p><strong>Year:</strong>  </p>

<p>2023  </p>

<p><strong>Publication Type:</strong>  </p>

<p>Conference  </p>

<p><strong>Discipline/Domain:</strong>  </p>

<p>Artificial Intelligence / Human-Centered Computing  </p>

<p><strong>Subdomain/Topic:</strong>  </p>

<p>Actionable Recourse, Fairness in Machine Learning, User Preferences, Plausibility  </p>

<p><strong>Contextual Background:</strong>  </p>

<p>The paper addresses how actionable recourse—recommendations enabling individuals to achieve desired outcomes from ML decision systems—should incorporate both individual preferences and group-level plausibility to enhance fairness, trustworthiness, and societal benefit. It is situated in domains like lending, hiring, and insurance, where algorithmic decisions have significant personal impacts.  </p>

<p><strong>Geographic/Institutional Context:</strong>  </p>

<p>University of California, Santa Cruz (USA)  </p>

<p><strong>Target Users/Stakeholders:</strong>  </p>

<p>Negatively impacted individuals seeking to reverse unfavorable algorithmic decisions; developers and policymakers concerned with fairness and transparency in ML systems.  </p>

<p><strong>Primary Methodology:</strong>  </p>

<p>Conceptual framework combined with empirical experiments on real-world datasets.  </p>

<p><strong>Primary Contribution Type:</strong>  </p>

<p>A conceptual and computational approach integrating user preferences and group-level plausibility into recourse generation.</p>

<hr />

<h2>General Summary of the Paper</h2>

<p>The paper explores how actionable recourse in ML decision systems can better account for individual user preferences and group-level plausibility to ensure fairness and feasibility. Current recourse methods optimize for factors like proximity, sparsity, and validity but often ignore personal constraints or socio-demographic context. The authors introduce three forms of user preference—scoring continuous features, ranking categorical features, and bounding feature values—and embed them in the optimization process for generating recourses. At the group level, they propose plausibility constraints based on the distribution of approved cases within the individual’s subgroup, aiming to avoid biased or impractical suggestions. Experimental results show that their method better adheres to individual preferences and mitigates plausibility bias across protected groups.  </p>

<hr />

<h2>Eligibility</h2>

<p>Eligible for inclusion: <strong>Yes</strong>  </p>

<hr />

<h2>How Actionability is Understood</h2>

<p>Actionability is defined as the <em>viability of taking a suggested action</em> within the context of recourse for ML decisions. It encompasses both feasibility for the individual (personal constraints, preferences) and plausibility within the socio-demographic group context.  </p>

<blockquote>
  <p>“Ensure the actionability (the viability of taking a suggested action) of recourse.” (p. n/a)  </p>
</blockquote>

<blockquote>
  <p>“Plausibility draws strong signals from group-level population information… to achieve low-cost recourses across protected groups.” (p. n/a)  </p>
</blockquote>

<hr />

<h2>What Makes Something Actionable</h2>

<ul>
<li><p><strong>Alignment with user preferences</strong> (continuous feature scores, categorical rankings, feature bounds)  </p></li>
<li><p><strong>Feasibility</strong> given personal constraints  </p></li>
<li><p><strong>Plausibility</strong> based on similarity to approved cases in the individual’s subgroup  </p></li>
<li><p><strong>Transparency</strong> to build trust  </p></li>
<li><p><strong>Fairness</strong> across groups with different distributional characteristics</p></li>
</ul>

<hr />

<h2>How Actionability is Achieved / Operationalized</h2>

<ul>
<li><p><strong>Framework/Approach Name(s):</strong> Not formally named, but described as constrained optimization incorporating user preferences and group-level plausibility metrics.  </p></li>
<li><p><strong>Methods/Levers:</strong> Optimization function embedding individual preferences; plausibility score constraint based on subgroup-approved distribution.  </p></li>
<li><p><strong>Operational Steps / Workflow:</strong>  </p>

<p> 1. Collect individual user preferences (three types).  </p>

<p> 2. Integrate these as constraints in recourse optimization.  </p>

<p> 3. Calculate group-level plausibility score.  </p>

<p> 4. Generate recourse maximizing plausibility while respecting user constraints.  </p></li>
<li><p><strong>Data &amp; Measures:</strong> Real-world datasets; plausibility score; recourse cost metrics.  </p></li>
<li><p><strong>Implementation Context:</strong> Lending, insurance, hiring decisions.  </p></li>
</ul>

<blockquote>
  <p>“We propose to capture… three types of user preferences… and embed them into an optimization function for guiding the recourse generation mechanism.” (p. n/a)  </p>
</blockquote>

<blockquote>
  <p>“We quantify plausibility of recourse with respect to the approved sub-population of the individual’s group…” (p. n/a)  </p>
</blockquote>

<hr />

<h2>Dimensions and Attributes of Actionability (Authors’ Perspective)</h2>

<ul>
<li><p><strong>CL (Clarity):</strong> Yes — linked to transparency and understandability in recourse generation.  </p></li>
<li><p><strong>CR (Contextual Relevance):</strong> Yes — plausibility relies on subgroup context.  </p></li>
<li><p><strong>FE (Feasibility):</strong> Yes — explicitly tied to personal constraints and preferences.  </p></li>
<li><p><strong>TI (Timeliness):</strong> Partial — not directly addressed as a criterion.  </p></li>
<li><p><strong>EX (Explainability):</strong> Partial — present via transparency but not deeply analyzed.  </p></li>
<li><p><strong>GA (Goal Alignment):</strong> Yes — recourse must align with the individual’s goal of entering the approved subgroup.  </p></li>
<li><p><strong>Other Dimensions Named by Authors:</strong> Plausibility; User Preference Diversity.</p></li>
</ul>

<hr />

<h2>Theoretical or Conceptual Foundations</h2>

<ul>
<li><p>Actionable Recourse in Linear Classification (Ustun et al., 2019)  </p></li>
<li><p>Counterfactual explanation generation methods (FACE, GS, CCHVAE)  </p></li>
<li><p>Local feasibility constraints (Mahajan et al., 2019)</p></li>
</ul>

<hr />

<h2>Indicators or Metrics for Actionability</h2>

<ul>
<li><p>Plausibility score based on proximity to approved subgroup manifold  </p></li>
<li><p>Recourse cost (individual and group-level)  </p></li>
<li><p>Adherence to stated user preferences  </p></li>
</ul>

<hr />

<h2>Barriers and Enablers to Actionability</h2>

<ul>
<li><p><strong>Barriers:</strong>  </p>

<p> - Universal cost metrics ignoring personal constraints  </p>

<p> - Distributional idiosyncrasies across groups  </p>

<p> - Lack of integration of user preferences in current methods  </p></li>
<li><p><strong>Enablers:</strong>  </p>

<p> - Explicit collection of user preferences  </p>

<p> - Group-level plausibility constraint  </p>

<p> - Transparent recourse generation</p></li>
</ul>

<hr />

<h2>Relation to Existing Literature</h2>

<p>The paper builds upon existing counterfactual explanation and actionable recourse literature but extends it by introducing a dual focus on individualized preference capture and group-level plausibility, which addresses fairness and feasibility more holistically than prior distance- or sparsity-based approaches.</p>

<hr />

<h2>Summary</h2>

<p>This paper advances the concept of actionable recourse by explicitly integrating <strong>individual-level preferences</strong> and <strong>group-level plausibility constraints</strong> into the generation process for counterfactual suggestions in ML decision systems. The authors propose an optimization-based framework that embeds user-defined continuous feature scores, categorical rankings, and bounds, while also evaluating the plausibility of recourse relative to the distribution of approved outcomes within the individual’s demographic group. By combining these perspectives, the method aims to enhance feasibility, fairness, and trustworthiness of recourse suggestions. Experimental results on real-world datasets demonstrate improved adherence to personal constraints and mitigation of plausibility bias across protected groups. The approach addresses gaps in current methods that focus mainly on universal cost functions and do not systematically incorporate socio-contextual constraints.</p>

<hr />

<h2>Scores</h2>

<ul>
<li><p><strong>Overall Relevance Score:</strong> 85 — Strong conceptual framing of actionability with explicit dimensions (preferences, plausibility, feasibility) and integration of fairness considerations.  </p></li>
<li><p><strong>Operationalization Score:</strong> 78 — Provides a clear methodology for integrating individual and group-level constraints into optimization, though operational details could be expanded for real-world deployment.</p></li>
</ul>

<hr />

<h2>Supporting Quotes from the Paper</h2>

<ul>
<li><p>“[Actionability is] the viability of taking a suggested action…” (p. n/a)  </p></li>
<li><p>“We propose to capture Alice’s three types of user preferences… and embed them into an optimization function…” (p. n/a)  </p></li>
<li><p>“We quantify plausibility of recourse with respect to the approved sub-population of the individual’s group…” (p. n/a)  </p></li>
<li><p>“Considering that she belongs to the sub-population of denied single parent, the recourse may not be actionable…” (p. n/a)  </p></li>
</ul>

<hr />

<h2>Actionability References to Other Papers</h2>

<ul>
<li><p>Ustun et al. (2019) — Actionable Recourse in Linear Classification  </p></li>
<li><p>Mahajan et al. (2019) — Local feasibility in counterfactual explanations  </p></li>
<li><p>Mothilal et al. (2020) — Diverse counterfactual explanations  </p></li>
<li><p>Poyiadzi et al. (2020) — FACE method  </p></li>
<li><p>Laugel et al. (2017) — Inverse classification interpretability  </p></li>
<li><p>Pawelczyk et al. (2020) — CCHVAE counterfactual generation</p></li>
</ul>
